{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from LSPIN_model import Model\n",
    "from utils import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear synthetic data generation\n",
    "\n",
    "Group 1: $X$ ~ $N(1,0.5)$,  $Y = -2X_1 + X_2 - 0.5X_3$\n",
    "\n",
    "Group 2: $X$ ~ $N(-1,0.5)$, $Y = -0.5X_3 + X_4 - 2X_5$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "Xs1 = np.random.normal(loc=1,scale=0.5,size=(300,5))\n",
    "Ys1 = -2*Xs1[:,0]+1*Xs1[:,1]-0.5*Xs1[:,2]\n",
    "\n",
    "Xs2 = np.random.normal(loc=-1,scale=0.5,size=(300,5))\n",
    "Ys2 = -0.5*Xs2[:,2]+1*Xs2[:,3]-2*Xs2[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate((Xs1,Xs2),axis=0)\n",
    "Y_data = np.concatenate((Ys1.reshape(-1,1),Ys2.reshape(-1,1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = Y_data-Y_data.min()\n",
    "Y_data=Y_data/Y_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ground truth group label of each sample\n",
    "case_labels = np.concatenate((np.array([1]*300),np.array([2]*300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = np.concatenate((Y_data,case_labels.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% for validation, 10% for test \n",
    "X_train,X_remain,yc_train,yc_remain = train_test_split(X_data,Y_data,train_size=0.8,shuffle=True,random_state=34)\n",
    "X_valid,X_test,yc_valid,yc_test = train_test_split(X_remain,yc_remain,train_size=0.5,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 10 samples used for training\n",
    "X_train,_,yc_train,_ = train_test_split(X_train,yc_train,train_size=10,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes:\n",
      "10 60 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample sizes:\")\n",
    "print(X_train.shape[0],X_valid.shape[0],X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = yc_train[:,0].reshape(-1,1)\n",
    "y_valid = yc_valid[:,0].reshape(-1,1)\n",
    "y_test = yc_test[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = yc_train[:,1]\n",
    "valid_label = yc_valid[:,1]\n",
    "test_label= yc_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 6, 1.0: 4})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 29, 1.0: 31})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(**{'_data':X_train, '_labels':y_train,\n",
    "                '_valid_data':X_valid, '_valid_labels':y_valid,\n",
    "                '_test_data':X_test, '_test_labels':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference ground truth feature matrix (training/test)\n",
    "ref_feat_mat_train = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in train_label])\n",
    "ref_feat_mat_test = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in test_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLSPIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llspin_objective(trial):  \n",
    "    global model\n",
    "            \n",
    "    params = {\n",
    "        \"feature_selection\" : True,\n",
    "        \"sigma\" : 0.5,\n",
    "        \"display_step\" : 500,\n",
    "        \"hidden_layers_node\" : [100,100,10,1], # hidden layers: 100,100,10,1\n",
    "        \"input_node\" : X_train.shape[1],\n",
    "        \"output_node\" : 1\n",
    "    }\n",
    "    params['stddev_input'] = 0.1 \n",
    "    params['activation']= 'none'\n",
    "    params['batch_size']= X_train.shape[0]\n",
    "    params['feature_selection_dimension']=[10]\n",
    "    params['lam'] = trial.suggest_loguniform('lam',1e-3,1e-2)\n",
    "    params['learning_rate'] = trial.suggest_loguniform('learning_rate', 1e-2, 2e-1)\n",
    "    num_epoch = trial.suggest_categorical('num_epoch', [2000,5000,10000,15000])\n",
    "\n",
    "    model_dir =None\n",
    "    model = Model(**params)\n",
    "    train_acces, train_losses, val_acces, val_losses = model.train(trial, dataset, model_dir, num_epoch=num_epoch)\n",
    "\n",
    "    print(\"In trial:---------------------\")\n",
    "    val_prediction = model.test(X_valid)[0]\n",
    "    mse = mean_squared_error(y_valid.reshape(-1),val_prediction.reshape(-1))\n",
    "    print(\"validation mse: {}\".format(mse))\n",
    "    \n",
    "    loss= mse\n",
    "            \n",
    "    return loss\n",
    "        \n",
    "def callback(study,trial):\n",
    "    global best_model\n",
    "    if study.best_trial == trial:\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:39:34,816]\u001b[0m A new study created in memory with name: no-name-859f30ba-983b-4382-8396-7f447c1fdf7c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010604906 valid loss= 0.012560671\n",
      "train reg_fs: 0.004470093175768852\n",
      "Epoch: 1000 train loss=0.016968865 valid loss= 0.012062725\n",
      "train reg_fs: 0.004493233747780323\n",
      "Epoch: 1500 train loss=0.016278829 valid loss= 0.012230149\n",
      "train reg_fs: 0.004516263958066702\n",
      "Epoch: 2000 train loss=0.014613844 valid loss= 0.011937684\n",
      "train reg_fs: 0.004535425454378128\n",
      "Epoch: 2500 train loss=0.011341271 valid loss= 0.011685958\n",
      "train reg_fs: 0.00454847514629364\n",
      "Epoch: 3000 train loss=0.010449624 valid loss= 0.011181092\n",
      "train reg_fs: 0.004558568354696035\n",
      "Epoch: 3500 train loss=0.011822904 valid loss= 0.011361351\n",
      "train reg_fs: 0.0045653763227164745\n",
      "Epoch: 4000 train loss=0.023249488 valid loss= 0.010991002\n",
      "train reg_fs: 0.004569294396787882\n",
      "Epoch: 4500 train loss=0.008979671 valid loss= 0.011048516\n",
      "train reg_fs: 0.004567359574139118\n",
      "Epoch: 5000 train loss=0.012232030 valid loss= 0.011131961\n",
      "train reg_fs: 0.004564294125884771\n",
      "Epoch: 5500 train loss=0.014747333 valid loss= 0.010839486\n",
      "train reg_fs: 0.004555249121040106\n",
      "Epoch: 6000 train loss=0.012002070 valid loss= 0.011052347\n",
      "train reg_fs: 0.004540278110653162\n",
      "Epoch: 6500 train loss=0.008801619 valid loss= 0.010830919\n",
      "train reg_fs: 0.004523235373198986\n",
      "Epoch: 7000 train loss=0.013853397 valid loss= 0.011090476\n",
      "train reg_fs: 0.0045018731616437435\n",
      "Epoch: 7500 train loss=0.011211422 valid loss= 0.010684031\n",
      "train reg_fs: 0.004479622934013605\n",
      "Epoch: 8000 train loss=0.010405276 valid loss= 0.011210713\n",
      "train reg_fs: 0.004455476067960262\n",
      "Epoch: 8500 train loss=0.010743465 valid loss= 0.010450996\n",
      "train reg_fs: 0.004426347091794014\n",
      "Epoch: 9000 train loss=0.010396223 valid loss= 0.010821208\n",
      "train reg_fs: 0.00439912686124444\n",
      "Epoch: 9500 train loss=0.011413379 valid loss= 0.010960328\n",
      "train reg_fs: 0.00437169661745429\n",
      "Epoch: 10000 train loss=0.008402342 valid loss= 0.010729868\n",
      "train reg_fs: 0.004344981163740158\n",
      "Epoch: 10500 train loss=0.011552547 valid loss= 0.010104721\n",
      "train reg_fs: 0.0043195211328566074\n",
      "Epoch: 11000 train loss=0.009551274 valid loss= 0.010237668\n",
      "train reg_fs: 0.004292864818125963\n",
      "Epoch: 11500 train loss=0.007818667 valid loss= 0.010053674\n",
      "train reg_fs: 0.00426647812128067\n",
      "Epoch: 12000 train loss=0.007234364 valid loss= 0.010455966\n",
      "train reg_fs: 0.00424069631844759\n",
      "Epoch: 12500 train loss=0.011716020 valid loss= 0.009690358\n",
      "train reg_fs: 0.004216912668198347\n",
      "Epoch: 13000 train loss=0.008229956 valid loss= 0.009992903\n",
      "train reg_fs: 0.004194094333797693\n",
      "Epoch: 13500 train loss=0.007104241 valid loss= 0.009754116\n",
      "train reg_fs: 0.004170973785221577\n",
      "Epoch: 14000 train loss=0.007570527 valid loss= 0.009443300\n",
      "train reg_fs: 0.004149602260440588\n",
      "Epoch: 14500 train loss=0.006850078 valid loss= 0.009292942\n",
      "train reg_fs: 0.0041305553168058395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:41:20,663]\u001b[0m Trial 0 finished with value: 0.005115962552702996 and parameters: {'lam': 0.005323416986151032, 'learning_rate': 0.01138761745815921, 'num_epoch': 15000}. Best is trial 0 with value: 0.005115962552702996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.010713438 valid loss= 0.009420076\n",
      "train reg_fs: 0.004108712542802095\n",
      "Optimization Finished!\n",
      "test loss: 0.010031543672084808, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005115962552702996\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018155865 valid loss= 0.014273824\n",
      "train reg_fs: 0.00776185467839241\n",
      "Epoch: 1000 train loss=0.016353332 valid loss= 0.014033789\n",
      "train reg_fs: 0.007765653543174267\n",
      "Epoch: 1500 train loss=0.013019951 valid loss= 0.013559317\n",
      "train reg_fs: 0.007548531051725149\n",
      "Epoch: 2000 train loss=0.011703068 valid loss= 0.012801116\n",
      "train reg_fs: 0.007189603988081217\n",
      "Epoch: 2500 train loss=0.011976153 valid loss= 0.010906220\n",
      "train reg_fs: 0.006922388914972544\n",
      "Epoch: 3000 train loss=0.008321772 valid loss= 0.009792577\n",
      "train reg_fs: 0.006675615441054106\n",
      "Epoch: 3500 train loss=0.009346087 valid loss= 0.009632761\n",
      "train reg_fs: 0.006409266497939825\n",
      "Epoch: 4000 train loss=0.008578040 valid loss= 0.009042656\n",
      "train reg_fs: 0.006172845605760813\n",
      "Epoch: 4500 train loss=0.007655153 valid loss= 0.008970041\n",
      "train reg_fs: 0.006002028472721577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:41:56,647]\u001b[0m Trial 1 finished with value: 0.003019079955294617 and parameters: {'lam': 0.008838318896272393, 'learning_rate': 0.11067111578047624, 'num_epoch': 5000}. Best is trial 1 with value: 0.003019079955294617.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.006254537 valid loss= 0.008896273\n",
      "train reg_fs: 0.005847209133207798\n",
      "Optimization Finished!\n",
      "test loss: 0.008765710517764091, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003019079955294617\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007908462 valid loss= 0.011115920\n",
      "train reg_fs: 0.0039762030355632305\n",
      "Epoch: 1000 train loss=0.015585454 valid loss= 0.011109073\n",
      "train reg_fs: 0.004041066858917475\n",
      "Epoch: 1500 train loss=0.024678685 valid loss= 0.010398252\n",
      "train reg_fs: 0.004032365046441555\n",
      "Epoch: 2000 train loss=0.007921781 valid loss= 0.010089977\n",
      "train reg_fs: 0.003962767776101828\n",
      "Epoch: 2500 train loss=0.007474450 valid loss= 0.010338854\n",
      "train reg_fs: 0.00387880252674222\n",
      "Epoch: 3000 train loss=0.008026700 valid loss= 0.009329170\n",
      "train reg_fs: 0.0038118669763207436\n",
      "Epoch: 3500 train loss=0.008212084 valid loss= 0.009537412\n",
      "train reg_fs: 0.0037518786266446114\n",
      "Epoch: 4000 train loss=0.007461965 valid loss= 0.008064155\n",
      "train reg_fs: 0.0036915969103574753\n",
      "Epoch: 4500 train loss=0.006573481 valid loss= 0.007529981\n",
      "train reg_fs: 0.0036223838105797768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:42:32,389]\u001b[0m Trial 2 finished with value: 0.0030372610000587016 and parameters: {'lam': 0.004590845476623955, 'learning_rate': 0.06221322205455364, 'num_epoch': 5000}. Best is trial 1 with value: 0.003019079955294617.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005825178 valid loss= 0.006604650\n",
      "train reg_fs: 0.0035186591558158398\n",
      "Optimization Finished!\n",
      "test loss: 0.006585412193089724, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0030372610000587016\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013246339 valid loss= 0.014997731\n",
      "train reg_fs: 0.00767709081992507\n",
      "Epoch: 1000 train loss=0.016483245 valid loss= 0.014929708\n",
      "train reg_fs: 0.007737363688647747\n",
      "Epoch: 1500 train loss=0.016076062 valid loss= 0.014230362\n",
      "train reg_fs: 0.007780604530125856\n",
      "Epoch: 2000 train loss=0.020995511 valid loss= 0.014068134\n",
      "train reg_fs: 0.007801208179444075\n",
      "Epoch: 2500 train loss=0.012662087 valid loss= 0.013505485\n",
      "train reg_fs: 0.00781348068267107\n",
      "Epoch: 3000 train loss=0.013655605 valid loss= 0.014065767\n",
      "train reg_fs: 0.007813764736056328\n",
      "Epoch: 3500 train loss=0.021372436 valid loss= 0.012845239\n",
      "train reg_fs: 0.007799674291163683\n",
      "Epoch: 4000 train loss=0.017675901 valid loss= 0.012756735\n",
      "train reg_fs: 0.00777121027931571\n",
      "Epoch: 4500 train loss=0.012662233 valid loss= 0.012727584\n",
      "train reg_fs: 0.0077316416427493095\n",
      "Epoch: 5000 train loss=0.016738953 valid loss= 0.012543882\n",
      "train reg_fs: 0.007667310535907745\n",
      "Epoch: 5500 train loss=0.016557774 valid loss= 0.012281613\n",
      "train reg_fs: 0.007581706624478102\n",
      "Epoch: 6000 train loss=0.011602857 valid loss= 0.011527972\n",
      "train reg_fs: 0.007481588050723076\n",
      "Epoch: 6500 train loss=0.011879871 valid loss= 0.011361022\n",
      "train reg_fs: 0.007359623443335295\n",
      "Epoch: 7000 train loss=0.013209209 valid loss= 0.010942437\n",
      "train reg_fs: 0.0072253854013979435\n",
      "Epoch: 7500 train loss=0.012722282 valid loss= 0.009977673\n",
      "train reg_fs: 0.007100104354321957\n",
      "Epoch: 8000 train loss=0.016352134 valid loss= 0.009815947\n",
      "train reg_fs: 0.0069846841506659985\n",
      "Epoch: 8500 train loss=0.011247059 valid loss= 0.009550225\n",
      "train reg_fs: 0.006882721558213234\n",
      "Epoch: 9000 train loss=0.017933773 valid loss= 0.009460775\n",
      "train reg_fs: 0.006786252837628126\n",
      "Epoch: 9500 train loss=0.010325074 valid loss= 0.009348469\n",
      "train reg_fs: 0.006701480597257614\n",
      "Epoch: 10000 train loss=0.015251471 valid loss= 0.009553074\n",
      "train reg_fs: 0.006619736086577177\n",
      "Epoch: 10500 train loss=0.008718901 valid loss= 0.009200118\n",
      "train reg_fs: 0.006543045397847891\n",
      "Epoch: 11000 train loss=0.009482214 valid loss= 0.009360665\n",
      "train reg_fs: 0.0064697954803705215\n",
      "Epoch: 11500 train loss=0.007983949 valid loss= 0.009193513\n",
      "train reg_fs: 0.006399647332727909\n",
      "Epoch: 12000 train loss=0.008894140 valid loss= 0.008860221\n",
      "train reg_fs: 0.006328443996608257\n",
      "Epoch: 12500 train loss=0.011170266 valid loss= 0.009310016\n",
      "train reg_fs: 0.006255457177758217\n",
      "Epoch: 13000 train loss=0.007633005 valid loss= 0.008841851\n",
      "train reg_fs: 0.006188977509737015\n",
      "Epoch: 13500 train loss=0.008305317 valid loss= 0.008095497\n",
      "train reg_fs: 0.006123846862465143\n",
      "Epoch: 14000 train loss=0.008676334 valid loss= 0.008765048\n",
      "train reg_fs: 0.0060586705803871155\n",
      "Epoch: 14500 train loss=0.008570533 valid loss= 0.008576865\n",
      "train reg_fs: 0.005998695269227028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:44:16,125]\u001b[0m Trial 3 finished with value: 0.0019017118404111128 and parameters: {'lam': 0.009048652507790512, 'learning_rate': 0.017676565138301067, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019017118404111128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.008317216 valid loss= 0.007992525\n",
      "train reg_fs: 0.005938077345490456\n",
      "Optimization Finished!\n",
      "test loss: 0.007793887984007597, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0019017118404111128\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006053469 valid loss= 0.008584560\n",
      "train reg_fs: 0.0010579917579889297\n",
      "Epoch: 1000 train loss=0.007167195 valid loss= 0.008354554\n",
      "train reg_fs: 0.0010698032565414906\n",
      "Epoch: 1500 train loss=0.009784027 valid loss= 0.008019943\n",
      "train reg_fs: 0.0010806042701005936\n",
      "Epoch: 2000 train loss=0.008746091 valid loss= 0.007951256\n",
      "train reg_fs: 0.0010893183061853051\n",
      "Epoch: 2500 train loss=0.011327194 valid loss= 0.007921319\n",
      "train reg_fs: 0.0010971337324008346\n",
      "Epoch: 3000 train loss=0.016086556 valid loss= 0.008210663\n",
      "train reg_fs: 0.0011034406488761306\n",
      "Epoch: 3500 train loss=0.012690787 valid loss= 0.007667857\n",
      "train reg_fs: 0.0011084334691986442\n",
      "Epoch: 4000 train loss=0.014563445 valid loss= 0.007671359\n",
      "train reg_fs: 0.0011125296587124467\n",
      "Epoch: 4500 train loss=0.006720396 valid loss= 0.007274535\n",
      "train reg_fs: 0.0011162046575918794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:44:51,759]\u001b[0m Trial 4 finished with value: 0.005873840246320358 and parameters: {'lam': 0.0012424478144719786, 'learning_rate': 0.015898020941265672, 'num_epoch': 5000}. Best is trial 3 with value: 0.0019017118404111128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.010291450 valid loss= 0.006991634\n",
      "train reg_fs: 0.0011186113115400076\n",
      "Optimization Finished!\n",
      "test loss: 0.007961997762322426, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005873840246320358\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012808256 valid loss= 0.012130239\n",
      "train reg_fs: 0.004470249637961388\n",
      "Epoch: 1000 train loss=0.017403610 valid loss= 0.011556278\n",
      "train reg_fs: 0.004503381438553333\n",
      "Epoch: 1500 train loss=0.014214478 valid loss= 0.011700343\n",
      "train reg_fs: 0.0044517675414681435\n",
      "Epoch: 2000 train loss=0.007428058 valid loss= 0.011633372\n",
      "train reg_fs: 0.004345263354480267\n",
      "Epoch: 2500 train loss=0.008593620 valid loss= 0.010231103\n",
      "train reg_fs: 0.004238656722009182\n",
      "Epoch: 3000 train loss=0.007470663 valid loss= 0.009470955\n",
      "train reg_fs: 0.004156217444688082\n",
      "Epoch: 3500 train loss=0.007947216 valid loss= 0.008746475\n",
      "train reg_fs: 0.0040665799751877785\n",
      "Epoch: 4000 train loss=0.012581028 valid loss= 0.008206903\n",
      "train reg_fs: 0.0039844270795583725\n",
      "Epoch: 4500 train loss=0.005568557 valid loss= 0.007491451\n",
      "train reg_fs: 0.0038815210573375225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:45:27,612]\u001b[0m Trial 5 finished with value: 0.0024353820384216437 and parameters: {'lam': 0.005188282004928067, 'learning_rate': 0.05852162659358529, 'num_epoch': 5000}. Best is trial 3 with value: 0.0019017118404111128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004519451 valid loss= 0.006269275\n",
      "train reg_fs: 0.0037609790451824665\n",
      "Optimization Finished!\n",
      "test loss: 0.006008547730743885, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024353820384216437\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013927144 valid loss= 0.012484577\n",
      "train reg_fs: 0.006489187479019165\n",
      "Epoch: 1000 train loss=0.015483825 valid loss= 0.012010472\n",
      "train reg_fs: 0.006475784350186586\n",
      "Epoch: 1500 train loss=0.013664007 valid loss= 0.012356635\n",
      "train reg_fs: 0.006357127334922552\n",
      "Epoch: 2000 train loss=0.012445919 valid loss= 0.011067425\n",
      "train reg_fs: 0.0061928643845021725\n",
      "Epoch: 2500 train loss=0.017507620 valid loss= 0.010629327\n",
      "train reg_fs: 0.006021219305694103\n",
      "Epoch: 3000 train loss=0.010376937 valid loss= 0.009708840\n",
      "train reg_fs: 0.005832854192703962\n",
      "Epoch: 3500 train loss=0.010733659 valid loss= 0.008796691\n",
      "train reg_fs: 0.0056528677232563496\n",
      "Epoch: 4000 train loss=0.012215565 valid loss= 0.008819889\n",
      "train reg_fs: 0.005490338429808617\n",
      "Epoch: 4500 train loss=0.007994215 valid loss= 0.008743808\n",
      "train reg_fs: 0.0053504654206335545\n",
      "Epoch: 5000 train loss=0.007210421 valid loss= 0.008992992\n",
      "train reg_fs: 0.005232415162026882\n",
      "Epoch: 5500 train loss=0.007961484 valid loss= 0.008969758\n",
      "train reg_fs: 0.005144766066223383\n",
      "Epoch: 6000 train loss=0.006353841 valid loss= 0.009239223\n",
      "train reg_fs: 0.005053679458796978\n",
      "Epoch: 6500 train loss=0.007172824 valid loss= 0.008972869\n",
      "train reg_fs: 0.004975438583642244\n",
      "Epoch: 7000 train loss=0.008297459 valid loss= 0.009081000\n",
      "train reg_fs: 0.004909604787826538\n",
      "Epoch: 7500 train loss=0.007034412 valid loss= 0.009056604\n",
      "train reg_fs: 0.00485083507373929\n",
      "Epoch: 8000 train loss=0.008325969 valid loss= 0.009192199\n",
      "train reg_fs: 0.004797046072781086\n",
      "Epoch: 8500 train loss=0.008446136 valid loss= 0.008822287\n",
      "train reg_fs: 0.004750940483063459\n",
      "Epoch: 9000 train loss=0.006983495 valid loss= 0.009225147\n",
      "train reg_fs: 0.004709926899522543\n",
      "Epoch: 9500 train loss=0.006412800 valid loss= 0.009134503\n",
      "train reg_fs: 0.004673935938626528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:46:38,197]\u001b[0m Trial 6 finished with value: 0.004424789589115596 and parameters: {'lam': 0.007575999242864385, 'learning_rate': 0.04443790337393647, 'num_epoch': 10000}. Best is trial 3 with value: 0.0019017118404111128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007227057 valid loss= 0.009255614\n",
      "train reg_fs: 0.004641002509742975\n",
      "Optimization Finished!\n",
      "test loss: 0.009201804175972939, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004424789589115596\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006314690 valid loss= 0.007569465\n",
      "train reg_fs: 0.0016327991615980864\n",
      "Epoch: 1000 train loss=0.007074292 valid loss= 0.007595936\n",
      "train reg_fs: 0.0016166908899322152\n",
      "Epoch: 1500 train loss=0.003416260 valid loss= 0.005592307\n",
      "train reg_fs: 0.0015691707376390696\n",
      "Epoch: 2000 train loss=0.008486298 valid loss= 0.004379160\n",
      "train reg_fs: 0.001532553811557591\n",
      "Epoch: 2500 train loss=0.003923073 valid loss= 0.003880493\n",
      "train reg_fs: 0.001499312580563128\n",
      "Epoch: 3000 train loss=0.015835300 valid loss= 0.003686528\n",
      "train reg_fs: 0.0014788125408813357\n",
      "Epoch: 3500 train loss=0.003351239 valid loss= 0.003410424\n",
      "train reg_fs: 0.0014649491058662534\n",
      "Epoch: 4000 train loss=0.002701009 valid loss= 0.003872581\n",
      "train reg_fs: 0.001451453659683466\n",
      "Epoch: 4500 train loss=0.002121546 valid loss= 0.003941635\n",
      "train reg_fs: 0.0014383791713044047\n",
      "Epoch: 5000 train loss=0.002133257 valid loss= 0.003744466\n",
      "train reg_fs: 0.0014278491726145148\n",
      "Epoch: 5500 train loss=0.002368881 valid loss= 0.003930667\n",
      "train reg_fs: 0.0014191357186064124\n",
      "Epoch: 6000 train loss=0.002940244 valid loss= 0.003948072\n",
      "train reg_fs: 0.0014122510328888893\n",
      "Epoch: 6500 train loss=0.002854530 valid loss= 0.003663146\n",
      "train reg_fs: 0.0014060164103284478\n",
      "Epoch: 7000 train loss=0.002515963 valid loss= 0.003628080\n",
      "train reg_fs: 0.0014011225430294871\n",
      "Epoch: 7500 train loss=0.003599506 valid loss= 0.003573838\n",
      "train reg_fs: 0.0013971631415188313\n",
      "Epoch: 8000 train loss=0.004839883 valid loss= 0.003436215\n",
      "train reg_fs: 0.0013936451869085431\n",
      "Epoch: 8500 train loss=0.003753727 valid loss= 0.003399400\n",
      "train reg_fs: 0.0013903517974540591\n",
      "Epoch: 9000 train loss=0.002341658 valid loss= 0.003258256\n",
      "train reg_fs: 0.0013875382719561458\n",
      "Epoch: 9500 train loss=0.002216377 valid loss= 0.003371973\n",
      "train reg_fs: 0.0013850723626092076\n",
      "Epoch: 10000 train loss=0.003025293 valid loss= 0.003194502\n",
      "train reg_fs: 0.0013830981915816665\n",
      "Epoch: 10500 train loss=0.003013269 valid loss= 0.003183323\n",
      "train reg_fs: 0.0013811822282150388\n",
      "Epoch: 11000 train loss=0.002905169 valid loss= 0.003489265\n",
      "train reg_fs: 0.001379415625706315\n",
      "Epoch: 11500 train loss=0.003456731 valid loss= 0.003262666\n",
      "train reg_fs: 0.001377273933030665\n",
      "Epoch: 12000 train loss=0.012265632 valid loss= 0.003353198\n",
      "train reg_fs: 0.0013747995253652334\n",
      "Epoch: 12500 train loss=0.004399670 valid loss= 0.003206812\n",
      "train reg_fs: 0.0013731527142226696\n",
      "Epoch: 13000 train loss=0.002179250 valid loss= 0.003376815\n",
      "train reg_fs: 0.0013711464125663042\n",
      "Epoch: 13500 train loss=0.002910962 valid loss= 0.003328966\n",
      "train reg_fs: 0.0013691069325432181\n",
      "Epoch: 14000 train loss=0.002776708 valid loss= 0.003286263\n",
      "train reg_fs: 0.0013668166939169168\n",
      "Epoch: 14500 train loss=0.002545589 valid loss= 0.003731691\n",
      "train reg_fs: 0.0013644048012793064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:48:22,124]\u001b[0m Trial 7 finished with value: 0.0018829556721344726 and parameters: {'lam': 0.0018652524283607871, 'learning_rate': 0.0763074115188201, 'num_epoch': 15000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004261161 valid loss= 0.003203854\n",
      "train reg_fs: 0.001362091163173318\n",
      "Optimization Finished!\n",
      "test loss: 0.0031277420930564404, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0018829556721344726\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007469012 valid loss= 0.007199566\n",
      "train reg_fs: 0.0015194524312391877\n",
      "Epoch: 1000 train loss=0.006116259 valid loss= 0.004277573\n",
      "train reg_fs: 0.0014001908712089062\n",
      "Epoch: 1500 train loss=0.005437258 valid loss= 0.004600210\n",
      "train reg_fs: 0.0013372799148783088\n",
      "Epoch: 2000 train loss=0.003392893 valid loss= 0.004421894\n",
      "train reg_fs: 0.0012841788120567799\n",
      "Epoch: 2500 train loss=0.001600963 valid loss= 0.003665796\n",
      "train reg_fs: 0.001247712061740458\n",
      "Epoch: 3000 train loss=0.001680941 valid loss= 0.003930656\n",
      "train reg_fs: 0.0012236410984769464\n",
      "Epoch: 3500 train loss=0.004405914 valid loss= 0.003371227\n",
      "train reg_fs: 0.0012057487620040774\n",
      "Epoch: 4000 train loss=0.003075398 valid loss= 0.003373644\n",
      "train reg_fs: 0.0011910187313333154\n",
      "Epoch: 4500 train loss=0.003457936 valid loss= 0.003479592\n",
      "train reg_fs: 0.0011795187601819634\n",
      "Epoch: 5000 train loss=0.003919980 valid loss= 0.003486702\n",
      "train reg_fs: 0.0011688165832310915\n",
      "Epoch: 5500 train loss=0.001284679 valid loss= 0.003718071\n",
      "train reg_fs: 0.0011598782148212194\n",
      "Epoch: 6000 train loss=0.006767713 valid loss= 0.003549746\n",
      "train reg_fs: 0.0011524140136316419\n",
      "Epoch: 6500 train loss=0.002834387 valid loss= 0.003567174\n",
      "train reg_fs: 0.001145740388892591\n",
      "Epoch: 7000 train loss=0.003215872 valid loss= 0.003528559\n",
      "train reg_fs: 0.0011399023933336139\n",
      "Epoch: 7500 train loss=0.005245124 valid loss= 0.004190374\n",
      "train reg_fs: 0.0011349072447046638\n",
      "Epoch: 8000 train loss=0.001425376 valid loss= 0.003386775\n",
      "train reg_fs: 0.001130559598095715\n",
      "Epoch: 8500 train loss=0.006961403 valid loss= 0.003242896\n",
      "train reg_fs: 0.0011271630646660924\n",
      "Epoch: 9000 train loss=0.002172751 valid loss= 0.003447058\n",
      "train reg_fs: 0.0011239410378038883\n",
      "Epoch: 9500 train loss=0.002498894 valid loss= 0.003535898\n",
      "train reg_fs: 0.0011210936354473233\n",
      "Epoch: 10000 train loss=0.003326339 valid loss= 0.003620936\n",
      "train reg_fs: 0.0011186858173459768\n",
      "Epoch: 10500 train loss=0.001805094 valid loss= 0.003602264\n",
      "train reg_fs: 0.001116465893574059\n",
      "Epoch: 11000 train loss=0.002089331 valid loss= 0.003316842\n",
      "train reg_fs: 0.0011146168690174818\n",
      "Epoch: 11500 train loss=0.002167703 valid loss= 0.003285953\n",
      "train reg_fs: 0.0011130663333460689\n",
      "Epoch: 12000 train loss=0.001281902 valid loss= 0.003630491\n",
      "train reg_fs: 0.0011114293010905385\n",
      "Epoch: 12500 train loss=0.002058404 valid loss= 0.003614934\n",
      "train reg_fs: 0.0011101615382358432\n",
      "Epoch: 13000 train loss=0.001912881 valid loss= 0.003484675\n",
      "train reg_fs: 0.001109040924347937\n",
      "Epoch: 13500 train loss=0.002570088 valid loss= 0.003620226\n",
      "train reg_fs: 0.0011080027325078845\n",
      "Epoch: 14000 train loss=0.004762358 valid loss= 0.003656230\n",
      "train reg_fs: 0.001107071409933269\n",
      "Epoch: 14500 train loss=0.005796729 valid loss= 0.003496171\n",
      "train reg_fs: 0.0011061610421165824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:50:06,502]\u001b[0m Trial 8 finished with value: 0.0022503081080902736 and parameters: {'lam': 0.0018294431773937165, 'learning_rate': 0.1714676542835499, 'num_epoch': 15000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001884319 valid loss= 0.003327637\n",
      "train reg_fs: 0.0011053701164200902\n",
      "Optimization Finished!\n",
      "test loss: 0.0031184556428343058, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022503081080902736\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011844147 valid loss= 0.007128962\n",
      "train reg_fs: 0.0013515406753867865\n",
      "Epoch: 1000 train loss=0.009877238 valid loss= 0.004124677\n",
      "train reg_fs: 0.0012803948484361172\n",
      "Epoch: 1500 train loss=0.009606186 valid loss= 0.003608161\n",
      "train reg_fs: 0.0012334717903286219\n",
      "Epoch: 2000 train loss=0.003427966 valid loss= 0.003711369\n",
      "train reg_fs: 0.001217404380440712\n",
      "Epoch: 2500 train loss=0.002511499 valid loss= 0.003736027\n",
      "train reg_fs: 0.001196706434711814\n",
      "Epoch: 3000 train loss=0.004082676 valid loss= 0.004103831\n",
      "train reg_fs: 0.0011756193125620484\n",
      "Epoch: 3500 train loss=0.007404013 valid loss= 0.003709466\n",
      "train reg_fs: 0.0011608756612986326\n",
      "Epoch: 4000 train loss=0.002107989 valid loss= 0.003770847\n",
      "train reg_fs: 0.0011509004980325699\n",
      "Epoch: 4500 train loss=0.001695112 valid loss= 0.003358517\n",
      "train reg_fs: 0.0011440220987424254\n",
      "Epoch: 5000 train loss=0.003784401 valid loss= 0.003210534\n",
      "train reg_fs: 0.0011382618686184287\n",
      "Epoch: 5500 train loss=0.003935073 valid loss= 0.003311044\n",
      "train reg_fs: 0.0011333475122228265\n",
      "Epoch: 6000 train loss=0.002257193 valid loss= 0.003696650\n",
      "train reg_fs: 0.0011294741416350007\n",
      "Epoch: 6500 train loss=0.006996272 valid loss= 0.003401400\n",
      "train reg_fs: 0.0011264414060860872\n",
      "Epoch: 7000 train loss=0.003792746 valid loss= 0.003494087\n",
      "train reg_fs: 0.0011238354491069913\n",
      "Epoch: 7500 train loss=0.002660838 valid loss= 0.003668022\n",
      "train reg_fs: 0.0011213927064090967\n",
      "Epoch: 8000 train loss=0.003086091 valid loss= 0.003386587\n",
      "train reg_fs: 0.001118989079259336\n",
      "Epoch: 8500 train loss=0.001568799 valid loss= 0.003295031\n",
      "train reg_fs: 0.0011169163044542074\n",
      "Epoch: 9000 train loss=0.001727485 valid loss= 0.003709215\n",
      "train reg_fs: 0.0011153480736538768\n",
      "Epoch: 9500 train loss=0.002134434 valid loss= 0.003217421\n",
      "train reg_fs: 0.001113979029469192\n",
      "Epoch: 10000 train loss=0.003212417 valid loss= 0.003368714\n",
      "train reg_fs: 0.0011125642340630293\n",
      "Epoch: 10500 train loss=0.010422551 valid loss= 0.003238176\n",
      "train reg_fs: 0.0011112802894786\n",
      "Epoch: 11000 train loss=0.002250075 valid loss= 0.003614512\n",
      "train reg_fs: 0.0011102196294814348\n",
      "Epoch: 11500 train loss=0.002399439 valid loss= 0.003371272\n",
      "train reg_fs: 0.0011093398788943887\n",
      "Epoch: 12000 train loss=0.002770603 valid loss= 0.003074881\n",
      "train reg_fs: 0.0011085992446169257\n",
      "Epoch: 12500 train loss=0.001453423 valid loss= 0.003235193\n",
      "train reg_fs: 0.0011076946975663304\n",
      "Epoch: 13000 train loss=0.001681898 valid loss= 0.003313334\n",
      "train reg_fs: 0.0011069419560953975\n",
      "Epoch: 13500 train loss=0.003271150 valid loss= 0.003375778\n",
      "train reg_fs: 0.0011062666308134794\n",
      "Epoch: 14000 train loss=0.002215614 valid loss= 0.003883984\n",
      "train reg_fs: 0.001105571980588138\n",
      "Epoch: 14500 train loss=0.001265939 valid loss= 0.003297132\n",
      "train reg_fs: 0.0011049811728298664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:51:49,480]\u001b[0m Trial 9 finished with value: 0.001935560847120119 and parameters: {'lam': 0.001570821458809122, 'learning_rate': 0.13604818291021806, 'num_epoch': 15000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001703734 valid loss= 0.002986984\n",
      "train reg_fs: 0.0011042158585041761\n",
      "Optimization Finished!\n",
      "test loss: 0.0029370603151619434, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001935560847120119\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.023020769 valid loss= 0.008640283\n",
      "train reg_fs: 0.002238204702734947\n",
      "Epoch: 1000 train loss=0.008058362 valid loss= 0.008569429\n",
      "train reg_fs: 0.0022689225152134895\n",
      "Epoch: 1500 train loss=0.014560143 valid loss= 0.008066980\n",
      "train reg_fs: 0.0022872290574014187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:52:04,805]\u001b[0m Trial 10 finished with value: 0.005372950439766705 and parameters: {'lam': 0.0026116333369841345, 'learning_rate': 0.03139728946886575, 'num_epoch': 2000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.009850218 valid loss= 0.007674578\n",
      "train reg_fs: 0.0022914609871804714\n",
      "Optimization Finished!\n",
      "test loss: 0.009582708589732647, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005372950439766705\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011413112 valid loss= 0.008207601\n",
      "train reg_fs: 0.002117099007591605\n",
      "Epoch: 1000 train loss=0.008706264 valid loss= 0.007652840\n",
      "train reg_fs: 0.0021362800616770983\n",
      "Epoch: 1500 train loss=0.011945487 valid loss= 0.008034935\n",
      "train reg_fs: 0.0021462177392095327\n",
      "Epoch: 2000 train loss=0.010731554 valid loss= 0.006741245\n",
      "train reg_fs: 0.0021494333632290363\n",
      "Epoch: 2500 train loss=0.008890000 valid loss= 0.006332746\n",
      "train reg_fs: 0.0021450112108141184\n",
      "Epoch: 3000 train loss=0.008123305 valid loss= 0.006180402\n",
      "train reg_fs: 0.00213578506372869\n",
      "Epoch: 3500 train loss=0.010602841 valid loss= 0.006319964\n",
      "train reg_fs: 0.0021187295205891132\n",
      "Epoch: 4000 train loss=0.005309784 valid loss= 0.005793870\n",
      "train reg_fs: 0.002098554279655218\n",
      "Epoch: 4500 train loss=0.002804352 valid loss= 0.005229758\n",
      "train reg_fs: 0.002080586040392518\n",
      "Epoch: 5000 train loss=0.010795762 valid loss= 0.004893878\n",
      "train reg_fs: 0.002062382409349084\n",
      "Epoch: 5500 train loss=0.007432573 valid loss= 0.004617658\n",
      "train reg_fs: 0.0020458216313272715\n",
      "Epoch: 6000 train loss=0.003844083 valid loss= 0.004511495\n",
      "train reg_fs: 0.0020298741292208433\n",
      "Epoch: 6500 train loss=0.008387474 valid loss= 0.004292508\n",
      "train reg_fs: 0.0020129578188061714\n",
      "Epoch: 7000 train loss=0.009974966 valid loss= 0.003897647\n",
      "train reg_fs: 0.001999526284635067\n",
      "Epoch: 7500 train loss=0.010969702 valid loss= 0.003925011\n",
      "train reg_fs: 0.0019881222397089005\n",
      "Epoch: 8000 train loss=0.010343404 valid loss= 0.003898549\n",
      "train reg_fs: 0.0019772218074649572\n",
      "Epoch: 8500 train loss=0.010650201 valid loss= 0.003862306\n",
      "train reg_fs: 0.0019673705101013184\n",
      "Epoch: 9000 train loss=0.004863906 valid loss= 0.004050724\n",
      "train reg_fs: 0.001959484303370118\n",
      "Epoch: 9500 train loss=0.006047125 valid loss= 0.003980394\n",
      "train reg_fs: 0.0019519923953339458\n",
      "Epoch: 10000 train loss=0.009831646 valid loss= 0.003816361\n",
      "train reg_fs: 0.0019445380894467235\n",
      "Epoch: 10500 train loss=0.002950263 valid loss= 0.003804269\n",
      "train reg_fs: 0.0019375609699636698\n",
      "Epoch: 11000 train loss=0.003333759 valid loss= 0.003681635\n",
      "train reg_fs: 0.001930864411406219\n",
      "Epoch: 11500 train loss=0.008835924 valid loss= 0.003780543\n",
      "train reg_fs: 0.001924112788401544\n",
      "Epoch: 12000 train loss=0.003504921 valid loss= 0.004243846\n",
      "train reg_fs: 0.001917612156830728\n",
      "Epoch: 12500 train loss=0.003771993 valid loss= 0.004041847\n",
      "train reg_fs: 0.0019116492476314306\n",
      "Epoch: 13000 train loss=0.005484287 valid loss= 0.003722876\n",
      "train reg_fs: 0.001904992968775332\n",
      "Epoch: 13500 train loss=0.004825788 valid loss= 0.003911798\n",
      "train reg_fs: 0.001897952170111239\n",
      "Epoch: 14000 train loss=0.005325723 valid loss= 0.003882194\n",
      "train reg_fs: 0.001890864921733737\n",
      "Epoch: 14500 train loss=0.004484059 valid loss= 0.003768446\n",
      "train reg_fs: 0.0018847150495275855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:53:48,920]\u001b[0m Trial 11 finished with value: 0.002334367861461971 and parameters: {'lam': 0.002487191789446873, 'learning_rate': 0.022202452958736404, 'num_epoch': 15000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007391231 valid loss= 0.004210796\n",
      "train reg_fs: 0.001878838986158371\n",
      "Optimization Finished!\n",
      "test loss: 0.0042444318532943726, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002334367861461971\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009928710 valid loss= 0.006570911\n",
      "train reg_fs: 0.0009762515546754003\n",
      "Epoch: 1000 train loss=0.011249623 valid loss= 0.006488331\n",
      "train reg_fs: 0.0009883953025564551\n",
      "Epoch: 1500 train loss=0.009887038 valid loss= 0.005703112\n",
      "train reg_fs: 0.0009841319406405091\n",
      "Epoch: 2000 train loss=0.003565038 valid loss= 0.005014886\n",
      "train reg_fs: 0.0009701164672151208\n",
      "Epoch: 2500 train loss=0.007559066 valid loss= 0.004397993\n",
      "train reg_fs: 0.0009546805522404611\n",
      "Epoch: 3000 train loss=0.004088103 valid loss= 0.004325592\n",
      "train reg_fs: 0.0009410359198227525\n",
      "Epoch: 3500 train loss=0.004780841 valid loss= 0.003717360\n",
      "train reg_fs: 0.0009304495761170983\n",
      "Epoch: 4000 train loss=0.002995202 valid loss= 0.003394033\n",
      "train reg_fs: 0.0009206621907651424\n",
      "Epoch: 4500 train loss=0.001393647 valid loss= 0.003298109\n",
      "train reg_fs: 0.0009118465823121369\n",
      "Epoch: 5000 train loss=0.003405350 valid loss= 0.004040753\n",
      "train reg_fs: 0.0009047304629348218\n",
      "Epoch: 5500 train loss=0.002405645 valid loss= 0.003611343\n",
      "train reg_fs: 0.0008954528602771461\n",
      "Epoch: 6000 train loss=0.003026953 valid loss= 0.003687215\n",
      "train reg_fs: 0.0008881750400178134\n",
      "Epoch: 6500 train loss=0.002804877 valid loss= 0.003766599\n",
      "train reg_fs: 0.0008817851776257157\n",
      "Epoch: 7000 train loss=0.003792441 valid loss= 0.003963116\n",
      "train reg_fs: 0.0008756719180382788\n",
      "Epoch: 7500 train loss=0.001959136 valid loss= 0.003701320\n",
      "train reg_fs: 0.0008708703680895269\n",
      "Epoch: 8000 train loss=0.004818158 valid loss= 0.004197948\n",
      "train reg_fs: 0.0008664867491461337\n",
      "Epoch: 8500 train loss=0.002513811 valid loss= 0.004180248\n",
      "train reg_fs: 0.0008615624392405152\n",
      "Epoch: 9000 train loss=0.002192110 valid loss= 0.003779198\n",
      "train reg_fs: 0.0008568796911276877\n",
      "Epoch: 9500 train loss=0.001181282 valid loss= 0.003918713\n",
      "train reg_fs: 0.000850914919283241\n",
      "Epoch: 10000 train loss=0.005245970 valid loss= 0.003703575\n",
      "train reg_fs: 0.0008470118627883494\n",
      "Epoch: 10500 train loss=0.001225393 valid loss= 0.003957478\n",
      "train reg_fs: 0.0008415417978540063\n",
      "Epoch: 11000 train loss=0.001914571 valid loss= 0.003883857\n",
      "train reg_fs: 0.0008376652258448303\n",
      "Epoch: 11500 train loss=0.003052516 valid loss= 0.003927966\n",
      "train reg_fs: 0.0008346671820618212\n",
      "Epoch: 12000 train loss=0.002832233 valid loss= 0.003508347\n",
      "train reg_fs: 0.0008300020708702505\n",
      "Epoch: 12500 train loss=0.001524454 valid loss= 0.003772165\n",
      "train reg_fs: 0.0008260447066277266\n",
      "Epoch: 13000 train loss=0.002580506 valid loss= 0.003817306\n",
      "train reg_fs: 0.0008221153984777629\n",
      "Epoch: 13500 train loss=0.002208510 valid loss= 0.003807503\n",
      "train reg_fs: 0.0008180162985809147\n",
      "Epoch: 14000 train loss=0.002325919 valid loss= 0.003819964\n",
      "train reg_fs: 0.0008134138188324869\n",
      "Epoch: 14500 train loss=0.001897718 valid loss= 0.003722405\n",
      "train reg_fs: 0.0008093032520264387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:55:31,149]\u001b[0m Trial 12 finished with value: 0.0028229043814599485 and parameters: {'lam': 0.001106647475332221, 'learning_rate': 0.08314799609609533, 'num_epoch': 15000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001247153 valid loss= 0.003624072\n",
      "train reg_fs: 0.0008056631195358932\n",
      "Optimization Finished!\n",
      "test loss: 0.004438722971826792, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028229043814599485\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009903617 valid loss= 0.010286695\n",
      "train reg_fs: 0.0028792330995202065\n",
      "Epoch: 1000 train loss=0.024785865 valid loss= 0.010082409\n",
      "train reg_fs: 0.002900740597397089\n",
      "Epoch: 1500 train loss=0.013088811 valid loss= 0.009469179\n",
      "train reg_fs: 0.002918758662417531\n",
      "Epoch: 2000 train loss=0.014023639 valid loss= 0.009857235\n",
      "train reg_fs: 0.0029338286258280277\n",
      "Epoch: 2500 train loss=0.015852036 valid loss= 0.009813980\n",
      "train reg_fs: 0.002948121866211295\n",
      "Epoch: 3000 train loss=0.012516386 valid loss= 0.009293900\n",
      "train reg_fs: 0.0029594774823635817\n",
      "Epoch: 3500 train loss=0.015514052 valid loss= 0.008929443\n",
      "train reg_fs: 0.0029679303988814354\n",
      "Epoch: 4000 train loss=0.008461924 valid loss= 0.009052494\n",
      "train reg_fs: 0.002974575851112604\n",
      "Epoch: 4500 train loss=0.011134264 valid loss= 0.008817454\n",
      "train reg_fs: 0.0029791288543492556\n",
      "Epoch: 5000 train loss=0.015988855 valid loss= 0.008744790\n",
      "train reg_fs: 0.0029813360888510942\n",
      "Epoch: 5500 train loss=0.008526770 valid loss= 0.008618249\n",
      "train reg_fs: 0.002983206883072853\n",
      "Epoch: 6000 train loss=0.008031882 valid loss= 0.008182354\n",
      "train reg_fs: 0.0029816715978085995\n",
      "Epoch: 6500 train loss=0.009744832 valid loss= 0.008346662\n",
      "train reg_fs: 0.002979594748467207\n",
      "Epoch: 7000 train loss=0.007168553 valid loss= 0.008971754\n",
      "train reg_fs: 0.0029755285941064358\n",
      "Epoch: 7500 train loss=0.008885060 valid loss= 0.007722854\n",
      "train reg_fs: 0.002968941815197468\n",
      "Epoch: 8000 train loss=0.013263289 valid loss= 0.007700950\n",
      "train reg_fs: 0.002961964812129736\n",
      "Epoch: 8500 train loss=0.010297072 valid loss= 0.008041192\n",
      "train reg_fs: 0.002951996633782983\n",
      "Epoch: 9000 train loss=0.006090971 valid loss= 0.007595625\n",
      "train reg_fs: 0.002940865932032466\n",
      "Epoch: 9500 train loss=0.016253170 valid loss= 0.007658009\n",
      "train reg_fs: 0.002931235358119011\n",
      "Epoch: 10000 train loss=0.009120330 valid loss= 0.007382424\n",
      "train reg_fs: 0.002919003600254655\n",
      "Epoch: 10500 train loss=0.009442640 valid loss= 0.007100212\n",
      "train reg_fs: 0.0029067713767290115\n",
      "Epoch: 11000 train loss=0.012783187 valid loss= 0.007218761\n",
      "train reg_fs: 0.0028929412364959717\n",
      "Epoch: 11500 train loss=0.007273640 valid loss= 0.007029959\n",
      "train reg_fs: 0.00287744146771729\n",
      "Epoch: 12000 train loss=0.010424494 valid loss= 0.006567215\n",
      "train reg_fs: 0.002862482564523816\n",
      "Epoch: 12500 train loss=0.008143571 valid loss= 0.006650258\n",
      "train reg_fs: 0.002847731113433838\n",
      "Epoch: 13000 train loss=0.013908436 valid loss= 0.006395936\n",
      "train reg_fs: 0.0028331398498266935\n",
      "Epoch: 13500 train loss=0.007541034 valid loss= 0.006625933\n",
      "train reg_fs: 0.0028194382321089506\n",
      "Epoch: 14000 train loss=0.008852197 valid loss= 0.005843519\n",
      "train reg_fs: 0.002804200630635023\n",
      "Epoch: 14500 train loss=0.005080462 valid loss= 0.005855113\n",
      "train reg_fs: 0.002790293889120221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:57:16,351]\u001b[0m Trial 13 finished with value: 0.0029525282309794897 and parameters: {'lam': 0.003417852796847912, 'learning_rate': 0.010549051349894896, 'num_epoch': 15000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007874388 valid loss= 0.005760927\n",
      "train reg_fs: 0.0027756488416343927\n",
      "Optimization Finished!\n",
      "test loss: 0.0063250064849853516, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029525282309794897\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011033748 valid loss= 0.008607670\n",
      "train reg_fs: 0.0014735906152054667\n",
      "Epoch: 1000 train loss=0.019072818 valid loss= 0.008325773\n",
      "train reg_fs: 0.001497445278801024\n",
      "Epoch: 1500 train loss=0.013068255 valid loss= 0.008571631\n",
      "train reg_fs: 0.0015126089565455914\n",
      "Epoch: 2000 train loss=0.003496553 valid loss= 0.008026428\n",
      "train reg_fs: 0.0015200902707874775\n",
      "Epoch: 2500 train loss=0.015624628 valid loss= 0.007546589\n",
      "train reg_fs: 0.001519882003776729\n",
      "Epoch: 3000 train loss=0.003840944 valid loss= 0.007491965\n",
      "train reg_fs: 0.0015118422452360392\n",
      "Epoch: 3500 train loss=0.005164304 valid loss= 0.007317470\n",
      "train reg_fs: 0.0014961533015593886\n",
      "Epoch: 4000 train loss=0.010460447 valid loss= 0.006456572\n",
      "train reg_fs: 0.0014720651088282466\n",
      "Epoch: 4500 train loss=0.006175346 valid loss= 0.005942907\n",
      "train reg_fs: 0.0014453971525654197\n",
      "Epoch: 5000 train loss=0.012094106 valid loss= 0.005506185\n",
      "train reg_fs: 0.0014196335105225444\n",
      "Epoch: 5500 train loss=0.003781506 valid loss= 0.004677304\n",
      "train reg_fs: 0.0013967598788440228\n",
      "Epoch: 6000 train loss=0.003330611 valid loss= 0.003851088\n",
      "train reg_fs: 0.0013757931301370263\n",
      "Epoch: 6500 train loss=0.006429480 valid loss= 0.003983744\n",
      "train reg_fs: 0.0013580856611952186\n",
      "Epoch: 7000 train loss=0.004770631 valid loss= 0.003939894\n",
      "train reg_fs: 0.0013436619192361832\n",
      "Epoch: 7500 train loss=0.002564587 valid loss= 0.004014142\n",
      "train reg_fs: 0.0013329446082934737\n",
      "Epoch: 8000 train loss=0.001774309 valid loss= 0.003859751\n",
      "train reg_fs: 0.0013240306871011853\n",
      "Epoch: 8500 train loss=0.002275279 valid loss= 0.004015475\n",
      "train reg_fs: 0.001315167173743248\n",
      "Epoch: 9000 train loss=0.002593838 valid loss= 0.003744796\n",
      "train reg_fs: 0.001307800062932074\n",
      "Epoch: 9500 train loss=0.002627266 valid loss= 0.004009224\n",
      "train reg_fs: 0.001301219454035163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:58:26,734]\u001b[0m Trial 14 finished with value: 0.002551412382535456 and parameters: {'lam': 0.0017145188613521413, 'learning_rate': 0.03427567587299454, 'num_epoch': 10000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005159752 valid loss= 0.003844660\n",
      "train reg_fs: 0.0012954357080161572\n",
      "Optimization Finished!\n",
      "test loss: 0.003625455778092146, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002551412382535456\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015286593 valid loss= 0.009285364\n",
      "train reg_fs: 0.0019301227293908596\n",
      "Epoch: 1000 train loss=0.011176081 valid loss= 0.010111060\n",
      "train reg_fs: 0.0019475162262097\n",
      "Epoch: 1500 train loss=0.010628535 valid loss= 0.008566004\n",
      "train reg_fs: 0.0019571278244256973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 21:58:42,405]\u001b[0m Trial 15 finished with value: 0.0069170957992163795 and parameters: {'lam': 0.002283040356485957, 'learning_rate': 0.021410781797220696, 'num_epoch': 2000}. Best is trial 7 with value: 0.0018829556721344726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.006687204 valid loss= 0.008895711\n",
      "train reg_fs: 0.001960235182195902\n",
      "Optimization Finished!\n",
      "test loss: 0.011297347024083138, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0069170957992163795\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012513174 valid loss= 0.008598447\n",
      "train reg_fs: 0.0030749603174626827\n",
      "Epoch: 1000 train loss=0.010101460 valid loss= 0.007404821\n",
      "train reg_fs: 0.0029790413100272417\n",
      "Epoch: 1500 train loss=0.014499326 valid loss= 0.005533297\n",
      "train reg_fs: 0.002844779519364238\n",
      "Epoch: 2000 train loss=0.010429896 valid loss= 0.005033274\n",
      "train reg_fs: 0.0027512807864695787\n",
      "Epoch: 2500 train loss=0.004501117 valid loss= 0.005056360\n",
      "train reg_fs: 0.0027007663156837225\n",
      "Epoch: 3000 train loss=0.008425184 valid loss= 0.004404318\n",
      "train reg_fs: 0.0026680449955165386\n",
      "Epoch: 3500 train loss=0.003812613 valid loss= 0.004636417\n",
      "train reg_fs: 0.0026386526878923178\n",
      "Epoch: 4000 train loss=0.004995136 valid loss= 0.004512892\n",
      "train reg_fs: 0.002615624340251088\n",
      "Epoch: 4500 train loss=0.005090954 valid loss= 0.003885095\n",
      "train reg_fs: 0.0025948414113372564\n",
      "Epoch: 5000 train loss=0.004188545 valid loss= 0.004076269\n",
      "train reg_fs: 0.002573862439021468\n",
      "Epoch: 5500 train loss=0.004802229 valid loss= 0.003731632\n",
      "train reg_fs: 0.0025515423621982336\n",
      "Epoch: 6000 train loss=0.004556037 valid loss= 0.003733193\n",
      "train reg_fs: 0.0025229500606656075\n",
      "Epoch: 6500 train loss=0.004503103 valid loss= 0.003622368\n",
      "train reg_fs: 0.002487689023837447\n",
      "Epoch: 7000 train loss=0.004588761 valid loss= 0.003659759\n",
      "train reg_fs: 0.0024575088173151016\n",
      "Epoch: 7500 train loss=0.003672855 valid loss= 0.004355670\n",
      "train reg_fs: 0.002428243635222316\n",
      "Epoch: 8000 train loss=0.005310400 valid loss= 0.004731465\n",
      "train reg_fs: 0.002409078646451235\n",
      "Epoch: 8500 train loss=0.003548682 valid loss= 0.003582079\n",
      "train reg_fs: 0.002396287862211466\n",
      "Epoch: 9000 train loss=0.003787397 valid loss= 0.003512983\n",
      "train reg_fs: 0.002379209967330098\n",
      "Epoch: 9500 train loss=0.005679787 valid loss= 0.003081271\n",
      "train reg_fs: 0.0023603506851941347\n",
      "Epoch: 10000 train loss=0.003464502 valid loss= 0.003693339\n",
      "train reg_fs: 0.0023449892178177834\n",
      "Epoch: 10500 train loss=0.005174692 valid loss= 0.003730318\n",
      "train reg_fs: 0.0023267832584679127\n",
      "Epoch: 11000 train loss=0.002656603 valid loss= 0.003382978\n",
      "train reg_fs: 0.002316318452358246\n",
      "Epoch: 11500 train loss=0.013103681 valid loss= 0.003420732\n",
      "train reg_fs: 0.0023052948527038097\n",
      "Epoch: 12000 train loss=0.002645859 valid loss= 0.003298105\n",
      "train reg_fs: 0.0022939699701964855\n",
      "Epoch: 12500 train loss=0.006214968 valid loss= 0.003331344\n",
      "train reg_fs: 0.0022873664274811745\n",
      "Epoch: 13000 train loss=0.002593508 valid loss= 0.003670135\n",
      "train reg_fs: 0.002277804771438241\n",
      "Epoch: 13500 train loss=0.004829192 valid loss= 0.003261260\n",
      "train reg_fs: 0.002266576513648033\n",
      "Epoch: 14000 train loss=0.003803151 valid loss= 0.003656619\n",
      "train reg_fs: 0.0022583603858947754\n",
      "Epoch: 14500 train loss=0.004061365 valid loss= 0.003081252\n",
      "train reg_fs: 0.0022479845210909843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:00:25,123]\u001b[0m Trial 16 finished with value: 0.0007508591478522734 and parameters: {'lam': 0.003608043998903256, 'learning_rate': 0.08806912559001144, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003176524 valid loss= 0.003058849\n",
      "train reg_fs: 0.002241733716800809\n",
      "Optimization Finished!\n",
      "test loss: 0.0027548319194465876, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0007508591478522734\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006070807 valid loss= 0.009497110\n",
      "train reg_fs: 0.003138526575639844\n",
      "Epoch: 1000 train loss=0.007693683 valid loss= 0.006155875\n",
      "train reg_fs: 0.0029109760653227568\n",
      "Epoch: 1500 train loss=0.003891932 valid loss= 0.004819260\n",
      "train reg_fs: 0.002699813572689891\n",
      "Epoch: 2000 train loss=0.005349271 valid loss= 0.004838497\n",
      "train reg_fs: 0.002579477848485112\n",
      "Epoch: 2500 train loss=0.002884756 valid loss= 0.004473033\n",
      "train reg_fs: 0.002500951522961259\n",
      "Epoch: 3000 train loss=0.004423446 valid loss= 0.004230172\n",
      "train reg_fs: 0.00244377669878304\n",
      "Epoch: 3500 train loss=0.003702619 valid loss= 0.005509012\n",
      "train reg_fs: 0.002398974960669875\n",
      "Epoch: 4000 train loss=0.010431359 valid loss= 0.004869555\n",
      "train reg_fs: 0.0023656017147004604\n",
      "Epoch: 4500 train loss=0.005884117 valid loss= 0.004907329\n",
      "train reg_fs: 0.0023344343062490225\n",
      "Epoch: 5000 train loss=0.002630434 valid loss= 0.005226714\n",
      "train reg_fs: 0.002307188231498003\n",
      "Epoch: 5500 train loss=0.004000084 valid loss= 0.004933277\n",
      "train reg_fs: 0.002281003398820758\n",
      "Epoch: 6000 train loss=0.004364136 valid loss= 0.005040893\n",
      "train reg_fs: 0.0022580523509532213\n",
      "Epoch: 6500 train loss=0.002766871 valid loss= 0.005753277\n",
      "train reg_fs: 0.002235188614577055\n",
      "Epoch: 7000 train loss=0.003122077 valid loss= 0.006462780\n",
      "train reg_fs: 0.0022194855846464634\n",
      "Epoch: 7500 train loss=0.005038477 valid loss= 0.006107132\n",
      "train reg_fs: 0.0022029969841241837\n",
      "Epoch: 8000 train loss=0.002633459 valid loss= 0.007479180\n",
      "train reg_fs: 0.002187695587053895\n",
      "Epoch: 8500 train loss=0.003074602 valid loss= 0.006280262\n",
      "train reg_fs: 0.002177865244448185\n",
      "Epoch: 9000 train loss=0.002706995 valid loss= 0.006127902\n",
      "train reg_fs: 0.0021657964680343866\n",
      "Epoch: 9500 train loss=0.003237180 valid loss= 0.006818036\n",
      "train reg_fs: 0.0021550178062170744\n",
      "Epoch: 10000 train loss=0.003989453 valid loss= 0.007115165\n",
      "train reg_fs: 0.0021491171792149544\n",
      "Epoch: 10500 train loss=0.003158959 valid loss= 0.005721420\n",
      "train reg_fs: 0.0021443378645926714\n",
      "Epoch: 11000 train loss=0.004367827 valid loss= 0.006867919\n",
      "train reg_fs: 0.002139057032763958\n",
      "Epoch: 11500 train loss=0.003454701 valid loss= 0.006944431\n",
      "train reg_fs: 0.002132255816832185\n",
      "Epoch: 12000 train loss=0.002530508 valid loss= 0.008187226\n",
      "train reg_fs: 0.00212671491317451\n",
      "Epoch: 12500 train loss=0.002793845 valid loss= 0.006544306\n",
      "train reg_fs: 0.0021233384031802416\n",
      "Epoch: 13000 train loss=0.004752473 valid loss= 0.006664851\n",
      "train reg_fs: 0.0021186198573559523\n",
      "Epoch: 13500 train loss=0.002974065 valid loss= 0.007057176\n",
      "train reg_fs: 0.0021142868790775537\n",
      "Epoch: 14000 train loss=0.004665545 valid loss= 0.006234000\n",
      "train reg_fs: 0.0021132559049874544\n",
      "Epoch: 14500 train loss=0.003121595 valid loss= 0.007243146\n",
      "train reg_fs: 0.002114341827109456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:02:09,929]\u001b[0m Trial 17 finished with value: 0.0046128477840627355 and parameters: {'lam': 0.0035706459784214046, 'learning_rate': 0.19997427536934867, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002853120 valid loss= 0.006769171\n",
      "train reg_fs: 0.0021100621670484543\n",
      "Optimization Finished!\n",
      "test loss: 0.006885358598083258, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0046128477840627355\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013342755 valid loss= 0.009631749\n",
      "train reg_fs: 0.0032378968317061663\n",
      "Epoch: 1000 train loss=0.007416021 valid loss= 0.010251641\n",
      "train reg_fs: 0.0031893968116492033\n",
      "Epoch: 1500 train loss=0.013177184 valid loss= 0.008001490\n",
      "train reg_fs: 0.0030912086367607117\n",
      "Epoch: 2000 train loss=0.007244772 valid loss= 0.006649315\n",
      "train reg_fs: 0.003017604351043701\n",
      "Epoch: 2500 train loss=0.006001312 valid loss= 0.005344435\n",
      "train reg_fs: 0.002938820980489254\n",
      "Epoch: 3000 train loss=0.005913008 valid loss= 0.005535393\n",
      "train reg_fs: 0.0028844738844782114\n",
      "Epoch: 3500 train loss=0.004250285 valid loss= 0.005572086\n",
      "train reg_fs: 0.002862812951207161\n",
      "Epoch: 4000 train loss=0.004611791 valid loss= 0.005805209\n",
      "train reg_fs: 0.0028445704374462366\n",
      "Epoch: 4500 train loss=0.006083999 valid loss= 0.005918203\n",
      "train reg_fs: 0.002832371974363923\n",
      "Epoch: 5000 train loss=0.003329184 valid loss= 0.005847626\n",
      "train reg_fs: 0.002819277113303542\n",
      "Epoch: 5500 train loss=0.005222507 valid loss= 0.006359278\n",
      "train reg_fs: 0.0027982513420283794\n",
      "Epoch: 6000 train loss=0.007042742 valid loss= 0.005703728\n",
      "train reg_fs: 0.0027728378772735596\n",
      "Epoch: 6500 train loss=0.003964061 valid loss= 0.006078658\n",
      "train reg_fs: 0.0027365735732018948\n",
      "Epoch: 7000 train loss=0.003325565 valid loss= 0.005919278\n",
      "train reg_fs: 0.0026973034255206585\n",
      "Epoch: 7500 train loss=0.004433751 valid loss= 0.005624579\n",
      "train reg_fs: 0.002662881277501583\n",
      "Epoch: 8000 train loss=0.003489418 valid loss= 0.005958905\n",
      "train reg_fs: 0.0026341374032199383\n",
      "Epoch: 8500 train loss=0.004163777 valid loss= 0.005530142\n",
      "train reg_fs: 0.002606465946882963\n",
      "Epoch: 9000 train loss=0.003457851 valid loss= 0.005383533\n",
      "train reg_fs: 0.0025829330552369356\n",
      "Epoch: 9500 train loss=0.005477948 valid loss= 0.005710597\n",
      "train reg_fs: 0.002578865271061659\n",
      "Epoch: 10000 train loss=0.004408930 valid loss= 0.005577776\n",
      "train reg_fs: 0.0025588381104171276\n",
      "Epoch: 10500 train loss=0.004450249 valid loss= 0.005549153\n",
      "train reg_fs: 0.0025466924998909235\n",
      "Epoch: 11000 train loss=0.004108039 valid loss= 0.005238975\n",
      "train reg_fs: 0.0025387785863131285\n",
      "Epoch: 11500 train loss=0.006506272 valid loss= 0.005104272\n",
      "train reg_fs: 0.002525539370253682\n",
      "Epoch: 12000 train loss=0.004165360 valid loss= 0.005339910\n",
      "train reg_fs: 0.0025158331263810396\n",
      "Epoch: 12500 train loss=0.004728915 valid loss= 0.005087012\n",
      "train reg_fs: 0.0025086181703954935\n",
      "Epoch: 13000 train loss=0.003177406 valid loss= 0.005095845\n",
      "train reg_fs: 0.0025052467826753855\n",
      "Epoch: 13500 train loss=0.004190075 valid loss= 0.004908835\n",
      "train reg_fs: 0.0024975629057735205\n",
      "Epoch: 14000 train loss=0.009133840 valid loss= 0.005084368\n",
      "train reg_fs: 0.002497802022844553\n",
      "Epoch: 14500 train loss=0.004625928 valid loss= 0.004727064\n",
      "train reg_fs: 0.0024933121167123318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:03:52,999]\u001b[0m Trial 18 finished with value: 0.0023202146728173558 and parameters: {'lam': 0.00373067845424892, 'learning_rate': 0.09177547163770258, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003968699 valid loss= 0.004750892\n",
      "train reg_fs: 0.0024893428198993206\n",
      "Optimization Finished!\n",
      "test loss: 0.004997709766030312, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023202146728173558\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019066356 valid loss= 0.007120711\n",
      "train reg_fs: 0.0017396315233781934\n",
      "Epoch: 1000 train loss=0.007938643 valid loss= 0.007132533\n",
      "train reg_fs: 0.0017351818969473243\n",
      "Epoch: 1500 train loss=0.003335959 valid loss= 0.006049735\n",
      "train reg_fs: 0.0016847836086526513\n",
      "Epoch: 2000 train loss=0.005059712 valid loss= 0.004504394\n",
      "train reg_fs: 0.0016197424847632647\n",
      "Epoch: 2500 train loss=0.003538338 valid loss= 0.004220450\n",
      "train reg_fs: 0.0015765599673613906\n",
      "Epoch: 3000 train loss=0.003664183 valid loss= 0.004162481\n",
      "train reg_fs: 0.0015506049385294318\n",
      "Epoch: 3500 train loss=0.002141057 valid loss= 0.004203809\n",
      "train reg_fs: 0.0015305137494578958\n",
      "Epoch: 4000 train loss=0.002060004 valid loss= 0.004134321\n",
      "train reg_fs: 0.0015102422330528498\n",
      "Epoch: 4500 train loss=0.006150825 valid loss= 0.004465437\n",
      "train reg_fs: 0.0014926486182957888\n",
      "Epoch: 5000 train loss=0.003409230 valid loss= 0.004284408\n",
      "train reg_fs: 0.0014762150822207332\n",
      "Epoch: 5500 train loss=0.002013378 valid loss= 0.004261102\n",
      "train reg_fs: 0.0014630905352532864\n",
      "Epoch: 6000 train loss=0.009549509 valid loss= 0.003936550\n",
      "train reg_fs: 0.0014506198931485415\n",
      "Epoch: 6500 train loss=0.002989747 valid loss= 0.003895650\n",
      "train reg_fs: 0.0014367117546498775\n",
      "Epoch: 7000 train loss=0.002620293 valid loss= 0.003684990\n",
      "train reg_fs: 0.0014238196890801191\n",
      "Epoch: 7500 train loss=0.002396906 valid loss= 0.003930554\n",
      "train reg_fs: 0.0014108259929344058\n",
      "Epoch: 8000 train loss=0.001788171 valid loss= 0.003738740\n",
      "train reg_fs: 0.0013993538450449705\n",
      "Epoch: 8500 train loss=0.002017880 valid loss= 0.003694050\n",
      "train reg_fs: 0.0013832421973347664\n",
      "Epoch: 9000 train loss=0.004374007 valid loss= 0.003758315\n",
      "train reg_fs: 0.0013680884148925543\n",
      "Epoch: 9500 train loss=0.002651824 valid loss= 0.003792243\n",
      "train reg_fs: 0.0013524007517844439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:05:02,590]\u001b[0m Trial 19 finished with value: 0.002091217749775138 and parameters: {'lam': 0.0019910406753438845, 'learning_rate': 0.06789365209190551, 'num_epoch': 10000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003650153 valid loss= 0.003411046\n",
      "train reg_fs: 0.001338066067546606\n",
      "Optimization Finished!\n",
      "test loss: 0.0032750696409493685, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002091217749775138\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013401729 valid loss= 0.006811302\n",
      "train reg_fs: 0.0012487675994634628\n",
      "Epoch: 1000 train loss=0.007988587 valid loss= 0.004004776\n",
      "train reg_fs: 0.0011713039129972458\n",
      "Epoch: 1500 train loss=0.002693622 valid loss= 0.003421893\n",
      "train reg_fs: 0.0011334741720929742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:05:18,120]\u001b[0m Trial 20 finished with value: 0.002225754346371028 and parameters: {'lam': 0.0014430350186709932, 'learning_rate': 0.13006727008877045, 'num_epoch': 2000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.004127055 valid loss= 0.003338540\n",
      "train reg_fs: 0.0011137438705191016\n",
      "Optimization Finished!\n",
      "test loss: 0.003523009829223156, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002225754346371028\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.026503390 valid loss= 0.012784006\n",
      "train reg_fs: 0.006195966154336929\n",
      "Epoch: 1000 train loss=0.016377259 valid loss= 0.011534434\n",
      "train reg_fs: 0.0062610916793346405\n",
      "Epoch: 1500 train loss=0.022117265 valid loss= 0.011657513\n",
      "train reg_fs: 0.0062647853046655655\n",
      "Epoch: 2000 train loss=0.018724259 valid loss= 0.011337986\n",
      "train reg_fs: 0.0062214769423007965\n",
      "Epoch: 2500 train loss=0.014854284 valid loss= 0.010312335\n",
      "train reg_fs: 0.006116781383752823\n",
      "Epoch: 3000 train loss=0.008947963 valid loss= 0.010451876\n",
      "train reg_fs: 0.005974625237286091\n",
      "Epoch: 3500 train loss=0.013592422 valid loss= 0.009383738\n",
      "train reg_fs: 0.005827037617564201\n",
      "Epoch: 4000 train loss=0.006668361 valid loss= 0.008636581\n",
      "train reg_fs: 0.005684633273631334\n",
      "Epoch: 4500 train loss=0.010488719 valid loss= 0.008659443\n",
      "train reg_fs: 0.005549794994294643\n",
      "Epoch: 5000 train loss=0.013311539 valid loss= 0.008164089\n",
      "train reg_fs: 0.005423506256192923\n",
      "Epoch: 5500 train loss=0.009225407 valid loss= 0.007810569\n",
      "train reg_fs: 0.005312180612236261\n",
      "Epoch: 6000 train loss=0.007868623 valid loss= 0.008236042\n",
      "train reg_fs: 0.005223990883678198\n",
      "Epoch: 6500 train loss=0.008101106 valid loss= 0.007545439\n",
      "train reg_fs: 0.005140900611877441\n",
      "Epoch: 7000 train loss=0.007589041 valid loss= 0.008086881\n",
      "train reg_fs: 0.005065607372671366\n",
      "Epoch: 7500 train loss=0.006487956 valid loss= 0.007500768\n",
      "train reg_fs: 0.004998944699764252\n",
      "Epoch: 8000 train loss=0.006977693 valid loss= 0.007750711\n",
      "train reg_fs: 0.004944894928485155\n",
      "Epoch: 8500 train loss=0.005397274 valid loss= 0.007237551\n",
      "train reg_fs: 0.004888052586466074\n",
      "Epoch: 9000 train loss=0.008792263 valid loss= 0.007346203\n",
      "train reg_fs: 0.004840020090341568\n",
      "Epoch: 9500 train loss=0.006804127 valid loss= 0.007355083\n",
      "train reg_fs: 0.00479789637029171\n",
      "Epoch: 10000 train loss=0.006247293 valid loss= 0.007104351\n",
      "train reg_fs: 0.004756289068609476\n",
      "Epoch: 10500 train loss=0.006765485 valid loss= 0.007154223\n",
      "train reg_fs: 0.0047149029560387135\n",
      "Epoch: 11000 train loss=0.007203716 valid loss= 0.007353120\n",
      "train reg_fs: 0.004677563440054655\n",
      "Epoch: 11500 train loss=0.005866693 valid loss= 0.006797086\n",
      "train reg_fs: 0.004644408356398344\n",
      "Epoch: 12000 train loss=0.008638080 valid loss= 0.006705989\n",
      "train reg_fs: 0.0046158586628735065\n",
      "Epoch: 12500 train loss=0.008051040 valid loss= 0.006907362\n",
      "train reg_fs: 0.004586060531437397\n",
      "Epoch: 13000 train loss=0.015592907 valid loss= 0.007230984\n",
      "train reg_fs: 0.004558982327580452\n",
      "Epoch: 13500 train loss=0.009891810 valid loss= 0.006996698\n",
      "train reg_fs: 0.004536694381386042\n",
      "Epoch: 14000 train loss=0.006207027 valid loss= 0.006766998\n",
      "train reg_fs: 0.0045131198130548\n",
      "Epoch: 14500 train loss=0.005017288 valid loss= 0.007086281\n",
      "train reg_fs: 0.004494440276175737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:07:02,334]\u001b[0m Trial 21 finished with value: 0.0023040307640287594 and parameters: {'lam': 0.0072189830007309405, 'learning_rate': 0.050963564113094405, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006015447 valid loss= 0.006838840\n",
      "train reg_fs: 0.004473936278373003\n",
      "Optimization Finished!\n",
      "test loss: 0.006774254143238068, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023040307640287594\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016123658 valid loss= 0.007258985\n",
      "train reg_fs: 0.0024051342625170946\n",
      "Epoch: 1000 train loss=0.006870749 valid loss= 0.007946112\n",
      "train reg_fs: 0.0024322918616235256\n",
      "Epoch: 1500 train loss=0.006218617 valid loss= 0.007122522\n",
      "train reg_fs: 0.0024352138862013817\n",
      "Epoch: 2000 train loss=0.005642612 valid loss= 0.007383783\n",
      "train reg_fs: 0.0024181390181183815\n",
      "Epoch: 2500 train loss=0.006940067 valid loss= 0.007085824\n",
      "train reg_fs: 0.0023973174393177032\n",
      "Epoch: 3000 train loss=0.005511649 valid loss= 0.007233885\n",
      "train reg_fs: 0.0023688925430178642\n",
      "Epoch: 3500 train loss=0.004581894 valid loss= 0.007239832\n",
      "train reg_fs: 0.0023346010129898787\n",
      "Epoch: 4000 train loss=0.003671639 valid loss= 0.006851068\n",
      "train reg_fs: 0.0022985918913036585\n",
      "Epoch: 4500 train loss=0.003502814 valid loss= 0.007067281\n",
      "train reg_fs: 0.002280134242027998\n",
      "Epoch: 5000 train loss=0.004315176 valid loss= 0.006827116\n",
      "train reg_fs: 0.002259302418678999\n",
      "Epoch: 5500 train loss=0.003168893 valid loss= 0.006209468\n",
      "train reg_fs: 0.002244491595774889\n",
      "Epoch: 6000 train loss=0.004174635 valid loss= 0.006325795\n",
      "train reg_fs: 0.00222332077100873\n",
      "Epoch: 6500 train loss=0.004772453 valid loss= 0.006194399\n",
      "train reg_fs: 0.002207640092819929\n",
      "Epoch: 7000 train loss=0.005990719 valid loss= 0.006611883\n",
      "train reg_fs: 0.002196253975853324\n",
      "Epoch: 7500 train loss=0.004998612 valid loss= 0.006625044\n",
      "train reg_fs: 0.002182238269597292\n",
      "Epoch: 8000 train loss=0.003675270 valid loss= 0.006590883\n",
      "train reg_fs: 0.0021682896185666323\n",
      "Epoch: 8500 train loss=0.004067120 valid loss= 0.006792054\n",
      "train reg_fs: 0.0021525213960558176\n",
      "Epoch: 9000 train loss=0.003266606 valid loss= 0.006182099\n",
      "train reg_fs: 0.0021438293624669313\n",
      "Epoch: 9500 train loss=0.003501348 valid loss= 0.006966847\n",
      "train reg_fs: 0.002132255816832185\n",
      "Epoch: 10000 train loss=0.003205659 valid loss= 0.007034964\n",
      "train reg_fs: 0.0021193719003349543\n",
      "Epoch: 10500 train loss=0.007298089 valid loss= 0.006844921\n",
      "train reg_fs: 0.0021089049987494946\n",
      "Epoch: 11000 train loss=0.006614618 valid loss= 0.006879777\n",
      "train reg_fs: 0.0020938110537827015\n",
      "Epoch: 11500 train loss=0.003194033 valid loss= 0.006857753\n",
      "train reg_fs: 0.0020811983849853277\n",
      "Epoch: 12000 train loss=0.003217055 valid loss= 0.006842404\n",
      "train reg_fs: 0.00207305490039289\n",
      "Epoch: 12500 train loss=0.004042744 valid loss= 0.006718492\n",
      "train reg_fs: 0.002068082569167018\n",
      "Epoch: 13000 train loss=0.002764167 valid loss= 0.007117591\n",
      "train reg_fs: 0.0020562808495014906\n",
      "Epoch: 13500 train loss=0.003388422 valid loss= 0.006921279\n",
      "train reg_fs: 0.002049338538199663\n",
      "Epoch: 14000 train loss=0.003926766 valid loss= 0.007192501\n",
      "train reg_fs: 0.002043074695393443\n",
      "Epoch: 14500 train loss=0.002855643 valid loss= 0.006891903\n",
      "train reg_fs: 0.0020328823011368513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:08:47,870]\u001b[0m Trial 22 finished with value: 0.005102653513283776 and parameters: {'lam': 0.0027371247962618265, 'learning_rate': 0.08463826747149511, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003414616 valid loss= 0.007119612\n",
      "train reg_fs: 0.002022662665694952\n",
      "Optimization Finished!\n",
      "test loss: 0.007596150040626526, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005102653513283776\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.026279490 valid loss= 0.015133752\n",
      "train reg_fs: 0.00843693595379591\n",
      "Epoch: 1000 train loss=0.017957419 valid loss= 0.014303993\n",
      "train reg_fs: 0.00842458475381136\n",
      "Epoch: 1500 train loss=0.016606482 valid loss= 0.014506951\n",
      "train reg_fs: 0.008291638456285\n",
      "Epoch: 2000 train loss=0.018051963 valid loss= 0.013418878\n",
      "train reg_fs: 0.008103893138468266\n",
      "Epoch: 2500 train loss=0.015410135 valid loss= 0.012752845\n",
      "train reg_fs: 0.007902144454419613\n",
      "Epoch: 3000 train loss=0.011685748 valid loss= 0.011916945\n",
      "train reg_fs: 0.007706106174737215\n",
      "Epoch: 3500 train loss=0.012516424 valid loss= 0.011534452\n",
      "train reg_fs: 0.007471045944839716\n",
      "Epoch: 4000 train loss=0.008701278 valid loss= 0.010413272\n",
      "train reg_fs: 0.007216311059892178\n",
      "Epoch: 4500 train loss=0.009583882 valid loss= 0.010393976\n",
      "train reg_fs: 0.006993523798882961\n",
      "Epoch: 5000 train loss=0.007873012 valid loss= 0.010062239\n",
      "train reg_fs: 0.006807801779359579\n",
      "Epoch: 5500 train loss=0.017479815 valid loss= 0.009687884\n",
      "train reg_fs: 0.006670351140201092\n",
      "Epoch: 6000 train loss=0.007633328 valid loss= 0.009365863\n",
      "train reg_fs: 0.006558357272297144\n",
      "Epoch: 6500 train loss=0.012022467 valid loss= 0.009232592\n",
      "train reg_fs: 0.006469216663390398\n",
      "Epoch: 7000 train loss=0.006688557 valid loss= 0.009024611\n",
      "train reg_fs: 0.0063989004120230675\n",
      "Epoch: 7500 train loss=0.011603221 valid loss= 0.008679331\n",
      "train reg_fs: 0.006344289053231478\n",
      "Epoch: 8000 train loss=0.010594506 valid loss= 0.008913548\n",
      "train reg_fs: 0.0062993839383125305\n",
      "Epoch: 8500 train loss=0.007030796 valid loss= 0.008930445\n",
      "train reg_fs: 0.00626265536993742\n",
      "Epoch: 9000 train loss=0.015613894 valid loss= 0.008540913\n",
      "train reg_fs: 0.006231450475752354\n",
      "Epoch: 9500 train loss=0.008927403 valid loss= 0.008551122\n",
      "train reg_fs: 0.006204993464052677\n",
      "Epoch: 10000 train loss=0.008975798 valid loss= 0.008611581\n",
      "train reg_fs: 0.006181760691106319\n",
      "Epoch: 10500 train loss=0.008528592 valid loss= 0.008449048\n",
      "train reg_fs: 0.006162108387798071\n",
      "Epoch: 11000 train loss=0.006835298 valid loss= 0.008292520\n",
      "train reg_fs: 0.0061445762403309345\n",
      "Epoch: 11500 train loss=0.006708930 valid loss= 0.008510596\n",
      "train reg_fs: 0.006129623390734196\n",
      "Epoch: 12000 train loss=0.007483651 valid loss= 0.008330893\n",
      "train reg_fs: 0.006116656120866537\n",
      "Epoch: 12500 train loss=0.006773093 valid loss= 0.008693112\n",
      "train reg_fs: 0.0061045680195093155\n",
      "Epoch: 13000 train loss=0.006280269 valid loss= 0.008470387\n",
      "train reg_fs: 0.006093417294323444\n",
      "Epoch: 13500 train loss=0.006607430 valid loss= 0.008119822\n",
      "train reg_fs: 0.006084055174142122\n",
      "Epoch: 14000 train loss=0.009961955 valid loss= 0.008165041\n",
      "train reg_fs: 0.006075066979974508\n",
      "Epoch: 14500 train loss=0.006567453 valid loss= 0.008574678\n",
      "train reg_fs: 0.0060670762322843075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:10:31,816]\u001b[0m Trial 23 finished with value: 0.0022044532547682073 and parameters: {'lam': 0.009935013652761861, 'learning_rate': 0.038629739037884324, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006892267 valid loss= 0.008140743\n",
      "train reg_fs: 0.006059916224330664\n",
      "Optimization Finished!\n",
      "test loss: 0.008013958111405373, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022044532547682073\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007948004 valid loss= 0.009662612\n",
      "train reg_fs: 0.0037514837458729744\n",
      "Epoch: 1000 train loss=0.010716124 valid loss= 0.008250263\n",
      "train reg_fs: 0.0036161956377327442\n",
      "Epoch: 1500 train loss=0.007024909 valid loss= 0.006864988\n",
      "train reg_fs: 0.0034833753015846014\n",
      "Epoch: 2000 train loss=0.007459047 valid loss= 0.006346475\n",
      "train reg_fs: 0.0033968142233788967\n",
      "Epoch: 2500 train loss=0.007364278 valid loss= 0.005944279\n",
      "train reg_fs: 0.003352121217176318\n",
      "Epoch: 3000 train loss=0.004759450 valid loss= 0.006267856\n",
      "train reg_fs: 0.0033269976265728474\n",
      "Epoch: 3500 train loss=0.008074616 valid loss= 0.005975218\n",
      "train reg_fs: 0.0033013501670211554\n",
      "Epoch: 4000 train loss=0.005059186 valid loss= 0.006321412\n",
      "train reg_fs: 0.0032709515653550625\n",
      "Epoch: 4500 train loss=0.004341454 valid loss= 0.006351808\n",
      "train reg_fs: 0.0032270459923893213\n",
      "Epoch: 5000 train loss=0.004565958 valid loss= 0.006449526\n",
      "train reg_fs: 0.0031644816044718027\n",
      "Epoch: 5500 train loss=0.003805276 valid loss= 0.006230395\n",
      "train reg_fs: 0.0030947241466492414\n",
      "Epoch: 6000 train loss=0.004020838 valid loss= 0.005769629\n",
      "train reg_fs: 0.003031008644029498\n",
      "Epoch: 6500 train loss=0.006486906 valid loss= 0.006377376\n",
      "train reg_fs: 0.0029709474183619022\n",
      "Epoch: 7000 train loss=0.005474451 valid loss= 0.005803851\n",
      "train reg_fs: 0.0029176368843764067\n",
      "Epoch: 7500 train loss=0.005283971 valid loss= 0.005650410\n",
      "train reg_fs: 0.002872381592169404\n",
      "Epoch: 8000 train loss=0.003991596 valid loss= 0.005644621\n",
      "train reg_fs: 0.0028362071607261896\n",
      "Epoch: 8500 train loss=0.007319473 valid loss= 0.005194285\n",
      "train reg_fs: 0.0028078528121113777\n",
      "Epoch: 9000 train loss=0.004381949 valid loss= 0.005187867\n",
      "train reg_fs: 0.0027855245862156153\n",
      "Epoch: 9500 train loss=0.003388033 valid loss= 0.005085896\n",
      "train reg_fs: 0.0027691200375556946\n",
      "Epoch: 10000 train loss=0.005025973 valid loss= 0.005577002\n",
      "train reg_fs: 0.002754253800958395\n",
      "Epoch: 10500 train loss=0.004159855 valid loss= 0.005028292\n",
      "train reg_fs: 0.0027415542863309383\n",
      "Epoch: 11000 train loss=0.007666983 valid loss= 0.004959246\n",
      "train reg_fs: 0.0027313486207276583\n",
      "Epoch: 11500 train loss=0.005864239 valid loss= 0.005335183\n",
      "train reg_fs: 0.002722317585721612\n",
      "Epoch: 12000 train loss=0.003403711 valid loss= 0.005273676\n",
      "train reg_fs: 0.002714442787691951\n",
      "Epoch: 12500 train loss=0.004917827 valid loss= 0.004825440\n",
      "train reg_fs: 0.002707729348912835\n",
      "Epoch: 13000 train loss=0.003870620 valid loss= 0.004852957\n",
      "train reg_fs: 0.002701906720176339\n",
      "Epoch: 13500 train loss=0.003332925 valid loss= 0.004774252\n",
      "train reg_fs: 0.002696544863283634\n",
      "Epoch: 14000 train loss=0.004190789 valid loss= 0.004808923\n",
      "train reg_fs: 0.002691980917006731\n",
      "Epoch: 14500 train loss=0.003380985 valid loss= 0.005058950\n",
      "train reg_fs: 0.002687747124582529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:12:16,348]\u001b[0m Trial 24 finished with value: 0.0022307479748219757 and parameters: {'lam': 0.004398492997092671, 'learning_rate': 0.07267065749346042, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003757828 valid loss= 0.004859296\n",
      "train reg_fs: 0.002684180159121752\n",
      "Optimization Finished!\n",
      "test loss: 0.004650640767067671, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022307479748219757\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019235877 valid loss= 0.010409055\n",
      "train reg_fs: 0.005939736496657133\n",
      "Epoch: 1000 train loss=0.011878712 valid loss= 0.010237385\n",
      "train reg_fs: 0.0059027764946222305\n",
      "Epoch: 1500 train loss=0.009258803 valid loss= 0.008257800\n",
      "train reg_fs: 0.005734850652515888\n",
      "Epoch: 2000 train loss=0.015386178 valid loss= 0.008107789\n",
      "train reg_fs: 0.0054770298302173615\n",
      "Epoch: 2500 train loss=0.011323310 valid loss= 0.007067992\n",
      "train reg_fs: 0.005199309438467026\n",
      "Epoch: 3000 train loss=0.010542240 valid loss= 0.007128745\n",
      "train reg_fs: 0.0049910410307347775\n",
      "Epoch: 3500 train loss=0.009673648 valid loss= 0.006060916\n",
      "train reg_fs: 0.004846625961363316\n",
      "Epoch: 4000 train loss=0.007542241 valid loss= 0.006311764\n",
      "train reg_fs: 0.004743317142128944\n",
      "Epoch: 4500 train loss=0.010123249 valid loss= 0.005979600\n",
      "train reg_fs: 0.004670985043048859\n",
      "Epoch: 5000 train loss=0.005373511 valid loss= 0.006019586\n",
      "train reg_fs: 0.004623978398740292\n",
      "Epoch: 5500 train loss=0.005551057 valid loss= 0.005692601\n",
      "train reg_fs: 0.004585782065987587\n",
      "Epoch: 6000 train loss=0.005729081 valid loss= 0.005480530\n",
      "train reg_fs: 0.004548298195004463\n",
      "Epoch: 6500 train loss=0.004720152 valid loss= 0.005517961\n",
      "train reg_fs: 0.004525963217020035\n",
      "Epoch: 7000 train loss=0.005125117 valid loss= 0.006346702\n",
      "train reg_fs: 0.004500969313085079\n",
      "Epoch: 7500 train loss=0.005183593 valid loss= 0.005643074\n",
      "train reg_fs: 0.004476750269532204\n",
      "Epoch: 8000 train loss=0.008467393 valid loss= 0.005265107\n",
      "train reg_fs: 0.004458141978830099\n",
      "Epoch: 8500 train loss=0.008689668 valid loss= 0.005619179\n",
      "train reg_fs: 0.004437696188688278\n",
      "Epoch: 9000 train loss=0.005264379 valid loss= 0.005451536\n",
      "train reg_fs: 0.0044245049357414246\n",
      "Epoch: 9500 train loss=0.004908582 valid loss= 0.005889267\n",
      "train reg_fs: 0.004411506932228804\n",
      "Epoch: 10000 train loss=0.004988475 valid loss= 0.005447428\n",
      "train reg_fs: 0.004404765088111162\n",
      "Epoch: 10500 train loss=0.004582230 valid loss= 0.005812725\n",
      "train reg_fs: 0.0043912604451179504\n",
      "Epoch: 11000 train loss=0.005678107 valid loss= 0.005474830\n",
      "train reg_fs: 0.004383853171020746\n",
      "Epoch: 11500 train loss=0.005238575 valid loss= 0.006112897\n",
      "train reg_fs: 0.0043747457675635815\n",
      "Epoch: 12000 train loss=0.007305055 valid loss= 0.006233538\n",
      "train reg_fs: 0.004363857675343752\n",
      "Epoch: 12500 train loss=0.005152158 valid loss= 0.006052462\n",
      "train reg_fs: 0.004355181474238634\n",
      "Epoch: 13000 train loss=0.014510233 valid loss= 0.006049630\n",
      "train reg_fs: 0.004345174878835678\n",
      "Epoch: 13500 train loss=0.006154343 valid loss= 0.005871272\n",
      "train reg_fs: 0.0043307882733643055\n",
      "Epoch: 14000 train loss=0.006586871 valid loss= 0.006026238\n",
      "train reg_fs: 0.004317483399063349\n",
      "Epoch: 14500 train loss=0.007121480 valid loss= 0.005783249\n",
      "train reg_fs: 0.004307209514081478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:14:02,302]\u001b[0m Trial 25 finished with value: 0.001995706525238943 and parameters: {'lam': 0.006807995384878954, 'learning_rate': 0.096787800102207, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004364511 valid loss= 0.006267567\n",
      "train reg_fs: 0.004297922365367413\n",
      "Optimization Finished!\n",
      "test loss: 0.00625956617295742, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001995706525238943\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012478332 valid loss= 0.009147539\n",
      "train reg_fs: 0.0018200112972408533\n",
      "Epoch: 1000 train loss=0.019452624 valid loss= 0.008923326\n",
      "train reg_fs: 0.001840866170823574\n",
      "Epoch: 1500 train loss=0.009058432 valid loss= 0.008859179\n",
      "train reg_fs: 0.0018541578901931643\n",
      "Epoch: 2000 train loss=0.011160480 valid loss= 0.008088523\n",
      "train reg_fs: 0.0018589271930977702\n",
      "Epoch: 2500 train loss=0.010395623 valid loss= 0.007591259\n",
      "train reg_fs: 0.0018532638205215335\n",
      "Epoch: 3000 train loss=0.007113291 valid loss= 0.007663637\n",
      "train reg_fs: 0.0018407275201752782\n",
      "Epoch: 3500 train loss=0.007944493 valid loss= 0.007199835\n",
      "train reg_fs: 0.0018242130754515529\n",
      "Epoch: 4000 train loss=0.007822944 valid loss= 0.006935195\n",
      "train reg_fs: 0.0018030157079920173\n",
      "Epoch: 4500 train loss=0.005719220 valid loss= 0.006293472\n",
      "train reg_fs: 0.001781527535058558\n",
      "Epoch: 5000 train loss=0.005573644 valid loss= 0.005684665\n",
      "train reg_fs: 0.0017631363589316607\n",
      "Epoch: 5500 train loss=0.007148780 valid loss= 0.005607524\n",
      "train reg_fs: 0.001743397442623973\n",
      "Epoch: 6000 train loss=0.010496023 valid loss= 0.005537122\n",
      "train reg_fs: 0.0017247239593416452\n",
      "Epoch: 6500 train loss=0.004749807 valid loss= 0.004773022\n",
      "train reg_fs: 0.0017062579281628132\n",
      "Epoch: 7000 train loss=0.004691091 valid loss= 0.004897701\n",
      "train reg_fs: 0.001687861979007721\n",
      "Epoch: 7500 train loss=0.016510047 valid loss= 0.005134347\n",
      "train reg_fs: 0.0016749773640185595\n",
      "Epoch: 8000 train loss=0.005677643 valid loss= 0.004716059\n",
      "train reg_fs: 0.0016631417674943805\n",
      "Epoch: 8500 train loss=0.003947271 valid loss= 0.004445215\n",
      "train reg_fs: 0.0016544347163289785\n",
      "Epoch: 9000 train loss=0.004956110 valid loss= 0.004819768\n",
      "train reg_fs: 0.0016473152209073305\n",
      "Epoch: 9500 train loss=0.006509434 valid loss= 0.005067925\n",
      "train reg_fs: 0.001641736482270062\n",
      "Epoch: 10000 train loss=0.004219122 valid loss= 0.004996588\n",
      "train reg_fs: 0.0016363636823371053\n",
      "Epoch: 10500 train loss=0.004048767 valid loss= 0.004897574\n",
      "train reg_fs: 0.0016325378092005849\n",
      "Epoch: 11000 train loss=0.007955042 valid loss= 0.004672498\n",
      "train reg_fs: 0.0016285289311781526\n",
      "Epoch: 11500 train loss=0.004546001 valid loss= 0.004909381\n",
      "train reg_fs: 0.001624656026251614\n",
      "Epoch: 12000 train loss=0.004325400 valid loss= 0.005044343\n",
      "train reg_fs: 0.0016206199070438743\n",
      "Epoch: 12500 train loss=0.003035652 valid loss= 0.004944857\n",
      "train reg_fs: 0.00161561684217304\n",
      "Epoch: 13000 train loss=0.003060985 valid loss= 0.004903522\n",
      "train reg_fs: 0.00161148386541754\n",
      "Epoch: 13500 train loss=0.003641142 valid loss= 0.004687562\n",
      "train reg_fs: 0.0016050862614065409\n",
      "Epoch: 14000 train loss=0.003463539 valid loss= 0.004862925\n",
      "train reg_fs: 0.0015991120599210262\n",
      "Epoch: 14500 train loss=0.013432652 valid loss= 0.004736320\n",
      "train reg_fs: 0.001591584412381053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:15:46,009]\u001b[0m Trial 26 finished with value: 0.003120365656689662 and parameters: {'lam': 0.0021261770578585764, 'learning_rate': 0.026802292036873558, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004678659 valid loss= 0.004694184\n",
      "train reg_fs: 0.0015852408250793815\n",
      "Optimization Finished!\n",
      "test loss: 0.0045986054465174675, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003120365656689662\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013646440 valid loss= 0.009013509\n",
      "train reg_fs: 0.0008763110381551087\n",
      "Epoch: 1000 train loss=0.008543363 valid loss= 0.008948126\n",
      "train reg_fs: 0.0008841360104270279\n",
      "Epoch: 1500 train loss=0.012047547 valid loss= 0.008940082\n",
      "train reg_fs: 0.0008900996181182563\n",
      "Epoch: 2000 train loss=0.014237564 valid loss= 0.008238799\n",
      "train reg_fs: 0.0008946321904659271\n",
      "Epoch: 2500 train loss=0.014020690 valid loss= 0.007556598\n",
      "train reg_fs: 0.000897073361556977\n",
      "Epoch: 3000 train loss=0.003279930 valid loss= 0.007913991\n",
      "train reg_fs: 0.0008986250031739473\n",
      "Epoch: 3500 train loss=0.008664410 valid loss= 0.007949557\n",
      "train reg_fs: 0.0008981676655821502\n",
      "Epoch: 4000 train loss=0.008209566 valid loss= 0.007477948\n",
      "train reg_fs: 0.0008964748121798038\n",
      "Epoch: 4500 train loss=0.007081697 valid loss= 0.007352676\n",
      "train reg_fs: 0.0008944089058786631\n",
      "Epoch: 5000 train loss=0.010296910 valid loss= 0.007078999\n",
      "train reg_fs: 0.0008905492722988129\n",
      "Epoch: 5500 train loss=0.008274750 valid loss= 0.006998350\n",
      "train reg_fs: 0.0008858554647304118\n",
      "Epoch: 6000 train loss=0.008521635 valid loss= 0.006628213\n",
      "train reg_fs: 0.0008808267884887755\n",
      "Epoch: 6500 train loss=0.004637958 valid loss= 0.006023111\n",
      "train reg_fs: 0.0008750358829274774\n",
      "Epoch: 7000 train loss=0.006916694 valid loss= 0.005843106\n",
      "train reg_fs: 0.0008701232145540416\n",
      "Epoch: 7500 train loss=0.004708805 valid loss= 0.005297247\n",
      "train reg_fs: 0.0008643913897685707\n",
      "Epoch: 8000 train loss=0.007319307 valid loss= 0.005141682\n",
      "train reg_fs: 0.0008596224361099303\n",
      "Epoch: 8500 train loss=0.004581860 valid loss= 0.005200265\n",
      "train reg_fs: 0.0008548584301024675\n",
      "Epoch: 9000 train loss=0.018621832 valid loss= 0.004403393\n",
      "train reg_fs: 0.0008504679426550865\n",
      "Epoch: 9500 train loss=0.004699187 valid loss= 0.004351939\n",
      "train reg_fs: 0.0008463009726256132\n",
      "Epoch: 10000 train loss=0.014385124 valid loss= 0.004165634\n",
      "train reg_fs: 0.0008417730568908155\n",
      "Epoch: 10500 train loss=0.007077404 valid loss= 0.003966502\n",
      "train reg_fs: 0.0008374273893423378\n",
      "Epoch: 11000 train loss=0.007105122 valid loss= 0.003563061\n",
      "train reg_fs: 0.0008325873641297221\n",
      "Epoch: 11500 train loss=0.003854173 valid loss= 0.003514002\n",
      "train reg_fs: 0.0008279979228973389\n",
      "Epoch: 12000 train loss=0.003741068 valid loss= 0.003418164\n",
      "train reg_fs: 0.0008233553380705416\n",
      "Epoch: 12500 train loss=0.003038209 valid loss= 0.002865571\n",
      "train reg_fs: 0.0008187979110516608\n",
      "Epoch: 13000 train loss=0.004822357 valid loss= 0.002795129\n",
      "train reg_fs: 0.0008144626044668257\n",
      "Epoch: 13500 train loss=0.004425835 valid loss= 0.002876675\n",
      "train reg_fs: 0.0008110137423500419\n",
      "Epoch: 14000 train loss=0.006247691 valid loss= 0.002597523\n",
      "train reg_fs: 0.0008074629004113376\n",
      "Epoch: 14500 train loss=0.005295918 valid loss= 0.002609653\n",
      "train reg_fs: 0.0008042319677770138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:17:30,003]\u001b[0m Trial 27 finished with value: 0.0018091932396352422 and parameters: {'lam': 0.001033429525194921, 'learning_rate': 0.013957671322118706, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006273623 valid loss= 0.002618114\n",
      "train reg_fs: 0.0008014144259504974\n",
      "Optimization Finished!\n",
      "test loss: 0.002874848200008273, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0018091932396352422\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010951998 valid loss= 0.007379653\n",
      "train reg_fs: 0.0010986028937622905\n",
      "Epoch: 1000 train loss=0.009744055 valid loss= 0.004499125\n",
      "train reg_fs: 0.0010300298454239964\n",
      "Epoch: 1500 train loss=0.009162490 valid loss= 0.003920902\n",
      "train reg_fs: 0.0009968439117074013\n",
      "Epoch: 2000 train loss=0.003595181 valid loss= 0.004418458\n",
      "train reg_fs: 0.0009827950270846486\n",
      "Epoch: 2500 train loss=0.003637810 valid loss= 0.003811312\n",
      "train reg_fs: 0.0009583411156199872\n",
      "Epoch: 3000 train loss=0.001796979 valid loss= 0.003793355\n",
      "train reg_fs: 0.0009269638685509562\n",
      "Epoch: 3500 train loss=0.010023518 valid loss= 0.004174130\n",
      "train reg_fs: 0.0009010067442432046\n",
      "Epoch: 4000 train loss=0.001378839 valid loss= 0.003293867\n",
      "train reg_fs: 0.0008784786914475262\n",
      "Epoch: 4500 train loss=0.001616470 valid loss= 0.003392675\n",
      "train reg_fs: 0.0008554796222597361\n",
      "Epoch: 5000 train loss=0.001388961 valid loss= 0.003455560\n",
      "train reg_fs: 0.0008399246726185083\n",
      "Epoch: 5500 train loss=0.001177892 valid loss= 0.003361735\n",
      "train reg_fs: 0.0008291605627164245\n",
      "Epoch: 6000 train loss=0.001462793 valid loss= 0.003469431\n",
      "train reg_fs: 0.0008217554423026741\n",
      "Epoch: 6500 train loss=0.004593932 valid loss= 0.003401350\n",
      "train reg_fs: 0.0008160328725352883\n",
      "Epoch: 7000 train loss=0.003154140 valid loss= 0.003308340\n",
      "train reg_fs: 0.0008115974487736821\n",
      "Epoch: 7500 train loss=0.001102035 valid loss= 0.003148698\n",
      "train reg_fs: 0.0008080799016170204\n",
      "Epoch: 8000 train loss=0.002581127 valid loss= 0.003228889\n",
      "train reg_fs: 0.000804993265774101\n",
      "Epoch: 8500 train loss=0.001762790 valid loss= 0.002891298\n",
      "train reg_fs: 0.0008028000593185425\n",
      "Epoch: 9000 train loss=0.001165362 valid loss= 0.003329315\n",
      "train reg_fs: 0.000800881942268461\n",
      "Epoch: 9500 train loss=0.001468517 valid loss= 0.003210214\n",
      "train reg_fs: 0.0007993191247805953\n",
      "Epoch: 10000 train loss=0.001061424 valid loss= 0.003670928\n",
      "train reg_fs: 0.000797949789557606\n",
      "Epoch: 10500 train loss=0.002134672 valid loss= 0.003341434\n",
      "train reg_fs: 0.0007968858699314296\n",
      "Epoch: 11000 train loss=0.001490335 valid loss= 0.002963198\n",
      "train reg_fs: 0.0007957685738801956\n",
      "Epoch: 11500 train loss=0.002728038 valid loss= 0.003250311\n",
      "train reg_fs: 0.0007948520360514522\n",
      "Epoch: 12000 train loss=0.001031008 valid loss= 0.002860746\n",
      "train reg_fs: 0.0007939859642647207\n",
      "Epoch: 12500 train loss=0.003174820 valid loss= 0.003097458\n",
      "train reg_fs: 0.0007931360742077231\n",
      "Epoch: 13000 train loss=0.001130947 valid loss= 0.003171984\n",
      "train reg_fs: 0.000792386825196445\n",
      "Epoch: 13500 train loss=0.002516366 valid loss= 0.003555062\n",
      "train reg_fs: 0.0007917101611383259\n",
      "Epoch: 14000 train loss=0.001288008 valid loss= 0.002730957\n",
      "train reg_fs: 0.0007911028806120157\n",
      "Epoch: 14500 train loss=0.001096576 valid loss= 0.003190412\n",
      "train reg_fs: 0.0007905775564722717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:19:14,343]\u001b[0m Trial 28 finished with value: 0.0024083218259417934 and parameters: {'lam': 0.0013075666060773084, 'learning_rate': 0.14983016424965628, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001872193 valid loss= 0.003178925\n",
      "train reg_fs: 0.0007900656783021986\n",
      "Optimization Finished!\n",
      "test loss: 0.0028928667306900024, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024083218259417934\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011957195 valid loss= 0.009976847\n",
      "train reg_fs: 0.0025381201412528753\n",
      "Epoch: 1000 train loss=0.015083417 valid loss= 0.009639069\n",
      "train reg_fs: 0.002559237414970994\n",
      "Epoch: 1500 train loss=0.014404693 valid loss= 0.009442158\n",
      "train reg_fs: 0.0025756387040019035\n",
      "Epoch: 2000 train loss=0.016773624 valid loss= 0.008925823\n",
      "train reg_fs: 0.0025910327676683664\n",
      "Epoch: 2500 train loss=0.009821795 valid loss= 0.008728768\n",
      "train reg_fs: 0.0026030992157757282\n",
      "Epoch: 3000 train loss=0.026438486 valid loss= 0.008547764\n",
      "train reg_fs: 0.002613023854792118\n",
      "Epoch: 3500 train loss=0.022219738 valid loss= 0.008552734\n",
      "train reg_fs: 0.002620765706524253\n",
      "Epoch: 4000 train loss=0.007503522 valid loss= 0.008350412\n",
      "train reg_fs: 0.002628440735861659\n",
      "Epoch: 4500 train loss=0.010724979 valid loss= 0.008247899\n",
      "train reg_fs: 0.002634212141856551\n",
      "Epoch: 5000 train loss=0.012560460 valid loss= 0.008588758\n",
      "train reg_fs: 0.002637404017150402\n",
      "Epoch: 5500 train loss=0.015714984 valid loss= 0.008078959\n",
      "train reg_fs: 0.0026416094042360783\n",
      "Epoch: 6000 train loss=0.007489478 valid loss= 0.007920303\n",
      "train reg_fs: 0.002645031549036503\n",
      "Epoch: 6500 train loss=0.012130985 valid loss= 0.008464574\n",
      "train reg_fs: 0.002646305598318577\n",
      "Epoch: 7000 train loss=0.008146826 valid loss= 0.007997273\n",
      "train reg_fs: 0.002646490465849638\n",
      "Epoch: 7500 train loss=0.016459253 valid loss= 0.007973890\n",
      "train reg_fs: 0.002645745873451233\n",
      "Epoch: 8000 train loss=0.005618298 valid loss= 0.007753553\n",
      "train reg_fs: 0.0026445086114108562\n",
      "Epoch: 8500 train loss=0.009499465 valid loss= 0.007532926\n",
      "train reg_fs: 0.002642519772052765\n",
      "Epoch: 9000 train loss=0.008346509 valid loss= 0.007504982\n",
      "train reg_fs: 0.0026392906438559294\n",
      "Epoch: 9500 train loss=0.014634086 valid loss= 0.007465953\n",
      "train reg_fs: 0.002635107608512044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:20:24,717]\u001b[0m Trial 29 finished with value: 0.00478063638432937 and parameters: {'lam': 0.002986559942070301, 'learning_rate': 0.012883894122722526, 'num_epoch': 10000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.020219557 valid loss= 0.007420425\n",
      "train reg_fs: 0.0026314209681004286\n",
      "Optimization Finished!\n",
      "test loss: 0.00803220085799694, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00478063638432937\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016120236 valid loss= 0.009250505\n",
      "train reg_fs: 0.0036556010600179434\n",
      "Epoch: 1000 train loss=0.006420803 valid loss= 0.010028756\n",
      "train reg_fs: 0.0035788461100310087\n",
      "Epoch: 1500 train loss=0.009471700 valid loss= 0.007130092\n",
      "train reg_fs: 0.0034099051263183355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:20:40,169]\u001b[0m Trial 30 finished with value: 0.002682153064652071 and parameters: {'lam': 0.0041844338339216535, 'learning_rate': 0.1072313599532026, 'num_epoch': 2000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.007838839 valid loss= 0.006050041\n",
      "train reg_fs: 0.0032887409906834364\n",
      "Optimization Finished!\n",
      "test loss: 0.006701227277517319, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002682153064652071\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015946584 valid loss= 0.009548680\n",
      "train reg_fs: 0.0009004365419968963\n",
      "Epoch: 1000 train loss=0.018151030 valid loss= 0.009776235\n",
      "train reg_fs: 0.0009086696663871408\n",
      "Epoch: 1500 train loss=0.011280173 valid loss= 0.009339950\n",
      "train reg_fs: 0.0009149961988441646\n",
      "Epoch: 2000 train loss=0.014808706 valid loss= 0.009395180\n",
      "train reg_fs: 0.0009204309899359941\n",
      "Epoch: 2500 train loss=0.019430917 valid loss= 0.009071880\n",
      "train reg_fs: 0.0009243868989869952\n",
      "Epoch: 3000 train loss=0.017751105 valid loss= 0.008429475\n",
      "train reg_fs: 0.0009275652118958533\n",
      "Epoch: 3500 train loss=0.006403077 valid loss= 0.008923195\n",
      "train reg_fs: 0.0009294122573919594\n",
      "Epoch: 4000 train loss=0.008055083 valid loss= 0.008580203\n",
      "train reg_fs: 0.0009301940444856882\n",
      "Epoch: 4500 train loss=0.017656174 valid loss= 0.008723066\n",
      "train reg_fs: 0.0009301598183810711\n",
      "Epoch: 5000 train loss=0.023080783 valid loss= 0.008880125\n",
      "train reg_fs: 0.0009293397306464612\n",
      "Epoch: 5500 train loss=0.005950797 valid loss= 0.008093820\n",
      "train reg_fs: 0.0009275504853576422\n",
      "Epoch: 6000 train loss=0.011603094 valid loss= 0.008869429\n",
      "train reg_fs: 0.0009249498252756894\n",
      "Epoch: 6500 train loss=0.004339028 valid loss= 0.008625756\n",
      "train reg_fs: 0.0009218145860359073\n",
      "Epoch: 7000 train loss=0.015254110 valid loss= 0.008994465\n",
      "train reg_fs: 0.0009179141488857567\n",
      "Epoch: 7500 train loss=0.006566694 valid loss= 0.008925984\n",
      "train reg_fs: 0.000912617368157953\n",
      "Epoch: 8000 train loss=0.012584675 valid loss= 0.008025972\n",
      "train reg_fs: 0.0009074946865439415\n",
      "Epoch: 8500 train loss=0.009516077 valid loss= 0.008769580\n",
      "train reg_fs: 0.0009022336453199387\n",
      "Epoch: 9000 train loss=0.007021911 valid loss= 0.008156508\n",
      "train reg_fs: 0.0008973467047326267\n",
      "Epoch: 9500 train loss=0.005748772 valid loss= 0.008191315\n",
      "train reg_fs: 0.0008923697751015425\n",
      "Epoch: 10000 train loss=0.005278650 valid loss= 0.008604662\n",
      "train reg_fs: 0.0008882282418198884\n",
      "Epoch: 10500 train loss=0.008494254 valid loss= 0.008897963\n",
      "train reg_fs: 0.0008840483496896923\n",
      "Epoch: 11000 train loss=0.006925377 valid loss= 0.008037178\n",
      "train reg_fs: 0.0008811152074486017\n",
      "Epoch: 11500 train loss=0.009639648 valid loss= 0.007849464\n",
      "train reg_fs: 0.0008781432989053428\n",
      "Epoch: 12000 train loss=0.006802907 valid loss= 0.008242147\n",
      "train reg_fs: 0.0008748648106120527\n",
      "Epoch: 12500 train loss=0.006019691 valid loss= 0.007428685\n",
      "train reg_fs: 0.0008721419144421816\n",
      "Epoch: 13000 train loss=0.004352058 valid loss= 0.008002836\n",
      "train reg_fs: 0.0008695978904142976\n",
      "Epoch: 13500 train loss=0.009831977 valid loss= 0.007329523\n",
      "train reg_fs: 0.0008674440323375165\n",
      "Epoch: 14000 train loss=0.007309542 valid loss= 0.007802531\n",
      "train reg_fs: 0.0008656561258248985\n",
      "Epoch: 14500 train loss=0.005208451 valid loss= 0.007889414\n",
      "train reg_fs: 0.0008639467414468527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:22:23,852]\u001b[0m Trial 31 finished with value: 0.0063234255176005515 and parameters: {'lam': 0.0010658271896825445, 'learning_rate': 0.013662070558080986, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006608738 valid loss= 0.007215418\n",
      "train reg_fs: 0.0008625808986835182\n",
      "Optimization Finished!\n",
      "test loss: 0.006859173998236656, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0063234255176005515\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020768821 valid loss= 0.012296095\n",
      "train reg_fs: 0.005376812536269426\n",
      "Epoch: 1000 train loss=0.016552674 valid loss= 0.011822985\n",
      "train reg_fs: 0.005419852677732706\n",
      "Epoch: 1500 train loss=0.014921581 valid loss= 0.011791265\n",
      "train reg_fs: 0.005453987512737513\n",
      "Epoch: 2000 train loss=0.015866755 valid loss= 0.011380507\n",
      "train reg_fs: 0.00547942565754056\n",
      "Epoch: 2500 train loss=0.013614031 valid loss= 0.011287465\n",
      "train reg_fs: 0.005494837183505297\n",
      "Epoch: 3000 train loss=0.017200848 valid loss= 0.011045218\n",
      "train reg_fs: 0.005508140195161104\n",
      "Epoch: 3500 train loss=0.014780214 valid loss= 0.011027787\n",
      "train reg_fs: 0.005509863141924143\n",
      "Epoch: 4000 train loss=0.009021443 valid loss= 0.011149734\n",
      "train reg_fs: 0.005507306195795536\n",
      "Epoch: 4500 train loss=0.009613729 valid loss= 0.011114756\n",
      "train reg_fs: 0.005498540587723255\n",
      "Epoch: 5000 train loss=0.008299012 valid loss= 0.010525931\n",
      "train reg_fs: 0.005481403321027756\n",
      "Epoch: 5500 train loss=0.017676776 valid loss= 0.010182094\n",
      "train reg_fs: 0.0054540191777050495\n",
      "Epoch: 6000 train loss=0.008208038 valid loss= 0.010210183\n",
      "train reg_fs: 0.005426239222288132\n",
      "Epoch: 6500 train loss=0.014771102 valid loss= 0.010508733\n",
      "train reg_fs: 0.005381972994655371\n",
      "Epoch: 7000 train loss=0.026653402 valid loss= 0.010071134\n",
      "train reg_fs: 0.005329471547156572\n",
      "Epoch: 7500 train loss=0.010971645 valid loss= 0.009797735\n",
      "train reg_fs: 0.005269072484225035\n",
      "Epoch: 8000 train loss=0.021670818 valid loss= 0.009159398\n",
      "train reg_fs: 0.005204482935369015\n",
      "Epoch: 8500 train loss=0.007454361 valid loss= 0.008624432\n",
      "train reg_fs: 0.005134413950145245\n",
      "Epoch: 9000 train loss=0.007811611 valid loss= 0.008198177\n",
      "train reg_fs: 0.005070353392511606\n",
      "Epoch: 9500 train loss=0.008412802 valid loss= 0.008638236\n",
      "train reg_fs: 0.005010675638914108\n",
      "Epoch: 10000 train loss=0.008194502 valid loss= 0.007849626\n",
      "train reg_fs: 0.0049531059339642525\n",
      "Epoch: 10500 train loss=0.008065333 valid loss= 0.007835763\n",
      "train reg_fs: 0.00490217050537467\n",
      "Epoch: 11000 train loss=0.008569371 valid loss= 0.007778268\n",
      "train reg_fs: 0.004849938675761223\n",
      "Epoch: 11500 train loss=0.011116866 valid loss= 0.007700869\n",
      "train reg_fs: 0.004806056153029203\n",
      "Epoch: 12000 train loss=0.009104842 valid loss= 0.007907543\n",
      "train reg_fs: 0.004766414873301983\n",
      "Epoch: 12500 train loss=0.009244502 valid loss= 0.007826873\n",
      "train reg_fs: 0.004729973617941141\n",
      "Epoch: 13000 train loss=0.007408323 valid loss= 0.007751160\n",
      "train reg_fs: 0.004699675366282463\n",
      "Epoch: 13500 train loss=0.009262549 valid loss= 0.007691899\n",
      "train reg_fs: 0.004667474422603846\n",
      "Epoch: 14000 train loss=0.005122624 valid loss= 0.007725641\n",
      "train reg_fs: 0.004640439059585333\n",
      "Epoch: 14500 train loss=0.007084757 valid loss= 0.007808609\n",
      "train reg_fs: 0.004613661207258701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:24:10,721]\u001b[0m Trial 32 finished with value: 0.002886058061732373 and parameters: {'lam': 0.006328537272903169, 'learning_rate': 0.016957524232583013, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.008806572 valid loss= 0.007594971\n",
      "train reg_fs: 0.0045879618264734745\n",
      "Optimization Finished!\n",
      "test loss: 0.007790253963321447, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002886058061732373\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008853611 valid loss= 0.007238714\n",
      "train reg_fs: 0.0008641256135888398\n",
      "Epoch: 1000 train loss=0.012829464 valid loss= 0.006649419\n",
      "train reg_fs: 0.0008701591868884861\n",
      "Epoch: 1500 train loss=0.005428165 valid loss= 0.006234271\n",
      "train reg_fs: 0.0008591479854658246\n",
      "Epoch: 2000 train loss=0.008343542 valid loss= 0.004918486\n",
      "train reg_fs: 0.0008357332553714514\n",
      "Epoch: 2500 train loss=0.004074561 valid loss= 0.004145841\n",
      "train reg_fs: 0.0008104561711661518\n",
      "Epoch: 3000 train loss=0.004189766 valid loss= 0.003730175\n",
      "train reg_fs: 0.0007898519979789853\n",
      "Epoch: 3500 train loss=0.001984360 valid loss= 0.003287266\n",
      "train reg_fs: 0.0007766730850562453\n",
      "Epoch: 4000 train loss=0.006048215 valid loss= 0.003327982\n",
      "train reg_fs: 0.0007676822133362293\n",
      "Epoch: 4500 train loss=0.007899912 valid loss= 0.003305536\n",
      "train reg_fs: 0.000758822076022625\n",
      "Epoch: 5000 train loss=0.003667250 valid loss= 0.003495348\n",
      "train reg_fs: 0.0007502693915739655\n",
      "Epoch: 5500 train loss=0.002415114 valid loss= 0.003138529\n",
      "train reg_fs: 0.000742332951631397\n",
      "Epoch: 6000 train loss=0.003781786 valid loss= 0.003143330\n",
      "train reg_fs: 0.0007345762569457293\n",
      "Epoch: 6500 train loss=0.018407747 valid loss= 0.003388044\n",
      "train reg_fs: 0.0007273523951880634\n",
      "Epoch: 7000 train loss=0.002957796 valid loss= 0.003523054\n",
      "train reg_fs: 0.0007206808659248054\n",
      "Epoch: 7500 train loss=0.004356041 valid loss= 0.003158155\n",
      "train reg_fs: 0.0007136317435652018\n",
      "Epoch: 8000 train loss=0.001137726 valid loss= 0.003097056\n",
      "train reg_fs: 0.0007075570756569505\n",
      "Epoch: 8500 train loss=0.001603155 valid loss= 0.003130859\n",
      "train reg_fs: 0.000701274024322629\n",
      "Epoch: 9000 train loss=0.002087234 valid loss= 0.003162037\n",
      "train reg_fs: 0.0006956956349313259\n",
      "Epoch: 9500 train loss=0.002120357 valid loss= 0.003039974\n",
      "train reg_fs: 0.0006902898894622922\n",
      "Epoch: 10000 train loss=0.001706695 valid loss= 0.003402432\n",
      "train reg_fs: 0.0006852996302768588\n",
      "Epoch: 10500 train loss=0.001717314 valid loss= 0.003212309\n",
      "train reg_fs: 0.0006794051732867956\n",
      "Epoch: 11000 train loss=0.001475122 valid loss= 0.003084935\n",
      "train reg_fs: 0.000674996234010905\n",
      "Epoch: 11500 train loss=0.001566840 valid loss= 0.003109148\n",
      "train reg_fs: 0.0006708634900860488\n",
      "Epoch: 12000 train loss=0.002519676 valid loss= 0.002970211\n",
      "train reg_fs: 0.0006666776607744396\n",
      "Epoch: 12500 train loss=0.003035235 valid loss= 0.003049607\n",
      "train reg_fs: 0.0006628948030993342\n",
      "Epoch: 13000 train loss=0.002679387 valid loss= 0.002966411\n",
      "train reg_fs: 0.0006595921004191041\n",
      "Epoch: 13500 train loss=0.005365109 valid loss= 0.003016976\n",
      "train reg_fs: 0.0006565889343619347\n",
      "Epoch: 14000 train loss=0.001734866 valid loss= 0.003061783\n",
      "train reg_fs: 0.0006535827997140586\n",
      "Epoch: 14500 train loss=0.002637194 valid loss= 0.002804711\n",
      "train reg_fs: 0.0006508597289212048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:25:55,322]\u001b[0m Trial 33 finished with value: 0.0023037814449502368 and parameters: {'lam': 0.0010015586377982656, 'learning_rate': 0.05161137582568779, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003097562 valid loss= 0.002949656\n",
      "train reg_fs: 0.0006485358462668955\n",
      "Optimization Finished!\n",
      "test loss: 0.0027042541187256575, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023037814449502368\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017045533 valid loss= 0.012061294\n",
      "train reg_fs: 0.004824168514460325\n",
      "Epoch: 1000 train loss=0.010896772 valid loss= 0.011708938\n",
      "train reg_fs: 0.0048516616225242615\n",
      "Epoch: 1500 train loss=0.013495203 valid loss= 0.011697495\n",
      "train reg_fs: 0.0048782736994326115\n",
      "Epoch: 2000 train loss=0.014611190 valid loss= 0.011426772\n",
      "train reg_fs: 0.004897941369563341\n",
      "Epoch: 2500 train loss=0.020068320 valid loss= 0.011325294\n",
      "train reg_fs: 0.0049146669916808605\n",
      "Epoch: 3000 train loss=0.011232531 valid loss= 0.011022676\n",
      "train reg_fs: 0.0049301073886454105\n",
      "Epoch: 3500 train loss=0.013968168 valid loss= 0.010849737\n",
      "train reg_fs: 0.004941571969538927\n",
      "Epoch: 4000 train loss=0.015884049 valid loss= 0.010991219\n",
      "train reg_fs: 0.004948877729475498\n",
      "Epoch: 4500 train loss=0.010659041 valid loss= 0.010386387\n",
      "train reg_fs: 0.0049543436616659164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:26:30,996]\u001b[0m Trial 34 finished with value: 0.0053717005369515024 and parameters: {'lam': 0.005693036078687218, 'learning_rate': 0.010076468673395893, 'num_epoch': 5000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.015978443 valid loss= 0.010320956\n",
      "train reg_fs: 0.004954982083290815\n",
      "Optimization Finished!\n",
      "test loss: 0.012236728332936764, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0053717005369515024\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013602710 valid loss= 0.014245586\n",
      "train reg_fs: 0.0071737561374902725\n",
      "Epoch: 1000 train loss=0.026179060 valid loss= 0.013733223\n",
      "train reg_fs: 0.007212682627141476\n",
      "Epoch: 1500 train loss=0.021673989 valid loss= 0.013158970\n",
      "train reg_fs: 0.007236639503389597\n",
      "Epoch: 2000 train loss=0.011716800 valid loss= 0.012990926\n",
      "train reg_fs: 0.007245590444654226\n",
      "Epoch: 2500 train loss=0.023673728 valid loss= 0.012807190\n",
      "train reg_fs: 0.007238018326461315\n",
      "Epoch: 3000 train loss=0.014133826 valid loss= 0.012153292\n",
      "train reg_fs: 0.007216166704893112\n",
      "Epoch: 3500 train loss=0.014795186 valid loss= 0.011950204\n",
      "train reg_fs: 0.0071757761761546135\n",
      "Epoch: 4000 train loss=0.028388152 valid loss= 0.011273042\n",
      "train reg_fs: 0.007114408537745476\n",
      "Epoch: 4500 train loss=0.010240190 valid loss= 0.010675283\n",
      "train reg_fs: 0.0070359837263822556\n",
      "Epoch: 5000 train loss=0.015290702 valid loss= 0.011198349\n",
      "train reg_fs: 0.006944356951862574\n",
      "Epoch: 5500 train loss=0.009282801 valid loss= 0.010273390\n",
      "train reg_fs: 0.0068345749750733376\n",
      "Epoch: 6000 train loss=0.011388321 valid loss= 0.009811880\n",
      "train reg_fs: 0.006721495185047388\n",
      "Epoch: 6500 train loss=0.013360023 valid loss= 0.009736269\n",
      "train reg_fs: 0.006616234313696623\n",
      "Epoch: 7000 train loss=0.012187559 valid loss= 0.009580517\n",
      "train reg_fs: 0.006523560266941786\n",
      "Epoch: 7500 train loss=0.018036935 valid loss= 0.009602030\n",
      "train reg_fs: 0.0064413887448608875\n",
      "Epoch: 8000 train loss=0.010008761 valid loss= 0.008981165\n",
      "train reg_fs: 0.006369010079652071\n",
      "Epoch: 8500 train loss=0.012488911 valid loss= 0.009487714\n",
      "train reg_fs: 0.006305753253400326\n",
      "Epoch: 9000 train loss=0.014330025 valid loss= 0.009187761\n",
      "train reg_fs: 0.006248311139643192\n",
      "Epoch: 9500 train loss=0.009956650 valid loss= 0.009196496\n",
      "train reg_fs: 0.006196652073413134\n",
      "Epoch: 10000 train loss=0.008508986 valid loss= 0.008866113\n",
      "train reg_fs: 0.006144886836409569\n",
      "Epoch: 10500 train loss=0.009445888 valid loss= 0.009092908\n",
      "train reg_fs: 0.006094697862863541\n",
      "Epoch: 11000 train loss=0.011004729 valid loss= 0.009023730\n",
      "train reg_fs: 0.0060445331037044525\n",
      "Epoch: 11500 train loss=0.012971323 valid loss= 0.008648339\n",
      "train reg_fs: 0.0059959301725029945\n",
      "Epoch: 12000 train loss=0.011564977 valid loss= 0.008300105\n",
      "train reg_fs: 0.005948243197053671\n",
      "Epoch: 12500 train loss=0.012301148 valid loss= 0.008483552\n",
      "train reg_fs: 0.005902253091335297\n",
      "Epoch: 13000 train loss=0.007796722 valid loss= 0.008787911\n",
      "train reg_fs: 0.005855916533619165\n",
      "Epoch: 13500 train loss=0.013841167 valid loss= 0.009130433\n",
      "train reg_fs: 0.005810748785734177\n",
      "Epoch: 14000 train loss=0.007252885 valid loss= 0.008319173\n",
      "train reg_fs: 0.005764394998550415\n",
      "Epoch: 14500 train loss=0.006849613 valid loss= 0.008437695\n",
      "train reg_fs: 0.005717714317142963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:28:14,662]\u001b[0m Trial 35 finished with value: 0.002529640463776674 and parameters: {'lam': 0.0084815885227383, 'learning_rate': 0.01593809924882831, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007550899 valid loss= 0.008475358\n",
      "train reg_fs: 0.005671184044331312\n",
      "Optimization Finished!\n",
      "test loss: 0.00864049606025219, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002529640463776674\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017329488 valid loss= 0.007204751\n",
      "train reg_fs: 0.001098104752600193\n",
      "Epoch: 1000 train loss=0.008714416 valid loss= 0.006414443\n",
      "train reg_fs: 0.0011087149614468217\n",
      "Epoch: 1500 train loss=0.010257093 valid loss= 0.005964266\n",
      "train reg_fs: 0.0011142475996166468\n",
      "Epoch: 2000 train loss=0.006447533 valid loss= 0.005760512\n",
      "train reg_fs: 0.0011158802080899477\n",
      "Epoch: 2500 train loss=0.006340735 valid loss= 0.005292233\n",
      "train reg_fs: 0.0011143824085593224\n",
      "Epoch: 3000 train loss=0.010735757 valid loss= 0.005214174\n",
      "train reg_fs: 0.0011092842323705554\n",
      "Epoch: 3500 train loss=0.005643069 valid loss= 0.004670208\n",
      "train reg_fs: 0.001100781373679638\n",
      "Epoch: 4000 train loss=0.004901196 valid loss= 0.004525492\n",
      "train reg_fs: 0.0010899994522333145\n",
      "Epoch: 4500 train loss=0.016449707 valid loss= 0.004438080\n",
      "train reg_fs: 0.0010770829394459724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:28:51,369]\u001b[0m Trial 36 finished with value: 0.003404834641275471 and parameters: {'lam': 0.0012808594886618361, 'learning_rate': 0.020150910093205028, 'num_epoch': 5000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004863568 valid loss= 0.004464018\n",
      "train reg_fs: 0.0010618583764880896\n",
      "Optimization Finished!\n",
      "test loss: 0.004872560501098633, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003404834641275471\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016631775 valid loss= 0.011228401\n",
      "train reg_fs: 0.00422899704426527\n",
      "Epoch: 1000 train loss=0.018604979 valid loss= 0.010868886\n",
      "train reg_fs: 0.00425388477742672\n",
      "Epoch: 1500 train loss=0.011497566 valid loss= 0.010076066\n",
      "train reg_fs: 0.004272453486919403\n",
      "Epoch: 2000 train loss=0.010294051 valid loss= 0.010042226\n",
      "train reg_fs: 0.004285228904336691\n",
      "Epoch: 2500 train loss=0.009504914 valid loss= 0.009871466\n",
      "train reg_fs: 0.004292348865419626\n",
      "Epoch: 3000 train loss=0.018693535 valid loss= 0.010034116\n",
      "train reg_fs: 0.0042935083620250225\n",
      "Epoch: 3500 train loss=0.010225308 valid loss= 0.009351182\n",
      "train reg_fs: 0.004290735349059105\n",
      "Epoch: 4000 train loss=0.011200057 valid loss= 0.008920096\n",
      "train reg_fs: 0.004278125707060099\n",
      "Epoch: 4500 train loss=0.009914702 valid loss= 0.009321772\n",
      "train reg_fs: 0.004260519985109568\n",
      "Epoch: 5000 train loss=0.013942106 valid loss= 0.009590194\n",
      "train reg_fs: 0.004237956367433071\n",
      "Epoch: 5500 train loss=0.016010385 valid loss= 0.009393458\n",
      "train reg_fs: 0.004209627863019705\n",
      "Epoch: 6000 train loss=0.005570827 valid loss= 0.009081593\n",
      "train reg_fs: 0.004177787806838751\n",
      "Epoch: 6500 train loss=0.009416353 valid loss= 0.008391958\n",
      "train reg_fs: 0.004140789154917002\n",
      "Epoch: 7000 train loss=0.009989654 valid loss= 0.008739723\n",
      "train reg_fs: 0.0041033742018043995\n",
      "Epoch: 7500 train loss=0.006361973 valid loss= 0.008362887\n",
      "train reg_fs: 0.00406445050612092\n",
      "Epoch: 8000 train loss=0.009836692 valid loss= 0.007655445\n",
      "train reg_fs: 0.004027199000120163\n",
      "Epoch: 8500 train loss=0.011177666 valid loss= 0.007360857\n",
      "train reg_fs: 0.003986438270658255\n",
      "Epoch: 9000 train loss=0.010914339 valid loss= 0.006958433\n",
      "train reg_fs: 0.00394862238317728\n",
      "Epoch: 9500 train loss=0.007820246 valid loss= 0.006965066\n",
      "train reg_fs: 0.003913213964551687\n",
      "Epoch: 10000 train loss=0.006994682 valid loss= 0.006843675\n",
      "train reg_fs: 0.003877757117152214\n",
      "Epoch: 10500 train loss=0.006379409 valid loss= 0.006447142\n",
      "train reg_fs: 0.0038447657134383917\n",
      "Epoch: 11000 train loss=0.005307236 valid loss= 0.006381189\n",
      "train reg_fs: 0.003814901225268841\n",
      "Epoch: 11500 train loss=0.007193240 valid loss= 0.006649323\n",
      "train reg_fs: 0.003788305213674903\n",
      "Epoch: 12000 train loss=0.008066947 valid loss= 0.006317410\n",
      "train reg_fs: 0.0037638270296156406\n",
      "Epoch: 12500 train loss=0.006722213 valid loss= 0.006131855\n",
      "train reg_fs: 0.0037415926344692707\n",
      "Epoch: 13000 train loss=0.008530574 valid loss= 0.006135788\n",
      "train reg_fs: 0.0037216199561953545\n",
      "Epoch: 13500 train loss=0.007159514 valid loss= 0.006350703\n",
      "train reg_fs: 0.003700800472870469\n",
      "Epoch: 14000 train loss=0.007629354 valid loss= 0.006327876\n",
      "train reg_fs: 0.003682360053062439\n",
      "Epoch: 14500 train loss=0.005362086 valid loss= 0.005979898\n",
      "train reg_fs: 0.0036629491951316595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:30:36,242]\u001b[0m Trial 37 finished with value: 0.002964848695565271 and parameters: {'lam': 0.0050105570824515305, 'learning_rate': 0.01290507262667527, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006535001 valid loss= 0.006714053\n",
      "train reg_fs: 0.003644297830760479\n",
      "Optimization Finished!\n",
      "test loss: 0.0065864757634699345, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002964848695565271\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012388908 valid loss= 0.014240563\n",
      "train reg_fs: 0.008242974057793617\n",
      "Epoch: 1000 train loss=0.011965809 valid loss= 0.012426786\n",
      "train reg_fs: 0.007581050973385572\n",
      "Epoch: 1500 train loss=0.010127455 valid loss= 0.010498592\n",
      "train reg_fs: 0.007036206312477589\n",
      "Epoch: 2000 train loss=0.012277322 valid loss= 0.010610563\n",
      "train reg_fs: 0.006648804061114788\n",
      "Epoch: 2500 train loss=0.007545968 valid loss= 0.009442236\n",
      "train reg_fs: 0.0063959937542676926\n",
      "Epoch: 3000 train loss=0.007193286 valid loss= 0.009118015\n",
      "train reg_fs: 0.006238202098757029\n",
      "Epoch: 3500 train loss=0.007531775 valid loss= 0.008500742\n",
      "train reg_fs: 0.00614320719614625\n",
      "Epoch: 4000 train loss=0.009004723 valid loss= 0.008024618\n",
      "train reg_fs: 0.00608373386785388\n",
      "Epoch: 4500 train loss=0.008677452 valid loss= 0.008238138\n",
      "train reg_fs: 0.006044541951268911\n",
      "Epoch: 5000 train loss=0.006394374 valid loss= 0.008141202\n",
      "train reg_fs: 0.006015933118760586\n",
      "Epoch: 5500 train loss=0.006529097 valid loss= 0.008047962\n",
      "train reg_fs: 0.00599433621391654\n",
      "Epoch: 6000 train loss=0.006415765 valid loss= 0.008136226\n",
      "train reg_fs: 0.005977856460958719\n",
      "Epoch: 6500 train loss=0.006579811 valid loss= 0.007869801\n",
      "train reg_fs: 0.005964826326817274\n",
      "Epoch: 7000 train loss=0.007398644 valid loss= 0.008036664\n",
      "train reg_fs: 0.005953911226242781\n",
      "Epoch: 7500 train loss=0.006392155 valid loss= 0.008065166\n",
      "train reg_fs: 0.0059442538768053055\n",
      "Epoch: 8000 train loss=0.009546626 valid loss= 0.007924273\n",
      "train reg_fs: 0.005936145782470703\n",
      "Epoch: 8500 train loss=0.006107868 valid loss= 0.008021477\n",
      "train reg_fs: 0.005929463542997837\n",
      "Epoch: 9000 train loss=0.007626661 valid loss= 0.008025462\n",
      "train reg_fs: 0.0059234388172626495\n",
      "Epoch: 9500 train loss=0.006352973 valid loss= 0.007828201\n",
      "train reg_fs: 0.0059185270220041275\n",
      "Epoch: 10000 train loss=0.009685129 valid loss= 0.008263590\n",
      "train reg_fs: 0.00591414887458086\n",
      "Epoch: 10500 train loss=0.006603519 valid loss= 0.008006028\n",
      "train reg_fs: 0.005910307168960571\n",
      "Epoch: 11000 train loss=0.006095794 valid loss= 0.008030354\n",
      "train reg_fs: 0.005906806327402592\n",
      "Epoch: 11500 train loss=0.011648688 valid loss= 0.008082679\n",
      "train reg_fs: 0.0059036193415522575\n",
      "Epoch: 12000 train loss=0.008034852 valid loss= 0.008067340\n",
      "train reg_fs: 0.005900801159441471\n",
      "Epoch: 12500 train loss=0.006902929 valid loss= 0.008072708\n",
      "train reg_fs: 0.00589817576110363\n",
      "Epoch: 13000 train loss=0.007082480 valid loss= 0.007989189\n",
      "train reg_fs: 0.005895801819860935\n",
      "Epoch: 13500 train loss=0.006297417 valid loss= 0.008046087\n",
      "train reg_fs: 0.0058937338180840015\n",
      "Epoch: 14000 train loss=0.008357654 valid loss= 0.008155874\n",
      "train reg_fs: 0.0058917757123708725\n",
      "Epoch: 14500 train loss=0.008121427 valid loss= 0.007729015\n",
      "train reg_fs: 0.0058900280855596066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:32:22,650]\u001b[0m Trial 38 finished with value: 0.0023676964272332664 and parameters: {'lam': 0.009826377452319068, 'learning_rate': 0.1192752509194197, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006045692 valid loss= 0.008083345\n",
      "train reg_fs: 0.005888399202376604\n",
      "Optimization Finished!\n",
      "test loss: 0.007921394892036915, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023676964272332664\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.004955078 valid loss= 0.007754335\n",
      "train reg_fs: 0.001315206871367991\n",
      "Epoch: 1000 train loss=0.008107355 valid loss= 0.007227044\n",
      "train reg_fs: 0.0013359113363549113\n",
      "Epoch: 1500 train loss=0.009348838 valid loss= 0.007179131\n",
      "train reg_fs: 0.001340737333521247\n",
      "Epoch: 2000 train loss=0.007214118 valid loss= 0.007621167\n",
      "train reg_fs: 0.0013310842914506793\n",
      "Epoch: 2500 train loss=0.008153402 valid loss= 0.005159948\n",
      "train reg_fs: 0.001308799721300602\n",
      "Epoch: 3000 train loss=0.005349909 valid loss= 0.004722133\n",
      "train reg_fs: 0.001279954332858324\n",
      "Epoch: 3500 train loss=0.005365211 valid loss= 0.003542718\n",
      "train reg_fs: 0.0012531582033261657\n",
      "Epoch: 4000 train loss=0.006399986 valid loss= 0.003286397\n",
      "train reg_fs: 0.001232837326824665\n",
      "Epoch: 4500 train loss=0.003484011 valid loss= 0.003571647\n",
      "train reg_fs: 0.001216957694850862\n",
      "Epoch: 5000 train loss=0.005828085 valid loss= 0.003050251\n",
      "train reg_fs: 0.0012078223517164588\n",
      "Epoch: 5500 train loss=0.003055011 valid loss= 0.003429683\n",
      "train reg_fs: 0.0012019394198432565\n",
      "Epoch: 6000 train loss=0.004552932 valid loss= 0.003231211\n",
      "train reg_fs: 0.0011953110806643963\n",
      "Epoch: 6500 train loss=0.004643960 valid loss= 0.003437658\n",
      "train reg_fs: 0.001188789727166295\n",
      "Epoch: 7000 train loss=0.003273037 valid loss= 0.003098920\n",
      "train reg_fs: 0.0011826260015368462\n",
      "Epoch: 7500 train loss=0.001710958 valid loss= 0.003379315\n",
      "train reg_fs: 0.0011770469136536121\n",
      "Epoch: 8000 train loss=0.006757477 valid loss= 0.002939171\n",
      "train reg_fs: 0.0011720230104401708\n",
      "Epoch: 8500 train loss=0.001983702 valid loss= 0.003216396\n",
      "train reg_fs: 0.0011668073711916804\n",
      "Epoch: 9000 train loss=0.003329349 valid loss= 0.003247660\n",
      "train reg_fs: 0.0011625487823039293\n",
      "Epoch: 9500 train loss=0.002778671 valid loss= 0.003344611\n",
      "train reg_fs: 0.001158070983365178\n",
      "Epoch: 10000 train loss=0.002079198 valid loss= 0.003120477\n",
      "train reg_fs: 0.0011540919076651335\n",
      "Epoch: 10500 train loss=0.003962088 valid loss= 0.003364400\n",
      "train reg_fs: 0.001151601318269968\n",
      "Epoch: 11000 train loss=0.001500835 valid loss= 0.003007836\n",
      "train reg_fs: 0.0011485150316730142\n",
      "Epoch: 11500 train loss=0.001715761 valid loss= 0.003272798\n",
      "train reg_fs: 0.001146088819950819\n",
      "Epoch: 12000 train loss=0.002441170 valid loss= 0.003098432\n",
      "train reg_fs: 0.0011440124362707138\n",
      "Epoch: 12500 train loss=0.002742928 valid loss= 0.003156041\n",
      "train reg_fs: 0.0011413246393203735\n",
      "Epoch: 13000 train loss=0.002575862 valid loss= 0.002845348\n",
      "train reg_fs: 0.0011394768953323364\n",
      "Epoch: 13500 train loss=0.004253330 valid loss= 0.002923268\n",
      "train reg_fs: 0.0011381044751033187\n",
      "Epoch: 14000 train loss=0.004216772 valid loss= 0.002609469\n",
      "train reg_fs: 0.0011367171537131071\n",
      "Epoch: 14500 train loss=0.010007698 valid loss= 0.002979571\n",
      "train reg_fs: 0.0011355042224749923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:34:07,545]\u001b[0m Trial 39 finished with value: 0.001646838217239548 and parameters: {'lam': 0.0015210345581808042, 'learning_rate': 0.05865019806235531, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001858509 valid loss= 0.002767369\n",
      "train reg_fs: 0.0011342988582327962\n",
      "Optimization Finished!\n",
      "test loss: 0.0029066321440041065, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001646838217239548\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011538474 valid loss= 0.007483693\n",
      "train reg_fs: 0.001379544846713543\n",
      "Epoch: 1000 train loss=0.010170907 valid loss= 0.006274830\n",
      "train reg_fs: 0.0013953214511275291\n",
      "Epoch: 1500 train loss=0.012209004 valid loss= 0.005921844\n",
      "train reg_fs: 0.0013898436445742846\n",
      "Epoch: 2000 train loss=0.006031579 valid loss= 0.005376889\n",
      "train reg_fs: 0.0013633326161652803\n",
      "Epoch: 2500 train loss=0.008244564 valid loss= 0.004398944\n",
      "train reg_fs: 0.0013196342624723911\n",
      "Epoch: 3000 train loss=0.011895967 valid loss= 0.004145020\n",
      "train reg_fs: 0.0012815234949812293\n",
      "Epoch: 3500 train loss=0.005043869 valid loss= 0.003937630\n",
      "train reg_fs: 0.0012610433623194695\n",
      "Epoch: 4000 train loss=0.018179880 valid loss= 0.004154483\n",
      "train reg_fs: 0.001250980538316071\n",
      "Epoch: 4500 train loss=0.002791280 valid loss= 0.004195410\n",
      "train reg_fs: 0.001245443127118051\n",
      "Epoch: 5000 train loss=0.008074466 valid loss= 0.003981299\n",
      "train reg_fs: 0.0012403662549331784\n",
      "Epoch: 5500 train loss=0.002742065 valid loss= 0.003948362\n",
      "train reg_fs: 0.0012352288467809558\n",
      "Epoch: 6000 train loss=0.003673354 valid loss= 0.004141445\n",
      "train reg_fs: 0.0012293379986658692\n",
      "Epoch: 6500 train loss=0.001996872 valid loss= 0.004322805\n",
      "train reg_fs: 0.001221482758410275\n",
      "Epoch: 7000 train loss=0.006660050 valid loss= 0.004015434\n",
      "train reg_fs: 0.0012122821062803268\n",
      "Epoch: 7500 train loss=0.003355293 valid loss= 0.003950573\n",
      "train reg_fs: 0.001203874358907342\n",
      "Epoch: 8000 train loss=0.006301971 valid loss= 0.004226059\n",
      "train reg_fs: 0.0011955257505178452\n",
      "Epoch: 8500 train loss=0.004066405 valid loss= 0.003989701\n",
      "train reg_fs: 0.0011878319783136249\n",
      "Epoch: 9000 train loss=0.003668183 valid loss= 0.003814148\n",
      "train reg_fs: 0.0011812001466751099\n",
      "Epoch: 9500 train loss=0.001551713 valid loss= 0.003884943\n",
      "train reg_fs: 0.001175245619378984\n",
      "Epoch: 10000 train loss=0.001741088 valid loss= 0.003449694\n",
      "train reg_fs: 0.0011704154312610626\n",
      "Epoch: 10500 train loss=0.004277417 valid loss= 0.003614906\n",
      "train reg_fs: 0.0011663835030049086\n",
      "Epoch: 11000 train loss=0.004650258 valid loss= 0.003427168\n",
      "train reg_fs: 0.001162487780675292\n",
      "Epoch: 11500 train loss=0.003057490 valid loss= 0.003502509\n",
      "train reg_fs: 0.0011591705260798335\n",
      "Epoch: 12000 train loss=0.002944049 valid loss= 0.003198069\n",
      "train reg_fs: 0.0011557921534404159\n",
      "Epoch: 12500 train loss=0.003619772 valid loss= 0.003602901\n",
      "train reg_fs: 0.001152506796643138\n",
      "Epoch: 13000 train loss=0.007237645 valid loss= 0.003696937\n",
      "train reg_fs: 0.001150299096480012\n",
      "Epoch: 13500 train loss=0.002553160 valid loss= 0.003325674\n",
      "train reg_fs: 0.0011479916283860803\n",
      "Epoch: 14000 train loss=0.001412942 valid loss= 0.003237064\n",
      "train reg_fs: 0.0011459814850240946\n",
      "Epoch: 14500 train loss=0.001853785 valid loss= 0.003244078\n",
      "train reg_fs: 0.0011442307149991393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:35:51,151]\u001b[0m Trial 40 finished with value: 0.002548770955095483 and parameters: {'lam': 0.0015856079685641915, 'learning_rate': 0.056575461604004416, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003610128 valid loss= 0.003653132\n",
      "train reg_fs: 0.0011423854157328606\n",
      "Optimization Finished!\n",
      "test loss: 0.0033480015117675066, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002548770955095483\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011171609 valid loss= 0.008262567\n",
      "train reg_fs: 0.001233124639838934\n",
      "Epoch: 1000 train loss=0.008900558 valid loss= 0.007385593\n",
      "train reg_fs: 0.0012324296403676271\n",
      "Epoch: 1500 train loss=0.007140610 valid loss= 0.005946730\n",
      "train reg_fs: 0.0012040459550917149\n",
      "Epoch: 2000 train loss=0.008967609 valid loss= 0.003738528\n",
      "train reg_fs: 0.0011648667277768254\n",
      "Epoch: 2500 train loss=0.011158283 valid loss= 0.003252959\n",
      "train reg_fs: 0.001138552324846387\n",
      "Epoch: 3000 train loss=0.002805718 valid loss= 0.003048937\n",
      "train reg_fs: 0.0011246714275330305\n",
      "Epoch: 3500 train loss=0.004425831 valid loss= 0.003383949\n",
      "train reg_fs: 0.001115738763473928\n",
      "Epoch: 4000 train loss=0.002534640 valid loss= 0.002884114\n",
      "train reg_fs: 0.0011078501120209694\n",
      "Epoch: 4500 train loss=0.003511490 valid loss= 0.003116420\n",
      "train reg_fs: 0.001099692191928625\n",
      "Epoch: 5000 train loss=0.001857655 valid loss= 0.003568407\n",
      "train reg_fs: 0.0010915965540334582\n",
      "Epoch: 5500 train loss=0.006126114 valid loss= 0.003312605\n",
      "train reg_fs: 0.0010842808987945318\n",
      "Epoch: 6000 train loss=0.002405869 valid loss= 0.003598572\n",
      "train reg_fs: 0.0010786165948957205\n",
      "Epoch: 6500 train loss=0.002977987 valid loss= 0.003420846\n",
      "train reg_fs: 0.0010740312281996012\n",
      "Epoch: 7000 train loss=0.004378221 valid loss= 0.003306406\n",
      "train reg_fs: 0.0010696017416194081\n",
      "Epoch: 7500 train loss=0.007512639 valid loss= 0.002869013\n",
      "train reg_fs: 0.0010663233697414398\n",
      "Epoch: 8000 train loss=0.004162794 valid loss= 0.003108190\n",
      "train reg_fs: 0.0010634950594976544\n",
      "Epoch: 8500 train loss=0.002464640 valid loss= 0.002991863\n",
      "train reg_fs: 0.0010611473117023706\n",
      "Epoch: 9000 train loss=0.001286054 valid loss= 0.002882389\n",
      "train reg_fs: 0.0010578284272924066\n",
      "Epoch: 9500 train loss=0.003403489 valid loss= 0.002705338\n",
      "train reg_fs: 0.0010557021014392376\n",
      "Epoch: 10000 train loss=0.006572629 valid loss= 0.002200007\n",
      "train reg_fs: 0.0010532132582738996\n",
      "Epoch: 10500 train loss=0.001199781 valid loss= 0.002763610\n",
      "train reg_fs: 0.001051244675181806\n",
      "Epoch: 11000 train loss=0.003905502 valid loss= 0.002624496\n",
      "train reg_fs: 0.0010494885500520468\n",
      "Epoch: 11500 train loss=0.002526721 valid loss= 0.002729913\n",
      "train reg_fs: 0.0010470590787008405\n",
      "Epoch: 12000 train loss=0.007642798 valid loss= 0.002690001\n",
      "train reg_fs: 0.0010442527709528804\n",
      "Epoch: 12500 train loss=0.001935430 valid loss= 0.002884901\n",
      "train reg_fs: 0.0010408941889181733\n",
      "Epoch: 13000 train loss=0.001720625 valid loss= 0.002539495\n",
      "train reg_fs: 0.0010377144208177924\n",
      "Epoch: 13500 train loss=0.004273810 valid loss= 0.002232728\n",
      "train reg_fs: 0.001033367938362062\n",
      "Epoch: 14000 train loss=0.001275283 valid loss= 0.002642407\n",
      "train reg_fs: 0.0010298697743564844\n",
      "Epoch: 14500 train loss=0.003719104 valid loss= 0.002750431\n",
      "train reg_fs: 0.001025264267809689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:37:35,473]\u001b[0m Trial 41 finished with value: 0.001592953421271089 and parameters: {'lam': 0.0014175228361357323, 'learning_rate': 0.07262710773873077, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004446342 valid loss= 0.002606141\n",
      "train reg_fs: 0.0010208867024630308\n",
      "Optimization Finished!\n",
      "test loss: 0.002486224751919508, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001592953421271089\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011180013 valid loss= 0.008499101\n",
      "train reg_fs: 0.0010599670931696892\n",
      "Epoch: 1000 train loss=0.006486157 valid loss= 0.008798046\n",
      "train reg_fs: 0.001073397696018219\n",
      "Epoch: 1500 train loss=0.009058837 valid loss= 0.008408393\n",
      "train reg_fs: 0.0010662995046004653\n",
      "Epoch: 2000 train loss=0.003753364 valid loss= 0.006526659\n",
      "train reg_fs: 0.0010455339215695858\n",
      "Epoch: 2500 train loss=0.008265681 valid loss= 0.005058318\n",
      "train reg_fs: 0.0010165638523176312\n",
      "Epoch: 3000 train loss=0.006647274 valid loss= 0.004052369\n",
      "train reg_fs: 0.0009893616661429405\n",
      "Epoch: 3500 train loss=0.004776878 valid loss= 0.003506074\n",
      "train reg_fs: 0.0009705325937829912\n",
      "Epoch: 4000 train loss=0.002404819 valid loss= 0.003587147\n",
      "train reg_fs: 0.0009612896828912199\n",
      "Epoch: 4500 train loss=0.002589229 valid loss= 0.004073315\n",
      "train reg_fs: 0.0009553083218634129\n",
      "Epoch: 5000 train loss=0.002640221 valid loss= 0.003678239\n",
      "train reg_fs: 0.0009496405255049467\n",
      "Epoch: 5500 train loss=0.003553621 valid loss= 0.003554910\n",
      "train reg_fs: 0.0009425448370166123\n",
      "Epoch: 6000 train loss=0.001601310 valid loss= 0.003667203\n",
      "train reg_fs: 0.0009342876728624105\n",
      "Epoch: 6500 train loss=0.002719065 valid loss= 0.003600900\n",
      "train reg_fs: 0.0009274882613681257\n",
      "Epoch: 7000 train loss=0.002543526 valid loss= 0.003801809\n",
      "train reg_fs: 0.0009205571841448545\n",
      "Epoch: 7500 train loss=0.002689244 valid loss= 0.003388432\n",
      "train reg_fs: 0.000915616808924824\n",
      "Epoch: 8000 train loss=0.002216159 valid loss= 0.003671784\n",
      "train reg_fs: 0.0009104741620831192\n",
      "Epoch: 8500 train loss=0.002316743 valid loss= 0.003695413\n",
      "train reg_fs: 0.0009059650474227965\n",
      "Epoch: 9000 train loss=0.002033598 valid loss= 0.003068432\n",
      "train reg_fs: 0.0009027229971252382\n",
      "Epoch: 9500 train loss=0.001884865 valid loss= 0.003430275\n",
      "train reg_fs: 0.0008997005643323064\n",
      "Epoch: 10000 train loss=0.002598567 valid loss= 0.003473522\n",
      "train reg_fs: 0.0008965462911874056\n",
      "Epoch: 10500 train loss=0.003698312 valid loss= 0.003323022\n",
      "train reg_fs: 0.0008934642537496984\n",
      "Epoch: 11000 train loss=0.006836119 valid loss= 0.003062178\n",
      "train reg_fs: 0.0008910848991945386\n",
      "Epoch: 11500 train loss=0.002122021 valid loss= 0.003171797\n",
      "train reg_fs: 0.0008885398856364191\n",
      "Epoch: 12000 train loss=0.010575186 valid loss= 0.003259906\n",
      "train reg_fs: 0.0008862513350322843\n",
      "Epoch: 12500 train loss=0.001842228 valid loss= 0.003070439\n",
      "train reg_fs: 0.0008835153421387076\n",
      "Epoch: 13000 train loss=0.002681985 valid loss= 0.003383857\n",
      "train reg_fs: 0.0008817673660814762\n",
      "Epoch: 13500 train loss=0.004325878 valid loss= 0.003017376\n",
      "train reg_fs: 0.000880204257555306\n",
      "Epoch: 14000 train loss=0.003785286 valid loss= 0.003109822\n",
      "train reg_fs: 0.0008787238621152937\n",
      "Epoch: 14500 train loss=0.001535116 valid loss= 0.003166386\n",
      "train reg_fs: 0.0008768154075369239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:39:18,572]\u001b[0m Trial 42 finished with value: 0.0020874842606452373 and parameters: {'lam': 0.0012142501383974335, 'learning_rate': 0.07303339988438468, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002660394 valid loss= 0.002938972\n",
      "train reg_fs: 0.0008755532908253372\n",
      "Optimization Finished!\n",
      "test loss: 0.002853086218237877, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020874842606452373\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015016271 valid loss= 0.007347773\n",
      "train reg_fs: 0.0012690661242231727\n",
      "Epoch: 1000 train loss=0.006854549 valid loss= 0.006887854\n",
      "train reg_fs: 0.0012757951626554132\n",
      "Epoch: 1500 train loss=0.010701227 valid loss= 0.006337670\n",
      "train reg_fs: 0.0012617496540769935\n",
      "Epoch: 2000 train loss=0.006815859 valid loss= 0.005311300\n",
      "train reg_fs: 0.0012342288391664624\n",
      "Epoch: 2500 train loss=0.010191700 valid loss= 0.004778706\n",
      "train reg_fs: 0.0012010715436190367\n",
      "Epoch: 3000 train loss=0.003484650 valid loss= 0.003483060\n",
      "train reg_fs: 0.0011716982116922736\n",
      "Epoch: 3500 train loss=0.006512010 valid loss= 0.003566825\n",
      "train reg_fs: 0.0011503041023388505\n",
      "Epoch: 4000 train loss=0.005951241 valid loss= 0.003404594\n",
      "train reg_fs: 0.0011358364718034863\n",
      "Epoch: 4500 train loss=0.006812760 valid loss= 0.003853355\n",
      "train reg_fs: 0.0011262723710387945\n",
      "Epoch: 5000 train loss=0.007491759 valid loss= 0.003734217\n",
      "train reg_fs: 0.001118857180699706\n",
      "Epoch: 5500 train loss=0.006119259 valid loss= 0.003470494\n",
      "train reg_fs: 0.0011144377058371902\n",
      "Epoch: 6000 train loss=0.003324118 valid loss= 0.003459072\n",
      "train reg_fs: 0.001111786812543869\n",
      "Epoch: 6500 train loss=0.003577660 valid loss= 0.003657717\n",
      "train reg_fs: 0.0011086583836004138\n",
      "Epoch: 7000 train loss=0.004596718 valid loss= 0.003875499\n",
      "train reg_fs: 0.0011068959720432758\n",
      "Epoch: 7500 train loss=0.005547842 valid loss= 0.003501431\n",
      "train reg_fs: 0.0011052732588723302\n",
      "Epoch: 8000 train loss=0.002851741 valid loss= 0.003818358\n",
      "train reg_fs: 0.0011040859390050173\n",
      "Epoch: 8500 train loss=0.002213195 valid loss= 0.003612152\n",
      "train reg_fs: 0.0011037804652005434\n",
      "Epoch: 9000 train loss=0.006981074 valid loss= 0.003155394\n",
      "train reg_fs: 0.0011035329662263393\n",
      "Epoch: 9500 train loss=0.002152763 valid loss= 0.003533656\n",
      "train reg_fs: 0.0011028448352590203\n",
      "Epoch: 10000 train loss=0.002411184 valid loss= 0.004201759\n",
      "train reg_fs: 0.0011016115313395858\n",
      "Epoch: 10500 train loss=0.006342875 valid loss= 0.003645267\n",
      "train reg_fs: 0.001101258909329772\n",
      "Epoch: 11000 train loss=0.005125544 valid loss= 0.003922137\n",
      "train reg_fs: 0.0011009188601747155\n",
      "Epoch: 11500 train loss=0.008428396 valid loss= 0.003419386\n",
      "train reg_fs: 0.0011005167616531253\n",
      "Epoch: 12000 train loss=0.002000551 valid loss= 0.003859721\n",
      "train reg_fs: 0.0010999621590599418\n",
      "Epoch: 12500 train loss=0.004122531 valid loss= 0.004007132\n",
      "train reg_fs: 0.0010995067423209548\n",
      "Epoch: 13000 train loss=0.003900460 valid loss= 0.003607704\n",
      "train reg_fs: 0.0010999273508787155\n",
      "Epoch: 13500 train loss=0.003603301 valid loss= 0.003783886\n",
      "train reg_fs: 0.0010993233881890774\n",
      "Epoch: 14000 train loss=0.008971574 valid loss= 0.003743715\n",
      "train reg_fs: 0.0010992788011208177\n",
      "Epoch: 14500 train loss=0.004877195 valid loss= 0.003742991\n",
      "train reg_fs: 0.001098836655728519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:41:04,471]\u001b[0m Trial 43 finished with value: 0.0033525998221773643 and parameters: {'lam': 0.0014862247007784088, 'learning_rate': 0.04510857817237862, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003422833 valid loss= 0.004479287\n",
      "train reg_fs: 0.0010983541142195463\n",
      "Optimization Finished!\n",
      "test loss: 0.004671732895076275, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0033525998221773643\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011432566 valid loss= 0.008503946\n",
      "train reg_fs: 0.0016192025505006313\n",
      "Epoch: 1000 train loss=0.010288566 valid loss= 0.009720525\n",
      "train reg_fs: 0.0016526286490261555\n",
      "Epoch: 1500 train loss=0.013568590 valid loss= 0.008238581\n",
      "train reg_fs: 0.001666203374043107\n",
      "Epoch: 2000 train loss=0.016344523 valid loss= 0.008275045\n",
      "train reg_fs: 0.0016607714351266623\n",
      "Epoch: 2500 train loss=0.007921334 valid loss= 0.007805015\n",
      "train reg_fs: 0.0016419776948168874\n",
      "Epoch: 3000 train loss=0.007767636 valid loss= 0.008067996\n",
      "train reg_fs: 0.00161638087593019\n",
      "Epoch: 3500 train loss=0.007494530 valid loss= 0.006844793\n",
      "train reg_fs: 0.0015967924846336246\n",
      "Epoch: 4000 train loss=0.003564608 valid loss= 0.007049233\n",
      "train reg_fs: 0.0015841602580621839\n",
      "Epoch: 4500 train loss=0.004473242 valid loss= 0.006595611\n",
      "train reg_fs: 0.001575223170220852\n",
      "Epoch: 5000 train loss=0.003939788 valid loss= 0.006355901\n",
      "train reg_fs: 0.0015611430862918496\n",
      "Epoch: 5500 train loss=0.004474118 valid loss= 0.005950525\n",
      "train reg_fs: 0.0015510849189013243\n",
      "Epoch: 6000 train loss=0.004134516 valid loss= 0.005673342\n",
      "train reg_fs: 0.0015442437725141644\n",
      "Epoch: 6500 train loss=0.008479781 valid loss= 0.005517576\n",
      "train reg_fs: 0.0015375753864645958\n",
      "Epoch: 7000 train loss=0.006636815 valid loss= 0.005211613\n",
      "train reg_fs: 0.001533261383883655\n",
      "Epoch: 7500 train loss=0.002839799 valid loss= 0.004680065\n",
      "train reg_fs: 0.0015272303717210889\n",
      "Epoch: 8000 train loss=0.002847918 valid loss= 0.004720178\n",
      "train reg_fs: 0.0015200527850538492\n",
      "Epoch: 8500 train loss=0.002997790 valid loss= 0.004972438\n",
      "train reg_fs: 0.0015147589147090912\n",
      "Epoch: 9000 train loss=0.002712665 valid loss= 0.004284611\n",
      "train reg_fs: 0.0015088670188561082\n",
      "Epoch: 9500 train loss=0.004719442 valid loss= 0.004502417\n",
      "train reg_fs: 0.001502847415395081\n",
      "Epoch: 10000 train loss=0.002807841 valid loss= 0.004283514\n",
      "train reg_fs: 0.0014937352389097214\n",
      "Epoch: 10500 train loss=0.002599692 valid loss= 0.004330147\n",
      "train reg_fs: 0.0014889310114085674\n",
      "Epoch: 11000 train loss=0.003524692 valid loss= 0.004155272\n",
      "train reg_fs: 0.0014788060216233134\n",
      "Epoch: 11500 train loss=0.002761347 valid loss= 0.004212499\n",
      "train reg_fs: 0.001468136440962553\n",
      "Epoch: 12000 train loss=0.002955321 valid loss= 0.004312654\n",
      "train reg_fs: 0.001461027655750513\n",
      "Epoch: 12500 train loss=0.003032319 valid loss= 0.004311276\n",
      "train reg_fs: 0.0014540953561663628\n",
      "Epoch: 13000 train loss=0.003047202 valid loss= 0.004344379\n",
      "train reg_fs: 0.0014467976288869977\n",
      "Epoch: 13500 train loss=0.004157205 valid loss= 0.004213008\n",
      "train reg_fs: 0.0014355945168063045\n",
      "Epoch: 14000 train loss=0.002269290 valid loss= 0.004315946\n",
      "train reg_fs: 0.0014286369550973177\n",
      "Epoch: 14500 train loss=0.002874706 valid loss= 0.004334274\n",
      "train reg_fs: 0.0014198784483596683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:42:50,536]\u001b[0m Trial 44 finished with value: 0.0027619606779797365 and parameters: {'lam': 0.0018649658578447734, 'learning_rate': 0.0604802198885013, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003694433 valid loss= 0.004186246\n",
      "train reg_fs: 0.0014101212145760655\n",
      "Optimization Finished!\n",
      "test loss: 0.004141325131058693, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027619606779797365\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020707037 valid loss= 0.006722507\n",
      "train reg_fs: 0.0009757947991602123\n",
      "Epoch: 1000 train loss=0.009551119 valid loss= 0.005897044\n",
      "train reg_fs: 0.0009435933898203075\n",
      "Epoch: 1500 train loss=0.007730165 valid loss= 0.004397386\n",
      "train reg_fs: 0.0009049298823811114\n",
      "Epoch: 2000 train loss=0.005471054 valid loss= 0.003869266\n",
      "train reg_fs: 0.0008761086501181126\n",
      "Epoch: 2500 train loss=0.003614358 valid loss= 0.003860977\n",
      "train reg_fs: 0.0008633162942714989\n",
      "Epoch: 3000 train loss=0.004842295 valid loss= 0.004332423\n",
      "train reg_fs: 0.000853858538903296\n",
      "Epoch: 3500 train loss=0.002155384 valid loss= 0.004117464\n",
      "train reg_fs: 0.0008481526747345924\n",
      "Epoch: 4000 train loss=0.005176002 valid loss= 0.004444867\n",
      "train reg_fs: 0.0008416164782829583\n",
      "Epoch: 4500 train loss=0.003274208 valid loss= 0.004442217\n",
      "train reg_fs: 0.0008362375083379447\n",
      "Epoch: 5000 train loss=0.006415948 valid loss= 0.004434330\n",
      "train reg_fs: 0.0008327794494107366\n",
      "Epoch: 5500 train loss=0.002483828 valid loss= 0.004380508\n",
      "train reg_fs: 0.0008294462459161878\n",
      "Epoch: 6000 train loss=0.001521439 valid loss= 0.004451365\n",
      "train reg_fs: 0.0008247861987911165\n",
      "Epoch: 6500 train loss=0.005023783 valid loss= 0.004444307\n",
      "train reg_fs: 0.0008216645219363272\n",
      "Epoch: 7000 train loss=0.003190348 valid loss= 0.004666185\n",
      "train reg_fs: 0.0008192498935386539\n",
      "Epoch: 7500 train loss=0.005043442 valid loss= 0.004596913\n",
      "train reg_fs: 0.0008164492319338024\n",
      "Epoch: 8000 train loss=0.003882771 valid loss= 0.004748294\n",
      "train reg_fs: 0.0008129127090796828\n",
      "Epoch: 8500 train loss=0.002096544 valid loss= 0.004618795\n",
      "train reg_fs: 0.0008104765438474715\n",
      "Epoch: 9000 train loss=0.002039728 valid loss= 0.004650522\n",
      "train reg_fs: 0.0008094205404631793\n",
      "Epoch: 9500 train loss=0.002816428 valid loss= 0.004520978\n",
      "train reg_fs: 0.0008057611994445324\n",
      "Epoch: 10000 train loss=0.002264282 valid loss= 0.004861832\n",
      "train reg_fs: 0.0008047122973948717\n",
      "Epoch: 10500 train loss=0.005594660 valid loss= 0.004712230\n",
      "train reg_fs: 0.0008024850976653397\n",
      "Epoch: 11000 train loss=0.002464579 valid loss= 0.004878340\n",
      "train reg_fs: 0.0007994332117959857\n",
      "Epoch: 11500 train loss=0.003429205 valid loss= 0.004875730\n",
      "train reg_fs: 0.0007962308591231704\n",
      "Epoch: 12000 train loss=0.002034044 valid loss= 0.004839152\n",
      "train reg_fs: 0.0007960763177834451\n",
      "Epoch: 12500 train loss=0.005487267 valid loss= 0.004564366\n",
      "train reg_fs: 0.0007933720480650663\n",
      "Epoch: 13000 train loss=0.002324584 valid loss= 0.004834428\n",
      "train reg_fs: 0.000791277620010078\n",
      "Epoch: 13500 train loss=0.002226422 valid loss= 0.004784684\n",
      "train reg_fs: 0.0007873577997088432\n",
      "Epoch: 14000 train loss=0.003988563 valid loss= 0.004647191\n",
      "train reg_fs: 0.0007834207499399781\n",
      "Epoch: 14500 train loss=0.003700725 valid loss= 0.004498411\n",
      "train reg_fs: 0.000782545655965805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:44:35,254]\u001b[0m Trial 45 finished with value: 0.003882195793057088 and parameters: {'lam': 0.0011437389440211018, 'learning_rate': 0.07944707422932908, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001685136 valid loss= 0.004689143\n",
      "train reg_fs: 0.0007794968551024795\n",
      "Optimization Finished!\n",
      "test loss: 0.004718598909676075, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003882195793057088\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009559117 valid loss= 0.007650145\n",
      "train reg_fs: 0.001210393849760294\n",
      "Epoch: 1000 train loss=0.015571970 valid loss= 0.007217044\n",
      "train reg_fs: 0.0012332615442574024\n",
      "Epoch: 1500 train loss=0.013146308 valid loss= 0.006274509\n",
      "train reg_fs: 0.0012416680110618472\n",
      "Epoch: 2000 train loss=0.008414361 valid loss= 0.004813503\n",
      "train reg_fs: 0.0012433003867045045\n",
      "Epoch: 2500 train loss=0.008534684 valid loss= 0.003763760\n",
      "train reg_fs: 0.0012363677378743887\n",
      "Epoch: 3000 train loss=0.001896690 valid loss= 0.004094923\n",
      "train reg_fs: 0.0012281654635444283\n",
      "Epoch: 3500 train loss=0.003444909 valid loss= 0.004029271\n",
      "train reg_fs: 0.0012202673824504018\n",
      "Epoch: 4000 train loss=0.004266612 valid loss= 0.004248197\n",
      "train reg_fs: 0.00121295393910259\n",
      "Epoch: 4500 train loss=0.004914214 valid loss= 0.004428671\n",
      "train reg_fs: 0.001205438282340765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:45:10,861]\u001b[0m Trial 46 finished with value: 0.0034988567743674845 and parameters: {'lam': 0.0013583390770096797, 'learning_rate': 0.10275592090203713, 'num_epoch': 5000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003796683 valid loss= 0.004688008\n",
      "train reg_fs: 0.0011969904880970716\n",
      "Optimization Finished!\n",
      "test loss: 0.005003178026527166, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0034988567743674845\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010735771 valid loss= 0.008581070\n",
      "train reg_fs: 0.002084996085613966\n",
      "Epoch: 1000 train loss=0.004480560 valid loss= 0.008505030\n",
      "train reg_fs: 0.0021068956702947617\n",
      "Epoch: 1500 train loss=0.007215075 valid loss= 0.008452072\n",
      "train reg_fs: 0.002099540550261736\n",
      "Epoch: 2000 train loss=0.010622695 valid loss= 0.007800933\n",
      "train reg_fs: 0.0020701789762824774\n",
      "Epoch: 2500 train loss=0.006518810 valid loss= 0.007599968\n",
      "train reg_fs: 0.0020336532033979893\n",
      "Epoch: 3000 train loss=0.006846811 valid loss= 0.006615547\n",
      "train reg_fs: 0.0019899634644389153\n",
      "Epoch: 3500 train loss=0.005589609 valid loss= 0.006059688\n",
      "train reg_fs: 0.0019528481643646955\n",
      "Epoch: 4000 train loss=0.004014129 valid loss= 0.005152962\n",
      "train reg_fs: 0.0019165041157975793\n",
      "Epoch: 4500 train loss=0.004709460 valid loss= 0.004730386\n",
      "train reg_fs: 0.0018817792879417539\n",
      "Epoch: 5000 train loss=0.004388285 valid loss= 0.004721230\n",
      "train reg_fs: 0.0018548478838056326\n",
      "Epoch: 5500 train loss=0.002557468 valid loss= 0.004753035\n",
      "train reg_fs: 0.001831431407481432\n",
      "Epoch: 6000 train loss=0.004201193 valid loss= 0.004424187\n",
      "train reg_fs: 0.001812058500945568\n",
      "Epoch: 6500 train loss=0.003363613 valid loss= 0.004634091\n",
      "train reg_fs: 0.0017946921288967133\n",
      "Epoch: 7000 train loss=0.006489373 valid loss= 0.004583497\n",
      "train reg_fs: 0.0017775562591850758\n",
      "Epoch: 7500 train loss=0.003990351 valid loss= 0.004429689\n",
      "train reg_fs: 0.0017640191363170743\n",
      "Epoch: 8000 train loss=0.002773199 valid loss= 0.004837822\n",
      "train reg_fs: 0.0017518758540973067\n",
      "Epoch: 8500 train loss=0.002820016 valid loss= 0.004780402\n",
      "train reg_fs: 0.0017391437431797385\n",
      "Epoch: 9000 train loss=0.005500206 valid loss= 0.004358611\n",
      "train reg_fs: 0.0017263870686292648\n",
      "Epoch: 9500 train loss=0.004330045 valid loss= 0.004695184\n",
      "train reg_fs: 0.0017134203808382154\n",
      "Epoch: 10000 train loss=0.004810525 valid loss= 0.004733775\n",
      "train reg_fs: 0.0017059645615518093\n",
      "Epoch: 10500 train loss=0.004708315 valid loss= 0.004336424\n",
      "train reg_fs: 0.0016983344685286283\n",
      "Epoch: 11000 train loss=0.003982813 valid loss= 0.004406723\n",
      "train reg_fs: 0.001687799347564578\n",
      "Epoch: 11500 train loss=0.002270451 valid loss= 0.004464968\n",
      "train reg_fs: 0.0016781515441834927\n",
      "Epoch: 12000 train loss=0.003065567 valid loss= 0.004379065\n",
      "train reg_fs: 0.0016680327244102955\n",
      "Epoch: 12500 train loss=0.002411859 valid loss= 0.004305927\n",
      "train reg_fs: 0.001660182955674827\n",
      "Epoch: 13000 train loss=0.002805399 valid loss= 0.004511536\n",
      "train reg_fs: 0.0016497279284521937\n",
      "Epoch: 13500 train loss=0.006177902 valid loss= 0.004364285\n",
      "train reg_fs: 0.0016432134434580803\n",
      "Epoch: 14000 train loss=0.009380762 valid loss= 0.004554115\n",
      "train reg_fs: 0.0016409402014687657\n",
      "Epoch: 14500 train loss=0.003384372 valid loss= 0.004558755\n",
      "train reg_fs: 0.0016347231576219201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:46:54,921]\u001b[0m Trial 47 finished with value: 0.003053283441201161 and parameters: {'lam': 0.0023988944004017256, 'learning_rate': 0.06698642978943162, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002537552 valid loss= 0.004671511\n",
      "train reg_fs: 0.0016304850578308105\n",
      "Optimization Finished!\n",
      "test loss: 0.004037296399474144, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003053283441201161\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007989945 valid loss= 0.008145459\n",
      "train reg_fs: 0.0014755291631445289\n",
      "Epoch: 1000 train loss=0.007453516 valid loss= 0.007693634\n",
      "train reg_fs: 0.0014917243970558047\n",
      "Epoch: 1500 train loss=0.007597215 valid loss= 0.007403127\n",
      "train reg_fs: 0.0014852572930976748\n",
      "Epoch: 2000 train loss=0.009811581 valid loss= 0.006753815\n",
      "train reg_fs: 0.0014631550293415785\n",
      "Epoch: 2500 train loss=0.013281403 valid loss= 0.006200241\n",
      "train reg_fs: 0.0014334996230900288\n",
      "Epoch: 3000 train loss=0.006431923 valid loss= 0.004919256\n",
      "train reg_fs: 0.0014035680796951056\n",
      "Epoch: 3500 train loss=0.003511249 valid loss= 0.004362524\n",
      "train reg_fs: 0.0013774195685982704\n",
      "Epoch: 4000 train loss=0.003289256 valid loss= 0.004286269\n",
      "train reg_fs: 0.0013544069370254874\n",
      "Epoch: 4500 train loss=0.003711571 valid loss= 0.004108830\n",
      "train reg_fs: 0.0013387157814577222\n",
      "Epoch: 5000 train loss=0.003614403 valid loss= 0.004424812\n",
      "train reg_fs: 0.0013251220807433128\n",
      "Epoch: 5500 train loss=0.003789019 valid loss= 0.004091371\n",
      "train reg_fs: 0.0013133058091625571\n",
      "Epoch: 6000 train loss=0.006176271 valid loss= 0.004105575\n",
      "train reg_fs: 0.0013036055024713278\n",
      "Epoch: 6500 train loss=0.011169447 valid loss= 0.004280351\n",
      "train reg_fs: 0.0012948724906891584\n",
      "Epoch: 7000 train loss=0.001705501 valid loss= 0.004065324\n",
      "train reg_fs: 0.0012866604374721646\n",
      "Epoch: 7500 train loss=0.004262004 valid loss= 0.004165565\n",
      "train reg_fs: 0.0012788274325430393\n",
      "Epoch: 8000 train loss=0.002846741 valid loss= 0.004064609\n",
      "train reg_fs: 0.0012716198107227683\n",
      "Epoch: 8500 train loss=0.001425023 valid loss= 0.003925838\n",
      "train reg_fs: 0.0012662779772654176\n",
      "Epoch: 9000 train loss=0.002258772 valid loss= 0.004031105\n",
      "train reg_fs: 0.00126078340690583\n",
      "Epoch: 9500 train loss=0.001947222 valid loss= 0.003932868\n",
      "train reg_fs: 0.0012557078152894974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:48:05,589]\u001b[0m Trial 48 finished with value: 0.0026839383024025347 and parameters: {'lam': 0.001708382410501945, 'learning_rate': 0.044163495977820155, 'num_epoch': 10000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001523634 valid loss= 0.003909480\n",
      "train reg_fs: 0.0012515411945059896\n",
      "Optimization Finished!\n",
      "test loss: 0.0037115232553333044, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026839383024025347\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010186864 valid loss= 0.007276641\n",
      "train reg_fs: 0.0008584494353272021\n",
      "Epoch: 1000 train loss=0.009052599 valid loss= 0.005506129\n",
      "train reg_fs: 0.0008267232333309948\n",
      "Epoch: 1500 train loss=0.014854534 valid loss= 0.004371121\n",
      "train reg_fs: 0.000794936204329133\n",
      "Epoch: 2000 train loss=0.003255692 valid loss= 0.004343249\n",
      "train reg_fs: 0.0007704966119490564\n",
      "Epoch: 2500 train loss=0.004106642 valid loss= 0.004074224\n",
      "train reg_fs: 0.0007550422451458871\n",
      "Epoch: 3000 train loss=0.001692226 valid loss= 0.003725738\n",
      "train reg_fs: 0.0007427230593748391\n",
      "Epoch: 3500 train loss=0.005210300 valid loss= 0.003698014\n",
      "train reg_fs: 0.0007277924451045692\n",
      "Epoch: 4000 train loss=0.006693834 valid loss= 0.003783440\n",
      "train reg_fs: 0.0007133752224035561\n",
      "Epoch: 4500 train loss=0.001022132 valid loss= 0.003788936\n",
      "train reg_fs: 0.0006982467602938414\n",
      "Epoch: 5000 train loss=0.002445771 valid loss= 0.003539627\n",
      "train reg_fs: 0.0006858711712993681\n",
      "Epoch: 5500 train loss=0.001890739 valid loss= 0.003267135\n",
      "train reg_fs: 0.0006753336056135595\n",
      "Epoch: 6000 train loss=0.004291158 valid loss= 0.003403823\n",
      "train reg_fs: 0.0006673683528788388\n",
      "Epoch: 6500 train loss=0.002582024 valid loss= 0.003184390\n",
      "train reg_fs: 0.0006605309317819774\n",
      "Epoch: 7000 train loss=0.001775501 valid loss= 0.003323271\n",
      "train reg_fs: 0.0006538719753734767\n",
      "Epoch: 7500 train loss=0.001872658 valid loss= 0.003223620\n",
      "train reg_fs: 0.0006488292710855603\n",
      "Epoch: 8000 train loss=0.004792633 valid loss= 0.002986421\n",
      "train reg_fs: 0.0006445517647080123\n",
      "Epoch: 8500 train loss=0.003093960 valid loss= 0.002879363\n",
      "train reg_fs: 0.0006410478963516653\n",
      "Epoch: 9000 train loss=0.003582241 valid loss= 0.003416132\n",
      "train reg_fs: 0.0006380400154739618\n",
      "Epoch: 9500 train loss=0.001827417 valid loss= 0.003046445\n",
      "train reg_fs: 0.0006354789948090911\n",
      "Epoch: 10000 train loss=0.001201713 valid loss= 0.003279955\n",
      "train reg_fs: 0.0006332613993436098\n",
      "Epoch: 10500 train loss=0.001983571 valid loss= 0.002871039\n",
      "train reg_fs: 0.0006313265184871852\n",
      "Epoch: 11000 train loss=0.002258207 valid loss= 0.003030862\n",
      "train reg_fs: 0.0006297407671809196\n",
      "Epoch: 11500 train loss=0.001527783 valid loss= 0.002864314\n",
      "train reg_fs: 0.0006281711393967271\n",
      "Epoch: 12000 train loss=0.002066596 valid loss= 0.002634861\n",
      "train reg_fs: 0.000626751862000674\n",
      "Epoch: 12500 train loss=0.001350894 valid loss= 0.002908384\n",
      "train reg_fs: 0.00062540452927351\n",
      "Epoch: 13000 train loss=0.002008559 valid loss= 0.003022059\n",
      "train reg_fs: 0.0006242822273634374\n",
      "Epoch: 13500 train loss=0.000864335 valid loss= 0.003270929\n",
      "train reg_fs: 0.0006232286687009037\n",
      "Epoch: 14000 train loss=0.014486083 valid loss= 0.002851839\n",
      "train reg_fs: 0.000622296123765409\n",
      "Epoch: 14500 train loss=0.001629775 valid loss= 0.002969748\n",
      "train reg_fs: 0.0006214459426701069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:49:50,953]\u001b[0m Trial 49 finished with value: 0.002406906621849814 and parameters: {'lam': 0.0010128450547305663, 'learning_rate': 0.08724396427907503, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001782334 valid loss= 0.003015831\n",
      "train reg_fs: 0.0006207213154993951\n",
      "Optimization Finished!\n",
      "test loss: 0.0027256638277322054, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002406906621849814\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019355461 valid loss= 0.008131718\n",
      "train reg_fs: 0.0025476766750216484\n",
      "Epoch: 1000 train loss=0.013940950 valid loss= 0.007233225\n",
      "train reg_fs: 0.0025418654549866915\n",
      "Epoch: 1500 train loss=0.011663069 valid loss= 0.006297098\n",
      "train reg_fs: 0.0024860475677996874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:50:06,508]\u001b[0m Trial 50 finished with value: 0.0026061936736402197 and parameters: {'lam': 0.00296443859551512, 'learning_rate': 0.05294338679528018, 'num_epoch': 2000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.009037632 valid loss= 0.005058252\n",
      "train reg_fs: 0.0024113936815410852\n",
      "Optimization Finished!\n",
      "test loss: 0.006231000646948814, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026061936736402197\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016015310 valid loss= 0.007152013\n",
      "train reg_fs: 0.0013477298198267817\n",
      "Epoch: 1000 train loss=0.011669800 valid loss= 0.006749208\n",
      "train reg_fs: 0.0013292725197970867\n",
      "Epoch: 1500 train loss=0.006819838 valid loss= 0.004829371\n",
      "train reg_fs: 0.001280128606595099\n",
      "Epoch: 2000 train loss=0.021758772 valid loss= 0.003981889\n",
      "train reg_fs: 0.0012331006582826376\n",
      "Epoch: 2500 train loss=0.002680158 valid loss= 0.003194826\n",
      "train reg_fs: 0.0011988780461251736\n",
      "Epoch: 3000 train loss=0.003470175 valid loss= 0.003795592\n",
      "train reg_fs: 0.0011742081260308623\n",
      "Epoch: 3500 train loss=0.003333050 valid loss= 0.003649022\n",
      "train reg_fs: 0.0011549036717042327\n",
      "Epoch: 4000 train loss=0.005245031 valid loss= 0.003973336\n",
      "train reg_fs: 0.0011381335789337754\n",
      "Epoch: 4500 train loss=0.001835185 valid loss= 0.003384403\n",
      "train reg_fs: 0.001124017289839685\n",
      "Epoch: 5000 train loss=0.005523692 valid loss= 0.003487289\n",
      "train reg_fs: 0.00111131533049047\n",
      "Epoch: 5500 train loss=0.001600613 valid loss= 0.003560483\n",
      "train reg_fs: 0.0010992512106895447\n",
      "Epoch: 6000 train loss=0.011080576 valid loss= 0.003239789\n",
      "train reg_fs: 0.0010869104880839586\n",
      "Epoch: 6500 train loss=0.002700362 valid loss= 0.003344538\n",
      "train reg_fs: 0.001074543222784996\n",
      "Epoch: 7000 train loss=0.005175691 valid loss= 0.003399485\n",
      "train reg_fs: 0.0010646935552358627\n",
      "Epoch: 7500 train loss=0.002251286 valid loss= 0.003303287\n",
      "train reg_fs: 0.0010565880220383406\n",
      "Epoch: 8000 train loss=0.002770211 valid loss= 0.003252408\n",
      "train reg_fs: 0.0010496309259906411\n",
      "Epoch: 8500 train loss=0.003771794 valid loss= 0.002894503\n",
      "train reg_fs: 0.0010426983935758471\n",
      "Epoch: 9000 train loss=0.001875558 valid loss= 0.003185214\n",
      "train reg_fs: 0.0010374418925493956\n",
      "Epoch: 9500 train loss=0.003424177 valid loss= 0.003419659\n",
      "train reg_fs: 0.0010332234669476748\n",
      "Epoch: 10000 train loss=0.008142036 valid loss= 0.003003263\n",
      "train reg_fs: 0.0010292421793565154\n",
      "Epoch: 10500 train loss=0.001783184 valid loss= 0.003379402\n",
      "train reg_fs: 0.0010256909299641848\n",
      "Epoch: 11000 train loss=0.002276692 valid loss= 0.003301024\n",
      "train reg_fs: 0.0010222330456599593\n",
      "Epoch: 11500 train loss=0.001943064 valid loss= 0.003231345\n",
      "train reg_fs: 0.0010191657347604632\n",
      "Epoch: 12000 train loss=0.002488833 valid loss= 0.003164090\n",
      "train reg_fs: 0.0010160061065107584\n",
      "Epoch: 12500 train loss=0.002021561 valid loss= 0.003154789\n",
      "train reg_fs: 0.001013208064250648\n",
      "Epoch: 13000 train loss=0.001412720 valid loss= 0.003164110\n",
      "train reg_fs: 0.0010104317916557193\n",
      "Epoch: 13500 train loss=0.002563152 valid loss= 0.003369950\n",
      "train reg_fs: 0.0010077140759676695\n",
      "Epoch: 14000 train loss=0.001667885 valid loss= 0.003187127\n",
      "train reg_fs: 0.001005238969810307\n",
      "Epoch: 14500 train loss=0.002139601 valid loss= 0.003252052\n",
      "train reg_fs: 0.001002759556286037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:51:50,589]\u001b[0m Trial 51 finished with value: 0.0021315080991468763 and parameters: {'lam': 0.0015662290576492306, 'learning_rate': 0.06296157971629239, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003703863 valid loss= 0.003126591\n",
      "train reg_fs: 0.0010002660565078259\n",
      "Optimization Finished!\n",
      "test loss: 0.0029794415459036827, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021315080991468763\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012782484 valid loss= 0.006040406\n",
      "train reg_fs: 0.001000716700218618\n",
      "Epoch: 1000 train loss=0.006614919 valid loss= 0.004328636\n",
      "train reg_fs: 0.0009542020270600915\n",
      "Epoch: 1500 train loss=0.004678344 valid loss= 0.003494233\n",
      "train reg_fs: 0.0009207387920469046\n",
      "Epoch: 2000 train loss=0.006700438 valid loss= 0.003251245\n",
      "train reg_fs: 0.0009086442878469825\n",
      "Epoch: 2500 train loss=0.006773853 valid loss= 0.003598092\n",
      "train reg_fs: 0.0009074365952983499\n",
      "Epoch: 3000 train loss=0.002645606 valid loss= 0.003868363\n",
      "train reg_fs: 0.0009099215967580676\n",
      "Epoch: 3500 train loss=0.002490028 valid loss= 0.003129938\n",
      "train reg_fs: 0.0009124982170760632\n",
      "Epoch: 4000 train loss=0.002748921 valid loss= 0.003574794\n",
      "train reg_fs: 0.0009136263397522271\n",
      "Epoch: 4500 train loss=0.002655798 valid loss= 0.003419244\n",
      "train reg_fs: 0.000911612412892282\n",
      "Epoch: 5000 train loss=0.006630937 valid loss= 0.003719662\n",
      "train reg_fs: 0.0009060663287527859\n",
      "Epoch: 5500 train loss=0.003204866 valid loss= 0.003383413\n",
      "train reg_fs: 0.0008989411289803684\n",
      "Epoch: 6000 train loss=0.001810050 valid loss= 0.003657385\n",
      "train reg_fs: 0.0008925635484047234\n",
      "Epoch: 6500 train loss=0.004438370 valid loss= 0.002809134\n",
      "train reg_fs: 0.0008879149681888521\n",
      "Epoch: 7000 train loss=0.002587697 valid loss= 0.003223629\n",
      "train reg_fs: 0.0008845573756843805\n",
      "Epoch: 7500 train loss=0.004639998 valid loss= 0.002607276\n",
      "train reg_fs: 0.0008819540380500257\n",
      "Epoch: 8000 train loss=0.005514195 valid loss= 0.002954533\n",
      "train reg_fs: 0.0008806601981632411\n",
      "Epoch: 8500 train loss=0.003218173 valid loss= 0.003018165\n",
      "train reg_fs: 0.0008793422020971775\n",
      "Epoch: 9000 train loss=0.006161979 valid loss= 0.002968528\n",
      "train reg_fs: 0.0008782789227552712\n",
      "Epoch: 9500 train loss=0.002440868 valid loss= 0.003087688\n",
      "train reg_fs: 0.0008769975393079221\n",
      "Epoch: 10000 train loss=0.002303503 valid loss= 0.002574659\n",
      "train reg_fs: 0.0008761542267166078\n",
      "Epoch: 10500 train loss=0.010131146 valid loss= 0.002621269\n",
      "train reg_fs: 0.00087527692085132\n",
      "Epoch: 11000 train loss=0.001665083 valid loss= 0.002544701\n",
      "train reg_fs: 0.0008748589898459613\n",
      "Epoch: 11500 train loss=0.002038008 valid loss= 0.002787087\n",
      "train reg_fs: 0.0008743722573854029\n",
      "Epoch: 12000 train loss=0.002022092 valid loss= 0.002973347\n",
      "train reg_fs: 0.0008739008335396647\n",
      "Epoch: 12500 train loss=0.002399567 valid loss= 0.002945003\n",
      "train reg_fs: 0.0008732810383662581\n",
      "Epoch: 13000 train loss=0.002923165 valid loss= 0.002580750\n",
      "train reg_fs: 0.0008727084496058524\n",
      "Epoch: 13500 train loss=0.002128162 valid loss= 0.002977744\n",
      "train reg_fs: 0.0008719422039575875\n",
      "Epoch: 14000 train loss=0.002219926 valid loss= 0.002682286\n",
      "train reg_fs: 0.0008707931847311556\n",
      "Epoch: 14500 train loss=0.006062181 valid loss= 0.002986256\n",
      "train reg_fs: 0.0008705558138899505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:53:33,439]\u001b[0m Trial 52 finished with value: 0.0018005739322869833 and parameters: {'lam': 0.0011750359953621764, 'learning_rate': 0.07811173222282745, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001822429 valid loss= 0.002654744\n",
      "train reg_fs: 0.0008694825228303671\n",
      "Optimization Finished!\n",
      "test loss: 0.0025245645083487034, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0018005739322869833\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012517046 valid loss= 0.006724318\n",
      "train reg_fs: 0.0009944273624569178\n",
      "Epoch: 1000 train loss=0.014060168 valid loss= 0.005822845\n",
      "train reg_fs: 0.0009899644646793604\n",
      "Epoch: 1500 train loss=0.005151101 valid loss= 0.003856292\n",
      "train reg_fs: 0.0009360258118249476\n",
      "Epoch: 2000 train loss=0.004978021 valid loss= 0.003388854\n",
      "train reg_fs: 0.0008913185447454453\n",
      "Epoch: 2500 train loss=0.007641298 valid loss= 0.003190256\n",
      "train reg_fs: 0.0008715449366718531\n",
      "Epoch: 3000 train loss=0.001629332 valid loss= 0.003103219\n",
      "train reg_fs: 0.0008615259430371225\n",
      "Epoch: 3500 train loss=0.002412556 valid loss= 0.003194246\n",
      "train reg_fs: 0.0008558745612390339\n",
      "Epoch: 4000 train loss=0.002801899 valid loss= 0.002901394\n",
      "train reg_fs: 0.0008515608496963978\n",
      "Epoch: 4500 train loss=0.002508049 valid loss= 0.002758761\n",
      "train reg_fs: 0.0008489724132232368\n",
      "Epoch: 5000 train loss=0.007257815 valid loss= 0.002545400\n",
      "train reg_fs: 0.0008477062801830471\n",
      "Epoch: 5500 train loss=0.001753869 valid loss= 0.002792259\n",
      "train reg_fs: 0.0008462410769425333\n",
      "Epoch: 6000 train loss=0.005244580 valid loss= 0.002645571\n",
      "train reg_fs: 0.0008455111528746784\n",
      "Epoch: 6500 train loss=0.001356086 valid loss= 0.002694262\n",
      "train reg_fs: 0.0008453144691884518\n",
      "Epoch: 7000 train loss=0.008198105 valid loss= 0.003156607\n",
      "train reg_fs: 0.0008446809370070696\n",
      "Epoch: 7500 train loss=0.001346029 valid loss= 0.003146460\n",
      "train reg_fs: 0.0008445850107818842\n",
      "Epoch: 8000 train loss=0.001326955 valid loss= 0.002808140\n",
      "train reg_fs: 0.0008442513062618673\n",
      "Epoch: 8500 train loss=0.010979695 valid loss= 0.002818576\n",
      "train reg_fs: 0.0008439032826572657\n",
      "Epoch: 9000 train loss=0.001669086 valid loss= 0.002938021\n",
      "train reg_fs: 0.000843833782710135\n",
      "Epoch: 9500 train loss=0.009918446 valid loss= 0.002656208\n",
      "train reg_fs: 0.0008435964700765908\n",
      "Epoch: 10000 train loss=0.001589524 valid loss= 0.002699565\n",
      "train reg_fs: 0.0008433092734776437\n",
      "Epoch: 10500 train loss=0.006202206 valid loss= 0.002376750\n",
      "train reg_fs: 0.0008429587469436228\n",
      "Epoch: 11000 train loss=0.001702256 valid loss= 0.002682927\n",
      "train reg_fs: 0.0008426941931247711\n",
      "Epoch: 11500 train loss=0.001968074 valid loss= 0.002500946\n",
      "train reg_fs: 0.0008424061234109104\n",
      "Epoch: 12000 train loss=0.001307434 valid loss= 0.002689395\n",
      "train reg_fs: 0.0008416604832746089\n",
      "Epoch: 12500 train loss=0.004152698 valid loss= 0.002703844\n",
      "train reg_fs: 0.0008412016904912889\n",
      "Epoch: 13000 train loss=0.003939650 valid loss= 0.002459573\n",
      "train reg_fs: 0.0008406433626078069\n",
      "Epoch: 13500 train loss=0.002159806 valid loss= 0.003033572\n",
      "train reg_fs: 0.0008399766520597041\n",
      "Epoch: 14000 train loss=0.004425763 valid loss= 0.002480065\n",
      "train reg_fs: 0.0008392311865463853\n",
      "Epoch: 14500 train loss=0.011446403 valid loss= 0.002936330\n",
      "train reg_fs: 0.0008386583649553359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:55:17,611]\u001b[0m Trial 53 finished with value: 0.002041703982852265 and parameters: {'lam': 0.001142750129982198, 'learning_rate': 0.0721754246807025, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002392652 valid loss= 0.002854104\n",
      "train reg_fs: 0.0008377699996344745\n",
      "Optimization Finished!\n",
      "test loss: 0.0027181238401681185, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002041703982852265\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007331649 valid loss= 0.007103403\n",
      "train reg_fs: 0.0012168838875368237\n",
      "Epoch: 1000 train loss=0.005723480 valid loss= 0.006143278\n",
      "train reg_fs: 0.0011617625132203102\n",
      "Epoch: 1500 train loss=0.006069505 valid loss= 0.003601182\n",
      "train reg_fs: 0.0010969950817525387\n",
      "Epoch: 2000 train loss=0.003494869 valid loss= 0.002986171\n",
      "train reg_fs: 0.0010437904857099056\n",
      "Epoch: 2500 train loss=0.001801418 valid loss= 0.003370287\n",
      "train reg_fs: 0.0010163412662222981\n",
      "Epoch: 3000 train loss=0.004335399 valid loss= 0.003376444\n",
      "train reg_fs: 0.0009922467870637774\n",
      "Epoch: 3500 train loss=0.002844574 valid loss= 0.003615615\n",
      "train reg_fs: 0.0009690261795185506\n",
      "Epoch: 4000 train loss=0.002188304 valid loss= 0.003138710\n",
      "train reg_fs: 0.0009502987377345562\n",
      "Epoch: 4500 train loss=0.005068035 valid loss= 0.003672899\n",
      "train reg_fs: 0.0009337571682408452\n",
      "Epoch: 5000 train loss=0.001925218 valid loss= 0.003020646\n",
      "train reg_fs: 0.0009213630692102015\n",
      "Epoch: 5500 train loss=0.004964930 valid loss= 0.003319513\n",
      "train reg_fs: 0.0009119231253862381\n",
      "Epoch: 6000 train loss=0.001441725 valid loss= 0.003129056\n",
      "train reg_fs: 0.0009041662560775876\n",
      "Epoch: 6500 train loss=0.007951112 valid loss= 0.003466785\n",
      "train reg_fs: 0.0008971847128123045\n",
      "Epoch: 7000 train loss=0.002087836 valid loss= 0.003292639\n",
      "train reg_fs: 0.0008914514328353107\n",
      "Epoch: 7500 train loss=0.003535315 valid loss= 0.003197333\n",
      "train reg_fs: 0.0008866377174854279\n",
      "Epoch: 8000 train loss=0.001811411 valid loss= 0.003220719\n",
      "train reg_fs: 0.0008820800576359034\n",
      "Epoch: 8500 train loss=0.002479636 valid loss= 0.003210078\n",
      "train reg_fs: 0.0008781250799074769\n",
      "Epoch: 9000 train loss=0.001965653 valid loss= 0.003170206\n",
      "train reg_fs: 0.0008745573577471077\n",
      "Epoch: 9500 train loss=0.001459600 valid loss= 0.003326672\n",
      "train reg_fs: 0.000871356634888798\n",
      "Epoch: 10000 train loss=0.003383636 valid loss= 0.003136703\n",
      "train reg_fs: 0.0008687632507644594\n",
      "Epoch: 10500 train loss=0.006459474 valid loss= 0.002900517\n",
      "train reg_fs: 0.000866300193592906\n",
      "Epoch: 11000 train loss=0.001153331 valid loss= 0.003215196\n",
      "train reg_fs: 0.0008642756729386747\n",
      "Epoch: 11500 train loss=0.001696040 valid loss= 0.003082314\n",
      "train reg_fs: 0.0008622780442237854\n",
      "Epoch: 12000 train loss=0.001687206 valid loss= 0.003114450\n",
      "train reg_fs: 0.0008604272734373808\n",
      "Epoch: 12500 train loss=0.002866324 valid loss= 0.002990997\n",
      "train reg_fs: 0.0008589616045355797\n",
      "Epoch: 13000 train loss=0.002841854 valid loss= 0.003356655\n",
      "train reg_fs: 0.0008575833635404706\n",
      "Epoch: 13500 train loss=0.004169104 valid loss= 0.003112557\n",
      "train reg_fs: 0.0008562474395148456\n",
      "Epoch: 14000 train loss=0.001006833 valid loss= 0.003297627\n",
      "train reg_fs: 0.0008551000501029193\n",
      "Epoch: 14500 train loss=0.001304418 valid loss= 0.002820162\n",
      "train reg_fs: 0.0008540601702407002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:57:01,529]\u001b[0m Trial 54 finished with value: 0.0022124739518945267 and parameters: {'lam': 0.001401523246247557, 'learning_rate': 0.11642728651486785, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001079712 valid loss= 0.003047453\n",
      "train reg_fs: 0.0008530645864084363\n",
      "Optimization Finished!\n",
      "test loss: 0.0029000442009419203, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022124739518945267\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011455358 valid loss= 0.008100037\n",
      "train reg_fs: 0.0014951428165659308\n",
      "Epoch: 1000 train loss=0.008689141 valid loss= 0.008938801\n",
      "train reg_fs: 0.0015157529851421714\n",
      "Epoch: 1500 train loss=0.007373849 valid loss= 0.008281903\n",
      "train reg_fs: 0.0015030722133815289\n",
      "Epoch: 2000 train loss=0.010824985 valid loss= 0.007586354\n",
      "train reg_fs: 0.0014695058343932033\n",
      "Epoch: 2500 train loss=0.005271805 valid loss= 0.006570992\n",
      "train reg_fs: 0.001433990546502173\n",
      "Epoch: 3000 train loss=0.003286006 valid loss= 0.006276422\n",
      "train reg_fs: 0.0014069147873669863\n",
      "Epoch: 3500 train loss=0.005448761 valid loss= 0.005809542\n",
      "train reg_fs: 0.0013870644615963101\n",
      "Epoch: 4000 train loss=0.004861596 valid loss= 0.004682278\n",
      "train reg_fs: 0.001368811121210456\n",
      "Epoch: 4500 train loss=0.003379173 valid loss= 0.004510813\n",
      "train reg_fs: 0.0013481051428243518\n",
      "Epoch: 5000 train loss=0.003172753 valid loss= 0.004423810\n",
      "train reg_fs: 0.0013276900863274932\n",
      "Epoch: 5500 train loss=0.002942142 valid loss= 0.004603229\n",
      "train reg_fs: 0.0013112490996718407\n",
      "Epoch: 6000 train loss=0.003309269 valid loss= 0.004284773\n",
      "train reg_fs: 0.0012945266207680106\n",
      "Epoch: 6500 train loss=0.005633027 valid loss= 0.004152311\n",
      "train reg_fs: 0.0012815202353522182\n",
      "Epoch: 7000 train loss=0.005286715 valid loss= 0.004467017\n",
      "train reg_fs: 0.0012713546166196465\n",
      "Epoch: 7500 train loss=0.003633564 valid loss= 0.004642994\n",
      "train reg_fs: 0.001259487122297287\n",
      "Epoch: 8000 train loss=0.002544723 valid loss= 0.004564026\n",
      "train reg_fs: 0.001249170396476984\n",
      "Epoch: 8500 train loss=0.001752122 valid loss= 0.004767341\n",
      "train reg_fs: 0.0012378799729049206\n",
      "Epoch: 9000 train loss=0.002637616 valid loss= 0.004732568\n",
      "train reg_fs: 0.0012269825674593449\n",
      "Epoch: 9500 train loss=0.004450653 valid loss= 0.004587963\n",
      "train reg_fs: 0.0012171714333817363\n",
      "Epoch: 10000 train loss=0.002758926 valid loss= 0.004770430\n",
      "train reg_fs: 0.001210356829687953\n",
      "Epoch: 10500 train loss=0.002129150 valid loss= 0.004806868\n",
      "train reg_fs: 0.001202508807182312\n",
      "Epoch: 11000 train loss=0.002430005 valid loss= 0.004893572\n",
      "train reg_fs: 0.0011950015323236585\n",
      "Epoch: 11500 train loss=0.002219295 valid loss= 0.004747604\n",
      "train reg_fs: 0.00118862628005445\n",
      "Epoch: 12000 train loss=0.003541528 valid loss= 0.004571793\n",
      "train reg_fs: 0.0011807361152023077\n",
      "Epoch: 12500 train loss=0.002909742 valid loss= 0.004879176\n",
      "train reg_fs: 0.0011743109207600355\n",
      "Epoch: 13000 train loss=0.002381070 valid loss= 0.004933822\n",
      "train reg_fs: 0.0011681918986141682\n",
      "Epoch: 13500 train loss=0.001812939 valid loss= 0.005103549\n",
      "train reg_fs: 0.0011623125756159425\n",
      "Epoch: 14000 train loss=0.002616713 valid loss= 0.005286196\n",
      "train reg_fs: 0.001155673642642796\n",
      "Epoch: 14500 train loss=0.002941697 valid loss= 0.005087313\n",
      "train reg_fs: 0.0011507029412314296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 22:58:46,876]\u001b[0m Trial 55 finished with value: 0.003870367223109636 and parameters: {'lam': 0.0017106314650317958, 'learning_rate': 0.07648925286204296, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002274016 valid loss= 0.005061990\n",
      "train reg_fs: 0.0011448689037933946\n",
      "Optimization Finished!\n",
      "test loss: 0.005253176670521498, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003870367223109636\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013102272 valid loss= 0.006047298\n",
      "train reg_fs: 0.0010384222259745002\n",
      "Epoch: 1000 train loss=0.014033833 valid loss= 0.005166504\n",
      "train reg_fs: 0.0009973449632525444\n",
      "Epoch: 1500 train loss=0.005224970 valid loss= 0.004199076\n",
      "train reg_fs: 0.0009407337638549507\n",
      "Epoch: 2000 train loss=0.009883925 valid loss= 0.004627264\n",
      "train reg_fs: 0.0009159616893157363\n",
      "Epoch: 2500 train loss=0.003820216 valid loss= 0.004583992\n",
      "train reg_fs: 0.0009084146004170179\n",
      "Epoch: 3000 train loss=0.004104217 valid loss= 0.004618954\n",
      "train reg_fs: 0.0009047577623277903\n",
      "Epoch: 3500 train loss=0.007983232 valid loss= 0.004291721\n",
      "train reg_fs: 0.0009061184828169644\n",
      "Epoch: 4000 train loss=0.004603097 valid loss= 0.004210890\n",
      "train reg_fs: 0.0009070936939679086\n",
      "Epoch: 4500 train loss=0.002825349 valid loss= 0.004235185\n",
      "train reg_fs: 0.0009080017334781587\n",
      "Epoch: 5000 train loss=0.003302925 valid loss= 0.004163910\n",
      "train reg_fs: 0.0009067438077181578\n",
      "Epoch: 5500 train loss=0.003860526 valid loss= 0.004111897\n",
      "train reg_fs: 0.0009018418495543301\n",
      "Epoch: 6000 train loss=0.001847842 valid loss= 0.003954594\n",
      "train reg_fs: 0.0008915942744351923\n",
      "Epoch: 6500 train loss=0.004001676 valid loss= 0.003923937\n",
      "train reg_fs: 0.0008804298704490066\n",
      "Epoch: 7000 train loss=0.001369418 valid loss= 0.003855069\n",
      "train reg_fs: 0.0008688376983627677\n",
      "Epoch: 7500 train loss=0.001481616 valid loss= 0.003476340\n",
      "train reg_fs: 0.0008589521166868508\n",
      "Epoch: 8000 train loss=0.002073935 valid loss= 0.003331409\n",
      "train reg_fs: 0.0008507500751875341\n",
      "Epoch: 8500 train loss=0.007998348 valid loss= 0.003220666\n",
      "train reg_fs: 0.0008440554956905544\n",
      "Epoch: 9000 train loss=0.015115830 valid loss= 0.003369369\n",
      "train reg_fs: 0.0008384015527553856\n",
      "Epoch: 9500 train loss=0.003573241 valid loss= 0.003518048\n",
      "train reg_fs: 0.0008359695784747601\n",
      "Epoch: 10000 train loss=0.001934825 valid loss= 0.002969384\n",
      "train reg_fs: 0.0008312977734021842\n",
      "Epoch: 10500 train loss=0.004256689 valid loss= 0.002941894\n",
      "train reg_fs: 0.0008263290510512888\n",
      "Epoch: 11000 train loss=0.007778950 valid loss= 0.003274221\n",
      "train reg_fs: 0.0008221575408242643\n",
      "Epoch: 11500 train loss=0.002910875 valid loss= 0.003123599\n",
      "train reg_fs: 0.0008176871342584491\n",
      "Epoch: 12000 train loss=0.001164505 valid loss= 0.003544077\n",
      "train reg_fs: 0.0008120842976495624\n",
      "Epoch: 12500 train loss=0.002836501 valid loss= 0.002905970\n",
      "train reg_fs: 0.0008076195954345167\n",
      "Epoch: 13000 train loss=0.001617402 valid loss= 0.003268872\n",
      "train reg_fs: 0.0008040238171815872\n",
      "Epoch: 13500 train loss=0.001825979 valid loss= 0.003176317\n",
      "train reg_fs: 0.0008002768736332655\n",
      "Epoch: 14000 train loss=0.001659095 valid loss= 0.003471561\n",
      "train reg_fs: 0.0007977972854860127\n",
      "Epoch: 14500 train loss=0.001599170 valid loss= 0.003009088\n",
      "train reg_fs: 0.0007943451637402177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:00:30,619]\u001b[0m Trial 56 finished with value: 0.0024338955629633193 and parameters: {'lam': 0.0011979074421392796, 'learning_rate': 0.09949923752781419, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001806068 valid loss= 0.003206538\n",
      "train reg_fs: 0.0007908337283879519\n",
      "Optimization Finished!\n",
      "test loss: 0.0028000923339277506, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024338955629633193\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012945380 valid loss= 0.006919026\n",
      "train reg_fs: 0.0018711872398853302\n",
      "Epoch: 1000 train loss=0.007353628 valid loss= 0.006631084\n",
      "train reg_fs: 0.0018537120195105672\n",
      "Epoch: 1500 train loss=0.005399025 valid loss= 0.004836697\n",
      "train reg_fs: 0.001770338392816484\n",
      "Epoch: 2000 train loss=0.007826574 valid loss= 0.004157961\n",
      "train reg_fs: 0.0017075545620173216\n",
      "Epoch: 2500 train loss=0.005819361 valid loss= 0.004171621\n",
      "train reg_fs: 0.0016822813777253032\n",
      "Epoch: 3000 train loss=0.004046588 valid loss= 0.004107888\n",
      "train reg_fs: 0.0016676465747877955\n",
      "Epoch: 3500 train loss=0.004560362 valid loss= 0.004267061\n",
      "train reg_fs: 0.001648786012083292\n",
      "Epoch: 4000 train loss=0.004576708 valid loss= 0.004583417\n",
      "train reg_fs: 0.0016309041529893875\n",
      "Epoch: 4500 train loss=0.005198424 valid loss= 0.004597108\n",
      "train reg_fs: 0.001615758053958416\n",
      "Epoch: 5000 train loss=0.003093150 valid loss= 0.003771651\n",
      "train reg_fs: 0.0016007587546482682\n",
      "Epoch: 5500 train loss=0.006405212 valid loss= 0.003704075\n",
      "train reg_fs: 0.00159022759180516\n",
      "Epoch: 6000 train loss=0.008745145 valid loss= 0.004128487\n",
      "train reg_fs: 0.0015820186818018556\n",
      "Epoch: 6500 train loss=0.003787298 valid loss= 0.003843807\n",
      "train reg_fs: 0.0015747601864859462\n",
      "Epoch: 7000 train loss=0.002697171 valid loss= 0.003886591\n",
      "train reg_fs: 0.0015654320595785975\n",
      "Epoch: 7500 train loss=0.004300237 valid loss= 0.003879375\n",
      "train reg_fs: 0.001557655050419271\n",
      "Epoch: 8000 train loss=0.002105781 valid loss= 0.003659704\n",
      "train reg_fs: 0.0015524942427873611\n",
      "Epoch: 8500 train loss=0.005740260 valid loss= 0.003785789\n",
      "train reg_fs: 0.0015448433114215732\n",
      "Epoch: 9000 train loss=0.002220203 valid loss= 0.003924700\n",
      "train reg_fs: 0.0015404588775709271\n",
      "Epoch: 9500 train loss=0.002405256 valid loss= 0.003718160\n",
      "train reg_fs: 0.0015384303405880928\n",
      "Epoch: 10000 train loss=0.006793789 valid loss= 0.003795743\n",
      "train reg_fs: 0.00153400341514498\n",
      "Epoch: 10500 train loss=0.003125976 valid loss= 0.003394941\n",
      "train reg_fs: 0.0015306085115298629\n",
      "Epoch: 11000 train loss=0.002333530 valid loss= 0.004230958\n",
      "train reg_fs: 0.001525923958979547\n",
      "Epoch: 11500 train loss=0.004637187 valid loss= 0.003532574\n",
      "train reg_fs: 0.0015217801555991173\n",
      "Epoch: 12000 train loss=0.005381037 valid loss= 0.003447515\n",
      "train reg_fs: 0.0015180783811956644\n",
      "Epoch: 12500 train loss=0.002026035 valid loss= 0.003375869\n",
      "train reg_fs: 0.0015142365591600537\n",
      "Epoch: 13000 train loss=0.001860559 valid loss= 0.003419653\n",
      "train reg_fs: 0.0015111817046999931\n",
      "Epoch: 13500 train loss=0.001924658 valid loss= 0.003920412\n",
      "train reg_fs: 0.001507192268036306\n",
      "Epoch: 14000 train loss=0.003483898 valid loss= 0.003770719\n",
      "train reg_fs: 0.0015057383570820093\n",
      "Epoch: 14500 train loss=0.001706426 valid loss= 0.003635372\n",
      "train reg_fs: 0.0015033213421702385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:02:15,488]\u001b[0m Trial 57 finished with value: 0.0020765946439756156 and parameters: {'lam': 0.002150871792614967, 'learning_rate': 0.09042603441445138, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001737736 valid loss= 0.003524216\n",
      "train reg_fs: 0.0015025361208245158\n",
      "Optimization Finished!\n",
      "test loss: 0.003422739915549755, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020765946439756156\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013581994 valid loss= 0.010519459\n",
      "train reg_fs: 0.0033171584364026785\n",
      "Epoch: 1000 train loss=0.013249260 valid loss= 0.009649208\n",
      "train reg_fs: 0.0033359441440552473\n",
      "Epoch: 1500 train loss=0.014694331 valid loss= 0.009302004\n",
      "train reg_fs: 0.0033084326423704624\n",
      "Epoch: 2000 train loss=0.007176440 valid loss= 0.009554584\n",
      "train reg_fs: 0.0032405531965196133\n",
      "Epoch: 2500 train loss=0.011709102 valid loss= 0.008925817\n",
      "train reg_fs: 0.0031653931364417076\n",
      "Epoch: 3000 train loss=0.007668835 valid loss= 0.008090580\n",
      "train reg_fs: 0.0030854609794914722\n",
      "Epoch: 3500 train loss=0.007663680 valid loss= 0.007144836\n",
      "train reg_fs: 0.0030088266357779503\n",
      "Epoch: 4000 train loss=0.005238695 valid loss= 0.006518928\n",
      "train reg_fs: 0.00293620559386909\n",
      "Epoch: 4500 train loss=0.003970389 valid loss= 0.006488389\n",
      "train reg_fs: 0.002885807305574417\n",
      "Epoch: 5000 train loss=0.005192428 valid loss= 0.006677986\n",
      "train reg_fs: 0.0028431180398911238\n",
      "Epoch: 5500 train loss=0.004900778 valid loss= 0.006846624\n",
      "train reg_fs: 0.0028068935498595238\n",
      "Epoch: 6000 train loss=0.004671065 valid loss= 0.006329802\n",
      "train reg_fs: 0.0027734222821891308\n",
      "Epoch: 6500 train loss=0.004216663 valid loss= 0.006615905\n",
      "train reg_fs: 0.0027422625571489334\n",
      "Epoch: 7000 train loss=0.006004795 valid loss= 0.006659118\n",
      "train reg_fs: 0.00271418783813715\n",
      "Epoch: 7500 train loss=0.003779387 valid loss= 0.006191884\n",
      "train reg_fs: 0.002682809019461274\n",
      "Epoch: 8000 train loss=0.003768458 valid loss= 0.005932723\n",
      "train reg_fs: 0.0026492117904126644\n",
      "Epoch: 8500 train loss=0.005149844 valid loss= 0.006368859\n",
      "train reg_fs: 0.002619365928694606\n",
      "Epoch: 9000 train loss=0.005039738 valid loss= 0.005907678\n",
      "train reg_fs: 0.0025916139129549265\n",
      "Epoch: 9500 train loss=0.004309509 valid loss= 0.005937692\n",
      "train reg_fs: 0.0025657147634774446\n",
      "Epoch: 10000 train loss=0.004296566 valid loss= 0.005537743\n",
      "train reg_fs: 0.00254213553853333\n",
      "Epoch: 10500 train loss=0.005281292 valid loss= 0.005255896\n",
      "train reg_fs: 0.0025209463201463223\n",
      "Epoch: 11000 train loss=0.003797893 valid loss= 0.005253911\n",
      "train reg_fs: 0.0025019447784870863\n",
      "Epoch: 11500 train loss=0.003220587 valid loss= 0.005177347\n",
      "train reg_fs: 0.0024872508365660906\n",
      "Epoch: 12000 train loss=0.003110779 valid loss= 0.005197336\n",
      "train reg_fs: 0.0024725852999836206\n",
      "Epoch: 12500 train loss=0.003607812 valid loss= 0.005163889\n",
      "train reg_fs: 0.0024606049992144108\n",
      "Epoch: 13000 train loss=0.002662671 valid loss= 0.004954364\n",
      "train reg_fs: 0.0024496293626725674\n",
      "Epoch: 13500 train loss=0.005020916 valid loss= 0.004978174\n",
      "train reg_fs: 0.002439633710309863\n",
      "Epoch: 14000 train loss=0.004612656 valid loss= 0.004970440\n",
      "train reg_fs: 0.0024310764856636524\n",
      "Epoch: 14500 train loss=0.007783901 valid loss= 0.004490893\n",
      "train reg_fs: 0.0024232135619968176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:04:00,256]\u001b[0m Trial 58 finished with value: 0.0025852467848266414 and parameters: {'lam': 0.003866862113892577, 'learning_rate': 0.046802779488728144, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004007449 valid loss= 0.004976200\n",
      "train reg_fs: 0.0024162146728485823\n",
      "Optimization Finished!\n",
      "test loss: 0.004696773365139961, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025852467848266414\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010987017 valid loss= 0.009753313\n",
      "train reg_fs: 0.0028384521137923002\n",
      "Epoch: 1000 train loss=0.008909489 valid loss= 0.009593360\n",
      "train reg_fs: 0.0028706917073577642\n",
      "Epoch: 1500 train loss=0.010125185 valid loss= 0.009594288\n",
      "train reg_fs: 0.002886183327063918\n",
      "Epoch: 2000 train loss=0.011700106 valid loss= 0.009107745\n",
      "train reg_fs: 0.0028872117400169373\n",
      "Epoch: 2500 train loss=0.011870308 valid loss= 0.008752386\n",
      "train reg_fs: 0.00287340534850955\n",
      "Epoch: 3000 train loss=0.011760224 valid loss= 0.008370671\n",
      "train reg_fs: 0.00284758023917675\n",
      "Epoch: 3500 train loss=0.005776770 valid loss= 0.008282561\n",
      "train reg_fs: 0.0028161697555333376\n",
      "Epoch: 4000 train loss=0.013114726 valid loss= 0.008440079\n",
      "train reg_fs: 0.002773741027340293\n",
      "Epoch: 4500 train loss=0.011547220 valid loss= 0.007864676\n",
      "train reg_fs: 0.0027336273342370987\n",
      "Epoch: 5000 train loss=0.020937216 valid loss= 0.008049213\n",
      "train reg_fs: 0.0026954482309520245\n",
      "Epoch: 5500 train loss=0.005430613 valid loss= 0.007481837\n",
      "train reg_fs: 0.0026608731132000685\n",
      "Epoch: 6000 train loss=0.009348611 valid loss= 0.007442392\n",
      "train reg_fs: 0.0026290714740753174\n",
      "Epoch: 6500 train loss=0.007480370 valid loss= 0.006907715\n",
      "train reg_fs: 0.0025954863522201777\n",
      "Epoch: 7000 train loss=0.006167362 valid loss= 0.005976615\n",
      "train reg_fs: 0.0025609468575567007\n",
      "Epoch: 7500 train loss=0.003337528 valid loss= 0.006178085\n",
      "train reg_fs: 0.0025265743024647236\n",
      "Epoch: 8000 train loss=0.004497324 valid loss= 0.005824476\n",
      "train reg_fs: 0.0024975736159831285\n",
      "Epoch: 8500 train loss=0.017492885 valid loss= 0.005782387\n",
      "train reg_fs: 0.002469167346134782\n",
      "Epoch: 9000 train loss=0.007400291 valid loss= 0.005811719\n",
      "train reg_fs: 0.0024456798564642668\n",
      "Epoch: 9500 train loss=0.004066308 valid loss= 0.005720452\n",
      "train reg_fs: 0.002420914126560092\n",
      "Epoch: 10000 train loss=0.007212548 valid loss= 0.005718739\n",
      "train reg_fs: 0.0023990690242499113\n",
      "Epoch: 10500 train loss=0.003468447 valid loss= 0.005595232\n",
      "train reg_fs: 0.0023770174011588097\n",
      "Epoch: 11000 train loss=0.003131185 valid loss= 0.005529038\n",
      "train reg_fs: 0.002354588359594345\n",
      "Epoch: 11500 train loss=0.006096330 valid loss= 0.005671795\n",
      "train reg_fs: 0.0023348312824964523\n",
      "Epoch: 12000 train loss=0.006217823 valid loss= 0.005512393\n",
      "train reg_fs: 0.0023137496318668127\n",
      "Epoch: 12500 train loss=0.003471927 valid loss= 0.005391636\n",
      "train reg_fs: 0.002293903613463044\n",
      "Epoch: 13000 train loss=0.004131728 valid loss= 0.005178737\n",
      "train reg_fs: 0.002274682279676199\n",
      "Epoch: 13500 train loss=0.002846042 valid loss= 0.005011990\n",
      "train reg_fs: 0.0022586658596992493\n",
      "Epoch: 14000 train loss=0.005173514 valid loss= 0.005182588\n",
      "train reg_fs: 0.002242309506982565\n",
      "Epoch: 14500 train loss=0.004203347 valid loss= 0.004985565\n",
      "train reg_fs: 0.002226511249318719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:05:44,264]\u001b[0m Trial 59 finished with value: 0.0026876708597248647 and parameters: {'lam': 0.0033118957890404723, 'learning_rate': 0.03382236463175319, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003547302 valid loss= 0.004911336\n",
      "train reg_fs: 0.002211497165262699\n",
      "Optimization Finished!\n",
      "test loss: 0.004766928963363171, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026876708597248647\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018928492 valid loss= 0.006850809\n",
      "train reg_fs: 0.0016429187962785363\n",
      "Epoch: 1000 train loss=0.020797348 valid loss= 0.006046346\n",
      "train reg_fs: 0.0016593950567767024\n",
      "Epoch: 1500 train loss=0.006775821 valid loss= 0.006196961\n",
      "train reg_fs: 0.0016620458336547017\n",
      "Epoch: 2000 train loss=0.006711832 valid loss= 0.005356750\n",
      "train reg_fs: 0.0016460416372865438\n",
      "Epoch: 2500 train loss=0.006971606 valid loss= 0.004996623\n",
      "train reg_fs: 0.0016214088536798954\n",
      "Epoch: 3000 train loss=0.008678160 valid loss= 0.004732673\n",
      "train reg_fs: 0.0015897281700745225\n",
      "Epoch: 3500 train loss=0.009055278 valid loss= 0.003796987\n",
      "train reg_fs: 0.0015610645059496164\n",
      "Epoch: 4000 train loss=0.008199451 valid loss= 0.003834769\n",
      "train reg_fs: 0.001541277626529336\n",
      "Epoch: 4500 train loss=0.002817775 valid loss= 0.003793997\n",
      "train reg_fs: 0.0015290745068341494\n",
      "Epoch: 5000 train loss=0.005797096 valid loss= 0.003937887\n",
      "train reg_fs: 0.0015215653693303466\n",
      "Epoch: 5500 train loss=0.007491812 valid loss= 0.003791467\n",
      "train reg_fs: 0.001516968011856079\n",
      "Epoch: 6000 train loss=0.005977624 valid loss= 0.003594747\n",
      "train reg_fs: 0.0015139784663915634\n",
      "Epoch: 6500 train loss=0.004720838 valid loss= 0.003904810\n",
      "train reg_fs: 0.0015103182522580028\n",
      "Epoch: 7000 train loss=0.004399301 valid loss= 0.003693949\n",
      "train reg_fs: 0.0015062589664012194\n",
      "Epoch: 7500 train loss=0.004187106 valid loss= 0.003670783\n",
      "train reg_fs: 0.0015014701057225466\n",
      "Epoch: 8000 train loss=0.003072664 valid loss= 0.003852066\n",
      "train reg_fs: 0.0014958528336137533\n",
      "Epoch: 8500 train loss=0.004856752 valid loss= 0.003501469\n",
      "train reg_fs: 0.00149074278306216\n",
      "Epoch: 9000 train loss=0.002014215 valid loss= 0.003858664\n",
      "train reg_fs: 0.0014847655547782779\n",
      "Epoch: 9500 train loss=0.004077750 valid loss= 0.003392178\n",
      "train reg_fs: 0.001478818361647427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:06:53,981]\u001b[0m Trial 60 finished with value: 0.0023342988228972276 and parameters: {'lam': 0.0019169958122027344, 'learning_rate': 0.03989294120727836, 'num_epoch': 10000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003431607 valid loss= 0.003795490\n",
      "train reg_fs: 0.0014730241382494569\n",
      "Optimization Finished!\n",
      "test loss: 0.003703500609844923, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023342988228972276\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016641816 valid loss= 0.008049402\n",
      "train reg_fs: 0.0012606903910636902\n",
      "Epoch: 1000 train loss=0.016354986 valid loss= 0.006928909\n",
      "train reg_fs: 0.0012700355146080256\n",
      "Epoch: 1500 train loss=0.005832113 valid loss= 0.006988517\n",
      "train reg_fs: 0.0012781975092366338\n",
      "Epoch: 2000 train loss=0.010424355 valid loss= 0.006734364\n",
      "train reg_fs: 0.0012843877775594592\n",
      "Epoch: 2500 train loss=0.014249017 valid loss= 0.006997919\n",
      "train reg_fs: 0.0012902128510177135\n",
      "Epoch: 3000 train loss=0.012536102 valid loss= 0.006699605\n",
      "train reg_fs: 0.0012954545672982931\n",
      "Epoch: 3500 train loss=0.012742626 valid loss= 0.006851790\n",
      "train reg_fs: 0.0012996755540370941\n",
      "Epoch: 4000 train loss=0.013297846 valid loss= 0.005993134\n",
      "train reg_fs: 0.0013035411247983575\n",
      "Epoch: 4500 train loss=0.005059978 valid loss= 0.007097518\n",
      "train reg_fs: 0.0013068668777123094\n",
      "Epoch: 5000 train loss=0.011797689 valid loss= 0.006625938\n",
      "train reg_fs: 0.0013091954169794917\n",
      "Epoch: 5500 train loss=0.013356971 valid loss= 0.007045706\n",
      "train reg_fs: 0.0013108212733641267\n",
      "Epoch: 6000 train loss=0.020513544 valid loss= 0.006477760\n",
      "train reg_fs: 0.0013118756469339132\n",
      "Epoch: 6500 train loss=0.008846292 valid loss= 0.006397480\n",
      "train reg_fs: 0.0013128493446856737\n",
      "Epoch: 7000 train loss=0.005059805 valid loss= 0.006654672\n",
      "train reg_fs: 0.0013130559818819165\n",
      "Epoch: 7500 train loss=0.006210948 valid loss= 0.006456568\n",
      "train reg_fs: 0.0013131832238286734\n",
      "Epoch: 8000 train loss=0.011534757 valid loss= 0.006273086\n",
      "train reg_fs: 0.001313057611696422\n",
      "Epoch: 8500 train loss=0.006705381 valid loss= 0.006433351\n",
      "train reg_fs: 0.001312009640969336\n",
      "Epoch: 9000 train loss=0.009770694 valid loss= 0.005954490\n",
      "train reg_fs: 0.0013112331507727504\n",
      "Epoch: 9500 train loss=0.008521105 valid loss= 0.006573458\n",
      "train reg_fs: 0.0013107231352478266\n",
      "Epoch: 10000 train loss=0.005342838 valid loss= 0.006408880\n",
      "train reg_fs: 0.0013088444247841835\n",
      "Epoch: 10500 train loss=0.008219117 valid loss= 0.006489862\n",
      "train reg_fs: 0.001307147555053234\n",
      "Epoch: 11000 train loss=0.008014589 valid loss= 0.006806617\n",
      "train reg_fs: 0.0013052683789283037\n",
      "Epoch: 11500 train loss=0.006989906 valid loss= 0.006182391\n",
      "train reg_fs: 0.001303369295783341\n",
      "Epoch: 12000 train loss=0.005077694 valid loss= 0.007087123\n",
      "train reg_fs: 0.0013011001283302903\n",
      "Epoch: 12500 train loss=0.005468805 valid loss= 0.006712040\n",
      "train reg_fs: 0.0012980755418539047\n",
      "Epoch: 13000 train loss=0.005639795 valid loss= 0.006731242\n",
      "train reg_fs: 0.0012954710982739925\n",
      "Epoch: 13500 train loss=0.003553411 valid loss= 0.006443429\n",
      "train reg_fs: 0.0012931691017001867\n",
      "Epoch: 14000 train loss=0.009338931 valid loss= 0.006659075\n",
      "train reg_fs: 0.0012899852590635419\n",
      "Epoch: 14500 train loss=0.004310115 valid loss= 0.006566322\n",
      "train reg_fs: 0.0012879379792138934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:08:37,045]\u001b[0m Trial 61 finished with value: 0.005069903074133535 and parameters: {'lam': 0.001497150690567459, 'learning_rate': 0.011404146119649915, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007234137 valid loss= 0.006383990\n",
      "train reg_fs: 0.001286068931221962\n",
      "Optimization Finished!\n",
      "test loss: 0.005953981541097164, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005069903074133535\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013591243 valid loss= 0.009028299\n",
      "train reg_fs: 0.0008897293009795249\n",
      "Epoch: 1000 train loss=0.007713799 valid loss= 0.008729861\n",
      "train reg_fs: 0.0008968248730525374\n",
      "Epoch: 1500 train loss=0.006322963 valid loss= 0.007348595\n",
      "train reg_fs: 0.0008997535333037376\n",
      "Epoch: 2000 train loss=0.008445159 valid loss= 0.007114767\n",
      "train reg_fs: 0.0008987770415842533\n",
      "Epoch: 2500 train loss=0.009674693 valid loss= 0.007107144\n",
      "train reg_fs: 0.0008950816700235009\n",
      "Epoch: 3000 train loss=0.007478177 valid loss= 0.006410260\n",
      "train reg_fs: 0.0008888525189831853\n",
      "Epoch: 3500 train loss=0.003235990 valid loss= 0.006829132\n",
      "train reg_fs: 0.0008827035780996084\n",
      "Epoch: 4000 train loss=0.007160094 valid loss= 0.005456309\n",
      "train reg_fs: 0.0008758671465329826\n",
      "Epoch: 4500 train loss=0.005417552 valid loss= 0.005795200\n",
      "train reg_fs: 0.0008695005089975893\n",
      "Epoch: 5000 train loss=0.005148785 valid loss= 0.005732979\n",
      "train reg_fs: 0.0008620606968179345\n",
      "Epoch: 5500 train loss=0.009003767 valid loss= 0.005232058\n",
      "train reg_fs: 0.0008562678704038262\n",
      "Epoch: 6000 train loss=0.007667524 valid loss= 0.005211963\n",
      "train reg_fs: 0.0008504227735102177\n",
      "Epoch: 6500 train loss=0.004577775 valid loss= 0.004661579\n",
      "train reg_fs: 0.0008442179532721639\n",
      "Epoch: 7000 train loss=0.003209639 valid loss= 0.004396213\n",
      "train reg_fs: 0.000839234737213701\n",
      "Epoch: 7500 train loss=0.003663178 valid loss= 0.004261198\n",
      "train reg_fs: 0.0008333900477737188\n",
      "Epoch: 8000 train loss=0.003644296 valid loss= 0.004174434\n",
      "train reg_fs: 0.0008281270274892449\n",
      "Epoch: 8500 train loss=0.004114204 valid loss= 0.004032339\n",
      "train reg_fs: 0.0008222507312893867\n",
      "Epoch: 9000 train loss=0.004049908 valid loss= 0.003943928\n",
      "train reg_fs: 0.0008172752568498254\n",
      "Epoch: 9500 train loss=0.007246596 valid loss= 0.003816701\n",
      "train reg_fs: 0.0008122249855659902\n",
      "Epoch: 10000 train loss=0.005253981 valid loss= 0.003712556\n",
      "train reg_fs: 0.000807648990303278\n",
      "Epoch: 10500 train loss=0.004674487 valid loss= 0.003442317\n",
      "train reg_fs: 0.0008038388332352042\n",
      "Epoch: 11000 train loss=0.005253353 valid loss= 0.003609174\n",
      "train reg_fs: 0.000800948531832546\n",
      "Epoch: 11500 train loss=0.003933404 valid loss= 0.003796231\n",
      "train reg_fs: 0.0007980628870427608\n",
      "Epoch: 12000 train loss=0.002037166 valid loss= 0.003568764\n",
      "train reg_fs: 0.0007958030910231173\n",
      "Epoch: 12500 train loss=0.004355227 valid loss= 0.003920268\n",
      "train reg_fs: 0.0007937962072901428\n",
      "Epoch: 13000 train loss=0.003460626 valid loss= 0.003762328\n",
      "train reg_fs: 0.0007921027136035264\n",
      "Epoch: 13500 train loss=0.002160465 valid loss= 0.003824711\n",
      "train reg_fs: 0.0007901909411884844\n",
      "Epoch: 14000 train loss=0.002099871 valid loss= 0.003774432\n",
      "train reg_fs: 0.0007887023966759443\n",
      "Epoch: 14500 train loss=0.005954809 valid loss= 0.003834268\n",
      "train reg_fs: 0.0007872229907661676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:10:20,607]\u001b[0m Trial 62 finished with value: 0.003283791402066417 and parameters: {'lam': 0.001053432884742981, 'learning_rate': 0.018505165071945277, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002614504 valid loss= 0.004086640\n",
      "train reg_fs: 0.0007862441707402468\n",
      "Optimization Finished!\n",
      "test loss: 0.004187252372503281, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003283791402066417\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009031697 valid loss= 0.006964431\n",
      "train reg_fs: 0.0011453785700723529\n",
      "Epoch: 1000 train loss=0.011096803 valid loss= 0.008353950\n",
      "train reg_fs: 0.0011646357597783208\n",
      "Epoch: 1500 train loss=0.006210943 valid loss= 0.007159106\n",
      "train reg_fs: 0.001173684373497963\n",
      "Epoch: 2000 train loss=0.007586324 valid loss= 0.006511089\n",
      "train reg_fs: 0.0011718320893123746\n",
      "Epoch: 2500 train loss=0.003642513 valid loss= 0.005918089\n",
      "train reg_fs: 0.0011624139733612537\n",
      "Epoch: 3000 train loss=0.007195512 valid loss= 0.005541418\n",
      "train reg_fs: 0.0011441154638305306\n",
      "Epoch: 3500 train loss=0.003302257 valid loss= 0.005241501\n",
      "train reg_fs: 0.0011203746544197202\n",
      "Epoch: 4000 train loss=0.003659186 valid loss= 0.004502656\n",
      "train reg_fs: 0.0011014807969331741\n",
      "Epoch: 4500 train loss=0.002540527 valid loss= 0.004104426\n",
      "train reg_fs: 0.001083057257346809\n",
      "Epoch: 5000 train loss=0.004820684 valid loss= 0.003720861\n",
      "train reg_fs: 0.0010677595855668187\n",
      "Epoch: 5500 train loss=0.002492405 valid loss= 0.003654902\n",
      "train reg_fs: 0.001053579500876367\n",
      "Epoch: 6000 train loss=0.006265625 valid loss= 0.003772914\n",
      "train reg_fs: 0.0010412582196295261\n",
      "Epoch: 6500 train loss=0.001773524 valid loss= 0.003944156\n",
      "train reg_fs: 0.001030842075124383\n",
      "Epoch: 7000 train loss=0.002150304 valid loss= 0.003758613\n",
      "train reg_fs: 0.0010217478265985847\n",
      "Epoch: 7500 train loss=0.003109662 valid loss= 0.003917309\n",
      "train reg_fs: 0.0010134499752894044\n",
      "Epoch: 8000 train loss=0.002279051 valid loss= 0.003775206\n",
      "train reg_fs: 0.0010071808937937021\n",
      "Epoch: 8500 train loss=0.003275967 valid loss= 0.003737385\n",
      "train reg_fs: 0.0009995464934036136\n",
      "Epoch: 9000 train loss=0.001878907 valid loss= 0.003979146\n",
      "train reg_fs: 0.0009929350344464183\n",
      "Epoch: 9500 train loss=0.004063973 valid loss= 0.004005584\n",
      "train reg_fs: 0.0009894412942230701\n",
      "Epoch: 10000 train loss=0.002655951 valid loss= 0.003612579\n",
      "train reg_fs: 0.0009847377659752965\n",
      "Epoch: 10500 train loss=0.001692216 valid loss= 0.004042125\n",
      "train reg_fs: 0.0009803780121728778\n",
      "Epoch: 11000 train loss=0.002651587 valid loss= 0.003736988\n",
      "train reg_fs: 0.0009745854185894132\n",
      "Epoch: 11500 train loss=0.001293806 valid loss= 0.003694421\n",
      "train reg_fs: 0.0009704906260594726\n",
      "Epoch: 12000 train loss=0.001351543 valid loss= 0.003911849\n",
      "train reg_fs: 0.0009684844990260899\n",
      "Epoch: 12500 train loss=0.007382870 valid loss= 0.003503173\n",
      "train reg_fs: 0.0009672344895079732\n",
      "Epoch: 13000 train loss=0.002404605 valid loss= 0.003751962\n",
      "train reg_fs: 0.0009620761265978217\n",
      "Epoch: 13500 train loss=0.002395767 valid loss= 0.003703651\n",
      "train reg_fs: 0.0009596882737241685\n",
      "Epoch: 14000 train loss=0.002374654 valid loss= 0.003765625\n",
      "train reg_fs: 0.0009565255604684353\n",
      "Epoch: 14500 train loss=0.001782375 valid loss= 0.003747756\n",
      "train reg_fs: 0.0009528269874863327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:12:07,158]\u001b[0m Trial 63 finished with value: 0.003006973758172662 and parameters: {'lam': 0.0013121809136713198, 'learning_rate': 0.06538866212349097, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005319633 valid loss= 0.003953677\n",
      "train reg_fs: 0.0009484023903496563\n",
      "Optimization Finished!\n",
      "test loss: 0.003976515028625727, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003006973758172662\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008710372 valid loss= 0.008715962\n",
      "train reg_fs: 0.0013844685163348913\n",
      "Epoch: 1000 train loss=0.010566801 valid loss= 0.008325983\n",
      "train reg_fs: 0.001398594817146659\n",
      "Epoch: 1500 train loss=0.012743431 valid loss= 0.007801107\n",
      "train reg_fs: 0.0014020378002896905\n",
      "Epoch: 2000 train loss=0.018226774 valid loss= 0.007096322\n",
      "train reg_fs: 0.0013957602204754949\n",
      "Epoch: 2500 train loss=0.010653340 valid loss= 0.006988474\n",
      "train reg_fs: 0.001381475361995399\n",
      "Epoch: 3000 train loss=0.005463567 valid loss= 0.006864754\n",
      "train reg_fs: 0.0013622234109789133\n",
      "Epoch: 3500 train loss=0.006159017 valid loss= 0.006392708\n",
      "train reg_fs: 0.0013413189444690943\n",
      "Epoch: 4000 train loss=0.003101611 valid loss= 0.005628238\n",
      "train reg_fs: 0.001321015995927155\n",
      "Epoch: 4500 train loss=0.004155154 valid loss= 0.004653702\n",
      "train reg_fs: 0.0013043818762525916\n",
      "Epoch: 5000 train loss=0.003939984 valid loss= 0.004831924\n",
      "train reg_fs: 0.0012874486856162548\n",
      "Epoch: 5500 train loss=0.006862646 valid loss= 0.004270228\n",
      "train reg_fs: 0.0012729964219033718\n",
      "Epoch: 6000 train loss=0.002169108 valid loss= 0.004453518\n",
      "train reg_fs: 0.0012604468502104282\n",
      "Epoch: 6500 train loss=0.004723898 valid loss= 0.004299428\n",
      "train reg_fs: 0.0012498717987909913\n",
      "Epoch: 7000 train loss=0.006785270 valid loss= 0.004402148\n",
      "train reg_fs: 0.0012409904738888144\n",
      "Epoch: 7500 train loss=0.007738914 valid loss= 0.004682493\n",
      "train reg_fs: 0.0012344419956207275\n",
      "Epoch: 8000 train loss=0.004145007 valid loss= 0.004285917\n",
      "train reg_fs: 0.001228348701260984\n",
      "Epoch: 8500 train loss=0.002192554 valid loss= 0.004470186\n",
      "train reg_fs: 0.001222947845235467\n",
      "Epoch: 9000 train loss=0.003645010 valid loss= 0.004408480\n",
      "train reg_fs: 0.0012184468796476722\n",
      "Epoch: 9500 train loss=0.004671603 valid loss= 0.004817764\n",
      "train reg_fs: 0.0012143298517912626\n",
      "Epoch: 10000 train loss=0.003185924 valid loss= 0.004581486\n",
      "train reg_fs: 0.0012108094524592161\n",
      "Epoch: 10500 train loss=0.005226539 valid loss= 0.004484464\n",
      "train reg_fs: 0.0012077010469511151\n",
      "Epoch: 11000 train loss=0.003287008 valid loss= 0.005003932\n",
      "train reg_fs: 0.0012050034711137414\n",
      "Epoch: 11500 train loss=0.004211732 valid loss= 0.004730365\n",
      "train reg_fs: 0.0012016557157039642\n",
      "Epoch: 12000 train loss=0.007777884 valid loss= 0.004924588\n",
      "train reg_fs: 0.0011988754849880934\n",
      "Epoch: 12500 train loss=0.002369659 valid loss= 0.004939106\n",
      "train reg_fs: 0.001195739139802754\n",
      "Epoch: 13000 train loss=0.003866878 valid loss= 0.004872591\n",
      "train reg_fs: 0.00119294342584908\n",
      "Epoch: 13500 train loss=0.003798433 valid loss= 0.004829768\n",
      "train reg_fs: 0.0011910658795386553\n",
      "Epoch: 14000 train loss=0.002464089 valid loss= 0.004896570\n",
      "train reg_fs: 0.0011871132301166654\n",
      "Epoch: 14500 train loss=0.006220357 valid loss= 0.004893634\n",
      "train reg_fs: 0.0011845912085846066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:13:51,236]\u001b[0m Trial 64 finished with value: 0.0036565980422327816 and parameters: {'lam': 0.001625650839042647, 'learning_rate': 0.026747745282440318, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004155112 valid loss= 0.004858190\n",
      "train reg_fs: 0.0011824513785541058\n",
      "Optimization Finished!\n",
      "test loss: 0.005112577695399523, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0036565980422327816\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018599007 valid loss= 0.007602942\n",
      "train reg_fs: 0.0012468351051211357\n",
      "Epoch: 1000 train loss=0.006523785 valid loss= 0.007936326\n",
      "train reg_fs: 0.00126217445358634\n",
      "Epoch: 1500 train loss=0.014093846 valid loss= 0.006940256\n",
      "train reg_fs: 0.001257365569472313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:14:06,832]\u001b[0m Trial 65 finished with value: 0.005601000069582507 and parameters: {'lam': 0.0014152300854805096, 'learning_rate': 0.08283910192417816, 'num_epoch': 2000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.009750589 valid loss= 0.006852604\n",
      "train reg_fs: 0.0012356553925201297\n",
      "Optimization Finished!\n",
      "test loss: 0.0070684789679944515, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005601000069582507\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014072167 valid loss= 0.007520041\n",
      "train reg_fs: 0.001111499615944922\n",
      "Epoch: 1000 train loss=0.011346182 valid loss= 0.007744716\n",
      "train reg_fs: 0.0011245645582675934\n",
      "Epoch: 1500 train loss=0.007697587 valid loss= 0.007153787\n",
      "train reg_fs: 0.001118023064918816\n",
      "Epoch: 2000 train loss=0.006975192 valid loss= 0.007274788\n",
      "train reg_fs: 0.0010998373618349433\n",
      "Epoch: 2500 train loss=0.006520452 valid loss= 0.006889910\n",
      "train reg_fs: 0.001084503368474543\n",
      "Epoch: 3000 train loss=0.008065162 valid loss= 0.007073621\n",
      "train reg_fs: 0.0010715842945501208\n",
      "Epoch: 3500 train loss=0.006448772 valid loss= 0.006398638\n",
      "train reg_fs: 0.001064795651473105\n",
      "Epoch: 4000 train loss=0.010228898 valid loss= 0.005749157\n",
      "train reg_fs: 0.0010608634911477566\n",
      "Epoch: 4500 train loss=0.005073214 valid loss= 0.005585807\n",
      "train reg_fs: 0.0010582968825474381\n",
      "Epoch: 5000 train loss=0.007177621 valid loss= 0.005638057\n",
      "train reg_fs: 0.0010560009395703673\n",
      "Epoch: 5500 train loss=0.003697725 valid loss= 0.005543217\n",
      "train reg_fs: 0.0010534970788285136\n",
      "Epoch: 6000 train loss=0.004256439 valid loss= 0.004914034\n",
      "train reg_fs: 0.0010510176653042436\n",
      "Epoch: 6500 train loss=0.003746141 valid loss= 0.004848246\n",
      "train reg_fs: 0.0010470772394910455\n",
      "Epoch: 7000 train loss=0.005304626 valid loss= 0.004562004\n",
      "train reg_fs: 0.0010421506594866514\n",
      "Epoch: 7500 train loss=0.004034626 valid loss= 0.004446625\n",
      "train reg_fs: 0.0010405125794932246\n",
      "Epoch: 8000 train loss=0.003964246 valid loss= 0.004372028\n",
      "train reg_fs: 0.0010381651809439063\n",
      "Epoch: 8500 train loss=0.004201650 valid loss= 0.004400227\n",
      "train reg_fs: 0.0010340395383536816\n",
      "Epoch: 9000 train loss=0.004297191 valid loss= 0.004352367\n",
      "train reg_fs: 0.0010291452053934336\n",
      "Epoch: 9500 train loss=0.003094292 valid loss= 0.004444399\n",
      "train reg_fs: 0.0010245240991935134\n",
      "Epoch: 10000 train loss=0.002858106 valid loss= 0.004328399\n",
      "train reg_fs: 0.0010216755326837301\n",
      "Epoch: 10500 train loss=0.004293905 valid loss= 0.004558680\n",
      "train reg_fs: 0.001016303081996739\n",
      "Epoch: 11000 train loss=0.005068320 valid loss= 0.004387138\n",
      "train reg_fs: 0.0010112206218764186\n",
      "Epoch: 11500 train loss=0.001476158 valid loss= 0.004156562\n",
      "train reg_fs: 0.0010051553836092353\n",
      "Epoch: 12000 train loss=0.002270289 valid loss= 0.004395773\n",
      "train reg_fs: 0.0010015311418101192\n",
      "Epoch: 12500 train loss=0.002878433 valid loss= 0.004503799\n",
      "train reg_fs: 0.0009970967657864094\n",
      "Epoch: 13000 train loss=0.001833558 valid loss= 0.004588393\n",
      "train reg_fs: 0.000991684035398066\n",
      "Epoch: 13500 train loss=0.001725724 valid loss= 0.004519380\n",
      "train reg_fs: 0.0009873054223135114\n",
      "Epoch: 14000 train loss=0.001523268 valid loss= 0.004454556\n",
      "train reg_fs: 0.0009834711672738194\n",
      "Epoch: 14500 train loss=0.004082147 valid loss= 0.004571066\n",
      "train reg_fs: 0.0009790138574317098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:15:51,944]\u001b[0m Trial 66 finished with value: 0.00351136172574455 and parameters: {'lam': 0.0012794688016633461, 'learning_rate': 0.05946037109910341, 'num_epoch': 15000}. Best is trial 16 with value: 0.0007508591478522734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002374289 valid loss= 0.004498646\n",
      "train reg_fs: 0.0009740751120261848\n",
      "Optimization Finished!\n",
      "test loss: 0.004825787618756294, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00351136172574455\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008743434 valid loss= 0.007596817\n",
      "train reg_fs: 0.001835873001255095\n",
      "Epoch: 1000 train loss=0.013403353 valid loss= 0.005780710\n",
      "train reg_fs: 0.0017760200425982475\n",
      "Epoch: 1500 train loss=0.012174530 valid loss= 0.003991031\n",
      "train reg_fs: 0.0016660229302942753\n",
      "Epoch: 2000 train loss=0.005273710 valid loss= 0.004240855\n",
      "train reg_fs: 0.0016328968340530992\n",
      "Epoch: 2500 train loss=0.003347346 valid loss= 0.004193229\n",
      "train reg_fs: 0.0016007398953661323\n",
      "Epoch: 3000 train loss=0.005609826 valid loss= 0.003986024\n",
      "train reg_fs: 0.0015722067328169942\n",
      "Epoch: 3500 train loss=0.006489348 valid loss= 0.003031361\n",
      "train reg_fs: 0.0015542589826509356\n",
      "Epoch: 4000 train loss=0.002002762 valid loss= 0.003445838\n",
      "train reg_fs: 0.0015400396659970284\n",
      "Epoch: 4500 train loss=0.002586256 valid loss= 0.003497134\n",
      "train reg_fs: 0.0015270095318555832\n",
      "Epoch: 5000 train loss=0.002163355 valid loss= 0.002868809\n",
      "train reg_fs: 0.001512246672064066\n",
      "Epoch: 5500 train loss=0.007117372 valid loss= 0.003641766\n",
      "train reg_fs: 0.0014956339728087187\n",
      "Epoch: 6000 train loss=0.002511755 valid loss= 0.002230174\n",
      "train reg_fs: 0.00147758808452636\n",
      "Epoch: 6500 train loss=0.006999927 valid loss= 0.002642030\n",
      "train reg_fs: 0.001460260828025639\n",
      "Epoch: 7000 train loss=0.003045659 valid loss= 0.002078861\n",
      "train reg_fs: 0.001447653048671782\n",
      "Epoch: 7500 train loss=0.010529540 valid loss= 0.001957548\n",
      "train reg_fs: 0.0014354637823998928\n",
      "Epoch: 8000 train loss=0.003024463 valid loss= 0.002019961\n",
      "train reg_fs: 0.0014272433472797275\n",
      "Epoch: 8500 train loss=0.001955488 valid loss= 0.002162734\n",
      "train reg_fs: 0.0014201212907209992\n",
      "Epoch: 9000 train loss=0.003072669 valid loss= 0.001672128\n",
      "train reg_fs: 0.0014146093744784594\n",
      "Epoch: 9500 train loss=0.001614918 valid loss= 0.002183966\n",
      "train reg_fs: 0.0014107530005276203\n",
      "Epoch: 10000 train loss=0.001820486 valid loss= 0.001763330\n",
      "train reg_fs: 0.0014074193313717842\n",
      "Epoch: 10500 train loss=0.002472006 valid loss= 0.002060484\n",
      "train reg_fs: 0.0014045012649148703\n",
      "Epoch: 11000 train loss=0.002715182 valid loss= 0.001850599\n",
      "train reg_fs: 0.0014018501387909055\n",
      "Epoch: 11500 train loss=0.002520340 valid loss= 0.002001732\n",
      "train reg_fs: 0.0013996530324220657\n",
      "Epoch: 12000 train loss=0.005521553 valid loss= 0.001738038\n",
      "train reg_fs: 0.001397754531353712\n",
      "Epoch: 12500 train loss=0.001720783 valid loss= 0.001751537\n",
      "train reg_fs: 0.0013962483499199152\n",
      "Epoch: 13000 train loss=0.002383983 valid loss= 0.001676339\n",
      "train reg_fs: 0.0013950124848634005\n",
      "Epoch: 13500 train loss=0.002149407 valid loss= 0.001809564\n",
      "train reg_fs: 0.001393915736116469\n",
      "Epoch: 14000 train loss=0.002442578 valid loss= 0.001783620\n",
      "train reg_fs: 0.0013929276028648019\n",
      "Epoch: 14500 train loss=0.003582184 valid loss= 0.001966607\n",
      "train reg_fs: 0.0013921399367973208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:17:37,877]\u001b[0m Trial 67 finished with value: 0.00021555817752089075 and parameters: {'lam': 0.0020811013859500485, 'learning_rate': 0.15266423143883523, 'num_epoch': 15000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002023510 valid loss= 0.001610480\n",
      "train reg_fs: 0.001391319208778441\n",
      "Optimization Finished!\n",
      "test loss: 0.001656136941164732, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00021555817752089075\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012996301 valid loss= 0.007818898\n",
      "train reg_fs: 0.0018129455856978893\n",
      "Epoch: 1000 train loss=0.009518194 valid loss= 0.008218951\n",
      "train reg_fs: 0.0017537898384034634\n",
      "Epoch: 1500 train loss=0.009970262 valid loss= 0.006146356\n",
      "train reg_fs: 0.0017010716255754232\n",
      "Epoch: 2000 train loss=0.002947171 valid loss= 0.004451237\n",
      "train reg_fs: 0.0016546997940167785\n",
      "Epoch: 2500 train loss=0.003173569 valid loss= 0.005162089\n",
      "train reg_fs: 0.0016124987741932273\n",
      "Epoch: 3000 train loss=0.007472905 valid loss= 0.004459272\n",
      "train reg_fs: 0.001556946663185954\n",
      "Epoch: 3500 train loss=0.002053271 valid loss= 0.004966120\n",
      "train reg_fs: 0.001525459229014814\n",
      "Epoch: 4000 train loss=0.004310393 valid loss= 0.004328923\n",
      "train reg_fs: 0.0014939232496544719\n",
      "Epoch: 4500 train loss=0.004567014 valid loss= 0.004367420\n",
      "train reg_fs: 0.001475025317631662\n",
      "Epoch: 5000 train loss=0.003388784 valid loss= 0.004392936\n",
      "train reg_fs: 0.001461412408389151\n",
      "Epoch: 5500 train loss=0.003048072 valid loss= 0.004331038\n",
      "train reg_fs: 0.0014489571331068873\n",
      "Epoch: 6000 train loss=0.003291278 valid loss= 0.004549783\n",
      "train reg_fs: 0.001435200683772564\n",
      "Epoch: 6500 train loss=0.003903335 valid loss= 0.004308177\n",
      "train reg_fs: 0.0014283867785707116\n",
      "Epoch: 7000 train loss=0.002564320 valid loss= 0.004191782\n",
      "train reg_fs: 0.0014210768276825547\n",
      "Epoch: 7500 train loss=0.002405924 valid loss= 0.004515282\n",
      "train reg_fs: 0.0014162880834192038\n",
      "Epoch: 8000 train loss=0.001728181 valid loss= 0.004179363\n",
      "train reg_fs: 0.0014093206264078617\n",
      "Epoch: 8500 train loss=0.005779664 valid loss= 0.004343935\n",
      "train reg_fs: 0.001405285089276731\n",
      "Epoch: 9000 train loss=0.002548323 valid loss= 0.004341562\n",
      "train reg_fs: 0.0013957144692540169\n",
      "Epoch: 9500 train loss=0.001863281 valid loss= 0.004406067\n",
      "train reg_fs: 0.0013880068436264992\n",
      "Epoch: 10000 train loss=0.002016485 valid loss= 0.004568342\n",
      "train reg_fs: 0.0013874378055334091\n",
      "Epoch: 10500 train loss=0.002078328 valid loss= 0.004469234\n",
      "train reg_fs: 0.0013885563239455223\n",
      "Epoch: 11000 train loss=0.007747364 valid loss= 0.004250147\n",
      "train reg_fs: 0.0013841817853972316\n",
      "Epoch: 11500 train loss=0.005271479 valid loss= 0.004302523\n",
      "train reg_fs: 0.0013793514808639884\n",
      "Epoch: 12000 train loss=0.002135448 valid loss= 0.004892303\n",
      "train reg_fs: 0.0013778603170067072\n",
      "Epoch: 12500 train loss=0.003902639 valid loss= 0.004348047\n",
      "train reg_fs: 0.0013732026563957334\n",
      "Epoch: 13000 train loss=0.002740643 valid loss= 0.004794953\n",
      "train reg_fs: 0.0013711381470784545\n",
      "Epoch: 13500 train loss=0.002366123 valid loss= 0.004525224\n",
      "train reg_fs: 0.001363574294373393\n",
      "Epoch: 14000 train loss=0.001945741 valid loss= 0.004849119\n",
      "train reg_fs: 0.001360782771371305\n",
      "Epoch: 14500 train loss=0.004110325 valid loss= 0.004771575\n",
      "train reg_fs: 0.0013572843745350838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:19:21,197]\u001b[0m Trial 68 finished with value: 0.003542053027054562 and parameters: {'lam': 0.0020467145513883974, 'learning_rate': 0.1833394597760154, 'num_epoch': 15000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002038941 valid loss= 0.004874705\n",
      "train reg_fs: 0.001353712985292077\n",
      "Optimization Finished!\n",
      "test loss: 0.00497006019577384, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003542053027054562\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008467844 valid loss= 0.005717556\n",
      "train reg_fs: 0.0015347785083577037\n",
      "Epoch: 1000 train loss=0.018666735 valid loss= 0.004150662\n",
      "train reg_fs: 0.0014465715503320098\n",
      "Epoch: 1500 train loss=0.002677354 valid loss= 0.003212823\n",
      "train reg_fs: 0.0013888219837099314\n",
      "Epoch: 2000 train loss=0.007432118 valid loss= 0.003349985\n",
      "train reg_fs: 0.0013603230472654104\n",
      "Epoch: 2500 train loss=0.004606635 valid loss= 0.003822966\n",
      "train reg_fs: 0.001339034060947597\n",
      "Epoch: 3000 train loss=0.005995493 valid loss= 0.003253419\n",
      "train reg_fs: 0.0013264445587992668\n",
      "Epoch: 3500 train loss=0.004684035 valid loss= 0.003411304\n",
      "train reg_fs: 0.001317734131589532\n",
      "Epoch: 4000 train loss=0.002306557 valid loss= 0.003106402\n",
      "train reg_fs: 0.0013121210504323244\n",
      "Epoch: 4500 train loss=0.003366970 valid loss= 0.002559805\n",
      "train reg_fs: 0.0013035705778747797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:19:57,559]\u001b[0m Trial 69 finished with value: 0.0015902847301452387 and parameters: {'lam': 0.0017592117576517245, 'learning_rate': 0.1501804909916878, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.001582386 valid loss= 0.002875012\n",
      "train reg_fs: 0.0012980856699869037\n",
      "Optimization Finished!\n",
      "test loss: 0.0028320960700511932, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0015902847301452387\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013851822 valid loss= 0.007216879\n",
      "train reg_fs: 0.0013932546135038137\n",
      "Epoch: 1000 train loss=0.004245797 valid loss= 0.004563754\n",
      "train reg_fs: 0.0012945706257596612\n",
      "Epoch: 1500 train loss=0.003523825 valid loss= 0.003943628\n",
      "train reg_fs: 0.0012204148806631565\n",
      "Epoch: 2000 train loss=0.002377600 valid loss= 0.004011745\n",
      "train reg_fs: 0.0011695132125169039\n",
      "Epoch: 2500 train loss=0.001839660 valid loss= 0.003774627\n",
      "train reg_fs: 0.0011378992348909378\n",
      "Epoch: 3000 train loss=0.002175641 valid loss= 0.003653857\n",
      "train reg_fs: 0.001116713392548263\n",
      "Epoch: 3500 train loss=0.005754821 valid loss= 0.003806582\n",
      "train reg_fs: 0.0011034848866984248\n",
      "Epoch: 4000 train loss=0.003866603 valid loss= 0.003254401\n",
      "train reg_fs: 0.0010916435858234763\n",
      "Epoch: 4500 train loss=0.005494214 valid loss= 0.003669583\n",
      "train reg_fs: 0.0010820388561114669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:20:33,288]\u001b[0m Trial 70 finished with value: 0.002570682182371911 and parameters: {'lam': 0.001716918038075558, 'learning_rate': 0.16020295014257693, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003366249 valid loss= 0.003633170\n",
      "train reg_fs: 0.0010742938611656427\n",
      "Optimization Finished!\n",
      "test loss: 0.0033906535245478153, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002570682182371911\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007492406 valid loss= 0.006395793\n",
      "train reg_fs: 0.001524255145341158\n",
      "Epoch: 1000 train loss=0.007187560 valid loss= 0.005097443\n",
      "train reg_fs: 0.0014335282612591982\n",
      "Epoch: 1500 train loss=0.004663562 valid loss= 0.004611650\n",
      "train reg_fs: 0.0013811259996145964\n",
      "Epoch: 2000 train loss=0.006689587 valid loss= 0.004692993\n",
      "train reg_fs: 0.0013701036805287004\n",
      "Epoch: 2500 train loss=0.004154192 valid loss= 0.004276446\n",
      "train reg_fs: 0.0013622255064547062\n",
      "Epoch: 3000 train loss=0.002946532 valid loss= 0.004140555\n",
      "train reg_fs: 0.0013444855576381087\n",
      "Epoch: 3500 train loss=0.003001892 valid loss= 0.004389371\n",
      "train reg_fs: 0.001319382805377245\n",
      "Epoch: 4000 train loss=0.007577438 valid loss= 0.003953499\n",
      "train reg_fs: 0.0013032713904976845\n",
      "Epoch: 4500 train loss=0.002695712 valid loss= 0.004366228\n",
      "train reg_fs: 0.0012896106345579028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:21:08,855]\u001b[0m Trial 71 finished with value: 0.0025207001630255708 and parameters: {'lam': 0.0017560135319563321, 'learning_rate': 0.14034195543922937, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004532358 valid loss= 0.003766860\n",
      "train reg_fs: 0.0012800408294424415\n",
      "Optimization Finished!\n",
      "test loss: 0.00358143774792552, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025207001630255708\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006969926 valid loss= 0.006579582\n",
      "train reg_fs: 0.0018851922359317541\n",
      "Epoch: 1000 train loss=0.005508614 valid loss= 0.004137720\n",
      "train reg_fs: 0.0017450274899601936\n",
      "Epoch: 1500 train loss=0.006919745 valid loss= 0.003938658\n",
      "train reg_fs: 0.0016737754922360182\n",
      "Epoch: 2000 train loss=0.003708721 valid loss= 0.003375491\n",
      "train reg_fs: 0.001621657283976674\n",
      "Epoch: 2500 train loss=0.003356002 valid loss= 0.004247808\n",
      "train reg_fs: 0.0015675215981900692\n",
      "Epoch: 3000 train loss=0.004149134 valid loss= 0.003231527\n",
      "train reg_fs: 0.001509808818809688\n",
      "Epoch: 3500 train loss=0.005205711 valid loss= 0.002773929\n",
      "train reg_fs: 0.0014644938055425882\n",
      "Epoch: 4000 train loss=0.002010594 valid loss= 0.003338737\n",
      "train reg_fs: 0.0014268612721934915\n",
      "Epoch: 4500 train loss=0.003859249 valid loss= 0.002837436\n",
      "train reg_fs: 0.0013977917842566967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:21:44,406]\u001b[0m Trial 72 finished with value: 0.001537389919043016 and parameters: {'lam': 0.002215407944461216, 'learning_rate': 0.1251270413029194, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002793730 valid loss= 0.002953909\n",
      "train reg_fs: 0.0013731783255934715\n",
      "Optimization Finished!\n",
      "test loss: 0.0027216868475079536, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001537389919043016\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009658329 valid loss= 0.008219154\n",
      "train reg_fs: 0.0022050905972719193\n",
      "Epoch: 1000 train loss=0.015848584 valid loss= 0.006473133\n",
      "train reg_fs: 0.0021014309022575617\n",
      "Epoch: 1500 train loss=0.003443091 valid loss= 0.004832756\n",
      "train reg_fs: 0.001992570236325264\n",
      "Epoch: 2000 train loss=0.009007972 valid loss= 0.005154505\n",
      "train reg_fs: 0.0019086339743807912\n",
      "Epoch: 2500 train loss=0.003009163 valid loss= 0.004974260\n",
      "train reg_fs: 0.001838376745581627\n",
      "Epoch: 3000 train loss=0.005720437 valid loss= 0.004343254\n",
      "train reg_fs: 0.0017847749404609203\n",
      "Epoch: 3500 train loss=0.002196451 valid loss= 0.004574155\n",
      "train reg_fs: 0.0017426859121769667\n",
      "Epoch: 4000 train loss=0.003535464 valid loss= 0.004331809\n",
      "train reg_fs: 0.001714971731416881\n",
      "Epoch: 4500 train loss=0.004369653 valid loss= 0.004213184\n",
      "train reg_fs: 0.0016927134711295366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:22:20,551]\u001b[0m Trial 73 finished with value: 0.0024196750560157142 and parameters: {'lam': 0.0026320112538921097, 'learning_rate': 0.1280338430495776, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002552099 valid loss= 0.004079544\n",
      "train reg_fs: 0.0016759070567786694\n",
      "Optimization Finished!\n",
      "test loss: 0.003780948230996728, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024196750560157142\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009142659 valid loss= 0.009497997\n",
      "train reg_fs: 0.002013224409893155\n",
      "Epoch: 1000 train loss=0.006319761 valid loss= 0.008354440\n",
      "train reg_fs: 0.00192523084115237\n",
      "Epoch: 1500 train loss=0.003476732 valid loss= 0.006041438\n",
      "train reg_fs: 0.0018752652686089277\n",
      "Epoch: 2000 train loss=0.007308780 valid loss= 0.005506366\n",
      "train reg_fs: 0.001840131008066237\n",
      "Epoch: 2500 train loss=0.004771788 valid loss= 0.004737915\n",
      "train reg_fs: 0.0018105488270521164\n",
      "Epoch: 3000 train loss=0.006174881 valid loss= 0.004527611\n",
      "train reg_fs: 0.0017685978673398495\n",
      "Epoch: 3500 train loss=0.002250070 valid loss= 0.004944501\n",
      "train reg_fs: 0.0017179213464260101\n",
      "Epoch: 4000 train loss=0.003680574 valid loss= 0.004793894\n",
      "train reg_fs: 0.0016671174671500921\n",
      "Epoch: 4500 train loss=0.003210173 valid loss= 0.004908521\n",
      "train reg_fs: 0.0016345888143405318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:22:56,710]\u001b[0m Trial 74 finished with value: 0.003406292530090382 and parameters: {'lam': 0.0022820965295847527, 'learning_rate': 0.18844406757356089, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003325563 valid loss= 0.005013701\n",
      "train reg_fs: 0.001609318656846881\n",
      "Optimization Finished!\n",
      "test loss: 0.0053947726264595985, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003406292530090382\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009091264 valid loss= 0.007829259\n",
      "train reg_fs: 0.0019295485690236092\n",
      "Epoch: 1000 train loss=0.004712115 valid loss= 0.005185430\n",
      "train reg_fs: 0.0018020363058894873\n",
      "Epoch: 1500 train loss=0.004405374 valid loss= 0.005544303\n",
      "train reg_fs: 0.0017054720083251595\n",
      "Epoch: 2000 train loss=0.011173621 valid loss= 0.005305365\n",
      "train reg_fs: 0.0016585326520726085\n",
      "Epoch: 2500 train loss=0.002372367 valid loss= 0.004760070\n",
      "train reg_fs: 0.001621168339625001\n",
      "Epoch: 3000 train loss=0.004358888 valid loss= 0.005067327\n",
      "train reg_fs: 0.0015976387076079845\n",
      "Epoch: 3500 train loss=0.005249966 valid loss= 0.004577212\n",
      "train reg_fs: 0.0015651328722015023\n",
      "Epoch: 4000 train loss=0.003590388 valid loss= 0.004457985\n",
      "train reg_fs: 0.0015430086059495807\n",
      "Epoch: 4500 train loss=0.003091490 valid loss= 0.004781754\n",
      "train reg_fs: 0.001527473796159029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:23:32,359]\u001b[0m Trial 75 finished with value: 0.0035127846420883488 and parameters: {'lam': 0.002220828667142205, 'learning_rate': 0.17221664525200214, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.001965688 valid loss= 0.005012132\n",
      "train reg_fs: 0.0015152590349316597\n",
      "Optimization Finished!\n",
      "test loss: 0.004165145102888346, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0035127846420883488\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005042805 valid loss= 0.007083983\n",
      "train reg_fs: 0.0016946704126894474\n",
      "Epoch: 1000 train loss=0.010639615 valid loss= 0.004428994\n",
      "train reg_fs: 0.0015976430149748921\n",
      "Epoch: 1500 train loss=0.005171042 valid loss= 0.003874447\n",
      "train reg_fs: 0.0015417564427480102\n",
      "Epoch: 2000 train loss=0.002761269 valid loss= 0.004086118\n",
      "train reg_fs: 0.0015192870050668716\n",
      "Epoch: 2500 train loss=0.003765063 valid loss= 0.004322472\n",
      "train reg_fs: 0.0014935553772374988\n",
      "Epoch: 3000 train loss=0.002757050 valid loss= 0.004056233\n",
      "train reg_fs: 0.0014713212149217725\n",
      "Epoch: 3500 train loss=0.007139337 valid loss= 0.003965081\n",
      "train reg_fs: 0.0014573733787983656\n",
      "Epoch: 4000 train loss=0.001731007 valid loss= 0.003832840\n",
      "train reg_fs: 0.001447364455088973\n",
      "Epoch: 4500 train loss=0.001797603 valid loss= 0.003720557\n",
      "train reg_fs: 0.0014388152630999684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:24:08,702]\u001b[0m Trial 76 finished with value: 0.002587944744810741 and parameters: {'lam': 0.001953251198044939, 'learning_rate': 0.14923099841310203, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004803088 valid loss= 0.003977482\n",
      "train reg_fs: 0.0014309410471469164\n",
      "Optimization Finished!\n",
      "test loss: 0.003714244347065687, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002587944744810741\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006793628 valid loss= 0.007979728\n",
      "train reg_fs: 0.002527609933167696\n",
      "Epoch: 1000 train loss=0.009395146 valid loss= 0.006377542\n",
      "train reg_fs: 0.0024044939782470465\n",
      "Epoch: 1500 train loss=0.006438788 valid loss= 0.004882106\n",
      "train reg_fs: 0.00226890598423779\n",
      "Epoch: 2000 train loss=0.005397413 valid loss= 0.004134906\n",
      "train reg_fs: 0.0022447234950959682\n",
      "Epoch: 2500 train loss=0.004875850 valid loss= 0.004427507\n",
      "train reg_fs: 0.0022435334976762533\n",
      "Epoch: 3000 train loss=0.005997091 valid loss= 0.004558508\n",
      "train reg_fs: 0.0022262237034738064\n",
      "Epoch: 3500 train loss=0.007899478 valid loss= 0.004326693\n",
      "train reg_fs: 0.0021801448892802\n",
      "Epoch: 4000 train loss=0.003058539 valid loss= 0.004065261\n",
      "train reg_fs: 0.002133140340447426\n",
      "Epoch: 4500 train loss=0.006860978 valid loss= 0.003236012\n",
      "train reg_fs: 0.002090368652716279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:24:45,034]\u001b[0m Trial 77 finished with value: 0.001135219766722894 and parameters: {'lam': 0.0029057678348261735, 'learning_rate': 0.1416692736343523, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003233237 valid loss= 0.003199764\n",
      "train reg_fs: 0.0020588610786944628\n",
      "Optimization Finished!\n",
      "test loss: 0.0031190048903226852, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001135219766722894\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008609645 valid loss= 0.008371859\n",
      "train reg_fs: 0.0024579199962317944\n",
      "Epoch: 1000 train loss=0.013313841 valid loss= 0.006017967\n",
      "train reg_fs: 0.002368186367675662\n",
      "Epoch: 1500 train loss=0.002907065 valid loss= 0.005122998\n",
      "train reg_fs: 0.00222700834274292\n",
      "Epoch: 2000 train loss=0.004627299 valid loss= 0.004799607\n",
      "train reg_fs: 0.0021565391216427088\n",
      "Epoch: 2500 train loss=0.003580663 valid loss= 0.004805867\n",
      "train reg_fs: 0.0021165660582482815\n",
      "Epoch: 3000 train loss=0.004504219 valid loss= 0.004104237\n",
      "train reg_fs: 0.0020880026277154684\n",
      "Epoch: 3500 train loss=0.002458171 valid loss= 0.003866099\n",
      "train reg_fs: 0.0020715580321848392\n",
      "Epoch: 4000 train loss=0.008106671 valid loss= 0.004142496\n",
      "train reg_fs: 0.00205679377540946\n",
      "Epoch: 4500 train loss=0.004001572 valid loss= 0.004170520\n",
      "train reg_fs: 0.00204601907171309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:25:21,047]\u001b[0m Trial 78 finished with value: 0.0020410762371836522 and parameters: {'lam': 0.0028076449588220775, 'learning_rate': 0.1265793744042306, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008816661 valid loss= 0.004043826\n",
      "train reg_fs: 0.0020351717248559\n",
      "Optimization Finished!\n",
      "test loss: 0.0040296707302331924, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020410762371836522\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010262157 valid loss= 0.007491814\n",
      "train reg_fs: 0.0021048644557595253\n",
      "Epoch: 1000 train loss=0.003956369 valid loss= 0.006431484\n",
      "train reg_fs: 0.0020442239474505186\n",
      "Epoch: 1500 train loss=0.006016330 valid loss= 0.005932012\n",
      "train reg_fs: 0.0019953546579927206\n",
      "Epoch: 2000 train loss=0.008380864 valid loss= 0.004465990\n",
      "train reg_fs: 0.0019493423169478774\n",
      "Epoch: 2500 train loss=0.003107884 valid loss= 0.004086981\n",
      "train reg_fs: 0.001902181189507246\n",
      "Epoch: 3000 train loss=0.003519195 valid loss= 0.004417947\n",
      "train reg_fs: 0.0018629038240760565\n",
      "Epoch: 3500 train loss=0.002627114 valid loss= 0.004515392\n",
      "train reg_fs: 0.001832535257562995\n",
      "Epoch: 4000 train loss=0.002128031 valid loss= 0.004072090\n",
      "train reg_fs: 0.0018117246218025684\n",
      "Epoch: 4500 train loss=0.003010673 valid loss= 0.004255748\n",
      "train reg_fs: 0.0017933041090145707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:25:56,992]\u001b[0m Trial 79 finished with value: 0.0024072606850529667 and parameters: {'lam': 0.0024279903106278803, 'learning_rate': 0.1396359676125076, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008932816 valid loss= 0.004194096\n",
      "train reg_fs: 0.0017727413214743137\n",
      "Optimization Finished!\n",
      "test loss: 0.004243377596139908, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024072606850529667\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009985202 valid loss= 0.008134296\n",
      "train reg_fs: 0.002778148278594017\n",
      "Epoch: 1000 train loss=0.006188657 valid loss= 0.006464052\n",
      "train reg_fs: 0.002696293406188488\n",
      "Epoch: 1500 train loss=0.008533092 valid loss= 0.004898692\n",
      "train reg_fs: 0.00257496302947402\n",
      "Epoch: 2000 train loss=0.007235786 valid loss= 0.004949535\n",
      "train reg_fs: 0.0024830319453030825\n",
      "Epoch: 2500 train loss=0.004227458 valid loss= 0.004560419\n",
      "train reg_fs: 0.00243326835334301\n",
      "Epoch: 3000 train loss=0.003838084 valid loss= 0.004780900\n",
      "train reg_fs: 0.002403089078143239\n",
      "Epoch: 3500 train loss=0.004231104 valid loss= 0.004362951\n",
      "train reg_fs: 0.002382271457463503\n",
      "Epoch: 4000 train loss=0.003694437 valid loss= 0.004020434\n",
      "train reg_fs: 0.0023654133547097445\n",
      "Epoch: 4500 train loss=0.005104384 valid loss= 0.004250868\n",
      "train reg_fs: 0.002352356445044279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:26:33,084]\u001b[0m Trial 80 finished with value: 0.0017307107376672531 and parameters: {'lam': 0.003195153322941951, 'learning_rate': 0.11417195466407205, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005547650 valid loss= 0.004031676\n",
      "train reg_fs: 0.00234019523486495\n",
      "Optimization Finished!\n",
      "test loss: 0.004116020165383816, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0017307107376672531\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015991006 valid loss= 0.008828461\n",
      "train reg_fs: 0.0026602474972605705\n",
      "Epoch: 1000 train loss=0.006094882 valid loss= 0.009716270\n",
      "train reg_fs: 0.0025709255132824183\n",
      "Epoch: 1500 train loss=0.006575829 valid loss= 0.007843852\n",
      "train reg_fs: 0.002492377767339349\n",
      "Epoch: 2000 train loss=0.006012721 valid loss= 0.006916917\n",
      "train reg_fs: 0.0024470961652696133\n",
      "Epoch: 2500 train loss=0.004611041 valid loss= 0.005685282\n",
      "train reg_fs: 0.002378123113885522\n",
      "Epoch: 3000 train loss=0.004735282 valid loss= 0.004657754\n",
      "train reg_fs: 0.0022880907636135817\n",
      "Epoch: 3500 train loss=0.003371903 valid loss= 0.004226868\n",
      "train reg_fs: 0.002184238750487566\n",
      "Epoch: 4000 train loss=0.005170805 valid loss= 0.004206384\n",
      "train reg_fs: 0.0021181649062782526\n",
      "Epoch: 4500 train loss=0.007060196 valid loss= 0.003572568\n",
      "train reg_fs: 0.002073398558422923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:27:08,589]\u001b[0m Trial 81 finished with value: 0.0017577053057263967 and parameters: {'lam': 0.0031397822471797366, 'learning_rate': 0.10908729893843694, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004617642 valid loss= 0.003856686\n",
      "train reg_fs: 0.0020410504657775164\n",
      "Optimization Finished!\n",
      "test loss: 0.003559838980436325, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0017577053057263967\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011489620 valid loss= 0.006889897\n",
      "train reg_fs: 0.002579333959147334\n",
      "Epoch: 1000 train loss=0.006219025 valid loss= 0.004833763\n",
      "train reg_fs: 0.0024596166331321\n",
      "Epoch: 1500 train loss=0.012467956 valid loss= 0.004724167\n",
      "train reg_fs: 0.0024084034375846386\n",
      "Epoch: 2000 train loss=0.006691518 valid loss= 0.005257452\n",
      "train reg_fs: 0.0023803538642823696\n",
      "Epoch: 2500 train loss=0.005303429 valid loss= 0.005667209\n",
      "train reg_fs: 0.0023556062951684\n",
      "Epoch: 3000 train loss=0.003914081 valid loss= 0.005293184\n",
      "train reg_fs: 0.0023274512495845556\n",
      "Epoch: 3500 train loss=0.005398557 valid loss= 0.005545207\n",
      "train reg_fs: 0.0022827766370028257\n",
      "Epoch: 4000 train loss=0.002794972 valid loss= 0.005626915\n",
      "train reg_fs: 0.0022160112857818604\n",
      "Epoch: 4500 train loss=0.002986806 valid loss= 0.005562911\n",
      "train reg_fs: 0.0021514007821679115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:27:45,292]\u001b[0m Trial 82 finished with value: 0.0028472003918256217 and parameters: {'lam': 0.003160673735067943, 'learning_rate': 0.11755098386399704, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002969263 valid loss= 0.004949156\n",
      "train reg_fs: 0.002100984798744321\n",
      "Optimization Finished!\n",
      "test loss: 0.004689021501690149, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028472003918256217\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006623794 valid loss= 0.008838774\n",
      "train reg_fs: 0.003254622220993042\n",
      "Epoch: 1000 train loss=0.007618360 valid loss= 0.007080450\n",
      "train reg_fs: 0.003102567745372653\n",
      "Epoch: 1500 train loss=0.007994757 valid loss= 0.005948378\n",
      "train reg_fs: 0.002925328677520156\n",
      "Epoch: 2000 train loss=0.005877365 valid loss= 0.006518543\n",
      "train reg_fs: 0.0027817683294415474\n",
      "Epoch: 2500 train loss=0.004487037 valid loss= 0.005563674\n",
      "train reg_fs: 0.002672358648851514\n",
      "Epoch: 3000 train loss=0.007619399 valid loss= 0.005575038\n",
      "train reg_fs: 0.0025890220422297716\n",
      "Epoch: 3500 train loss=0.004428678 valid loss= 0.005182448\n",
      "train reg_fs: 0.002529396442696452\n",
      "Epoch: 4000 train loss=0.004023504 valid loss= 0.005141115\n",
      "train reg_fs: 0.0024872147478163242\n",
      "Epoch: 4500 train loss=0.003187612 valid loss= 0.005221878\n",
      "train reg_fs: 0.002455679001286626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:28:22,310]\u001b[0m Trial 83 finished with value: 0.0023989599510994843 and parameters: {'lam': 0.0038599451225879372, 'learning_rate': 0.10969903334120991, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008968791 valid loss= 0.004809950\n",
      "train reg_fs: 0.0024317791685462\n",
      "Optimization Finished!\n",
      "test loss: 0.004558945540338755, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023989599510994843\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006713236 valid loss= 0.008678015\n",
      "train reg_fs: 0.0030710818246006966\n",
      "Epoch: 1000 train loss=0.007625989 valid loss= 0.006480258\n",
      "train reg_fs: 0.002865107962861657\n",
      "Epoch: 1500 train loss=0.006297441 valid loss= 0.005784566\n",
      "train reg_fs: 0.002717360621318221\n",
      "Epoch: 2000 train loss=0.018135387 valid loss= 0.006077456\n",
      "train reg_fs: 0.002627292415127158\n",
      "Epoch: 2500 train loss=0.008182765 valid loss= 0.006454137\n",
      "train reg_fs: 0.0025584965478628874\n",
      "Epoch: 3000 train loss=0.008360618 valid loss= 0.006133143\n",
      "train reg_fs: 0.0025097462348639965\n",
      "Epoch: 3500 train loss=0.005833193 valid loss= 0.006123976\n",
      "train reg_fs: 0.002460683463141322\n",
      "Epoch: 4000 train loss=0.004544384 valid loss= 0.005646730\n",
      "train reg_fs: 0.002423639874905348\n",
      "Epoch: 4500 train loss=0.005967471 valid loss= 0.005942265\n",
      "train reg_fs: 0.002392553025856614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:28:58,635]\u001b[0m Trial 84 finished with value: 0.0034921837198243 and parameters: {'lam': 0.003583326026222177, 'learning_rate': 0.15731335836944113, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003849941 valid loss= 0.005915881\n",
      "train reg_fs: 0.0023601939901709557\n",
      "Optimization Finished!\n",
      "test loss: 0.006452581379562616, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0034921837198243\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014721563 valid loss= 0.007607661\n",
      "train reg_fs: 0.0027125156484544277\n",
      "Epoch: 1000 train loss=0.008033923 valid loss= 0.004698961\n",
      "train reg_fs: 0.002531038597226143\n",
      "Epoch: 1500 train loss=0.005887919 valid loss= 0.004298036\n",
      "train reg_fs: 0.002412200439721346\n",
      "Epoch: 2000 train loss=0.004647640 valid loss= 0.004928556\n",
      "train reg_fs: 0.0023652883246541023\n",
      "Epoch: 2500 train loss=0.005541650 valid loss= 0.004330959\n",
      "train reg_fs: 0.002328617265447974\n",
      "Epoch: 3000 train loss=0.005467644 valid loss= 0.004092967\n",
      "train reg_fs: 0.0023018254432827234\n",
      "Epoch: 3500 train loss=0.004563104 valid loss= 0.003863143\n",
      "train reg_fs: 0.0022677406668663025\n",
      "Epoch: 4000 train loss=0.003316873 valid loss= 0.003889120\n",
      "train reg_fs: 0.0022403865586966276\n",
      "Epoch: 4500 train loss=0.005359308 valid loss= 0.003886028\n",
      "train reg_fs: 0.0022238469682633877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:29:34,815]\u001b[0m Trial 85 finished with value: 0.0011090075848304507 and parameters: {'lam': 0.0031681128834811275, 'learning_rate': 0.09620749346895524, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.006788803 valid loss= 0.003404466\n",
      "train reg_fs: 0.002205953001976013\n",
      "Optimization Finished!\n",
      "test loss: 0.003953126259148121, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0011090075848304507\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016826980 valid loss= 0.011456742\n",
      "train reg_fs: 0.00355400238186121\n",
      "Epoch: 1000 train loss=0.011952566 valid loss= 0.010695065\n",
      "train reg_fs: 0.003503885120153427\n",
      "Epoch: 1500 train loss=0.009914452 valid loss= 0.010151802\n",
      "train reg_fs: 0.003416287712752819\n",
      "Epoch: 2000 train loss=0.008582325 valid loss= 0.010289385\n",
      "train reg_fs: 0.003356027649715543\n",
      "Epoch: 2500 train loss=0.006891222 valid loss= 0.009668956\n",
      "train reg_fs: 0.003318651346489787\n",
      "Epoch: 3000 train loss=0.007223899 valid loss= 0.010133730\n",
      "train reg_fs: 0.0033071632497012615\n",
      "Epoch: 3500 train loss=0.006470984 valid loss= 0.009307193\n",
      "train reg_fs: 0.0032958139199763536\n",
      "Epoch: 4000 train loss=0.009392282 valid loss= 0.009436565\n",
      "train reg_fs: 0.0032970586325973272\n",
      "Epoch: 4500 train loss=0.005403554 valid loss= 0.008929756\n",
      "train reg_fs: 0.0032959706149995327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:30:11,095]\u001b[0m Trial 86 finished with value: 0.00567952311482327 and parameters: {'lam': 0.004107181487609764, 'learning_rate': 0.09093711901292047, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.014268572 valid loss= 0.009094112\n",
      "train reg_fs: 0.0033049164339900017\n",
      "Optimization Finished!\n",
      "test loss: 0.0089631462469697, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00567952311482327\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013566559 valid loss= 0.009079267\n",
      "train reg_fs: 0.0028686707373708487\n",
      "Epoch: 1000 train loss=0.014525470 valid loss= 0.007902673\n",
      "train reg_fs: 0.002669411478564143\n",
      "Epoch: 1500 train loss=0.004303784 valid loss= 0.005191430\n",
      "train reg_fs: 0.0024651545099914074\n",
      "Epoch: 2000 train loss=0.005022766 valid loss= 0.005244995\n",
      "train reg_fs: 0.0023475675843656063\n",
      "Epoch: 2500 train loss=0.004948459 valid loss= 0.004938158\n",
      "train reg_fs: 0.0022842090111225843\n",
      "Epoch: 3000 train loss=0.005369276 valid loss= 0.005057123\n",
      "train reg_fs: 0.002239715773612261\n",
      "Epoch: 3500 train loss=0.005273761 valid loss= 0.004832380\n",
      "train reg_fs: 0.002208454767242074\n",
      "Epoch: 4000 train loss=0.005912646 valid loss= 0.004516864\n",
      "train reg_fs: 0.002185177057981491\n",
      "Epoch: 4500 train loss=0.005597582 valid loss= 0.004945228\n",
      "train reg_fs: 0.002165751764550805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:30:47,132]\u001b[0m Trial 87 finished with value: 0.0023961339753973397 and parameters: {'lam': 0.0034140619471637523, 'learning_rate': 0.09703602926043885, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.006281209 valid loss= 0.004525776\n",
      "train reg_fs: 0.002150613581761718\n",
      "Optimization Finished!\n",
      "test loss: 0.004270411096513271, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023961339753973397\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016373299 valid loss= 0.008007148\n",
      "train reg_fs: 0.002512567676603794\n",
      "Epoch: 1000 train loss=0.004877880 valid loss= 0.008937290\n",
      "train reg_fs: 0.00247124838642776\n",
      "Epoch: 1500 train loss=0.007136047 valid loss= 0.008326754\n",
      "train reg_fs: 0.0023854707833379507\n",
      "Epoch: 2000 train loss=0.004894433 valid loss= 0.006605200\n",
      "train reg_fs: 0.002333466662093997\n",
      "Epoch: 2500 train loss=0.005715195 valid loss= 0.006177356\n",
      "train reg_fs: 0.0022901478223502636\n",
      "Epoch: 3000 train loss=0.006296951 valid loss= 0.005323693\n",
      "train reg_fs: 0.0022321846336126328\n",
      "Epoch: 3500 train loss=0.004256418 valid loss= 0.005650408\n",
      "train reg_fs: 0.0021645217202603817\n",
      "Epoch: 4000 train loss=0.004087981 valid loss= 0.005254963\n",
      "train reg_fs: 0.0021189069375395775\n",
      "Epoch: 4500 train loss=0.005524250 valid loss= 0.005491596\n",
      "train reg_fs: 0.0020830300636589527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:31:22,668]\u001b[0m Trial 88 finished with value: 0.002950152519794576 and parameters: {'lam': 0.002881259955995483, 'learning_rate': 0.12382285754213439, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003078862 valid loss= 0.005010831\n",
      "train reg_fs: 0.0020581725984811783\n",
      "Optimization Finished!\n",
      "test loss: 0.004605128429830074, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002950152519794576\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013887930 valid loss= 0.006939086\n",
      "train reg_fs: 0.0021550103556364775\n",
      "Epoch: 1000 train loss=0.005789342 valid loss= 0.004416079\n",
      "train reg_fs: 0.0020244454499334097\n",
      "Epoch: 1500 train loss=0.003712999 valid loss= 0.004743963\n",
      "train reg_fs: 0.0019643553532660007\n",
      "Epoch: 2000 train loss=0.005074971 valid loss= 0.004366078\n",
      "train reg_fs: 0.0019103335216641426\n",
      "Epoch: 2500 train loss=0.003966917 valid loss= 0.004775145\n",
      "train reg_fs: 0.00185615592636168\n",
      "Epoch: 3000 train loss=0.004568968 valid loss= 0.004627674\n",
      "train reg_fs: 0.0018103817710652947\n",
      "Epoch: 3500 train loss=0.003605771 valid loss= 0.004327239\n",
      "train reg_fs: 0.0017501782858744264\n",
      "Epoch: 4000 train loss=0.007889961 valid loss= 0.004526257\n",
      "train reg_fs: 0.0016969303833320737\n",
      "Epoch: 4500 train loss=0.003426322 valid loss= 0.004331628\n",
      "train reg_fs: 0.0016549724387004972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:31:58,904]\u001b[0m Trial 89 finished with value: 0.002454480012172691 and parameters: {'lam': 0.002551654985349968, 'learning_rate': 0.1369888661619301, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002117453 valid loss= 0.004064875\n",
      "train reg_fs: 0.0016304737655445933\n",
      "Optimization Finished!\n",
      "test loss: 0.0038658189587295055, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002454480012172691\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007512316 valid loss= 0.010528604\n",
      "train reg_fs: 0.004151409026235342\n",
      "Epoch: 1000 train loss=0.006164346 valid loss= 0.010170155\n",
      "train reg_fs: 0.0039824615232646465\n",
      "Epoch: 1500 train loss=0.006920352 valid loss= 0.008362196\n",
      "train reg_fs: 0.0038224540185183287\n",
      "Epoch: 2000 train loss=0.010747751 valid loss= 0.007523644\n",
      "train reg_fs: 0.003724724519997835\n",
      "Epoch: 2500 train loss=0.005599641 valid loss= 0.007810653\n",
      "train reg_fs: 0.003639818634837866\n",
      "Epoch: 3000 train loss=0.007592997 valid loss= 0.007765456\n",
      "train reg_fs: 0.003568841377273202\n",
      "Epoch: 3500 train loss=0.004725277 valid loss= 0.007990744\n",
      "train reg_fs: 0.0034912219271063805\n",
      "Epoch: 4000 train loss=0.004259434 valid loss= 0.008013654\n",
      "train reg_fs: 0.0034172844607383013\n",
      "Epoch: 4500 train loss=0.004813049 valid loss= 0.008171598\n",
      "train reg_fs: 0.003348051803186536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:32:34,707]\u001b[0m Trial 90 finished with value: 0.004841276023155661 and parameters: {'lam': 0.004728069660212941, 'learning_rate': 0.16834545467084255, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004387561 valid loss= 0.008160707\n",
      "train reg_fs: 0.0032819437328726053\n",
      "Optimization Finished!\n",
      "test loss: 0.008277816697955132, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004841276023155661\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007674648 valid loss= 0.007413296\n",
      "train reg_fs: 0.0027367372531443834\n",
      "Epoch: 1000 train loss=0.015204418 valid loss= 0.006519051\n",
      "train reg_fs: 0.0026213296223431826\n",
      "Epoch: 1500 train loss=0.006567473 valid loss= 0.005506096\n",
      "train reg_fs: 0.00245611066929996\n",
      "Epoch: 2000 train loss=0.003525263 valid loss= 0.005556380\n",
      "train reg_fs: 0.0023562752176076174\n",
      "Epoch: 2500 train loss=0.007683114 valid loss= 0.004949905\n",
      "train reg_fs: 0.002289784839376807\n",
      "Epoch: 3000 train loss=0.003317922 valid loss= 0.005106040\n",
      "train reg_fs: 0.0022287380415946245\n",
      "Epoch: 3500 train loss=0.002613107 valid loss= 0.005014511\n",
      "train reg_fs: 0.0021686346735805273\n",
      "Epoch: 4000 train loss=0.003326058 valid loss= 0.004750543\n",
      "train reg_fs: 0.002116893418133259\n",
      "Epoch: 4500 train loss=0.002925777 valid loss= 0.004384504\n",
      "train reg_fs: 0.0020760861225426197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:33:11,679]\u001b[0m Trial 91 finished with value: 0.0023322879563534064 and parameters: {'lam': 0.0031696010721726474, 'learning_rate': 0.11087626911652455, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002916491 valid loss= 0.004356696\n",
      "train reg_fs: 0.002046226989477873\n",
      "Optimization Finished!\n",
      "test loss: 0.004221981856971979, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023322879563534064\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008023460 valid loss= 0.010974811\n",
      "train reg_fs: 0.002636561868712306\n",
      "Epoch: 1000 train loss=0.004703335 valid loss= 0.009306975\n",
      "train reg_fs: 0.002462199656292796\n",
      "Epoch: 1500 train loss=0.011449487 valid loss= 0.006335462\n",
      "train reg_fs: 0.0022777849808335304\n",
      "Epoch: 2000 train loss=0.003855974 valid loss= 0.004666203\n",
      "train reg_fs: 0.0021345573477447033\n",
      "Epoch: 2500 train loss=0.008439730 valid loss= 0.004822433\n",
      "train reg_fs: 0.0020588617771863937\n",
      "Epoch: 3000 train loss=0.002770334 valid loss= 0.004207867\n",
      "train reg_fs: 0.0020112800411880016\n",
      "Epoch: 3500 train loss=0.002459950 valid loss= 0.004060281\n",
      "train reg_fs: 0.0019820737652480602\n",
      "Epoch: 4000 train loss=0.009173073 valid loss= 0.004298851\n",
      "train reg_fs: 0.0019611138850450516\n",
      "Epoch: 4500 train loss=0.002728195 valid loss= 0.004418615\n",
      "train reg_fs: 0.0019433795241639018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:33:48,148]\u001b[0m Trial 92 finished with value: 0.0021946988944706565 and parameters: {'lam': 0.0030337506476680338, 'learning_rate': 0.14830568297202193, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003126191 valid loss= 0.004112768\n",
      "train reg_fs: 0.0019287073519080877\n",
      "Optimization Finished!\n",
      "test loss: 0.0038941160310059786, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021946988944706565\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007035492 valid loss= 0.008670996\n",
      "train reg_fs: 0.002361123915761709\n",
      "Epoch: 1000 train loss=0.008513088 valid loss= 0.008905056\n",
      "train reg_fs: 0.002382389036938548\n",
      "Epoch: 1500 train loss=0.006558903 valid loss= 0.007250527\n",
      "train reg_fs: 0.002355310833081603\n",
      "Epoch: 2000 train loss=0.005517933 valid loss= 0.006197437\n",
      "train reg_fs: 0.0022929830010980368\n",
      "Epoch: 2500 train loss=0.006114708 valid loss= 0.004971133\n",
      "train reg_fs: 0.002231200458481908\n",
      "Epoch: 3000 train loss=0.008198980 valid loss= 0.004790460\n",
      "train reg_fs: 0.0021728104911744595\n",
      "Epoch: 3500 train loss=0.005361599 valid loss= 0.004159299\n",
      "train reg_fs: 0.0021301170345395803\n",
      "Epoch: 4000 train loss=0.003047772 valid loss= 0.004097143\n",
      "train reg_fs: 0.0021005412563681602\n",
      "Epoch: 4500 train loss=0.003293200 valid loss= 0.004375549\n",
      "train reg_fs: 0.0020755643490701914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:34:24,596]\u001b[0m Trial 93 finished with value: 0.0023301398458654694 and parameters: {'lam': 0.0026748018040046347, 'learning_rate': 0.10348055812461707, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003937905 valid loss= 0.004386982\n",
      "train reg_fs: 0.0020539029501378536\n",
      "Optimization Finished!\n",
      "test loss: 0.004723311867564917, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023301398458654694\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016351826 valid loss= 0.008437196\n",
      "train reg_fs: 0.002815760439261794\n",
      "Epoch: 1000 train loss=0.007995921 valid loss= 0.006452416\n",
      "train reg_fs: 0.0026919746305793524\n",
      "Epoch: 1500 train loss=0.006875788 valid loss= 0.005736497\n",
      "train reg_fs: 0.0025431173853576183\n",
      "Epoch: 2000 train loss=0.004731597 valid loss= 0.005559292\n",
      "train reg_fs: 0.0025029019452631474\n",
      "Epoch: 2500 train loss=0.006860137 valid loss= 0.005447520\n",
      "train reg_fs: 0.002479882212355733\n",
      "Epoch: 3000 train loss=0.003792779 valid loss= 0.005329680\n",
      "train reg_fs: 0.002448269398882985\n",
      "Epoch: 3500 train loss=0.004123929 valid loss= 0.005458331\n",
      "train reg_fs: 0.002404693281278014\n",
      "Epoch: 4000 train loss=0.009178108 valid loss= 0.005171363\n",
      "train reg_fs: 0.002362973289564252\n",
      "Epoch: 4500 train loss=0.004712145 valid loss= 0.004776801\n",
      "train reg_fs: 0.0023271641694009304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:35:00,735]\u001b[0m Trial 94 finished with value: 0.0025880190711165827 and parameters: {'lam': 0.0032154907308397985, 'learning_rate': 0.11236090492285145, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003400864 valid loss= 0.004829927\n",
      "train reg_fs: 0.0022955855820327997\n",
      "Optimization Finished!\n",
      "test loss: 0.004662524908781052, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025880190711165827\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020248618 valid loss= 0.008832996\n",
      "train reg_fs: 0.0032076251227408648\n",
      "Epoch: 1000 train loss=0.006454113 valid loss= 0.008037283\n",
      "train reg_fs: 0.003240826539695263\n",
      "Epoch: 1500 train loss=0.010409107 valid loss= 0.007844402\n",
      "train reg_fs: 0.0032207288313657045\n",
      "Epoch: 2000 train loss=0.007567554 valid loss= 0.006845383\n",
      "train reg_fs: 0.003166390582919121\n",
      "Epoch: 2500 train loss=0.006880472 valid loss= 0.006251265\n",
      "train reg_fs: 0.0030992303509265184\n",
      "Epoch: 3000 train loss=0.012619499 valid loss= 0.006384694\n",
      "train reg_fs: 0.003040397074073553\n",
      "Epoch: 3500 train loss=0.005681420 valid loss= 0.006736048\n",
      "train reg_fs: 0.002990136155858636\n",
      "Epoch: 4000 train loss=0.004489495 valid loss= 0.006448542\n",
      "train reg_fs: 0.0029480985831469297\n",
      "Epoch: 4500 train loss=0.008222586 valid loss= 0.006675090\n",
      "train reg_fs: 0.002909318311139941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:35:36,696]\u001b[0m Trial 95 finished with value: 0.004061492502402429 and parameters: {'lam': 0.003645534684755006, 'learning_rate': 0.09478066072999745, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.006486431 valid loss= 0.006958636\n",
      "train reg_fs: 0.0028725960291922092\n",
      "Optimization Finished!\n",
      "test loss: 0.007484192028641701, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004061492502402429\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018947352 valid loss= 0.009045346\n",
      "train reg_fs: 0.0017932915361598134\n",
      "Epoch: 1000 train loss=0.014570198 valid loss= 0.010591570\n",
      "train reg_fs: 0.0018335619242861867\n",
      "Epoch: 1500 train loss=0.011023671 valid loss= 0.010615024\n",
      "train reg_fs: 0.001849046559073031\n",
      "Epoch: 2000 train loss=0.009313037 valid loss= 0.009363705\n",
      "train reg_fs: 0.001840145094320178\n",
      "Epoch: 2500 train loss=0.005228346 valid loss= 0.007913118\n",
      "train reg_fs: 0.001819260767661035\n",
      "Epoch: 3000 train loss=0.008186351 valid loss= 0.007174395\n",
      "train reg_fs: 0.0017871047602966428\n",
      "Epoch: 3500 train loss=0.009080389 valid loss= 0.005600132\n",
      "train reg_fs: 0.0017601606668904424\n",
      "Epoch: 4000 train loss=0.004469082 valid loss= 0.005536975\n",
      "train reg_fs: 0.0017394083552062511\n",
      "Epoch: 4500 train loss=0.010421193 valid loss= 0.004274695\n",
      "train reg_fs: 0.0017154670786112547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:36:12,995]\u001b[0m Trial 96 finished with value: 0.002081645488466547 and parameters: {'lam': 0.0020449860459223657, 'learning_rate': 0.08524040371385361, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003922906 valid loss= 0.003797114\n",
      "train reg_fs: 0.0016969883581623435\n",
      "Optimization Finished!\n",
      "test loss: 0.003955169580876827, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002081645488466547\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009013718 valid loss= 0.009808669\n",
      "train reg_fs: 0.0030485838651657104\n",
      "Epoch: 1000 train loss=0.020375047 valid loss= 0.008199626\n",
      "train reg_fs: 0.003045395715162158\n",
      "Epoch: 1500 train loss=0.008725507 valid loss= 0.006910657\n",
      "train reg_fs: 0.0029381951317191124\n",
      "Epoch: 2000 train loss=0.013773524 valid loss= 0.005938879\n",
      "train reg_fs: 0.0027649160474538803\n",
      "Epoch: 2500 train loss=0.005818434 valid loss= 0.005775562\n",
      "train reg_fs: 0.002671460621058941\n",
      "Epoch: 3000 train loss=0.007565008 valid loss= 0.005591209\n",
      "train reg_fs: 0.002608441049233079\n",
      "Epoch: 3500 train loss=0.004437427 valid loss= 0.005587463\n",
      "train reg_fs: 0.002570523414760828\n",
      "Epoch: 4000 train loss=0.004704922 valid loss= 0.005676059\n",
      "train reg_fs: 0.0025408898945897818\n",
      "Epoch: 4500 train loss=0.004502285 valid loss= 0.005892473\n",
      "train reg_fs: 0.002494822721928358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:36:49,352]\u001b[0m Trial 97 finished with value: 0.0037582108999406486 and parameters: {'lam': 0.0034499081862360195, 'learning_rate': 0.1340415196745983, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005246666 valid loss= 0.006299774\n",
      "train reg_fs: 0.0024591912515461445\n",
      "Optimization Finished!\n",
      "test loss: 0.006010288372635841, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0037582108999406486\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009571450 valid loss= 0.007820467\n",
      "train reg_fs: 0.0015913896495476365\n",
      "Epoch: 1000 train loss=0.009562254 valid loss= 0.007176247\n",
      "train reg_fs: 0.0016160458326339722\n",
      "Epoch: 1500 train loss=0.008493525 valid loss= 0.006770010\n",
      "train reg_fs: 0.0016235726652666926\n",
      "Epoch: 2000 train loss=0.007469947 valid loss= 0.006460600\n",
      "train reg_fs: 0.001615660497918725\n",
      "Epoch: 2500 train loss=0.007595424 valid loss= 0.005986225\n",
      "train reg_fs: 0.0016030914848670363\n",
      "Epoch: 3000 train loss=0.005343477 valid loss= 0.005548579\n",
      "train reg_fs: 0.0015891160583123565\n",
      "Epoch: 3500 train loss=0.003024333 valid loss= 0.006064950\n",
      "train reg_fs: 0.0015744181582704186\n",
      "Epoch: 4000 train loss=0.003752959 valid loss= 0.006070558\n",
      "train reg_fs: 0.0015611937269568443\n",
      "Epoch: 4500 train loss=0.002988157 valid loss= 0.006026927\n",
      "train reg_fs: 0.001548644620925188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:37:25,051]\u001b[0m Trial 98 finished with value: 0.004064542779272764 and parameters: {'lam': 0.0018144903741010893, 'learning_rate': 0.07057821625946266, 'num_epoch': 5000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002300148 valid loss= 0.005618502\n",
      "train reg_fs: 0.0015390487387776375\n",
      "Optimization Finished!\n",
      "test loss: 0.005287067033350468, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004064542779272764\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007796298 valid loss= 0.007534463\n",
      "train reg_fs: 0.0020559553522616625\n",
      "Epoch: 1000 train loss=0.010112742 valid loss= 0.005711773\n",
      "train reg_fs: 0.001987673342227936\n",
      "Epoch: 1500 train loss=0.004969172 valid loss= 0.003513340\n",
      "train reg_fs: 0.0018904758617281914\n",
      "Epoch: 2000 train loss=0.004760974 valid loss= 0.002961257\n",
      "train reg_fs: 0.0018224522937089205\n",
      "Epoch: 2500 train loss=0.002906471 valid loss= 0.003495350\n",
      "train reg_fs: 0.001780288526788354\n",
      "Epoch: 3000 train loss=0.006793926 valid loss= 0.003205120\n",
      "train reg_fs: 0.0017471590545028448\n",
      "Epoch: 3500 train loss=0.003393524 valid loss= 0.002437704\n",
      "train reg_fs: 0.0017211709637194872\n",
      "Epoch: 4000 train loss=0.002776165 valid loss= 0.002929028\n",
      "train reg_fs: 0.001702603418380022\n",
      "Epoch: 4500 train loss=0.003008528 valid loss= 0.002613564\n",
      "train reg_fs: 0.0016850923420861363\n",
      "Epoch: 5000 train loss=0.006631532 valid loss= 0.002760343\n",
      "train reg_fs: 0.001672091195359826\n",
      "Epoch: 5500 train loss=0.002391676 valid loss= 0.003223330\n",
      "train reg_fs: 0.0016590214800089598\n",
      "Epoch: 6000 train loss=0.003250657 valid loss= 0.003504649\n",
      "train reg_fs: 0.001649985322728753\n",
      "Epoch: 6500 train loss=0.003255675 valid loss= 0.002209156\n",
      "train reg_fs: 0.0016426965594291687\n",
      "Epoch: 7000 train loss=0.003255558 valid loss= 0.003111971\n",
      "train reg_fs: 0.001636347034946084\n",
      "Epoch: 7500 train loss=0.001799116 valid loss= 0.002109602\n",
      "train reg_fs: 0.0016302878502756357\n",
      "Epoch: 8000 train loss=0.001936632 valid loss= 0.002382537\n",
      "train reg_fs: 0.0016249801265075803\n",
      "Epoch: 8500 train loss=0.002193491 valid loss= 0.002087827\n",
      "train reg_fs: 0.0016208579763770103\n",
      "Epoch: 9000 train loss=0.002888003 valid loss= 0.002344136\n",
      "train reg_fs: 0.0016178316436707973\n",
      "Epoch: 9500 train loss=0.002113039 valid loss= 0.002293036\n",
      "train reg_fs: 0.0016150231240317225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-31 23:38:35,937]\u001b[0m Trial 99 finished with value: 0.0005522875122046641 and parameters: {'lam': 0.002389328625473885, 'learning_rate': 0.10412325349010412, 'num_epoch': 10000}. Best is trial 67 with value: 0.00021555817752089075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003799984 valid loss= 0.002172594\n",
      "train reg_fs: 0.0016123397508636117\n",
      "Optimization Finished!\n",
      "test loss: 0.002126675099134445, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0005522875122046641\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "model = None\n",
    "study = optuna.create_study(pruner=None)\n",
    "study.optimize(llspin_objective, n_trials=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_mat_train = best_model.get_prob_alpha(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = study.best_params['learning_rate']\n",
    "best_epoch = study.best_params['num_epoch']\n",
    "best_lam = study.best_params['lam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Finished*************\n",
      "Best model's lambda: 0.0020811013859500485\n",
      "Best model's learning rate: 0.15266423143883523\n",
      "Best model's num of epochs: 15000\n",
      "Test mse : 0.00025906965903572585\n",
      "Test r2 : 0.9937485729628137\n"
     ]
    }
   ],
   "source": [
    "y_pred_llspin = best_model.test(X_test)[0]\n",
    "            \n",
    "print(\"Trial Finished*************\")\n",
    "print(\"Best model's lambda: {}\".format(best_lam))\n",
    "print(\"Best model's learning rate: {}\".format(best_lr))\n",
    "print(\"Best model's num of epochs: {}\".format(best_epoch))\n",
    "print(\"Test mse : {}\".format(mean_squared_error(y_test.reshape(-1),y_pred_llspin.reshape(-1))))\n",
    "print(\"Test r2 : {}\".format(r2_score(y_test.reshape(-1),y_pred_llspin.reshape(-1),multioutput='raw_values')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the training gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm,colors\n",
    "\n",
    "cmap = cm.Blues\n",
    "bounds=[0,0.5,1]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "title_size = 30\n",
    "xtick_size = 20\n",
    "ytick_size = 20\n",
    "xlabel_size = 35\n",
    "ylabel_size = 35\n",
    "colorbar_tick_size = 20\n",
    "title_pad = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "sorted_order = np.concatenate((np.where(train_label == 1)[0],np.where(train_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_train[sorted_order,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([1,3,5,7,9])\n",
    "axes[0].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "im2 = axes[1].imshow(gate_mat_train[sorted_order,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([1,3,5,7,9])\n",
    "axes[1].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the test gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_mat_test = best_model.get_prob_alpha(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "fig.subplots_adjust(bottom=0.01)\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_test[sorted_order_test,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([0,9,19,29,39,49])\n",
    "axes[0].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "    \n",
    "im2 = axes[1].imshow(gate_mat_test[sorted_order_test,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([0,9,19,29,39,49])\n",
    "axes[1].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "    \n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
