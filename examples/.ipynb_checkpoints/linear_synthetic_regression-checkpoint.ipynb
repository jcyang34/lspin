{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from lspin.lspin_model import Model\n",
    "from lspin.utils import DataSet\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm,colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if need to use GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear synthetic data generation\n",
    "\n",
    "Group 1: $X$ ~ $N(1,0.5)$,  $Y = -2X_1 + X_2 - 0.5X_3$\n",
    "\n",
    "Group 2: $X$ ~ $N(-1,0.5)$, $Y = -0.5X_3 + X_4 - 2X_5$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "Xs1 = np.random.normal(loc=1,scale=0.5,size=(300,5))\n",
    "Ys1 = -2*Xs1[:,0]+1*Xs1[:,1]-0.5*Xs1[:,2]\n",
    "\n",
    "Xs2 = np.random.normal(loc=-1,scale=0.5,size=(300,5))\n",
    "Ys2 = -0.5*Xs2[:,2]+1*Xs2[:,3]-2*Xs2[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate((Xs1,Xs2),axis=0)\n",
    "Y_data = np.concatenate((Ys1.reshape(-1,1),Ys2.reshape(-1,1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = Y_data-Y_data.min()\n",
    "Y_data=Y_data/Y_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ground truth group label of each sample\n",
    "case_labels = np.concatenate((np.array([1]*300),np.array([2]*300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = np.concatenate((Y_data,case_labels.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% for validation, 10% for test \n",
    "X_train,X_remain,yc_train,yc_remain = train_test_split(X_data,Y_data,train_size=0.8,shuffle=True,random_state=34)\n",
    "X_valid,X_test,yc_valid,yc_test = train_test_split(X_remain,yc_remain,train_size=0.5,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 10 samples used for training\n",
    "X_train,_,yc_train,_ = train_test_split(X_train,yc_train,train_size=10,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes:\n",
      "10 60 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample sizes:\")\n",
    "print(X_train.shape[0],X_valid.shape[0],X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = yc_train[:,0].reshape(-1,1)\n",
    "y_valid = yc_valid[:,0].reshape(-1,1)\n",
    "y_test = yc_test[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = yc_train[:,1]\n",
    "valid_label = yc_valid[:,1]\n",
    "test_label= yc_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 6, 1.0: 4})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 29, 1.0: 31})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(**{'_data':X_train, '_labels':y_train,\n",
    "                '_valid_data':X_valid, '_valid_labels':y_valid,\n",
    "                '_test_data':X_test, '_test_labels':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference ground truth feature matrix (training/test)\n",
    "ref_feat_mat_train = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in train_label])\n",
    "ref_feat_mat_test = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in test_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLSPIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function for optuna hyper-parameter optimization\n",
    "def llspin_objective(trial):  \n",
    "    global model\n",
    "    \n",
    "    # hyper-parameter specification\n",
    "    params = {     \n",
    "        \"input_node\" : X_train.shape[1],       # input dimension for the prediction network\n",
    "        \"hidden_layers_node\" : [100,100,10,1], # number of nodes for each hidden layer of the prediction net\n",
    "        \"output_node\" : 1,                     # number of nodes for the output layer of the prediction net\n",
    "        \"feature_selection\" : True,            # if using the gating net\n",
    "        \"gating_net_hidden_layers_node\": [10], # number of nodes for each hidden layer of the gating net\n",
    "        \"display_step\" : 500                   # number of epochs to output info\n",
    "    }\n",
    "    params['activation']= 'none' # linear prediction\n",
    "    params['batch_size']= X_train.shape[0]\n",
    "    \n",
    "    # hyper-parameter to optimize: lambda, learning rate, number of epochs\n",
    "    params['lam'] = trial.suggest_loguniform('lam',1e-3,1e-2)\n",
    "    params['learning_rate'] = trial.suggest_loguniform('learning_rate', 1e-2, 2e-1)\n",
    "    num_epoch = trial.suggest_categorical('num_epoch', [2000,5000,10000,15000])\n",
    "\n",
    "    # specify the model with these parameters and train the model\n",
    "    model_dir =None\n",
    "    model = Model(**params)\n",
    "    train_acces, train_losses, val_acces, val_losses = model.train(trial, dataset, model_dir, num_epoch=num_epoch)\n",
    "\n",
    "    print(\"In trial:---------------------\")\n",
    "    val_prediction = model.test(X_valid)[0]\n",
    "    mse = mean_squared_error(y_valid.reshape(-1),val_prediction.reshape(-1))\n",
    "    print(\"validation mse: {}\".format(mse))\n",
    "    \n",
    "    loss= mse\n",
    "            \n",
    "    return loss\n",
    "        \n",
    "def callback(study,trial):\n",
    "    global best_model\n",
    "    if study.best_trial == trial:\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:33:39,905]\u001b[0m A new study created in memory with name: no-name-621c05a0-174d-4754-9651-4e4b781d9508\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009697011 valid loss= 0.008388120\n",
      "train reg_fs: 0.0013551067095249891\n",
      "Epoch: 1000 train loss=0.014722394 valid loss= 0.007856987\n",
      "train reg_fs: 0.001367635908536613\n",
      "Epoch: 1500 train loss=0.020595901 valid loss= 0.007884451\n",
      "train reg_fs: 0.0013785153860226274\n",
      "Epoch: 2000 train loss=0.009446532 valid loss= 0.007667622\n",
      "train reg_fs: 0.0013882594648748636\n",
      "Epoch: 2500 train loss=0.009747269 valid loss= 0.007797400\n",
      "train reg_fs: 0.0013961186632514\n",
      "Epoch: 3000 train loss=0.006126662 valid loss= 0.007918450\n",
      "train reg_fs: 0.0014036324573680758\n",
      "Epoch: 3500 train loss=0.014548547 valid loss= 0.007453454\n",
      "train reg_fs: 0.0014091298216953874\n",
      "Epoch: 4000 train loss=0.008949714 valid loss= 0.007218767\n",
      "train reg_fs: 0.0014145394088700414\n",
      "Epoch: 4500 train loss=0.007253684 valid loss= 0.007893791\n",
      "train reg_fs: 0.001418770058080554\n",
      "Epoch: 5000 train loss=0.006082294 valid loss= 0.006969958\n",
      "train reg_fs: 0.0014224214246496558\n",
      "Epoch: 5500 train loss=0.010977981 valid loss= 0.007961488\n",
      "train reg_fs: 0.0014255928108468652\n",
      "Epoch: 6000 train loss=0.007991868 valid loss= 0.007261055\n",
      "train reg_fs: 0.0014284754870459437\n",
      "Epoch: 6500 train loss=0.006419949 valid loss= 0.007317234\n",
      "train reg_fs: 0.0014309474499896169\n",
      "Epoch: 7000 train loss=0.009252145 valid loss= 0.007403156\n",
      "train reg_fs: 0.0014332743594422936\n",
      "Epoch: 7500 train loss=0.008128776 valid loss= 0.007386979\n",
      "train reg_fs: 0.0014350727433338761\n",
      "Epoch: 8000 train loss=0.007303218 valid loss= 0.007199449\n",
      "train reg_fs: 0.0014363819500431418\n",
      "Epoch: 8500 train loss=0.009688796 valid loss= 0.007169710\n",
      "train reg_fs: 0.0014375961618497968\n",
      "Epoch: 9000 train loss=0.009540527 valid loss= 0.007228332\n",
      "train reg_fs: 0.0014386225957423449\n",
      "Epoch: 9500 train loss=0.011868289 valid loss= 0.007416694\n",
      "train reg_fs: 0.0014391840668395162\n",
      "Epoch: 10000 train loss=0.009981859 valid loss= 0.006749738\n",
      "train reg_fs: 0.0014392378507182002\n",
      "Epoch: 10500 train loss=0.005788518 valid loss= 0.006677278\n",
      "train reg_fs: 0.0014391641598194838\n",
      "Epoch: 11000 train loss=0.008718120 valid loss= 0.006594601\n",
      "train reg_fs: 0.0014389462303370237\n",
      "Epoch: 11500 train loss=0.006486101 valid loss= 0.006617835\n",
      "train reg_fs: 0.0014387286501005292\n",
      "Epoch: 12000 train loss=0.003949310 valid loss= 0.006058688\n",
      "train reg_fs: 0.0014383987290784717\n",
      "Epoch: 12500 train loss=0.004044131 valid loss= 0.006703127\n",
      "train reg_fs: 0.0014379245694726706\n",
      "Epoch: 13000 train loss=0.005928365 valid loss= 0.005960175\n",
      "train reg_fs: 0.0014372162986546755\n",
      "Epoch: 13500 train loss=0.005655317 valid loss= 0.006256556\n",
      "train reg_fs: 0.0014364604139700532\n",
      "Epoch: 14000 train loss=0.007978046 valid loss= 0.005903599\n",
      "train reg_fs: 0.0014355476014316082\n",
      "Epoch: 14500 train loss=0.004311236 valid loss= 0.005742929\n",
      "train reg_fs: 0.0014342092908918858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:35:28,503]\u001b[0m Trial 0 finished with value: 0.004463284107418791 and parameters: {'lam': 0.0015882276264305452, 'learning_rate': 0.013527642980568966, 'num_epoch': 15000}. Best is trial 0 with value: 0.004463284107418791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006079318 valid loss= 0.005890806\n",
      "train reg_fs: 0.0014333612052723765\n",
      "In trial:---------------------\n",
      "validation mse: 0.004463284107418791\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014411129 valid loss= 0.009406045\n",
      "train reg_fs: 0.0030058431439101696\n",
      "Epoch: 1000 train loss=0.010063510 valid loss= 0.009725103\n",
      "train reg_fs: 0.0030120934825390577\n",
      "Epoch: 1500 train loss=0.009218581 valid loss= 0.010280768\n",
      "train reg_fs: 0.00294273579493165\n",
      "Epoch: 2000 train loss=0.008792315 valid loss= 0.008899130\n",
      "train reg_fs: 0.0028654378838837147\n",
      "Epoch: 2500 train loss=0.003993861 valid loss= 0.008127145\n",
      "train reg_fs: 0.0028039775788784027\n",
      "Epoch: 3000 train loss=0.005074102 valid loss= 0.007605886\n",
      "train reg_fs: 0.002748558297753334\n",
      "Epoch: 3500 train loss=0.006432082 valid loss= 0.006928289\n",
      "train reg_fs: 0.002689413260668516\n",
      "Epoch: 4000 train loss=0.008764779 valid loss= 0.006509831\n",
      "train reg_fs: 0.002624963643029332\n",
      "Epoch: 4500 train loss=0.006350219 valid loss= 0.006428972\n",
      "train reg_fs: 0.002553290454670787\n",
      "Epoch: 5000 train loss=0.006180895 valid loss= 0.005917035\n",
      "train reg_fs: 0.002499320777133107\n",
      "Epoch: 5500 train loss=0.003228002 valid loss= 0.006318905\n",
      "train reg_fs: 0.002449401654303074\n",
      "Epoch: 6000 train loss=0.002746199 valid loss= 0.005695093\n",
      "train reg_fs: 0.002411710098385811\n",
      "Epoch: 6500 train loss=0.004155754 valid loss= 0.005931183\n",
      "train reg_fs: 0.0023764343932271004\n",
      "Epoch: 7000 train loss=0.002790553 valid loss= 0.004922327\n",
      "train reg_fs: 0.002344294684007764\n",
      "Epoch: 7500 train loss=0.010613133 valid loss= 0.005375385\n",
      "train reg_fs: 0.002316452329978347\n",
      "Epoch: 8000 train loss=0.004959856 valid loss= 0.005219518\n",
      "train reg_fs: 0.0022907215170562267\n",
      "Epoch: 8500 train loss=0.005201465 valid loss= 0.005327551\n",
      "train reg_fs: 0.002267886884510517\n",
      "Epoch: 9000 train loss=0.002750499 valid loss= 0.004660223\n",
      "train reg_fs: 0.002247675321996212\n",
      "Epoch: 9500 train loss=0.003287442 valid loss= 0.004718964\n",
      "train reg_fs: 0.0022274141665548086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:36:42,493]\u001b[0m Trial 1 finished with value: 0.002419669159472906 and parameters: {'lam': 0.003457058043906371, 'learning_rate': 0.0794334317343112, 'num_epoch': 10000}. Best is trial 1 with value: 0.002419669159472906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007207579 valid loss= 0.004604346\n",
      "train reg_fs: 0.0022074924781918526\n",
      "In trial:---------------------\n",
      "validation mse: 0.002419669159472906\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014124954 valid loss= 0.009548541\n",
      "train reg_fs: 0.0037389115896075964\n",
      "Epoch: 1000 train loss=0.018067522 valid loss= 0.009370244\n",
      "train reg_fs: 0.003749022725969553\n",
      "Epoch: 1500 train loss=0.010941813 valid loss= 0.008706741\n",
      "train reg_fs: 0.003697515930980444\n",
      "Epoch: 2000 train loss=0.006261283 valid loss= 0.006832578\n",
      "train reg_fs: 0.0036031492054462433\n",
      "Epoch: 2500 train loss=0.006912017 valid loss= 0.005850954\n",
      "train reg_fs: 0.0035027458798140287\n",
      "Epoch: 3000 train loss=0.005220648 valid loss= 0.005394677\n",
      "train reg_fs: 0.0034192348830401897\n",
      "Epoch: 3500 train loss=0.006840178 valid loss= 0.005623726\n",
      "train reg_fs: 0.0033591946121305227\n",
      "Epoch: 4000 train loss=0.004673129 valid loss= 0.005467270\n",
      "train reg_fs: 0.0033111090306192636\n",
      "Epoch: 4500 train loss=0.003914674 valid loss= 0.005645177\n",
      "train reg_fs: 0.003274225862696767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:37:19,886]\u001b[0m Trial 2 finished with value: 0.002251302945897863 and parameters: {'lam': 0.004335444202730945, 'learning_rate': 0.03971952500709454, 'num_epoch': 5000}. Best is trial 2 with value: 0.002251302945897863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.006538083 valid loss= 0.005483877\n",
      "train reg_fs: 0.0032393517903983593\n",
      "In trial:---------------------\n",
      "validation mse: 0.002251302945897863\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010621476 valid loss= 0.007134207\n",
      "train reg_fs: 0.001240310026332736\n",
      "Epoch: 1000 train loss=0.004152014 valid loss= 0.006187281\n",
      "train reg_fs: 0.0011768646072596312\n",
      "Epoch: 1500 train loss=0.004398386 valid loss= 0.004057649\n",
      "train reg_fs: 0.001113124773837626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:37:36,057]\u001b[0m Trial 3 finished with value: 0.003217484040488643 and parameters: {'lam': 0.0014958824045764156, 'learning_rate': 0.09311527636874589, 'num_epoch': 2000}. Best is trial 2 with value: 0.002251302945897863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.004506537 valid loss= 0.004308334\n",
      "train reg_fs: 0.0010717854602262378\n",
      "In trial:---------------------\n",
      "validation mse: 0.003217484040488643\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010338895 valid loss= 0.009846373\n",
      "train reg_fs: 0.002177541609853506\n",
      "Epoch: 1000 train loss=0.005475379 valid loss= 0.009835446\n",
      "train reg_fs: 0.002122304867953062\n",
      "Epoch: 1500 train loss=0.007329551 valid loss= 0.008705125\n",
      "train reg_fs: 0.0020519238896667957\n",
      "Epoch: 2000 train loss=0.004279540 valid loss= 0.007139318\n",
      "train reg_fs: 0.0020092171616852283\n",
      "Epoch: 2500 train loss=0.004999828 valid loss= 0.007137275\n",
      "train reg_fs: 0.0019584051333367825\n",
      "Epoch: 3000 train loss=0.004219645 valid loss= 0.005919606\n",
      "train reg_fs: 0.0018907106714323163\n",
      "Epoch: 3500 train loss=0.004127912 valid loss= 0.004450593\n",
      "train reg_fs: 0.0018027846235781908\n",
      "Epoch: 4000 train loss=0.004382188 valid loss= 0.004520155\n",
      "train reg_fs: 0.0017419727519154549\n",
      "Epoch: 4500 train loss=0.003783121 valid loss= 0.004101900\n",
      "train reg_fs: 0.0017012370517477393\n",
      "Epoch: 5000 train loss=0.001833515 valid loss= 0.004409039\n",
      "train reg_fs: 0.0016738967970013618\n",
      "Epoch: 5500 train loss=0.007514398 valid loss= 0.004226812\n",
      "train reg_fs: 0.0016523301601409912\n",
      "Epoch: 6000 train loss=0.006848739 valid loss= 0.003833239\n",
      "train reg_fs: 0.0016363468021154404\n",
      "Epoch: 6500 train loss=0.002928037 valid loss= 0.003965245\n",
      "train reg_fs: 0.001622289652004838\n",
      "Epoch: 7000 train loss=0.001832021 valid loss= 0.004164506\n",
      "train reg_fs: 0.0016111979493871331\n",
      "Epoch: 7500 train loss=0.001935461 valid loss= 0.004293510\n",
      "train reg_fs: 0.001602211152203381\n",
      "Epoch: 8000 train loss=0.003042931 valid loss= 0.004082245\n",
      "train reg_fs: 0.0015939294826239347\n",
      "Epoch: 8500 train loss=0.002515473 valid loss= 0.003557940\n",
      "train reg_fs: 0.0015871839132159948\n",
      "Epoch: 9000 train loss=0.003632566 valid loss= 0.004137510\n",
      "train reg_fs: 0.0015813108766451478\n",
      "Epoch: 9500 train loss=0.004708719 valid loss= 0.003730174\n",
      "train reg_fs: 0.0015762040857225657\n",
      "Epoch: 10000 train loss=0.005505135 valid loss= 0.003593817\n",
      "train reg_fs: 0.0015714241890236735\n",
      "Epoch: 10500 train loss=0.001691848 valid loss= 0.003852365\n",
      "train reg_fs: 0.00156728969886899\n",
      "Epoch: 11000 train loss=0.004296827 valid loss= 0.003833129\n",
      "train reg_fs: 0.0015636837342754006\n",
      "Epoch: 11500 train loss=0.001806041 valid loss= 0.003668331\n",
      "train reg_fs: 0.001560404198244214\n",
      "Epoch: 12000 train loss=0.002151824 valid loss= 0.003852390\n",
      "train reg_fs: 0.0015573414275422692\n",
      "Epoch: 12500 train loss=0.003569449 valid loss= 0.003998473\n",
      "train reg_fs: 0.001554648159071803\n",
      "Epoch: 13000 train loss=0.012336523 valid loss= 0.004298326\n",
      "train reg_fs: 0.0015523162437602878\n",
      "Epoch: 13500 train loss=0.008408102 valid loss= 0.003948808\n",
      "train reg_fs: 0.0015502760652452707\n",
      "Epoch: 14000 train loss=0.005082664 valid loss= 0.003822261\n",
      "train reg_fs: 0.001548480591736734\n",
      "Epoch: 14500 train loss=0.003073109 valid loss= 0.003734546\n",
      "train reg_fs: 0.0015466933837160468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:39:24,270]\u001b[0m Trial 4 finished with value: 0.0021450847529553485 and parameters: {'lam': 0.002537674852783063, 'learning_rate': 0.09176201685579755, 'num_epoch': 15000}. Best is trial 4 with value: 0.0021450847529553485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002488660 valid loss= 0.003658832\n",
      "train reg_fs: 0.0015451404033228755\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021450847529553485\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016241189 valid loss= 0.011270252\n",
      "train reg_fs: 0.0038233576342463493\n",
      "Epoch: 1000 train loss=0.011932136 valid loss= 0.011096564\n",
      "train reg_fs: 0.003859224496409297\n",
      "Epoch: 1500 train loss=0.013104609 valid loss= 0.010572846\n",
      "train reg_fs: 0.0038854964077472687\n",
      "Epoch: 2000 train loss=0.027466303 valid loss= 0.009953501\n",
      "train reg_fs: 0.003897449467331171\n",
      "Epoch: 2500 train loss=0.014036442 valid loss= 0.009807834\n",
      "train reg_fs: 0.003903912380337715\n",
      "Epoch: 3000 train loss=0.015115564 valid loss= 0.009413488\n",
      "train reg_fs: 0.003901207121089101\n",
      "Epoch: 3500 train loss=0.012064504 valid loss= 0.009785326\n",
      "train reg_fs: 0.003893197514116764\n",
      "Epoch: 4000 train loss=0.008907633 valid loss= 0.009152035\n",
      "train reg_fs: 0.0038752849213778973\n",
      "Epoch: 4500 train loss=0.010664172 valid loss= 0.008752656\n",
      "train reg_fs: 0.003847872605547309\n",
      "Epoch: 5000 train loss=0.010142965 valid loss= 0.009013224\n",
      "train reg_fs: 0.0038114963099360466\n",
      "Epoch: 5500 train loss=0.014536532 valid loss= 0.008455521\n",
      "train reg_fs: 0.003768267808482051\n",
      "Epoch: 6000 train loss=0.006912568 valid loss= 0.007860731\n",
      "train reg_fs: 0.003723748493939638\n",
      "Epoch: 6500 train loss=0.008189464 valid loss= 0.007382944\n",
      "train reg_fs: 0.0036800496745854616\n",
      "Epoch: 7000 train loss=0.013683362 valid loss= 0.006859907\n",
      "train reg_fs: 0.003639073111116886\n",
      "Epoch: 7500 train loss=0.008187697 valid loss= 0.006670217\n",
      "train reg_fs: 0.003600189695134759\n",
      "Epoch: 8000 train loss=0.009436951 valid loss= 0.006660844\n",
      "train reg_fs: 0.0035643435548990965\n",
      "Epoch: 8500 train loss=0.009568600 valid loss= 0.006719254\n",
      "train reg_fs: 0.003534856019541621\n",
      "Epoch: 9000 train loss=0.006580149 valid loss= 0.006584090\n",
      "train reg_fs: 0.003511961316689849\n",
      "Epoch: 9500 train loss=0.013421544 valid loss= 0.006756829\n",
      "train reg_fs: 0.0034912063274532557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:40:37,207]\u001b[0m Trial 5 finished with value: 0.0030329089596353017 and parameters: {'lam': 0.004510027537852955, 'learning_rate': 0.019371030792006402, 'num_epoch': 10000}. Best is trial 4 with value: 0.0021450847529553485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.008736812 valid loss= 0.006548172\n",
      "train reg_fs: 0.0034742129500955343\n",
      "In trial:---------------------\n",
      "validation mse: 0.0030329089596353017\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010449197 valid loss= 0.007124346\n",
      "train reg_fs: 0.0011459673987701535\n",
      "Epoch: 1000 train loss=0.008056415 valid loss= 0.006065165\n",
      "train reg_fs: 0.0011125579476356506\n",
      "Epoch: 1500 train loss=0.005535983 valid loss= 0.003905750\n",
      "train reg_fs: 0.0010568087454885244\n",
      "Epoch: 2000 train loss=0.003720280 valid loss= 0.003376925\n",
      "train reg_fs: 0.0010136928176507354\n",
      "Epoch: 2500 train loss=0.003410179 valid loss= 0.003629322\n",
      "train reg_fs: 0.0009906882187351584\n",
      "Epoch: 3000 train loss=0.004934529 valid loss= 0.003661469\n",
      "train reg_fs: 0.000977668329142034\n",
      "Epoch: 3500 train loss=0.005249653 valid loss= 0.003361695\n",
      "train reg_fs: 0.0009676302433945239\n",
      "Epoch: 4000 train loss=0.004076646 valid loss= 0.003090370\n",
      "train reg_fs: 0.0009602888021618128\n",
      "Epoch: 4500 train loss=0.002261402 valid loss= 0.003446396\n",
      "train reg_fs: 0.0009545977227389812\n",
      "Epoch: 5000 train loss=0.002037990 valid loss= 0.003282863\n",
      "train reg_fs: 0.0009500159067101777\n",
      "Epoch: 5500 train loss=0.003228420 valid loss= 0.003163445\n",
      "train reg_fs: 0.0009457607520744205\n",
      "Epoch: 6000 train loss=0.005559385 valid loss= 0.003515816\n",
      "train reg_fs: 0.0009421904105693102\n",
      "Epoch: 6500 train loss=0.001657581 valid loss= 0.003241764\n",
      "train reg_fs: 0.0009386668680235744\n",
      "Epoch: 7000 train loss=0.003516972 valid loss= 0.003000503\n",
      "train reg_fs: 0.0009357843082398176\n",
      "Epoch: 7500 train loss=0.003190527 valid loss= 0.003113182\n",
      "train reg_fs: 0.0009333165944553912\n",
      "Epoch: 8000 train loss=0.002947669 valid loss= 0.003239372\n",
      "train reg_fs: 0.0009306624997407198\n",
      "Epoch: 8500 train loss=0.001583135 valid loss= 0.003110341\n",
      "train reg_fs: 0.0009281879174523056\n",
      "Epoch: 9000 train loss=0.008352058 valid loss= 0.003553329\n",
      "train reg_fs: 0.0009266430861316621\n",
      "Epoch: 9500 train loss=0.001420510 valid loss= 0.003113374\n",
      "train reg_fs: 0.0009246735135093331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:41:50,395]\u001b[0m Trial 6 finished with value: 0.002011230264851386 and parameters: {'lam': 0.0012966116282226029, 'learning_rate': 0.11628440543308168, 'num_epoch': 10000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001701909 valid loss= 0.002899653\n",
      "train reg_fs: 0.0009226629044860601\n",
      "In trial:---------------------\n",
      "validation mse: 0.002011230264851386\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009403404 valid loss= 0.010025105\n",
      "train reg_fs: 0.003985313698649406\n",
      "Epoch: 1000 train loss=0.008982313 valid loss= 0.006523507\n",
      "train reg_fs: 0.00363637856207788\n",
      "Epoch: 1500 train loss=0.005667223 valid loss= 0.006750470\n",
      "train reg_fs: 0.0034779931884258986\n",
      "Epoch: 2000 train loss=0.007093525 valid loss= 0.006898453\n",
      "train reg_fs: 0.0033212541602551937\n",
      "Epoch: 2500 train loss=0.005297781 valid loss= 0.006184448\n",
      "train reg_fs: 0.0031582005321979523\n",
      "Epoch: 3000 train loss=0.008094631 valid loss= 0.006047363\n",
      "train reg_fs: 0.003030163235962391\n",
      "Epoch: 3500 train loss=0.005911274 valid loss= 0.005262286\n",
      "train reg_fs: 0.0029622353613376617\n",
      "Epoch: 4000 train loss=0.003566145 valid loss= 0.005197242\n",
      "train reg_fs: 0.002921963343396783\n",
      "Epoch: 4500 train loss=0.003493574 valid loss= 0.005164518\n",
      "train reg_fs: 0.00289534660987556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:42:28,911]\u001b[0m Trial 7 finished with value: 0.0023021390135772577 and parameters: {'lam': 0.0046832948533216045, 'learning_rate': 0.18730247650617446, 'num_epoch': 5000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003891998 valid loss= 0.005128378\n",
      "train reg_fs: 0.0028777746483683586\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023021390135772577\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020909153 valid loss= 0.009507000\n",
      "train reg_fs: 0.0023637101985514164\n",
      "Epoch: 1000 train loss=0.009660327 valid loss= 0.009307045\n",
      "train reg_fs: 0.002397543052211404\n",
      "Epoch: 1500 train loss=0.011751050 valid loss= 0.008824630\n",
      "train reg_fs: 0.0024172307457774878\n",
      "Epoch: 2000 train loss=0.012735880 valid loss= 0.008549755\n",
      "train reg_fs: 0.0024287065025418997\n",
      "Epoch: 2500 train loss=0.008400958 valid loss= 0.008588554\n",
      "train reg_fs: 0.0024340732488781214\n",
      "Epoch: 3000 train loss=0.008470048 valid loss= 0.009042997\n",
      "train reg_fs: 0.002431541448459029\n",
      "Epoch: 3500 train loss=0.012815523 valid loss= 0.008860659\n",
      "train reg_fs: 0.002424441510811448\n",
      "Epoch: 4000 train loss=0.007656238 valid loss= 0.009110192\n",
      "train reg_fs: 0.002413097769021988\n",
      "Epoch: 4500 train loss=0.004781872 valid loss= 0.009333317\n",
      "train reg_fs: 0.002395675051957369\n",
      "Epoch: 5000 train loss=0.006777328 valid loss= 0.008182083\n",
      "train reg_fs: 0.002382555976510048\n",
      "Epoch: 5500 train loss=0.006587464 valid loss= 0.008243771\n",
      "train reg_fs: 0.0023687134962528944\n",
      "Epoch: 6000 train loss=0.008647507 valid loss= 0.008421512\n",
      "train reg_fs: 0.002353778574615717\n",
      "Epoch: 6500 train loss=0.009316554 valid loss= 0.008214340\n",
      "train reg_fs: 0.002339012920856476\n",
      "Epoch: 7000 train loss=0.010952901 valid loss= 0.007836686\n",
      "train reg_fs: 0.0023267304059118032\n",
      "Epoch: 7500 train loss=0.007986972 valid loss= 0.008006479\n",
      "train reg_fs: 0.0023184933234006166\n",
      "Epoch: 8000 train loss=0.004852959 valid loss= 0.007495560\n",
      "train reg_fs: 0.0023112869821488857\n",
      "Epoch: 8500 train loss=0.011381120 valid loss= 0.007142494\n",
      "train reg_fs: 0.0023055074270814657\n",
      "Epoch: 9000 train loss=0.007428557 valid loss= 0.007991863\n",
      "train reg_fs: 0.0022981958463788033\n",
      "Epoch: 9500 train loss=0.007459746 valid loss= 0.007083958\n",
      "train reg_fs: 0.002291473327204585\n",
      "Epoch: 10000 train loss=0.003954914 valid loss= 0.007142909\n",
      "train reg_fs: 0.002286255592480302\n",
      "Epoch: 10500 train loss=0.006193331 valid loss= 0.006846424\n",
      "train reg_fs: 0.0022828076034784317\n",
      "Epoch: 11000 train loss=0.009009316 valid loss= 0.006873633\n",
      "train reg_fs: 0.002278632251545787\n",
      "Epoch: 11500 train loss=0.009766124 valid loss= 0.006878277\n",
      "train reg_fs: 0.0022756019607186317\n",
      "Epoch: 12000 train loss=0.003809626 valid loss= 0.006948194\n",
      "train reg_fs: 0.0022696189116686583\n",
      "Epoch: 12500 train loss=0.004304812 valid loss= 0.006447020\n",
      "train reg_fs: 0.002264447044581175\n",
      "Epoch: 13000 train loss=0.004562339 valid loss= 0.006464584\n",
      "train reg_fs: 0.002259870059788227\n",
      "Epoch: 13500 train loss=0.004778993 valid loss= 0.006528261\n",
      "train reg_fs: 0.0022527386900037527\n",
      "Epoch: 14000 train loss=0.006156823 valid loss= 0.006327856\n",
      "train reg_fs: 0.002247764030471444\n",
      "Epoch: 14500 train loss=0.003092330 valid loss= 0.006768215\n",
      "train reg_fs: 0.00224185804836452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:44:18,386]\u001b[0m Trial 8 finished with value: 0.004699929750613716 and parameters: {'lam': 0.0027626945482059637, 'learning_rate': 0.03255787314633055, 'num_epoch': 15000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004235690 valid loss= 0.006997230\n",
      "train reg_fs: 0.0022379716392606497\n",
      "In trial:---------------------\n",
      "validation mse: 0.004699929750613716\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011998404 valid loss= 0.009266401\n",
      "train reg_fs: 0.0023080431856215\n",
      "Epoch: 1000 train loss=0.007703857 valid loss= 0.009331357\n",
      "train reg_fs: 0.002234867075458169\n",
      "Epoch: 1500 train loss=0.004161337 valid loss= 0.007867332\n",
      "train reg_fs: 0.002166353166103363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:44:34,770]\u001b[0m Trial 9 finished with value: 0.004483848969863957 and parameters: {'lam': 0.0026027622591037114, 'learning_rate': 0.14544635122165875, 'num_epoch': 2000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.005906688 valid loss= 0.006647401\n",
      "train reg_fs: 0.002117797965183854\n",
      "In trial:---------------------\n",
      "validation mse: 0.004483848969863957\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015454939 valid loss= 0.014113007\n",
      "train reg_fs: 0.008379075676202774\n",
      "Epoch: 1000 train loss=0.011569401 valid loss= 0.013449152\n",
      "train reg_fs: 0.008242126554250717\n",
      "Epoch: 1500 train loss=0.012932949 valid loss= 0.012311365\n",
      "train reg_fs: 0.007851408794522285\n",
      "Epoch: 2000 train loss=0.012145722 valid loss= 0.010399730\n",
      "train reg_fs: 0.007383755873888731\n",
      "Epoch: 2500 train loss=0.014164804 valid loss= 0.010501010\n",
      "train reg_fs: 0.007017120718955994\n",
      "Epoch: 3000 train loss=0.007336158 valid loss= 0.009952255\n",
      "train reg_fs: 0.006722454912960529\n",
      "Epoch: 3500 train loss=0.009768052 valid loss= 0.009328462\n",
      "train reg_fs: 0.006515976507216692\n",
      "Epoch: 4000 train loss=0.007418022 valid loss= 0.009141943\n",
      "train reg_fs: 0.0063666244968771935\n",
      "Epoch: 4500 train loss=0.008921295 valid loss= 0.009003207\n",
      "train reg_fs: 0.00626631174236536\n",
      "Epoch: 5000 train loss=0.007597841 valid loss= 0.008586068\n",
      "train reg_fs: 0.006191641557961702\n",
      "Epoch: 5500 train loss=0.013251074 valid loss= 0.008720106\n",
      "train reg_fs: 0.006137925665825605\n",
      "Epoch: 6000 train loss=0.007153561 valid loss= 0.008476163\n",
      "train reg_fs: 0.006095303222537041\n",
      "Epoch: 6500 train loss=0.007806407 valid loss= 0.008340223\n",
      "train reg_fs: 0.006060936022549868\n",
      "Epoch: 7000 train loss=0.007435238 valid loss= 0.008305978\n",
      "train reg_fs: 0.006033626385033131\n",
      "Epoch: 7500 train loss=0.007346152 valid loss= 0.008489360\n",
      "train reg_fs: 0.0060118683613836765\n",
      "Epoch: 8000 train loss=0.006614281 valid loss= 0.008195781\n",
      "train reg_fs: 0.00599347660318017\n",
      "Epoch: 8500 train loss=0.008229406 valid loss= 0.007931099\n",
      "train reg_fs: 0.005977366119623184\n",
      "Epoch: 9000 train loss=0.006617561 valid loss= 0.008258914\n",
      "train reg_fs: 0.005963183008134365\n",
      "Epoch: 9500 train loss=0.009300266 valid loss= 0.008103253\n",
      "train reg_fs: 0.0059515307657420635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:45:48,920]\u001b[0m Trial 10 finished with value: 0.002376983387096194 and parameters: {'lam': 0.009749161724452527, 'learning_rate': 0.061885485509518195, 'num_epoch': 10000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006248029 valid loss= 0.008188056\n",
      "train reg_fs: 0.005941531155258417\n",
      "In trial:---------------------\n",
      "validation mse: 0.002376983387096194\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016018959 valid loss= 0.007911014\n",
      "train reg_fs: 0.0009156244923360646\n",
      "Epoch: 1000 train loss=0.007324033 valid loss= 0.009625535\n",
      "train reg_fs: 0.0009289621957577765\n",
      "Epoch: 1500 train loss=0.004920049 valid loss= 0.008661451\n",
      "train reg_fs: 0.0009172811405733228\n",
      "Epoch: 2000 train loss=0.003602560 valid loss= 0.006879861\n",
      "train reg_fs: 0.0008920080726966262\n",
      "Epoch: 2500 train loss=0.003714173 valid loss= 0.006619991\n",
      "train reg_fs: 0.0008820039802230895\n",
      "Epoch: 3000 train loss=0.009196714 valid loss= 0.006399508\n",
      "train reg_fs: 0.0008728782995603979\n",
      "Epoch: 3500 train loss=0.002168237 valid loss= 0.005334182\n",
      "train reg_fs: 0.000869711278937757\n",
      "Epoch: 4000 train loss=0.003813947 valid loss= 0.004788429\n",
      "train reg_fs: 0.0008676799479871988\n",
      "Epoch: 4500 train loss=0.003821214 valid loss= 0.004676310\n",
      "train reg_fs: 0.0008623331086710095\n",
      "Epoch: 5000 train loss=0.002453659 valid loss= 0.004940349\n",
      "train reg_fs: 0.0008576774853281677\n",
      "Epoch: 5500 train loss=0.002562483 valid loss= 0.004720056\n",
      "train reg_fs: 0.0008537190733477473\n",
      "Epoch: 6000 train loss=0.002649384 valid loss= 0.004596548\n",
      "train reg_fs: 0.0008510156767442822\n",
      "Epoch: 6500 train loss=0.004155623 valid loss= 0.004833786\n",
      "train reg_fs: 0.0008476778748445213\n",
      "Epoch: 7000 train loss=0.005621033 valid loss= 0.005008185\n",
      "train reg_fs: 0.0008423907565884292\n",
      "Epoch: 7500 train loss=0.001831509 valid loss= 0.004968942\n",
      "train reg_fs: 0.0008385461987927556\n",
      "Epoch: 8000 train loss=0.003712065 valid loss= 0.005202116\n",
      "train reg_fs: 0.0008369544520974159\n",
      "Epoch: 8500 train loss=0.004317034 valid loss= 0.005126179\n",
      "train reg_fs: 0.0008337442995980382\n",
      "Epoch: 9000 train loss=0.001723535 valid loss= 0.005078456\n",
      "train reg_fs: 0.0008301750058308244\n",
      "Epoch: 9500 train loss=0.001668580 valid loss= 0.005199775\n",
      "train reg_fs: 0.0008295669103972614\n",
      "Epoch: 10000 train loss=0.001392513 valid loss= 0.005533019\n",
      "train reg_fs: 0.0008261524490080774\n",
      "Epoch: 10500 train loss=0.001669517 valid loss= 0.005331077\n",
      "train reg_fs: 0.0008230910752899945\n",
      "Epoch: 11000 train loss=0.001997392 valid loss= 0.005375098\n",
      "train reg_fs: 0.0008201535674743354\n",
      "Epoch: 11500 train loss=0.003271689 valid loss= 0.005197766\n",
      "train reg_fs: 0.0008184686303138733\n",
      "Epoch: 12000 train loss=0.001511939 valid loss= 0.005857311\n",
      "train reg_fs: 0.0008164320606738329\n",
      "Epoch: 12500 train loss=0.001099939 valid loss= 0.006103592\n",
      "train reg_fs: 0.0008121246355585754\n",
      "Epoch: 13000 train loss=0.001834640 valid loss= 0.005714198\n",
      "train reg_fs: 0.0008126359898597002\n",
      "Epoch: 13500 train loss=0.002235291 valid loss= 0.005648267\n",
      "train reg_fs: 0.0008076021331362426\n",
      "Epoch: 14000 train loss=0.001351441 valid loss= 0.006207811\n",
      "train reg_fs: 0.0008063409477472305\n",
      "Epoch: 14500 train loss=0.002299978 valid loss= 0.005650966\n",
      "train reg_fs: 0.0008058491512201726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:47:37,073]\u001b[0m Trial 11 finished with value: 0.004787175958914328 and parameters: {'lam': 0.0010248639820242315, 'learning_rate': 0.13204967977019638, 'num_epoch': 15000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001993516 valid loss= 0.005601568\n",
      "train reg_fs: 0.0008043603738769889\n",
      "In trial:---------------------\n",
      "validation mse: 0.004787175958914328\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016391454 valid loss= 0.006587427\n",
      "train reg_fs: 0.0014280836330726743\n",
      "Epoch: 1000 train loss=0.007119088 valid loss= 0.005049675\n",
      "train reg_fs: 0.0013421535259112716\n",
      "Epoch: 1500 train loss=0.010199955 valid loss= 0.004281804\n",
      "train reg_fs: 0.0012784111313521862\n",
      "Epoch: 2000 train loss=0.004473335 valid loss= 0.004084141\n",
      "train reg_fs: 0.0012513753026723862\n",
      "Epoch: 2500 train loss=0.005773444 valid loss= 0.004257336\n",
      "train reg_fs: 0.00123776204418391\n",
      "Epoch: 3000 train loss=0.004204729 valid loss= 0.003897468\n",
      "train reg_fs: 0.0012324710842221975\n",
      "Epoch: 3500 train loss=0.008342567 valid loss= 0.004398947\n",
      "train reg_fs: 0.0012252888409420848\n",
      "Epoch: 4000 train loss=0.006000793 valid loss= 0.004105421\n",
      "train reg_fs: 0.0012111649848520756\n",
      "Epoch: 4500 train loss=0.001956171 valid loss= 0.004022258\n",
      "train reg_fs: 0.001183957327157259\n",
      "Epoch: 5000 train loss=0.005842578 valid loss= 0.004307040\n",
      "train reg_fs: 0.0011590783251449466\n",
      "Epoch: 5500 train loss=0.002421857 valid loss= 0.003960071\n",
      "train reg_fs: 0.001138739287853241\n",
      "Epoch: 6000 train loss=0.003498164 valid loss= 0.003587754\n",
      "train reg_fs: 0.001124267466366291\n",
      "Epoch: 6500 train loss=0.002672808 valid loss= 0.003647389\n",
      "train reg_fs: 0.001112423837184906\n",
      "Epoch: 7000 train loss=0.002731928 valid loss= 0.003807798\n",
      "train reg_fs: 0.0011030026944354177\n",
      "Epoch: 7500 train loss=0.002402825 valid loss= 0.003540054\n",
      "train reg_fs: 0.0010940777137875557\n",
      "Epoch: 8000 train loss=0.005010938 valid loss= 0.003695400\n",
      "train reg_fs: 0.0010871220147237182\n",
      "Epoch: 8500 train loss=0.002254925 valid loss= 0.003489164\n",
      "train reg_fs: 0.00108041288331151\n",
      "Epoch: 9000 train loss=0.001990465 valid loss= 0.003481703\n",
      "train reg_fs: 0.0010750694200396538\n",
      "Epoch: 9500 train loss=0.002087874 valid loss= 0.003687023\n",
      "train reg_fs: 0.0010697932448238134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:48:50,397]\u001b[0m Trial 12 finished with value: 0.0023566040739452293 and parameters: {'lam': 0.0016965979857980946, 'learning_rate': 0.09872766720402426, 'num_epoch': 10000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002004664 valid loss= 0.003411294\n",
      "train reg_fs: 0.0010653429199010134\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023566040739452293\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.002868703 valid loss= 0.004507346\n",
      "train reg_fs: 0.0009842131985351443\n",
      "Epoch: 1000 train loss=0.002796870 valid loss= 0.003474542\n",
      "train reg_fs: 0.0009027211926877499\n",
      "Epoch: 1500 train loss=0.004904778 valid loss= 0.003250519\n",
      "train reg_fs: 0.0008743276703171432\n",
      "Epoch: 2000 train loss=0.003760478 valid loss= 0.003740240\n",
      "train reg_fs: 0.000850966083817184\n",
      "Epoch: 2500 train loss=0.003035176 valid loss= 0.003361124\n",
      "train reg_fs: 0.0008291075355373323\n",
      "Epoch: 3000 train loss=0.005212926 valid loss= 0.003029730\n",
      "train reg_fs: 0.0008061160915531218\n",
      "Epoch: 3500 train loss=0.003998644 valid loss= 0.003580708\n",
      "train reg_fs: 0.0007901783683337271\n",
      "Epoch: 4000 train loss=0.001181281 valid loss= 0.003345862\n",
      "train reg_fs: 0.0007771496311761439\n",
      "Epoch: 4500 train loss=0.001058275 valid loss= 0.003150357\n",
      "train reg_fs: 0.0007682740688323975\n",
      "Epoch: 5000 train loss=0.001875256 valid loss= 0.003105035\n",
      "train reg_fs: 0.0007613027701154351\n",
      "Epoch: 5500 train loss=0.002424193 valid loss= 0.002961956\n",
      "train reg_fs: 0.0007553797913715243\n",
      "Epoch: 6000 train loss=0.001668769 valid loss= 0.002797096\n",
      "train reg_fs: 0.0007506700931116939\n",
      "Epoch: 6500 train loss=0.001956504 valid loss= 0.003098415\n",
      "train reg_fs: 0.0007469292031601071\n",
      "Epoch: 7000 train loss=0.000989657 valid loss= 0.003010920\n",
      "train reg_fs: 0.0007435246370732784\n",
      "Epoch: 7500 train loss=0.001145977 valid loss= 0.002935450\n",
      "train reg_fs: 0.0007410948164761066\n",
      "Epoch: 8000 train loss=0.001501249 valid loss= 0.002900524\n",
      "train reg_fs: 0.0007389376987703145\n",
      "Epoch: 8500 train loss=0.003598479 valid loss= 0.003547570\n",
      "train reg_fs: 0.000736800953745842\n",
      "Epoch: 9000 train loss=0.002572712 valid loss= 0.002974516\n",
      "train reg_fs: 0.0007351584499701858\n",
      "Epoch: 9500 train loss=0.001332049 valid loss= 0.003384927\n",
      "train reg_fs: 0.0007336321868933737\n",
      "Epoch: 10000 train loss=0.001617985 valid loss= 0.002992696\n",
      "train reg_fs: 0.0007323315367102623\n",
      "Epoch: 10500 train loss=0.001104895 valid loss= 0.003280157\n",
      "train reg_fs: 0.0007311922963708639\n",
      "Epoch: 11000 train loss=0.001313751 valid loss= 0.003191963\n",
      "train reg_fs: 0.0007301851292140782\n",
      "Epoch: 11500 train loss=0.002161107 valid loss= 0.003299007\n",
      "train reg_fs: 0.0007293638773262501\n",
      "Epoch: 12000 train loss=0.003423597 valid loss= 0.002955677\n",
      "train reg_fs: 0.0007286139880307019\n",
      "Epoch: 12500 train loss=0.001989866 valid loss= 0.003006140\n",
      "train reg_fs: 0.0007278529228642583\n",
      "Epoch: 13000 train loss=0.002356533 valid loss= 0.003022231\n",
      "train reg_fs: 0.0007271826616488397\n",
      "Epoch: 13500 train loss=0.004380207 valid loss= 0.002904233\n",
      "train reg_fs: 0.0007266218890435994\n",
      "Epoch: 14000 train loss=0.000853444 valid loss= 0.002731194\n",
      "train reg_fs: 0.0007261348073370755\n",
      "Epoch: 14500 train loss=0.001815884 valid loss= 0.003196521\n",
      "train reg_fs: 0.0007256894023157656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:50:40,809]\u001b[0m Trial 13 finished with value: 0.0024565636821589727 and parameters: {'lam': 0.0012034807928430116, 'learning_rate': 0.1962447916230159, 'num_epoch': 15000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001429138 valid loss= 0.003163192\n",
      "train reg_fs: 0.0007253112271428108\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024565636821589727\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022938725 valid loss= 0.005984172\n",
      "train reg_fs: 0.0018126773647964\n",
      "Epoch: 1000 train loss=0.006551063 valid loss= 0.004864055\n",
      "train reg_fs: 0.0017486189026385546\n",
      "Epoch: 1500 train loss=0.012969160 valid loss= 0.004277452\n",
      "train reg_fs: 0.0016988570569083095\n",
      "Epoch: 2000 train loss=0.005532911 valid loss= 0.003981804\n",
      "train reg_fs: 0.0016791195375844836\n",
      "Epoch: 2500 train loss=0.008119998 valid loss= 0.004323503\n",
      "train reg_fs: 0.001668754150159657\n",
      "Epoch: 3000 train loss=0.006725132 valid loss= 0.003909631\n",
      "train reg_fs: 0.0016624298878014088\n",
      "Epoch: 3500 train loss=0.005722531 valid loss= 0.003951576\n",
      "train reg_fs: 0.0016542599769309163\n",
      "Epoch: 4000 train loss=0.004217277 valid loss= 0.003891269\n",
      "train reg_fs: 0.001645402517169714\n",
      "Epoch: 4500 train loss=0.004362095 valid loss= 0.004157573\n",
      "train reg_fs: 0.0016335156979039311\n",
      "Epoch: 5000 train loss=0.003466595 valid loss= 0.003865974\n",
      "train reg_fs: 0.001622784766368568\n",
      "Epoch: 5500 train loss=0.002657000 valid loss= 0.004020096\n",
      "train reg_fs: 0.0016119590727612376\n",
      "Epoch: 6000 train loss=0.003880769 valid loss= 0.003845707\n",
      "train reg_fs: 0.0016034874133765697\n",
      "Epoch: 6500 train loss=0.002239268 valid loss= 0.003637311\n",
      "train reg_fs: 0.0015959911979734898\n",
      "Epoch: 7000 train loss=0.004389942 valid loss= 0.003693197\n",
      "train reg_fs: 0.0015902894083410501\n",
      "Epoch: 7500 train loss=0.005485178 valid loss= 0.003845878\n",
      "train reg_fs: 0.0015840604901313782\n",
      "Epoch: 8000 train loss=0.005243318 valid loss= 0.004007871\n",
      "train reg_fs: 0.0015782687114551663\n",
      "Epoch: 8500 train loss=0.006202087 valid loss= 0.003670968\n",
      "train reg_fs: 0.0015730594750493765\n",
      "Epoch: 9000 train loss=0.002091233 valid loss= 0.003933982\n",
      "train reg_fs: 0.0015684126410633326\n",
      "Epoch: 9500 train loss=0.002242050 valid loss= 0.003769478\n",
      "train reg_fs: 0.0015640450874343514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:51:53,770]\u001b[0m Trial 14 finished with value: 0.0023626045991079025 and parameters: {'lam': 0.00214807586466441, 'learning_rate': 0.059108348681558044, 'num_epoch': 10000}. Best is trial 6 with value: 0.002011230264851386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003288331 valid loss= 0.003875440\n",
      "train reg_fs: 0.0015602662460878491\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023626045991079025\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.030798329 valid loss= 0.012546526\n",
      "train reg_fs: 0.006252278108149767\n",
      "Epoch: 1000 train loss=0.009844540 valid loss= 0.014311662\n",
      "train reg_fs: 0.006009945645928383\n",
      "Epoch: 1500 train loss=0.020192456 valid loss= 0.010440599\n",
      "train reg_fs: 0.005558544769883156\n",
      "Epoch: 2000 train loss=0.009436019 valid loss= 0.008016452\n",
      "train reg_fs: 0.005129518918693066\n",
      "Epoch: 2500 train loss=0.011259994 valid loss= 0.006949677\n",
      "train reg_fs: 0.004753319080919027\n",
      "Epoch: 3000 train loss=0.009974822 valid loss= 0.006966074\n",
      "train reg_fs: 0.004547591786831617\n",
      "Epoch: 3500 train loss=0.004715815 valid loss= 0.006550565\n",
      "train reg_fs: 0.004422415979206562\n",
      "Epoch: 4000 train loss=0.006493575 valid loss= 0.006166706\n",
      "train reg_fs: 0.004339482635259628\n",
      "Epoch: 4500 train loss=0.006326209 valid loss= 0.005494149\n",
      "train reg_fs: 0.004283321555703878\n",
      "Epoch: 5000 train loss=0.006691423 valid loss= 0.006055631\n",
      "train reg_fs: 0.004244192037731409\n",
      "Epoch: 5500 train loss=0.005611083 valid loss= 0.006368751\n",
      "train reg_fs: 0.004215467721223831\n",
      "Epoch: 6000 train loss=0.010015601 valid loss= 0.006094591\n",
      "train reg_fs: 0.0041939872317016125\n",
      "Epoch: 6500 train loss=0.004578322 valid loss= 0.005717726\n",
      "train reg_fs: 0.004175921902060509\n",
      "Epoch: 7000 train loss=0.005348036 valid loss= 0.005869832\n",
      "train reg_fs: 0.004162670578807592\n",
      "Epoch: 7500 train loss=0.008447649 valid loss= 0.006526380\n",
      "train reg_fs: 0.004151527304202318\n",
      "Epoch: 8000 train loss=0.008150905 valid loss= 0.006041608\n",
      "train reg_fs: 0.004142357502132654\n",
      "Epoch: 8500 train loss=0.005642026 valid loss= 0.006329104\n",
      "train reg_fs: 0.004134131595492363\n",
      "Epoch: 9000 train loss=0.016166968 valid loss= 0.007090519\n",
      "train reg_fs: 0.004127827938646078\n",
      "Epoch: 9500 train loss=0.005324052 valid loss= 0.005804661\n",
      "train reg_fs: 0.004122158512473106\n",
      "Epoch: 10000 train loss=0.007803932 valid loss= 0.005824504\n",
      "train reg_fs: 0.004117156378924847\n",
      "Epoch: 10500 train loss=0.005230273 valid loss= 0.005625606\n",
      "train reg_fs: 0.004112656228244305\n",
      "Epoch: 11000 train loss=0.006040969 valid loss= 0.005279305\n",
      "train reg_fs: 0.004108663648366928\n",
      "Epoch: 11500 train loss=0.005343794 valid loss= 0.005872113\n",
      "train reg_fs: 0.0041053155437111855\n",
      "Epoch: 12000 train loss=0.005192142 valid loss= 0.006187199\n",
      "train reg_fs: 0.0041021062061190605\n",
      "Epoch: 12500 train loss=0.004929502 valid loss= 0.005739802\n",
      "train reg_fs: 0.004099229350686073\n",
      "Epoch: 13000 train loss=0.009110264 valid loss= 0.005871509\n",
      "train reg_fs: 0.004096603486686945\n",
      "Epoch: 13500 train loss=0.006908129 valid loss= 0.005696254\n",
      "train reg_fs: 0.00409435760229826\n",
      "Epoch: 14000 train loss=0.005952865 valid loss= 0.005566848\n",
      "train reg_fs: 0.004092394839972258\n",
      "Epoch: 14500 train loss=0.006304830 valid loss= 0.005925368\n",
      "train reg_fs: 0.004090602044016123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:53:43,673]\u001b[0m Trial 15 finished with value: 0.00117361469693742 and parameters: {'lam': 0.007211824987972077, 'learning_rate': 0.12017619839670315, 'num_epoch': 15000}. Best is trial 15 with value: 0.00117361469693742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005601975 valid loss= 0.005414211\n",
      "train reg_fs: 0.0040888311341404915\n",
      "In trial:---------------------\n",
      "validation mse: 0.00117361469693742\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013195059 valid loss= 0.013145091\n",
      "train reg_fs: 0.007175754755735397\n",
      "Epoch: 1000 train loss=0.015589822 valid loss= 0.013706022\n",
      "train reg_fs: 0.0069374036975204945\n",
      "Epoch: 1500 train loss=0.010934648 valid loss= 0.010195372\n",
      "train reg_fs: 0.006499571725726128\n",
      "Epoch: 2000 train loss=0.010626648 valid loss= 0.009192324\n",
      "train reg_fs: 0.006011460907757282\n",
      "Epoch: 2500 train loss=0.011656949 valid loss= 0.008794235\n",
      "train reg_fs: 0.005598806776106358\n",
      "Epoch: 3000 train loss=0.005989522 valid loss= 0.007770716\n",
      "train reg_fs: 0.005321206524968147\n",
      "Epoch: 3500 train loss=0.006532269 valid loss= 0.007671986\n",
      "train reg_fs: 0.005121258087456226\n",
      "Epoch: 4000 train loss=0.018643767 valid loss= 0.007657446\n",
      "train reg_fs: 0.004963873419910669\n",
      "Epoch: 4500 train loss=0.005766373 valid loss= 0.007058305\n",
      "train reg_fs: 0.00482972664758563\n",
      "Epoch: 5000 train loss=0.006005393 valid loss= 0.007427666\n",
      "train reg_fs: 0.004722169134765863\n",
      "Epoch: 5500 train loss=0.007219084 valid loss= 0.006946113\n",
      "train reg_fs: 0.004641155246645212\n",
      "Epoch: 6000 train loss=0.005030153 valid loss= 0.007262485\n",
      "train reg_fs: 0.004579329863190651\n",
      "Epoch: 6500 train loss=0.006331308 valid loss= 0.006942621\n",
      "train reg_fs: 0.004526179749518633\n",
      "Epoch: 7000 train loss=0.006234992 valid loss= 0.007074446\n",
      "train reg_fs: 0.004482615273445845\n",
      "Epoch: 7500 train loss=0.005137765 valid loss= 0.006810496\n",
      "train reg_fs: 0.00444499496370554\n",
      "Epoch: 8000 train loss=0.005346992 valid loss= 0.006656404\n",
      "train reg_fs: 0.004413319285959005\n",
      "Epoch: 8500 train loss=0.005722414 valid loss= 0.006651225\n",
      "train reg_fs: 0.0043864198960363865\n",
      "Epoch: 9000 train loss=0.008165925 valid loss= 0.006774561\n",
      "train reg_fs: 0.004363017622381449\n",
      "Epoch: 9500 train loss=0.009603204 valid loss= 0.006733235\n",
      "train reg_fs: 0.004342882893979549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:54:57,699]\u001b[0m Trial 16 finished with value: 0.002316495724047592 and parameters: {'lam': 0.008230029085235117, 'learning_rate': 0.13994253361175976, 'num_epoch': 10000}. Best is trial 15 with value: 0.00117361469693742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005484725 valid loss= 0.006668308\n",
      "train reg_fs: 0.004324919078499079\n",
      "In trial:---------------------\n",
      "validation mse: 0.002316495724047592\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.025736965 valid loss= 0.014139647\n",
      "train reg_fs: 0.00707297632470727\n",
      "Epoch: 1000 train loss=0.023136877 valid loss= 0.013740177\n",
      "train reg_fs: 0.007085761986672878\n",
      "Epoch: 1500 train loss=0.016910605 valid loss= 0.013483225\n",
      "train reg_fs: 0.007032041437923908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:55:13,967]\u001b[0m Trial 17 finished with value: 0.005787058130026567 and parameters: {'lam': 0.008356380018347433, 'learning_rate': 0.027316076223074585, 'num_epoch': 2000}. Best is trial 15 with value: 0.00117361469693742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.011149075 valid loss= 0.012725871\n",
      "train reg_fs: 0.006898253224790096\n",
      "In trial:---------------------\n",
      "validation mse: 0.005787058130026567\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020432720 valid loss= 0.011011526\n",
      "train reg_fs: 0.005421603098511696\n",
      "Epoch: 1000 train loss=0.022811584 valid loss= 0.010229653\n",
      "train reg_fs: 0.005381672643125057\n",
      "Epoch: 1500 train loss=0.009076593 valid loss= 0.008807620\n",
      "train reg_fs: 0.00519305607303977\n",
      "Epoch: 2000 train loss=0.012421186 valid loss= 0.008316856\n",
      "train reg_fs: 0.004983421880751848\n",
      "Epoch: 2500 train loss=0.008644935 valid loss= 0.007535165\n",
      "train reg_fs: 0.004855901934206486\n",
      "Epoch: 3000 train loss=0.010125465 valid loss= 0.007256045\n",
      "train reg_fs: 0.004778353497385979\n",
      "Epoch: 3500 train loss=0.006437485 valid loss= 0.007782929\n",
      "train reg_fs: 0.004725587088614702\n",
      "Epoch: 4000 train loss=0.012618743 valid loss= 0.006927278\n",
      "train reg_fs: 0.0046774898655712605\n",
      "Epoch: 4500 train loss=0.007678800 valid loss= 0.007211362\n",
      "train reg_fs: 0.0046184975653886795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:55:51,729]\u001b[0m Trial 18 finished with value: 0.0028015693047270442 and parameters: {'lam': 0.006364371631489912, 'learning_rate': 0.05335821387313943, 'num_epoch': 5000}. Best is trial 15 with value: 0.00117361469693742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.006244947 valid loss= 0.007479395\n",
      "train reg_fs: 0.004560070112347603\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028015693047270442\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009133263 valid loss= 0.011977739\n",
      "train reg_fs: 0.004971963353455067\n",
      "Epoch: 1000 train loss=0.015394883 valid loss= 0.010279248\n",
      "train reg_fs: 0.00451242970302701\n",
      "Epoch: 1500 train loss=0.010985665 valid loss= 0.007059746\n",
      "train reg_fs: 0.004068434238433838\n",
      "Epoch: 2000 train loss=0.024785107 valid loss= 0.006557086\n",
      "train reg_fs: 0.0038062280509620905\n",
      "Epoch: 2500 train loss=0.006702926 valid loss= 0.006457454\n",
      "train reg_fs: 0.003686582902446389\n",
      "Epoch: 3000 train loss=0.008882747 valid loss= 0.006117559\n",
      "train reg_fs: 0.003618451301008463\n",
      "Epoch: 3500 train loss=0.005284186 valid loss= 0.006025719\n",
      "train reg_fs: 0.003576509188860655\n",
      "Epoch: 4000 train loss=0.004622613 valid loss= 0.005661780\n",
      "train reg_fs: 0.0035461396910250187\n",
      "Epoch: 4500 train loss=0.004245242 valid loss= 0.005837064\n",
      "train reg_fs: 0.0035246831830590963\n",
      "Epoch: 5000 train loss=0.007351339 valid loss= 0.006122398\n",
      "train reg_fs: 0.003509239526465535\n",
      "Epoch: 5500 train loss=0.005715906 valid loss= 0.005613513\n",
      "train reg_fs: 0.003497315337881446\n",
      "Epoch: 6000 train loss=0.004195301 valid loss= 0.005405709\n",
      "train reg_fs: 0.00348747824318707\n",
      "Epoch: 6500 train loss=0.004522075 valid loss= 0.005744488\n",
      "train reg_fs: 0.0034793999511748552\n",
      "Epoch: 7000 train loss=0.004516513 valid loss= 0.005941616\n",
      "train reg_fs: 0.0034729584585875273\n",
      "Epoch: 7500 train loss=0.004231950 valid loss= 0.005928610\n",
      "train reg_fs: 0.0034671842586249113\n",
      "Epoch: 8000 train loss=0.004581067 valid loss= 0.005794793\n",
      "train reg_fs: 0.003462289460003376\n",
      "Epoch: 8500 train loss=0.004943060 valid loss= 0.005877615\n",
      "train reg_fs: 0.0034582121297717094\n",
      "Epoch: 9000 train loss=0.004071862 valid loss= 0.005383676\n",
      "train reg_fs: 0.0034548442345112562\n",
      "Epoch: 9500 train loss=0.004098472 valid loss= 0.005631907\n",
      "train reg_fs: 0.0034519447945058346\n",
      "Epoch: 10000 train loss=0.004662418 valid loss= 0.005551552\n",
      "train reg_fs: 0.0034494653809815645\n",
      "Epoch: 10500 train loss=0.003988126 valid loss= 0.005813464\n",
      "train reg_fs: 0.0034472018014639616\n",
      "Epoch: 11000 train loss=0.004489249 valid loss= 0.005901059\n",
      "train reg_fs: 0.003445260226726532\n",
      "Epoch: 11500 train loss=0.003735128 valid loss= 0.005639009\n",
      "train reg_fs: 0.0034434818662703037\n",
      "Epoch: 12000 train loss=0.005156205 valid loss= 0.005690797\n",
      "train reg_fs: 0.0034419987350702286\n",
      "Epoch: 12500 train loss=0.003644913 valid loss= 0.005822529\n",
      "train reg_fs: 0.0034406206104904413\n",
      "Epoch: 13000 train loss=0.013481477 valid loss= 0.006086829\n",
      "train reg_fs: 0.003439367515966296\n",
      "Epoch: 13500 train loss=0.004491116 valid loss= 0.005661837\n",
      "train reg_fs: 0.0034382734447717667\n",
      "Epoch: 14000 train loss=0.004906912 valid loss= 0.005874963\n",
      "train reg_fs: 0.003437208943068981\n",
      "Epoch: 14500 train loss=0.004975910 valid loss= 0.005357834\n",
      "train reg_fs: 0.003436200087890029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:57:42,324]\u001b[0m Trial 19 finished with value: 0.0023303999142469103 and parameters: {'lam': 0.005735844644500562, 'learning_rate': 0.18086733342957975, 'num_epoch': 15000}. Best is trial 15 with value: 0.00117361469693742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006906606 valid loss= 0.005665876\n",
      "train reg_fs: 0.003435294609516859\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023303999142469103\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010962475 valid loss= 0.009894152\n",
      "train reg_fs: 0.003137231105938554\n",
      "Epoch: 1000 train loss=0.008884751 valid loss= 0.009051154\n",
      "train reg_fs: 0.0030152855906635523\n",
      "Epoch: 1500 train loss=0.007083147 valid loss= 0.007434400\n",
      "train reg_fs: 0.002907141111791134\n",
      "Epoch: 2000 train loss=0.009653619 valid loss= 0.006897819\n",
      "train reg_fs: 0.0028496866580098867\n",
      "Epoch: 2500 train loss=0.005539913 valid loss= 0.006145274\n",
      "train reg_fs: 0.0027945740148425102\n",
      "Epoch: 3000 train loss=0.004382458 valid loss= 0.005473453\n",
      "train reg_fs: 0.0027269385755062103\n",
      "Epoch: 3500 train loss=0.004233493 valid loss= 0.004968553\n",
      "train reg_fs: 0.0026371662970632315\n",
      "Epoch: 4000 train loss=0.004538476 valid loss= 0.005248394\n",
      "train reg_fs: 0.002579071093350649\n",
      "Epoch: 4500 train loss=0.005057773 valid loss= 0.004884363\n",
      "train reg_fs: 0.0025379962753504515\n",
      "Epoch: 5000 train loss=0.004213613 valid loss= 0.005302613\n",
      "train reg_fs: 0.0025068942923098803\n",
      "Epoch: 5500 train loss=0.003473588 valid loss= 0.005306303\n",
      "train reg_fs: 0.002471756422892213\n",
      "Epoch: 6000 train loss=0.003394422 valid loss= 0.005038838\n",
      "train reg_fs: 0.002447484526783228\n",
      "Epoch: 6500 train loss=0.003202911 valid loss= 0.005138418\n",
      "train reg_fs: 0.0024246599059551954\n",
      "Epoch: 7000 train loss=0.004782399 valid loss= 0.005308472\n",
      "train reg_fs: 0.00240564183332026\n",
      "Epoch: 7500 train loss=0.005131850 valid loss= 0.004959937\n",
      "train reg_fs: 0.0023782015778124332\n",
      "Epoch: 8000 train loss=0.003090260 valid loss= 0.004718156\n",
      "train reg_fs: 0.0023509033489972353\n",
      "Epoch: 8500 train loss=0.003190869 valid loss= 0.004540415\n",
      "train reg_fs: 0.0023338093888014555\n",
      "Epoch: 9000 train loss=0.004444620 valid loss= 0.004640586\n",
      "train reg_fs: 0.0023087647277861834\n",
      "Epoch: 9500 train loss=0.003312505 valid loss= 0.004711555\n",
      "train reg_fs: 0.002286012750118971\n",
      "Epoch: 10000 train loss=0.005337628 valid loss= 0.004707083\n",
      "train reg_fs: 0.0022712410427629948\n",
      "Epoch: 10500 train loss=0.004597532 valid loss= 0.005110383\n",
      "train reg_fs: 0.002253391547128558\n",
      "Epoch: 11000 train loss=0.002864389 valid loss= 0.004484923\n",
      "train reg_fs: 0.002240335801616311\n",
      "Epoch: 11500 train loss=0.002628277 valid loss= 0.004386364\n",
      "train reg_fs: 0.002227995079010725\n",
      "Epoch: 12000 train loss=0.002940627 valid loss= 0.004353085\n",
      "train reg_fs: 0.002218197099864483\n",
      "Epoch: 12500 train loss=0.003679079 valid loss= 0.004409857\n",
      "train reg_fs: 0.0022093874868005514\n",
      "Epoch: 13000 train loss=0.002476491 valid loss= 0.004454464\n",
      "train reg_fs: 0.002203666605055332\n",
      "Epoch: 13500 train loss=0.014869500 valid loss= 0.004472431\n",
      "train reg_fs: 0.0021978248842060566\n",
      "Epoch: 14000 train loss=0.003188472 valid loss= 0.004591484\n",
      "train reg_fs: 0.0021934316027909517\n",
      "Epoch: 14500 train loss=0.003887665 valid loss= 0.004544913\n",
      "train reg_fs: 0.002189504448324442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:59:31,255]\u001b[0m Trial 20 finished with value: 0.002203090851671149 and parameters: {'lam': 0.0035938451850308635, 'learning_rate': 0.1289900471494015, 'num_epoch': 15000}. Best is trial 15 with value: 0.00117361469693742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002939441 valid loss= 0.004343632\n",
      "train reg_fs: 0.0021860201377421618\n",
      "In trial:---------------------\n",
      "validation mse: 0.002203090851671149\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010622990 valid loss= 0.007160089\n",
      "train reg_fs: 0.0018225022358819842\n",
      "Epoch: 1000 train loss=0.010890872 valid loss= 0.007835528\n",
      "train reg_fs: 0.0018285542028024793\n",
      "Epoch: 1500 train loss=0.008538564 valid loss= 0.006377301\n",
      "train reg_fs: 0.0017790418351069093\n",
      "Epoch: 2000 train loss=0.006464738 valid loss= 0.003816110\n",
      "train reg_fs: 0.0017005307599902153\n",
      "Epoch: 2500 train loss=0.008496978 valid loss= 0.004274009\n",
      "train reg_fs: 0.0016323794843629003\n",
      "Epoch: 3000 train loss=0.003461474 valid loss= 0.004016079\n",
      "train reg_fs: 0.0015919188736006618\n",
      "Epoch: 3500 train loss=0.006157130 valid loss= 0.003934896\n",
      "train reg_fs: 0.0015647421823814511\n",
      "Epoch: 4000 train loss=0.006579329 valid loss= 0.003666325\n",
      "train reg_fs: 0.0015443223528563976\n",
      "Epoch: 4500 train loss=0.001930176 valid loss= 0.003619825\n",
      "train reg_fs: 0.0015297663630917668\n",
      "Epoch: 5000 train loss=0.002265977 valid loss= 0.003421998\n",
      "train reg_fs: 0.0015170328551903367\n",
      "Epoch: 5500 train loss=0.003102251 valid loss= 0.003228916\n",
      "train reg_fs: 0.0015077019343152642\n",
      "Epoch: 6000 train loss=0.003283347 valid loss= 0.003228396\n",
      "train reg_fs: 0.0014977861428633332\n",
      "Epoch: 6500 train loss=0.002684673 valid loss= 0.002748381\n",
      "train reg_fs: 0.0014879845548421144\n",
      "Epoch: 7000 train loss=0.002382440 valid loss= 0.003113653\n",
      "train reg_fs: 0.0014786850661039352\n",
      "Epoch: 7500 train loss=0.002731960 valid loss= 0.002433497\n",
      "train reg_fs: 0.0014699844177812338\n",
      "Epoch: 8000 train loss=0.002623426 valid loss= 0.002806066\n",
      "train reg_fs: 0.0014628823846578598\n",
      "Epoch: 8500 train loss=0.003059795 valid loss= 0.002666887\n",
      "train reg_fs: 0.0014552928041666746\n",
      "Epoch: 9000 train loss=0.001986708 valid loss= 0.002718502\n",
      "train reg_fs: 0.0014486894942820072\n",
      "Epoch: 9500 train loss=0.002989759 valid loss= 0.002470273\n",
      "train reg_fs: 0.0014425953850150108\n",
      "Epoch: 10000 train loss=0.001711383 valid loss= 0.002429802\n",
      "train reg_fs: 0.0014362481888383627\n",
      "Epoch: 10500 train loss=0.003485600 valid loss= 0.002874027\n",
      "train reg_fs: 0.001431215088814497\n",
      "Epoch: 11000 train loss=0.001732941 valid loss= 0.002428534\n",
      "train reg_fs: 0.0014260475290939212\n",
      "Epoch: 11500 train loss=0.001738115 valid loss= 0.001934060\n",
      "train reg_fs: 0.0014216339914128184\n",
      "Epoch: 12000 train loss=0.001815413 valid loss= 0.002416785\n",
      "train reg_fs: 0.0014177588745951653\n",
      "Epoch: 12500 train loss=0.002086401 valid loss= 0.001904435\n",
      "train reg_fs: 0.0014148125192150474\n",
      "Epoch: 13000 train loss=0.004444773 valid loss= 0.002211756\n",
      "train reg_fs: 0.0014122565044090152\n",
      "Epoch: 13500 train loss=0.005124820 valid loss= 0.002407570\n",
      "train reg_fs: 0.0014095802325755358\n",
      "Epoch: 14000 train loss=0.002135765 valid loss= 0.001918649\n",
      "train reg_fs: 0.0014074422651901841\n",
      "Epoch: 14500 train loss=0.002153679 valid loss= 0.001873007\n",
      "train reg_fs: 0.001405496965162456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:01:20,890]\u001b[0m Trial 21 finished with value: 0.0008402301502041076 and parameters: {'lam': 0.0020797493620445533, 'learning_rate': 0.08619736199915204, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004607626 valid loss= 0.002248347\n",
      "train reg_fs: 0.0014039591187611222\n",
      "In trial:---------------------\n",
      "validation mse: 0.0008402301502041076\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014331811 valid loss= 0.008551879\n",
      "train reg_fs: 0.0017085953149944544\n",
      "Epoch: 1000 train loss=0.009569261 valid loss= 0.007141778\n",
      "train reg_fs: 0.0017136411042883992\n",
      "Epoch: 1500 train loss=0.015409484 valid loss= 0.007804777\n",
      "train reg_fs: 0.0016862874617800117\n",
      "Epoch: 2000 train loss=0.004651366 valid loss= 0.006450999\n",
      "train reg_fs: 0.0016334877582266927\n",
      "Epoch: 2500 train loss=0.009306156 valid loss= 0.006056715\n",
      "train reg_fs: 0.0015871410723775625\n",
      "Epoch: 3000 train loss=0.009317676 valid loss= 0.004620112\n",
      "train reg_fs: 0.0015487143537029624\n",
      "Epoch: 3500 train loss=0.006074958 valid loss= 0.003652663\n",
      "train reg_fs: 0.0015098011353984475\n",
      "Epoch: 4000 train loss=0.003058779 valid loss= 0.003771791\n",
      "train reg_fs: 0.00148767011705786\n",
      "Epoch: 4500 train loss=0.004313828 valid loss= 0.003573193\n",
      "train reg_fs: 0.001475039403885603\n",
      "Epoch: 5000 train loss=0.004558820 valid loss= 0.003553198\n",
      "train reg_fs: 0.001458903425373137\n",
      "Epoch: 5500 train loss=0.007928601 valid loss= 0.003530682\n",
      "train reg_fs: 0.0014443995896726847\n",
      "Epoch: 6000 train loss=0.003245170 valid loss= 0.003413608\n",
      "train reg_fs: 0.0014300012262538075\n",
      "Epoch: 6500 train loss=0.003313129 valid loss= 0.003838668\n",
      "train reg_fs: 0.0014103485736995935\n",
      "Epoch: 7000 train loss=0.003382535 valid loss= 0.003412411\n",
      "train reg_fs: 0.0013925828970968723\n",
      "Epoch: 7500 train loss=0.002862692 valid loss= 0.003544085\n",
      "train reg_fs: 0.0013779905857518315\n",
      "Epoch: 8000 train loss=0.002421533 valid loss= 0.003347655\n",
      "train reg_fs: 0.0013647036394104362\n",
      "Epoch: 8500 train loss=0.002750520 valid loss= 0.003347627\n",
      "train reg_fs: 0.0013509654672816396\n",
      "Epoch: 9000 train loss=0.003223454 valid loss= 0.002876608\n",
      "train reg_fs: 0.0013378300936892629\n",
      "Epoch: 9500 train loss=0.006411860 valid loss= 0.003392719\n",
      "train reg_fs: 0.0013279140694066882\n",
      "Epoch: 10000 train loss=0.002468148 valid loss= 0.002915502\n",
      "train reg_fs: 0.0013182306429371238\n",
      "Epoch: 10500 train loss=0.005648279 valid loss= 0.003245992\n",
      "train reg_fs: 0.0013109322171658278\n",
      "Epoch: 11000 train loss=0.002681281 valid loss= 0.003094113\n",
      "train reg_fs: 0.0013036472955718637\n",
      "Epoch: 11500 train loss=0.005233740 valid loss= 0.002734907\n",
      "train reg_fs: 0.0012982614571228623\n",
      "Epoch: 12000 train loss=0.003324971 valid loss= 0.002887758\n",
      "train reg_fs: 0.0012943572364747524\n",
      "Epoch: 12500 train loss=0.001959082 valid loss= 0.003274327\n",
      "train reg_fs: 0.001288940547965467\n",
      "Epoch: 13000 train loss=0.001782584 valid loss= 0.002949284\n",
      "train reg_fs: 0.0012831063941121101\n",
      "Epoch: 13500 train loss=0.001401759 valid loss= 0.003003378\n",
      "train reg_fs: 0.0012784549035131931\n",
      "Epoch: 14000 train loss=0.002365371 valid loss= 0.002671813\n",
      "train reg_fs: 0.001276935450732708\n",
      "Epoch: 14500 train loss=0.003920415 valid loss= 0.002295608\n",
      "train reg_fs: 0.0012750707101076841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:03:11,898]\u001b[0m Trial 22 finished with value: 0.0012522715259768173 and parameters: {'lam': 0.0019764506660471543, 'learning_rate': 0.06744694199233696, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002063409 valid loss= 0.002560464\n",
      "train reg_fs: 0.001272460911422968\n",
      "In trial:---------------------\n",
      "validation mse: 0.0012522715259768173\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011315052 valid loss= 0.007434722\n",
      "train reg_fs: 0.001707797171548009\n",
      "Epoch: 1000 train loss=0.011127386 valid loss= 0.007229101\n",
      "train reg_fs: 0.0016593248583376408\n",
      "Epoch: 1500 train loss=0.009774052 valid loss= 0.005227873\n",
      "train reg_fs: 0.0015751020982861519\n",
      "Epoch: 2000 train loss=0.005755343 valid loss= 0.004456850\n",
      "train reg_fs: 0.0015063462778925896\n",
      "Epoch: 2500 train loss=0.005395611 valid loss= 0.004724354\n",
      "train reg_fs: 0.0014631267404183745\n",
      "Epoch: 3000 train loss=0.003140672 valid loss= 0.004619108\n",
      "train reg_fs: 0.0014265135396271944\n",
      "Epoch: 3500 train loss=0.004889920 valid loss= 0.004491573\n",
      "train reg_fs: 0.0013950002612546086\n",
      "Epoch: 4000 train loss=0.002552676 valid loss= 0.004446505\n",
      "train reg_fs: 0.001365718781016767\n",
      "Epoch: 4500 train loss=0.002238567 valid loss= 0.004155597\n",
      "train reg_fs: 0.0013437778688967228\n",
      "Epoch: 5000 train loss=0.001899612 valid loss= 0.004093294\n",
      "train reg_fs: 0.0013249441981315613\n",
      "Epoch: 5500 train loss=0.002700409 valid loss= 0.003960044\n",
      "train reg_fs: 0.001310024643316865\n",
      "Epoch: 6000 train loss=0.003782012 valid loss= 0.003805904\n",
      "train reg_fs: 0.0012978221056982875\n",
      "Epoch: 6500 train loss=0.011195101 valid loss= 0.003924001\n",
      "train reg_fs: 0.0012872210936620831\n",
      "Epoch: 7000 train loss=0.001880808 valid loss= 0.003996984\n",
      "train reg_fs: 0.0012777496594935656\n",
      "Epoch: 7500 train loss=0.002989207 valid loss= 0.004232692\n",
      "train reg_fs: 0.001270053326152265\n",
      "Epoch: 8000 train loss=0.005721448 valid loss= 0.004044801\n",
      "train reg_fs: 0.001263572252355516\n",
      "Epoch: 8500 train loss=0.001915004 valid loss= 0.003697282\n",
      "train reg_fs: 0.0012580282054841518\n",
      "Epoch: 9000 train loss=0.001858570 valid loss= 0.003803687\n",
      "train reg_fs: 0.0012524246703833342\n",
      "Epoch: 9500 train loss=0.004704207 valid loss= 0.003303027\n",
      "train reg_fs: 0.001247607171535492\n",
      "Epoch: 10000 train loss=0.002027553 valid loss= 0.003792191\n",
      "train reg_fs: 0.0012435669777914882\n",
      "Epoch: 10500 train loss=0.007761602 valid loss= 0.003781474\n",
      "train reg_fs: 0.0012396780075505376\n",
      "Epoch: 11000 train loss=0.010936895 valid loss= 0.003545502\n",
      "train reg_fs: 0.0012364201247692108\n",
      "Epoch: 11500 train loss=0.003438026 valid loss= 0.003988987\n",
      "train reg_fs: 0.0012332183541730046\n",
      "Epoch: 12000 train loss=0.001962725 valid loss= 0.003658179\n",
      "train reg_fs: 0.0012304349802434444\n",
      "Epoch: 12500 train loss=0.005167263 valid loss= 0.003734580\n",
      "train reg_fs: 0.0012278264621272683\n",
      "Epoch: 13000 train loss=0.002692390 valid loss= 0.003497960\n",
      "train reg_fs: 0.0012253466993570328\n",
      "Epoch: 13500 train loss=0.002079621 valid loss= 0.003464832\n",
      "train reg_fs: 0.0012233038432896137\n",
      "Epoch: 14000 train loss=0.003396333 valid loss= 0.003738966\n",
      "train reg_fs: 0.001221297075971961\n",
      "Epoch: 14500 train loss=0.004363527 valid loss= 0.003576683\n",
      "train reg_fs: 0.0012194182490929961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:05:00,838]\u001b[0m Trial 23 finished with value: 0.002741834148896545 and parameters: {'lam': 0.00198418025013068, 'learning_rate': 0.07254337877345714, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006442671 valid loss= 0.003938873\n",
      "train reg_fs: 0.001217770273797214\n",
      "In trial:---------------------\n",
      "validation mse: 0.002741834148896545\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017862145 valid loss= 0.008099085\n",
      "train reg_fs: 0.0017145798774436116\n",
      "Epoch: 1000 train loss=0.016497210 valid loss= 0.008493779\n",
      "train reg_fs: 0.0017425606492906809\n",
      "Epoch: 1500 train loss=0.007847492 valid loss= 0.007172043\n",
      "train reg_fs: 0.0017576601821929216\n",
      "Epoch: 2000 train loss=0.006924520 valid loss= 0.007065527\n",
      "train reg_fs: 0.001761151826940477\n",
      "Epoch: 2500 train loss=0.006448841 valid loss= 0.007029818\n",
      "train reg_fs: 0.0017611535731703043\n",
      "Epoch: 3000 train loss=0.012124119 valid loss= 0.007161323\n",
      "train reg_fs: 0.0017577321268618107\n",
      "Epoch: 3500 train loss=0.006908001 valid loss= 0.007365422\n",
      "train reg_fs: 0.001749435206875205\n",
      "Epoch: 4000 train loss=0.008221162 valid loss= 0.006242525\n",
      "train reg_fs: 0.00174250069539994\n",
      "Epoch: 4500 train loss=0.007511621 valid loss= 0.006559731\n",
      "train reg_fs: 0.001734850462526083\n",
      "Epoch: 5000 train loss=0.007224003 valid loss= 0.006281991\n",
      "train reg_fs: 0.0017260180320590734\n",
      "Epoch: 5500 train loss=0.002874791 valid loss= 0.006873325\n",
      "train reg_fs: 0.0017150905914604664\n",
      "Epoch: 6000 train loss=0.008234636 valid loss= 0.006612883\n",
      "train reg_fs: 0.0017078722594305873\n",
      "Epoch: 6500 train loss=0.002754947 valid loss= 0.006189464\n",
      "train reg_fs: 0.001699803164228797\n",
      "Epoch: 7000 train loss=0.007959450 valid loss= 0.006567560\n",
      "train reg_fs: 0.0016907036770135164\n",
      "Epoch: 7500 train loss=0.003508470 valid loss= 0.006305709\n",
      "train reg_fs: 0.00168175611179322\n",
      "Epoch: 8000 train loss=0.003687391 valid loss= 0.006297796\n",
      "train reg_fs: 0.001674711238592863\n",
      "Epoch: 8500 train loss=0.003783406 valid loss= 0.006479784\n",
      "train reg_fs: 0.0016649217577651143\n",
      "Epoch: 9000 train loss=0.004503638 valid loss= 0.006833280\n",
      "train reg_fs: 0.0016563339158892632\n",
      "Epoch: 9500 train loss=0.003148963 valid loss= 0.006649348\n",
      "train reg_fs: 0.001649602665565908\n",
      "Epoch: 10000 train loss=0.003794736 valid loss= 0.006626796\n",
      "train reg_fs: 0.0016423426568508148\n",
      "Epoch: 10500 train loss=0.004266273 valid loss= 0.006541363\n",
      "train reg_fs: 0.0016360132722184062\n",
      "Epoch: 11000 train loss=0.005337644 valid loss= 0.006369301\n",
      "train reg_fs: 0.0016304097371175885\n",
      "Epoch: 11500 train loss=0.003816455 valid loss= 0.006534877\n",
      "train reg_fs: 0.0016256198287010193\n",
      "Epoch: 12000 train loss=0.004676946 valid loss= 0.006291878\n",
      "train reg_fs: 0.001621044473722577\n",
      "Epoch: 12500 train loss=0.003480333 valid loss= 0.006833120\n",
      "train reg_fs: 0.0016132608288899064\n",
      "Epoch: 13000 train loss=0.004580131 valid loss= 0.006470971\n",
      "train reg_fs: 0.0016086972318589687\n",
      "Epoch: 13500 train loss=0.005558499 valid loss= 0.006818302\n",
      "train reg_fs: 0.0016039548208937049\n",
      "Epoch: 14000 train loss=0.003898784 valid loss= 0.006643828\n",
      "train reg_fs: 0.0016014989232644439\n",
      "Epoch: 14500 train loss=0.002491160 valid loss= 0.006628101\n",
      "train reg_fs: 0.001595612266100943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:06:51,437]\u001b[0m Trial 24 finished with value: 0.005010090845596196 and parameters: {'lam': 0.001985600700671473, 'learning_rate': 0.043172653007309, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004144778 valid loss= 0.006613117\n",
      "train reg_fs: 0.0015909948851913214\n",
      "In trial:---------------------\n",
      "validation mse: 0.005010090845596196\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014166385 valid loss= 0.007752608\n",
      "train reg_fs: 0.001957495929673314\n",
      "Epoch: 1000 train loss=0.017264947 valid loss= 0.007389381\n",
      "train reg_fs: 0.0019436903530731797\n",
      "Epoch: 1500 train loss=0.007569151 valid loss= 0.005810565\n",
      "train reg_fs: 0.0018776602810248733\n",
      "Epoch: 2000 train loss=0.003419503 valid loss= 0.004145009\n",
      "train reg_fs: 0.0017971599008888006\n",
      "Epoch: 2500 train loss=0.004165312 valid loss= 0.004848680\n",
      "train reg_fs: 0.0017506100703030825\n",
      "Epoch: 3000 train loss=0.002837014 valid loss= 0.004611599\n",
      "train reg_fs: 0.001720466767437756\n",
      "Epoch: 3500 train loss=0.004813328 valid loss= 0.004374566\n",
      "train reg_fs: 0.0017013255273923278\n",
      "Epoch: 4000 train loss=0.005568756 valid loss= 0.004220908\n",
      "train reg_fs: 0.0016870683757588267\n",
      "Epoch: 4500 train loss=0.004915464 valid loss= 0.003826968\n",
      "train reg_fs: 0.001676994957961142\n",
      "Epoch: 5000 train loss=0.009858392 valid loss= 0.003995762\n",
      "train reg_fs: 0.0016690636985003948\n",
      "Epoch: 5500 train loss=0.002814851 valid loss= 0.003616546\n",
      "train reg_fs: 0.0016618123045191169\n",
      "Epoch: 6000 train loss=0.002697208 valid loss= 0.003736378\n",
      "train reg_fs: 0.0016564374091103673\n",
      "Epoch: 6500 train loss=0.004517125 valid loss= 0.003729448\n",
      "train reg_fs: 0.0016517475014552474\n",
      "Epoch: 7000 train loss=0.009319953 valid loss= 0.003704238\n",
      "train reg_fs: 0.0016467595705762506\n",
      "Epoch: 7500 train loss=0.009118116 valid loss= 0.003502672\n",
      "train reg_fs: 0.001642284682020545\n",
      "Epoch: 8000 train loss=0.002962278 valid loss= 0.004041560\n",
      "train reg_fs: 0.0016382818575948477\n",
      "Epoch: 8500 train loss=0.004582282 valid loss= 0.003514874\n",
      "train reg_fs: 0.0016350357327610254\n",
      "Epoch: 9000 train loss=0.002230093 valid loss= 0.003599305\n",
      "train reg_fs: 0.001632037339732051\n",
      "Epoch: 9500 train loss=0.005288093 valid loss= 0.003941816\n",
      "train reg_fs: 0.0016287903999909759\n",
      "Epoch: 10000 train loss=0.004375193 valid loss= 0.004077693\n",
      "train reg_fs: 0.0016256470698863268\n",
      "Epoch: 10500 train loss=0.003108122 valid loss= 0.003920092\n",
      "train reg_fs: 0.00162230315618217\n",
      "Epoch: 11000 train loss=0.001903226 valid loss= 0.003606860\n",
      "train reg_fs: 0.0016195571515709162\n",
      "Epoch: 11500 train loss=0.005908656 valid loss= 0.003588373\n",
      "train reg_fs: 0.0016163723776116967\n",
      "Epoch: 12000 train loss=0.003775597 valid loss= 0.003699244\n",
      "train reg_fs: 0.0016139065846800804\n",
      "Epoch: 12500 train loss=0.009453273 valid loss= 0.003770590\n",
      "train reg_fs: 0.0016116217011585832\n",
      "Epoch: 13000 train loss=0.001828755 valid loss= 0.003723708\n",
      "train reg_fs: 0.0016091016586869955\n",
      "Epoch: 13500 train loss=0.001875289 valid loss= 0.003789443\n",
      "train reg_fs: 0.0016070757992565632\n",
      "Epoch: 14000 train loss=0.010499137 valid loss= 0.003662532\n",
      "train reg_fs: 0.0016046995297074318\n",
      "Epoch: 14500 train loss=0.001991193 valid loss= 0.003862151\n",
      "train reg_fs: 0.0016027780948206782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:08:39,959]\u001b[0m Trial 25 finished with value: 0.0024163542322984486 and parameters: {'lam': 0.0022434850270626086, 'learning_rate': 0.07439270865037324, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001993010 valid loss= 0.003955128\n",
      "train reg_fs: 0.0016007397789508104\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024163542322984486\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019345803 valid loss= 0.009593633\n",
      "train reg_fs: 0.002547498559579253\n",
      "Epoch: 1000 train loss=0.008015152 valid loss= 0.008325907\n",
      "train reg_fs: 0.00257966760545969\n",
      "Epoch: 1500 train loss=0.014985327 valid loss= 0.007658656\n",
      "train reg_fs: 0.0025687054730951786\n",
      "Epoch: 2000 train loss=0.009912740 valid loss= 0.007506416\n",
      "train reg_fs: 0.0025352316442877054\n",
      "Epoch: 2500 train loss=0.014233861 valid loss= 0.006981071\n",
      "train reg_fs: 0.002501864917576313\n",
      "Epoch: 3000 train loss=0.007236756 valid loss= 0.006317213\n",
      "train reg_fs: 0.0024724947288632393\n",
      "Epoch: 3500 train loss=0.019100575 valid loss= 0.005766714\n",
      "train reg_fs: 0.002447019098326564\n",
      "Epoch: 4000 train loss=0.012810376 valid loss= 0.004860356\n",
      "train reg_fs: 0.0024131466634571552\n",
      "Epoch: 4500 train loss=0.009173000 valid loss= 0.004648680\n",
      "train reg_fs: 0.0023691183887422085\n",
      "Epoch: 5000 train loss=0.005729591 valid loss= 0.004514745\n",
      "train reg_fs: 0.002324646105989814\n",
      "Epoch: 5500 train loss=0.004983250 valid loss= 0.004489974\n",
      "train reg_fs: 0.002289646537974477\n",
      "Epoch: 6000 train loss=0.010422751 valid loss= 0.004473091\n",
      "train reg_fs: 0.0022633878979831934\n",
      "Epoch: 6500 train loss=0.005726445 valid loss= 0.004666377\n",
      "train reg_fs: 0.0022413115948438644\n",
      "Epoch: 7000 train loss=0.002813522 valid loss= 0.004315862\n",
      "train reg_fs: 0.0022244849242269993\n",
      "Epoch: 7500 train loss=0.004432105 valid loss= 0.004294020\n",
      "train reg_fs: 0.0022102128714323044\n",
      "Epoch: 8000 train loss=0.003543511 valid loss= 0.004599712\n",
      "train reg_fs: 0.0021969228982925415\n",
      "Epoch: 8500 train loss=0.002870311 valid loss= 0.004256300\n",
      "train reg_fs: 0.002185483230277896\n",
      "Epoch: 9000 train loss=0.004999259 valid loss= 0.004553832\n",
      "train reg_fs: 0.002176570938900113\n",
      "Epoch: 9500 train loss=0.005083682 valid loss= 0.004460177\n",
      "train reg_fs: 0.0021665790118277073\n",
      "Epoch: 10000 train loss=0.004239267 valid loss= 0.004470318\n",
      "train reg_fs: 0.0021567316725850105\n",
      "Epoch: 10500 train loss=0.003619283 valid loss= 0.004364521\n",
      "train reg_fs: 0.0021479593124240637\n",
      "Epoch: 11000 train loss=0.003063455 valid loss= 0.004172034\n",
      "train reg_fs: 0.002140679629519582\n",
      "Epoch: 11500 train loss=0.003973085 valid loss= 0.004128234\n",
      "train reg_fs: 0.0021344798151403666\n",
      "Epoch: 12000 train loss=0.002822215 valid loss= 0.004174224\n",
      "train reg_fs: 0.0021279274951666594\n",
      "Epoch: 12500 train loss=0.003576840 valid loss= 0.004298966\n",
      "train reg_fs: 0.002122139325365424\n",
      "Epoch: 13000 train loss=0.002742006 valid loss= 0.004584134\n",
      "train reg_fs: 0.00211710506118834\n",
      "Epoch: 13500 train loss=0.002612022 valid loss= 0.004323664\n",
      "train reg_fs: 0.002113111549988389\n",
      "Epoch: 14000 train loss=0.008075618 valid loss= 0.004154519\n",
      "train reg_fs: 0.0021090046502649784\n",
      "Epoch: 14500 train loss=0.004785302 valid loss= 0.004465309\n",
      "train reg_fs: 0.0021046956535428762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:10:29,944]\u001b[0m Trial 26 finished with value: 0.0021252770411422294 and parameters: {'lam': 0.002952212827464963, 'learning_rate': 0.052683711721177244, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002749989 valid loss= 0.004158997\n",
      "train reg_fs: 0.002099713310599327\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021252770411422294\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009067731 valid loss= 0.007306883\n",
      "train reg_fs: 0.001527080312371254\n",
      "Epoch: 1000 train loss=0.012840641 valid loss= 0.004328966\n",
      "train reg_fs: 0.0014179543359205127\n",
      "Epoch: 1500 train loss=0.004418679 valid loss= 0.004078101\n",
      "train reg_fs: 0.0013491787249222398\n",
      "Epoch: 2000 train loss=0.005889877 valid loss= 0.003707240\n",
      "train reg_fs: 0.001332236803136766\n",
      "Epoch: 2500 train loss=0.003620851 valid loss= 0.003638762\n",
      "train reg_fs: 0.0013182456605136395\n",
      "Epoch: 3000 train loss=0.006848902 valid loss= 0.003924352\n",
      "train reg_fs: 0.0013113606255501509\n",
      "Epoch: 3500 train loss=0.004883253 valid loss= 0.003738412\n",
      "train reg_fs: 0.0013089595595374703\n",
      "Epoch: 4000 train loss=0.002810054 valid loss= 0.003679196\n",
      "train reg_fs: 0.0013001952320337296\n",
      "Epoch: 4500 train loss=0.007002318 valid loss= 0.004293271\n",
      "train reg_fs: 0.0012997339945286512\n",
      "Epoch: 5000 train loss=0.002487307 valid loss= 0.003985248\n",
      "train reg_fs: 0.0013010038528591394\n",
      "Epoch: 5500 train loss=0.006810491 valid loss= 0.004123817\n",
      "train reg_fs: 0.0012996745062991977\n",
      "Epoch: 6000 train loss=0.003803786 valid loss= 0.004294133\n",
      "train reg_fs: 0.0012848562328144908\n",
      "Epoch: 6500 train loss=0.003854324 valid loss= 0.004302950\n",
      "train reg_fs: 0.0012593860737979412\n",
      "Epoch: 7000 train loss=0.004036695 valid loss= 0.004016672\n",
      "train reg_fs: 0.0012334969360381365\n",
      "Epoch: 7500 train loss=0.002734056 valid loss= 0.003839170\n",
      "train reg_fs: 0.0012158916797488928\n",
      "Epoch: 8000 train loss=0.003994204 valid loss= 0.003345137\n",
      "train reg_fs: 0.001202504034154117\n",
      "Epoch: 8500 train loss=0.002429445 valid loss= 0.003699604\n",
      "train reg_fs: 0.001192270778119564\n",
      "Epoch: 9000 train loss=0.005357182 valid loss= 0.003261520\n",
      "train reg_fs: 0.0011836967896670103\n",
      "Epoch: 9500 train loss=0.001346474 valid loss= 0.003412793\n",
      "train reg_fs: 0.0011753083672374487\n",
      "Epoch: 10000 train loss=0.002639757 valid loss= 0.003427427\n",
      "train reg_fs: 0.0011680740863084793\n",
      "Epoch: 10500 train loss=0.002535776 valid loss= 0.003427430\n",
      "train reg_fs: 0.0011605758918449283\n",
      "Epoch: 11000 train loss=0.001490696 valid loss= 0.003323100\n",
      "train reg_fs: 0.0011536147212609649\n",
      "Epoch: 11500 train loss=0.002287871 valid loss= 0.003300716\n",
      "train reg_fs: 0.001146789058111608\n",
      "Epoch: 12000 train loss=0.002603597 valid loss= 0.003525269\n",
      "train reg_fs: 0.0011398597853258252\n",
      "Epoch: 12500 train loss=0.001494536 valid loss= 0.003261036\n",
      "train reg_fs: 0.0011340761557221413\n",
      "Epoch: 13000 train loss=0.004948251 valid loss= 0.003826598\n",
      "train reg_fs: 0.001128607545979321\n",
      "Epoch: 13500 train loss=0.003258737 valid loss= 0.003543995\n",
      "train reg_fs: 0.0011235950514674187\n",
      "Epoch: 14000 train loss=0.003093547 valid loss= 0.003502649\n",
      "train reg_fs: 0.001119348336942494\n",
      "Epoch: 14500 train loss=0.002575444 valid loss= 0.003283120\n",
      "train reg_fs: 0.0011151137296110392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:12:20,229]\u001b[0m Trial 27 finished with value: 0.002335438067617974 and parameters: {'lam': 0.0017890044771398832, 'learning_rate': 0.10773281412817444, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002084437 valid loss= 0.003431962\n",
      "train reg_fs: 0.0011115013621747494\n",
      "In trial:---------------------\n",
      "validation mse: 0.002335438067617974\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011600208 valid loss= 0.008768122\n",
      "train reg_fs: 0.0012437046971172094\n",
      "Epoch: 1000 train loss=0.020209858 valid loss= 0.008833219\n",
      "train reg_fs: 0.0012694571632891893\n",
      "Epoch: 1500 train loss=0.018630203 valid loss= 0.008272801\n",
      "train reg_fs: 0.0012790649197995663\n",
      "Epoch: 2000 train loss=0.003947118 valid loss= 0.009233789\n",
      "train reg_fs: 0.0012691882438957691\n",
      "Epoch: 2500 train loss=0.007129783 valid loss= 0.008375308\n",
      "train reg_fs: 0.001239862060174346\n",
      "Epoch: 3000 train loss=0.010622928 valid loss= 0.007018290\n",
      "train reg_fs: 0.0012124701170250773\n",
      "Epoch: 3500 train loss=0.003220531 valid loss= 0.006325325\n",
      "train reg_fs: 0.001192116760648787\n",
      "Epoch: 4000 train loss=0.006099568 valid loss= 0.005662949\n",
      "train reg_fs: 0.0011750778649002314\n",
      "Epoch: 4500 train loss=0.006726726 valid loss= 0.005179081\n",
      "train reg_fs: 0.0011635213159024715\n",
      "Epoch: 5000 train loss=0.004540958 valid loss= 0.005120963\n",
      "train reg_fs: 0.0011546806199476123\n",
      "Epoch: 5500 train loss=0.003790938 valid loss= 0.004983686\n",
      "train reg_fs: 0.0011464247945696115\n",
      "Epoch: 6000 train loss=0.002863010 valid loss= 0.004554939\n",
      "train reg_fs: 0.0011380210053175688\n",
      "Epoch: 6500 train loss=0.003834530 valid loss= 0.004356503\n",
      "train reg_fs: 0.0011311896378174424\n",
      "Epoch: 7000 train loss=0.001830391 valid loss= 0.003519049\n",
      "train reg_fs: 0.0011256154393777251\n",
      "Epoch: 7500 train loss=0.011425868 valid loss= 0.003800516\n",
      "train reg_fs: 0.001118746935389936\n",
      "Epoch: 8000 train loss=0.004161858 valid loss= 0.003490684\n",
      "train reg_fs: 0.0011094255605712533\n",
      "Epoch: 8500 train loss=0.002712453 valid loss= 0.003277271\n",
      "train reg_fs: 0.0010966846020892262\n",
      "Epoch: 9000 train loss=0.002571893 valid loss= 0.003425851\n",
      "train reg_fs: 0.0010848426027223468\n",
      "Epoch: 9500 train loss=0.004704632 valid loss= 0.003404506\n",
      "train reg_fs: 0.0010721893049776554\n",
      "Epoch: 10000 train loss=0.008311535 valid loss= 0.003605392\n",
      "train reg_fs: 0.0010589342564344406\n",
      "Epoch: 10500 train loss=0.002060236 valid loss= 0.003415944\n",
      "train reg_fs: 0.0010499487398192286\n",
      "Epoch: 11000 train loss=0.002831824 valid loss= 0.003439890\n",
      "train reg_fs: 0.0010400409810245037\n",
      "Epoch: 11500 train loss=0.004040082 valid loss= 0.003730641\n",
      "train reg_fs: 0.0010315821273252368\n",
      "Epoch: 12000 train loss=0.005459793 valid loss= 0.003607291\n",
      "train reg_fs: 0.0010261662537232041\n",
      "Epoch: 12500 train loss=0.001934715 valid loss= 0.003559330\n",
      "train reg_fs: 0.0010190994944423437\n",
      "Epoch: 13000 train loss=0.004815721 valid loss= 0.003592249\n",
      "train reg_fs: 0.0010129893198609352\n",
      "Epoch: 13500 train loss=0.002679662 valid loss= 0.003645928\n",
      "train reg_fs: 0.0010078371269628406\n",
      "Epoch: 14000 train loss=0.002276377 valid loss= 0.003505818\n",
      "train reg_fs: 0.0010037494357675314\n",
      "Epoch: 14500 train loss=0.001920483 valid loss= 0.003845426\n",
      "train reg_fs: 0.0009998638415709138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:14:08,864]\u001b[0m Trial 28 finished with value: 0.0025137764696476655 and parameters: {'lam': 0.0014084549445859435, 'learning_rate': 0.0766710393018702, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002102058 valid loss= 0.003496883\n",
      "train reg_fs: 0.0009971020044758916\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025137764696476655\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020748816 valid loss= 0.008754528\n",
      "train reg_fs: 0.002102632075548172\n",
      "Epoch: 1000 train loss=0.006532697 valid loss= 0.008660419\n",
      "train reg_fs: 0.002088490640744567\n",
      "Epoch: 1500 train loss=0.007942094 valid loss= 0.007236373\n",
      "train reg_fs: 0.0020179443527013063\n",
      "Epoch: 2000 train loss=0.002802824 valid loss= 0.005945753\n",
      "train reg_fs: 0.0019732292275875807\n",
      "Epoch: 2500 train loss=0.008396928 valid loss= 0.004807321\n",
      "train reg_fs: 0.001943320850841701\n",
      "Epoch: 3000 train loss=0.003695725 valid loss= 0.005865050\n",
      "train reg_fs: 0.001912976847961545\n",
      "Epoch: 3500 train loss=0.008560620 valid loss= 0.004821982\n",
      "train reg_fs: 0.0018808938330039382\n",
      "Epoch: 4000 train loss=0.003224173 valid loss= 0.005167797\n",
      "train reg_fs: 0.0018614351283758879\n",
      "Epoch: 4500 train loss=0.003441820 valid loss= 0.005115146\n",
      "train reg_fs: 0.001840901211835444\n",
      "Epoch: 5000 train loss=0.003981183 valid loss= 0.005280314\n",
      "train reg_fs: 0.0018229593988507986\n",
      "Epoch: 5500 train loss=0.002095872 valid loss= 0.005247635\n",
      "train reg_fs: 0.0018038748530671\n",
      "Epoch: 6000 train loss=0.003051055 valid loss= 0.005076118\n",
      "train reg_fs: 0.0017875836929306388\n",
      "Epoch: 6500 train loss=0.003334334 valid loss= 0.005160902\n",
      "train reg_fs: 0.0017671569949015975\n",
      "Epoch: 7000 train loss=0.003533415 valid loss= 0.004997823\n",
      "train reg_fs: 0.0017495217034593225\n",
      "Epoch: 7500 train loss=0.004030590 valid loss= 0.005580831\n",
      "train reg_fs: 0.0017266583163291216\n",
      "Epoch: 8000 train loss=0.002716569 valid loss= 0.005214808\n",
      "train reg_fs: 0.0017059789970517159\n",
      "Epoch: 8500 train loss=0.002577470 valid loss= 0.005024270\n",
      "train reg_fs: 0.0016886345110833645\n",
      "Epoch: 9000 train loss=0.002013466 valid loss= 0.005239296\n",
      "train reg_fs: 0.0016684470465406775\n",
      "Epoch: 9500 train loss=0.002458046 valid loss= 0.004915041\n",
      "train reg_fs: 0.0016505394596606493\n",
      "Epoch: 10000 train loss=0.001766229 valid loss= 0.004751150\n",
      "train reg_fs: 0.001634947839193046\n",
      "Epoch: 10500 train loss=0.002584163 valid loss= 0.004894724\n",
      "train reg_fs: 0.0016199513338506222\n",
      "Epoch: 11000 train loss=0.002336372 valid loss= 0.004932145\n",
      "train reg_fs: 0.001608582097105682\n",
      "Epoch: 11500 train loss=0.002398576 valid loss= 0.004999568\n",
      "train reg_fs: 0.0015959973679855466\n",
      "Epoch: 12000 train loss=0.002554121 valid loss= 0.004713931\n",
      "train reg_fs: 0.001585891586728394\n",
      "Epoch: 12500 train loss=0.004633345 valid loss= 0.005398377\n",
      "train reg_fs: 0.0015790876932442188\n",
      "Epoch: 13000 train loss=0.001880386 valid loss= 0.004873694\n",
      "train reg_fs: 0.0015709722647443414\n",
      "Epoch: 13500 train loss=0.003541335 valid loss= 0.004839836\n",
      "train reg_fs: 0.001563501893542707\n",
      "Epoch: 14000 train loss=0.005284258 valid loss= 0.005095490\n",
      "train reg_fs: 0.0015575235011056066\n",
      "Epoch: 14500 train loss=0.001888316 valid loss= 0.004953031\n",
      "train reg_fs: 0.00155004789121449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:15:58,054]\u001b[0m Trial 29 finished with value: 0.0037996554148199756 and parameters: {'lam': 0.0023572753903256622, 'learning_rate': 0.15739916481554597, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002388848 valid loss= 0.005330758\n",
      "train reg_fs: 0.001541260164231062\n",
      "In trial:---------------------\n",
      "validation mse: 0.0037996554148199756\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012171948 valid loss= 0.009764211\n",
      "train reg_fs: 0.0028480184264481068\n",
      "Epoch: 1000 train loss=0.018239718 valid loss= 0.009905876\n",
      "train reg_fs: 0.002881689229980111\n",
      "Epoch: 1500 train loss=0.017107772 valid loss= 0.009419127\n",
      "train reg_fs: 0.0028989382553845644\n",
      "Epoch: 2000 train loss=0.008884927 valid loss= 0.008747829\n",
      "train reg_fs: 0.002897594589740038\n",
      "Epoch: 2500 train loss=0.009344034 valid loss= 0.008892032\n",
      "train reg_fs: 0.0028728784527629614\n",
      "Epoch: 3000 train loss=0.012696994 valid loss= 0.008693360\n",
      "train reg_fs: 0.0028282389976084232\n",
      "Epoch: 3500 train loss=0.007035146 valid loss= 0.008425575\n",
      "train reg_fs: 0.0027725091204047203\n",
      "Epoch: 4000 train loss=0.006687532 valid loss= 0.007704836\n",
      "train reg_fs: 0.002721098018810153\n",
      "Epoch: 4500 train loss=0.004134239 valid loss= 0.007414917\n",
      "train reg_fs: 0.002664931584149599\n",
      "Epoch: 5000 train loss=0.005674705 valid loss= 0.006379741\n",
      "train reg_fs: 0.002618028549477458\n",
      "Epoch: 5500 train loss=0.004770201 valid loss= 0.005972703\n",
      "train reg_fs: 0.0025765502359718084\n",
      "Epoch: 6000 train loss=0.017841062 valid loss= 0.005935872\n",
      "train reg_fs: 0.0025385855697095394\n",
      "Epoch: 6500 train loss=0.011155839 valid loss= 0.006009290\n",
      "train reg_fs: 0.0025087299291044474\n",
      "Epoch: 7000 train loss=0.005732673 valid loss= 0.005837583\n",
      "train reg_fs: 0.0024776733480393887\n",
      "Epoch: 7500 train loss=0.007857352 valid loss= 0.005610226\n",
      "train reg_fs: 0.0024496400728821754\n",
      "Epoch: 8000 train loss=0.005256717 valid loss= 0.006430120\n",
      "train reg_fs: 0.002421238226816058\n",
      "Epoch: 8500 train loss=0.008606860 valid loss= 0.005639083\n",
      "train reg_fs: 0.0023959598038345575\n",
      "Epoch: 9000 train loss=0.003807703 valid loss= 0.005646576\n",
      "train reg_fs: 0.0023705638013780117\n",
      "Epoch: 9500 train loss=0.003724176 valid loss= 0.005847188\n",
      "train reg_fs: 0.0023444262333214283\n",
      "Epoch: 10000 train loss=0.004282860 valid loss= 0.005535393\n",
      "train reg_fs: 0.0023214281536638737\n",
      "Epoch: 10500 train loss=0.005152893 valid loss= 0.005956643\n",
      "train reg_fs: 0.0022962037473917007\n",
      "Epoch: 11000 train loss=0.006895046 valid loss= 0.005891614\n",
      "train reg_fs: 0.0022728361655026674\n",
      "Epoch: 11500 train loss=0.003741933 valid loss= 0.005492148\n",
      "train reg_fs: 0.0022521307691931725\n",
      "Epoch: 12000 train loss=0.003231435 valid loss= 0.005423087\n",
      "train reg_fs: 0.0022323953453451395\n",
      "Epoch: 12500 train loss=0.002685983 valid loss= 0.005250809\n",
      "train reg_fs: 0.002215000567957759\n",
      "Epoch: 13000 train loss=0.003529163 valid loss= 0.005248181\n",
      "train reg_fs: 0.002199626062065363\n",
      "Epoch: 13500 train loss=0.003980758 valid loss= 0.004956445\n",
      "train reg_fs: 0.0021844138391315937\n",
      "Epoch: 14000 train loss=0.002736283 valid loss= 0.004587839\n",
      "train reg_fs: 0.002171749249100685\n",
      "Epoch: 14500 train loss=0.005897282 valid loss= 0.004914263\n",
      "train reg_fs: 0.0021600350737571716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:17:45,895]\u001b[0m Trial 30 finished with value: 0.0029552387543617413 and parameters: {'lam': 0.0033118259536412667, 'learning_rate': 0.03260293375942707, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002800347 valid loss= 0.005098465\n",
      "train reg_fs: 0.0021489060018211603\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029552387543617413\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008645510 valid loss= 0.008011562\n",
      "train reg_fs: 0.0011020958190783858\n",
      "Epoch: 1000 train loss=0.005721251 valid loss= 0.007248723\n",
      "train reg_fs: 0.0010595382191240788\n",
      "Epoch: 1500 train loss=0.003890436 valid loss= 0.005116610\n",
      "train reg_fs: 0.0010143392719328403\n",
      "Epoch: 2000 train loss=0.007186628 valid loss= 0.004216917\n",
      "train reg_fs: 0.0009739674278534949\n",
      "Epoch: 2500 train loss=0.003064191 valid loss= 0.004688249\n",
      "train reg_fs: 0.0009496270795352757\n",
      "Epoch: 3000 train loss=0.003125612 valid loss= 0.004762791\n",
      "train reg_fs: 0.0009381159325130284\n",
      "Epoch: 3500 train loss=0.003699288 valid loss= 0.004638746\n",
      "train reg_fs: 0.0009316432988271117\n",
      "Epoch: 4000 train loss=0.012447177 valid loss= 0.004829516\n",
      "train reg_fs: 0.0009339680545963347\n",
      "Epoch: 4500 train loss=0.009828012 valid loss= 0.004485121\n",
      "train reg_fs: 0.0009355801157653332\n",
      "Epoch: 5000 train loss=0.002258793 valid loss= 0.005028705\n",
      "train reg_fs: 0.0009354232461191714\n",
      "Epoch: 5500 train loss=0.002314228 valid loss= 0.004441270\n",
      "train reg_fs: 0.0009375857189297676\n",
      "Epoch: 6000 train loss=0.003925632 valid loss= 0.004216081\n",
      "train reg_fs: 0.0009371099295094609\n",
      "Epoch: 6500 train loss=0.002344216 valid loss= 0.004386433\n",
      "train reg_fs: 0.0009364055586047471\n",
      "Epoch: 7000 train loss=0.003772059 valid loss= 0.004051908\n",
      "train reg_fs: 0.0009338696836493909\n",
      "Epoch: 7500 train loss=0.002251072 valid loss= 0.004149468\n",
      "train reg_fs: 0.0009309215238317847\n",
      "Epoch: 8000 train loss=0.002882928 valid loss= 0.003713294\n",
      "train reg_fs: 0.0009276586351916194\n",
      "Epoch: 8500 train loss=0.002602092 valid loss= 0.003847498\n",
      "train reg_fs: 0.0009232073207385838\n",
      "Epoch: 9000 train loss=0.002640797 valid loss= 0.003725184\n",
      "train reg_fs: 0.0009223585366271436\n",
      "Epoch: 9500 train loss=0.003779814 valid loss= 0.003684741\n",
      "train reg_fs: 0.0009178591426461935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:18:59,282]\u001b[0m Trial 31 finished with value: 0.0026361462032056366 and parameters: {'lam': 0.0012852718050764894, 'learning_rate': 0.10905920329985949, 'num_epoch': 10000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002131895 valid loss= 0.003548291\n",
      "train reg_fs: 0.0009151120320893824\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026361462032056366\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010166439 valid loss= 0.006631225\n",
      "train reg_fs: 0.0009407457546330988\n",
      "Epoch: 1000 train loss=0.002904490 valid loss= 0.004883629\n",
      "train reg_fs: 0.0009099417366087437\n",
      "Epoch: 1500 train loss=0.005624439 valid loss= 0.003559200\n",
      "train reg_fs: 0.0008842983515933156\n",
      "Epoch: 2000 train loss=0.007150416 valid loss= 0.003419301\n",
      "train reg_fs: 0.0008588327909819782\n",
      "Epoch: 2500 train loss=0.004028264 valid loss= 0.003346015\n",
      "train reg_fs: 0.0008410795126110315\n",
      "Epoch: 3000 train loss=0.013589748 valid loss= 0.003382541\n",
      "train reg_fs: 0.0008311700657941401\n",
      "Epoch: 3500 train loss=0.001384795 valid loss= 0.003252254\n",
      "train reg_fs: 0.0008206239435821772\n",
      "Epoch: 4000 train loss=0.008808141 valid loss= 0.003231235\n",
      "train reg_fs: 0.0008101888815872371\n",
      "Epoch: 4500 train loss=0.002496485 valid loss= 0.003580195\n",
      "train reg_fs: 0.0008016256615519524\n",
      "Epoch: 5000 train loss=0.001673899 valid loss= 0.003300153\n",
      "train reg_fs: 0.0007954839966259897\n",
      "Epoch: 5500 train loss=0.003815894 valid loss= 0.003173161\n",
      "train reg_fs: 0.00078793108696118\n",
      "Epoch: 6000 train loss=0.001787310 valid loss= 0.003355986\n",
      "train reg_fs: 0.0007833492127247155\n",
      "Epoch: 6500 train loss=0.002328147 valid loss= 0.003319856\n",
      "train reg_fs: 0.0007772155804559588\n",
      "Epoch: 7000 train loss=0.001412690 valid loss= 0.002967243\n",
      "train reg_fs: 0.0007724742172285914\n",
      "Epoch: 7500 train loss=0.002346972 valid loss= 0.002904207\n",
      "train reg_fs: 0.0007686305325478315\n",
      "Epoch: 8000 train loss=0.006140841 valid loss= 0.003143312\n",
      "train reg_fs: 0.0007660621195100248\n",
      "Epoch: 8500 train loss=0.003199936 valid loss= 0.002875216\n",
      "train reg_fs: 0.0007623991114087403\n",
      "Epoch: 9000 train loss=0.001206527 valid loss= 0.003194662\n",
      "train reg_fs: 0.0007581321988254786\n",
      "Epoch: 9500 train loss=0.001878261 valid loss= 0.002844261\n",
      "train reg_fs: 0.0007566282874904573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:20:12,531]\u001b[0m Trial 32 finished with value: 0.002254405942234111 and parameters: {'lam': 0.0010750624320724782, 'learning_rate': 0.11884470372824833, 'num_epoch': 10000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001990356 valid loss= 0.002989475\n",
      "train reg_fs: 0.0007538561476394534\n",
      "In trial:---------------------\n",
      "validation mse: 0.002254405942234111\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.023020752 valid loss= 0.007835521\n",
      "train reg_fs: 0.0014483853010460734\n",
      "Epoch: 1000 train loss=0.018595140 valid loss= 0.007685792\n",
      "train reg_fs: 0.0014724470674991608\n",
      "Epoch: 1500 train loss=0.008141370 valid loss= 0.007966618\n",
      "train reg_fs: 0.0014805340906605124\n",
      "Epoch: 2000 train loss=0.006032504 valid loss= 0.007404175\n",
      "train reg_fs: 0.0014782021753489971\n",
      "Epoch: 2500 train loss=0.010731633 valid loss= 0.005921131\n",
      "train reg_fs: 0.001467251917347312\n",
      "Epoch: 3000 train loss=0.005362496 valid loss= 0.005457949\n",
      "train reg_fs: 0.001448284718208015\n",
      "Epoch: 3500 train loss=0.003666888 valid loss= 0.004964703\n",
      "train reg_fs: 0.0014288300881162286\n",
      "Epoch: 4000 train loss=0.011294319 valid loss= 0.004717150\n",
      "train reg_fs: 0.0014136891113594174\n",
      "Epoch: 4500 train loss=0.007796274 valid loss= 0.004834951\n",
      "train reg_fs: 0.0013976420741528273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:20:50,376]\u001b[0m Trial 33 finished with value: 0.0033245123153423342 and parameters: {'lam': 0.0016642043707910219, 'learning_rate': 0.0654585637973478, 'num_epoch': 5000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003839192 valid loss= 0.004725259\n",
      "train reg_fs: 0.0013844138011336327\n",
      "In trial:---------------------\n",
      "validation mse: 0.0033245123153423342\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012533973 valid loss= 0.008090716\n",
      "train reg_fs: 0.0012451588409021497\n",
      "Epoch: 1000 train loss=0.014923777 valid loss= 0.007163733\n",
      "train reg_fs: 0.001226138207130134\n",
      "Epoch: 1500 train loss=0.005797812 valid loss= 0.005587917\n",
      "train reg_fs: 0.0011921398108825088\n",
      "Epoch: 2000 train loss=0.005482986 valid loss= 0.004078196\n",
      "train reg_fs: 0.0011642992030829191\n",
      "Epoch: 2500 train loss=0.006264183 valid loss= 0.003435309\n",
      "train reg_fs: 0.0011374952737241983\n",
      "Epoch: 3000 train loss=0.004303213 valid loss= 0.003396118\n",
      "train reg_fs: 0.001125949784182012\n",
      "Epoch: 3500 train loss=0.004399046 valid loss= 0.003477070\n",
      "train reg_fs: 0.0011245543137192726\n",
      "Epoch: 4000 train loss=0.003735605 valid loss= 0.003506356\n",
      "train reg_fs: 0.001127072493545711\n",
      "Epoch: 4500 train loss=0.003429648 valid loss= 0.003480778\n",
      "train reg_fs: 0.0011308256071060896\n",
      "Epoch: 5000 train loss=0.001677592 valid loss= 0.003295022\n",
      "train reg_fs: 0.001134154968895018\n",
      "Epoch: 5500 train loss=0.004097820 valid loss= 0.003279909\n",
      "train reg_fs: 0.0011360493954271078\n",
      "Epoch: 6000 train loss=0.003641166 valid loss= 0.003545796\n",
      "train reg_fs: 0.0011338443728163838\n",
      "Epoch: 6500 train loss=0.003231315 valid loss= 0.003511576\n",
      "train reg_fs: 0.0011275517754256725\n",
      "Epoch: 7000 train loss=0.007914351 valid loss= 0.003343236\n",
      "train reg_fs: 0.0011185209732502699\n",
      "Epoch: 7500 train loss=0.002332670 valid loss= 0.003681612\n",
      "train reg_fs: 0.0011089527979493141\n",
      "Epoch: 8000 train loss=0.003533981 valid loss= 0.003029601\n",
      "train reg_fs: 0.001101026777178049\n",
      "Epoch: 8500 train loss=0.004533466 valid loss= 0.003082792\n",
      "train reg_fs: 0.0010951001895591617\n",
      "Epoch: 9000 train loss=0.001904168 valid loss= 0.003027971\n",
      "train reg_fs: 0.0010907702380791306\n",
      "Epoch: 9500 train loss=0.007193973 valid loss= 0.002942585\n",
      "train reg_fs: 0.001087482669390738\n",
      "Epoch: 10000 train loss=0.002058265 valid loss= 0.002930441\n",
      "train reg_fs: 0.0010848715901374817\n",
      "Epoch: 10500 train loss=0.006741778 valid loss= 0.003052687\n",
      "train reg_fs: 0.001083064591512084\n",
      "Epoch: 11000 train loss=0.004400207 valid loss= 0.002992163\n",
      "train reg_fs: 0.0010812280233949423\n",
      "Epoch: 11500 train loss=0.001720535 valid loss= 0.003308505\n",
      "train reg_fs: 0.0010798177681863308\n",
      "Epoch: 12000 train loss=0.003558650 valid loss= 0.003168455\n",
      "train reg_fs: 0.0010785185731947422\n",
      "Epoch: 12500 train loss=0.003903575 valid loss= 0.003102659\n",
      "train reg_fs: 0.0010775300906971097\n",
      "Epoch: 13000 train loss=0.009656127 valid loss= 0.002859782\n",
      "train reg_fs: 0.001076610409654677\n",
      "Epoch: 13500 train loss=0.001667259 valid loss= 0.002590336\n",
      "train reg_fs: 0.00107584020588547\n",
      "Epoch: 14000 train loss=0.004174137 valid loss= 0.002872685\n",
      "train reg_fs: 0.0010748323984444141\n",
      "Epoch: 14500 train loss=0.002588742 valid loss= 0.002880516\n",
      "train reg_fs: 0.0010738124838098884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:22:41,128]\u001b[0m Trial 34 finished with value: 0.0020677322879364456 and parameters: {'lam': 0.0014287207547013534, 'learning_rate': 0.08859560514547304, 'num_epoch': 15000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001755637 valid loss= 0.003114418\n",
      "train reg_fs: 0.0010730883805081248\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020677322879364456\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012852527 valid loss= 0.011855339\n",
      "train reg_fs: 0.00313172722235322\n",
      "Epoch: 1000 train loss=0.013970105 valid loss= 0.011881663\n",
      "train reg_fs: 0.003153175115585327\n",
      "Epoch: 1500 train loss=0.020016467 valid loss= 0.011154455\n",
      "train reg_fs: 0.0031740686390548944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:22:57,139]\u001b[0m Trial 35 finished with value: 0.007305356900071312 and parameters: {'lam': 0.0037061648543382382, 'learning_rate': 0.010312270382279191, 'num_epoch': 2000}. Best is trial 21 with value: 0.0008402301502041076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.018462542 valid loss= 0.010500301\n",
      "train reg_fs: 0.0031906820368021727\n",
      "In trial:---------------------\n",
      "validation mse: 0.007305356900071312\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009336193 valid loss= 0.005702262\n",
      "train reg_fs: 0.0010093201417475939\n",
      "Epoch: 1000 train loss=0.003983424 valid loss= 0.004533019\n",
      "train reg_fs: 0.000980244716629386\n",
      "Epoch: 1500 train loss=0.004282975 valid loss= 0.003038119\n",
      "train reg_fs: 0.0009493810939602554\n",
      "Epoch: 2000 train loss=0.005995143 valid loss= 0.003032209\n",
      "train reg_fs: 0.000933032133616507\n",
      "Epoch: 2500 train loss=0.001964430 valid loss= 0.002644401\n",
      "train reg_fs: 0.0009262481471523643\n",
      "Epoch: 3000 train loss=0.004099448 valid loss= 0.002897515\n",
      "train reg_fs: 0.0009205700480379164\n",
      "Epoch: 3500 train loss=0.002630971 valid loss= 0.002538386\n",
      "train reg_fs: 0.0009131139377132058\n",
      "Epoch: 4000 train loss=0.006291576 valid loss= 0.002527583\n",
      "train reg_fs: 0.0009043382597155869\n",
      "Epoch: 4500 train loss=0.001964917 valid loss= 0.002854704\n",
      "train reg_fs: 0.0008975205710157752\n",
      "Epoch: 5000 train loss=0.005317863 valid loss= 0.003093228\n",
      "train reg_fs: 0.000891539384610951\n",
      "Epoch: 5500 train loss=0.001233162 valid loss= 0.002549346\n",
      "train reg_fs: 0.0008866605930961668\n",
      "Epoch: 6000 train loss=0.002952809 valid loss= 0.003020529\n",
      "train reg_fs: 0.0008824820979498327\n",
      "Epoch: 6500 train loss=0.001487965 valid loss= 0.002454676\n",
      "train reg_fs: 0.0008783223456703126\n",
      "Epoch: 7000 train loss=0.003098154 valid loss= 0.002852047\n",
      "train reg_fs: 0.0008747028768993914\n",
      "Epoch: 7500 train loss=0.003411128 valid loss= 0.002427364\n",
      "train reg_fs: 0.0008713469724170864\n",
      "Epoch: 8000 train loss=0.003822549 valid loss= 0.002347894\n",
      "train reg_fs: 0.000868104980327189\n",
      "Epoch: 8500 train loss=0.001851507 valid loss= 0.002164423\n",
      "train reg_fs: 0.0008645076886750758\n",
      "Epoch: 9000 train loss=0.004046670 valid loss= 0.002416931\n",
      "train reg_fs: 0.0008604691829532385\n",
      "Epoch: 9500 train loss=0.003454568 valid loss= 0.002634764\n",
      "train reg_fs: 0.0008567318436689675\n",
      "Epoch: 10000 train loss=0.003461028 valid loss= 0.002216702\n",
      "train reg_fs: 0.0008528251782990992\n",
      "Epoch: 10500 train loss=0.001579087 valid loss= 0.001984773\n",
      "train reg_fs: 0.0008481902186758816\n",
      "Epoch: 11000 train loss=0.002191179 valid loss= 0.001627719\n",
      "train reg_fs: 0.000842881971038878\n",
      "Epoch: 11500 train loss=0.001924017 valid loss= 0.001977986\n",
      "train reg_fs: 0.0008391038281843066\n",
      "Epoch: 12000 train loss=0.001431149 valid loss= 0.001563858\n",
      "train reg_fs: 0.0008346080430783331\n",
      "Epoch: 12500 train loss=0.001270647 valid loss= 0.002006848\n",
      "train reg_fs: 0.0008305439259856939\n",
      "Epoch: 13000 train loss=0.003688191 valid loss= 0.002042637\n",
      "train reg_fs: 0.00082688860129565\n",
      "Epoch: 13500 train loss=0.002059393 valid loss= 0.001676323\n",
      "train reg_fs: 0.0008236560970544815\n",
      "Epoch: 14000 train loss=0.004340652 valid loss= 0.001714075\n",
      "train reg_fs: 0.0008205031626857817\n",
      "Epoch: 14500 train loss=0.001439669 valid loss= 0.001461753\n",
      "train reg_fs: 0.0008172751986421645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:24:45,813]\u001b[0m Trial 36 finished with value: 0.0008029169352910764 and parameters: {'lam': 0.00118126567374733, 'learning_rate': 0.08505711564868858, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001672086 valid loss= 0.001617810\n",
      "train reg_fs: 0.0008144905441440642\n",
      "In trial:---------------------\n",
      "validation mse: 0.0008029169352910764\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019994432 valid loss= 0.007910229\n",
      "train reg_fs: 0.0009871063521131873\n",
      "Epoch: 1000 train loss=0.016275350 valid loss= 0.008248281\n",
      "train reg_fs: 0.0009890731889754534\n",
      "Epoch: 1500 train loss=0.005024038 valid loss= 0.007790073\n",
      "train reg_fs: 0.0009670928120613098\n",
      "Epoch: 2000 train loss=0.006601850 valid loss= 0.006848269\n",
      "train reg_fs: 0.0009460044675506651\n",
      "Epoch: 2500 train loss=0.004136297 valid loss= 0.006616267\n",
      "train reg_fs: 0.0009310569730587304\n",
      "Epoch: 3000 train loss=0.006864818 valid loss= 0.005994946\n",
      "train reg_fs: 0.0009147379314526916\n",
      "Epoch: 3500 train loss=0.005621380 valid loss= 0.005180316\n",
      "train reg_fs: 0.0008944833534769714\n",
      "Epoch: 4000 train loss=0.006484739 valid loss= 0.003949840\n",
      "train reg_fs: 0.0008721452322788537\n",
      "Epoch: 4500 train loss=0.001474855 valid loss= 0.003068120\n",
      "train reg_fs: 0.0008462102268822491\n",
      "Epoch: 5000 train loss=0.008062115 valid loss= 0.003878764\n",
      "train reg_fs: 0.0008271181141026318\n",
      "Epoch: 5500 train loss=0.001367262 valid loss= 0.003696943\n",
      "train reg_fs: 0.0008128837216645479\n",
      "Epoch: 6000 train loss=0.002295521 valid loss= 0.003729735\n",
      "train reg_fs: 0.000802193651907146\n",
      "Epoch: 6500 train loss=0.002848453 valid loss= 0.003576605\n",
      "train reg_fs: 0.0007943913224153221\n",
      "Epoch: 7000 train loss=0.006244851 valid loss= 0.003504811\n",
      "train reg_fs: 0.0007869391702115536\n",
      "Epoch: 7500 train loss=0.006575131 valid loss= 0.003130960\n",
      "train reg_fs: 0.0007801187457516789\n",
      "Epoch: 8000 train loss=0.002930935 valid loss= 0.003365953\n",
      "train reg_fs: 0.000773260835558176\n",
      "Epoch: 8500 train loss=0.001825055 valid loss= 0.003017955\n",
      "train reg_fs: 0.0007686025346629322\n",
      "Epoch: 9000 train loss=0.004329965 valid loss= 0.003188061\n",
      "train reg_fs: 0.0007646888843737543\n",
      "Epoch: 9500 train loss=0.005713355 valid loss= 0.003240247\n",
      "train reg_fs: 0.0007579858065582812\n",
      "Epoch: 10000 train loss=0.001711487 valid loss= 0.003233377\n",
      "train reg_fs: 0.00075256556738168\n",
      "Epoch: 10500 train loss=0.005890863 valid loss= 0.003345562\n",
      "train reg_fs: 0.000747819256503135\n",
      "Epoch: 11000 train loss=0.001621393 valid loss= 0.002935878\n",
      "train reg_fs: 0.0007422617054544389\n",
      "Epoch: 11500 train loss=0.001123921 valid loss= 0.003252310\n",
      "train reg_fs: 0.0007381028844974935\n",
      "Epoch: 12000 train loss=0.001892457 valid loss= 0.003112112\n",
      "train reg_fs: 0.000733323220629245\n",
      "Epoch: 12500 train loss=0.001849912 valid loss= 0.003045242\n",
      "train reg_fs: 0.0007300312863662839\n",
      "Epoch: 13000 train loss=0.003362611 valid loss= 0.002966309\n",
      "train reg_fs: 0.0007252565119415522\n",
      "Epoch: 13500 train loss=0.004148535 valid loss= 0.003297279\n",
      "train reg_fs: 0.0007222589338198304\n",
      "Epoch: 14000 train loss=0.002399667 valid loss= 0.003146037\n",
      "train reg_fs: 0.0007198761450126767\n",
      "Epoch: 14500 train loss=0.002443496 valid loss= 0.003223626\n",
      "train reg_fs: 0.000716875889338553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:26:34,362]\u001b[0m Trial 37 finished with value: 0.0022656837725998956 and parameters: {'lam': 0.0011323895651857998, 'learning_rate': 0.08501962911663037, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001381262 valid loss= 0.002970343\n",
      "train reg_fs: 0.0007142428657971323\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022656837725998956\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012903180 valid loss= 0.008596244\n",
      "train reg_fs: 0.003388642566278577\n",
      "Epoch: 1000 train loss=0.008316079 valid loss= 0.007274007\n",
      "train reg_fs: 0.003153775352984667\n",
      "Epoch: 1500 train loss=0.011259824 valid loss= 0.006799477\n",
      "train reg_fs: 0.0029656521510332823\n",
      "Epoch: 2000 train loss=0.003814477 valid loss= 0.006322643\n",
      "train reg_fs: 0.002873153192922473\n",
      "Epoch: 2500 train loss=0.007243664 valid loss= 0.006309112\n",
      "train reg_fs: 0.0028159974608570337\n",
      "Epoch: 3000 train loss=0.006370983 valid loss= 0.006323755\n",
      "train reg_fs: 0.0027653772849589586\n",
      "Epoch: 3500 train loss=0.006278403 valid loss= 0.006734969\n",
      "train reg_fs: 0.002720183227211237\n",
      "Epoch: 4000 train loss=0.005967614 valid loss= 0.006380086\n",
      "train reg_fs: 0.0026772785931825638\n",
      "Epoch: 4500 train loss=0.004335282 valid loss= 0.006606658\n",
      "train reg_fs: 0.0026444075629115105\n",
      "Epoch: 5000 train loss=0.004603089 valid loss= 0.006663418\n",
      "train reg_fs: 0.002616559388116002\n",
      "Epoch: 5500 train loss=0.007475168 valid loss= 0.006808433\n",
      "train reg_fs: 0.00258818082511425\n",
      "Epoch: 6000 train loss=0.012674681 valid loss= 0.006744884\n",
      "train reg_fs: 0.0025627671275287867\n",
      "Epoch: 6500 train loss=0.004811013 valid loss= 0.006520716\n",
      "train reg_fs: 0.002538403496146202\n",
      "Epoch: 7000 train loss=0.003423528 valid loss= 0.006582978\n",
      "train reg_fs: 0.0025155607145279646\n",
      "Epoch: 7500 train loss=0.009247279 valid loss= 0.006898919\n",
      "train reg_fs: 0.0024923942983150482\n",
      "Epoch: 8000 train loss=0.004324090 valid loss= 0.006655241\n",
      "train reg_fs: 0.0024681484792381525\n",
      "Epoch: 8500 train loss=0.008507501 valid loss= 0.006756421\n",
      "train reg_fs: 0.0024478265549987555\n",
      "Epoch: 9000 train loss=0.005178316 valid loss= 0.006789412\n",
      "train reg_fs: 0.0024300136137753725\n",
      "Epoch: 9500 train loss=0.006016069 valid loss= 0.006401460\n",
      "train reg_fs: 0.0024131941609084606\n",
      "Epoch: 10000 train loss=0.004652151 valid loss= 0.006620135\n",
      "train reg_fs: 0.0023991272319108248\n",
      "Epoch: 10500 train loss=0.005590045 valid loss= 0.006683502\n",
      "train reg_fs: 0.0023864945396780968\n",
      "Epoch: 11000 train loss=0.005266210 valid loss= 0.006451447\n",
      "train reg_fs: 0.002375211799517274\n",
      "Epoch: 11500 train loss=0.004507973 valid loss= 0.006497376\n",
      "train reg_fs: 0.0023653393145650625\n",
      "Epoch: 12000 train loss=0.004309813 valid loss= 0.007054497\n",
      "train reg_fs: 0.0023560873232781887\n",
      "Epoch: 12500 train loss=0.005135742 valid loss= 0.006657268\n",
      "train reg_fs: 0.002348970388993621\n",
      "Epoch: 13000 train loss=0.004017896 valid loss= 0.006592574\n",
      "train reg_fs: 0.002342771040275693\n",
      "Epoch: 13500 train loss=0.005351775 valid loss= 0.006782615\n",
      "train reg_fs: 0.0023370857816189528\n",
      "Epoch: 14000 train loss=0.005064607 valid loss= 0.007004661\n",
      "train reg_fs: 0.002332075498998165\n",
      "Epoch: 14500 train loss=0.005938679 valid loss= 0.006874413\n",
      "train reg_fs: 0.002327975817024708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:28:23,269]\u001b[0m Trial 38 finished with value: 0.004711852203351426 and parameters: {'lam': 0.004014663144244838, 'learning_rate': 0.09575536356959813, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003957516 valid loss= 0.007128492\n",
      "train reg_fs: 0.0023234619293361902\n",
      "In trial:---------------------\n",
      "validation mse: 0.004711852203351426\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010737938 valid loss= 0.008741639\n",
      "train reg_fs: 0.0016626304714009166\n",
      "Epoch: 1000 train loss=0.010702634 valid loss= 0.009227290\n",
      "train reg_fs: 0.00167216791305691\n",
      "Epoch: 1500 train loss=0.009969529 valid loss= 0.008092053\n",
      "train reg_fs: 0.0016578973736613989\n",
      "Epoch: 2000 train loss=0.005782703 valid loss= 0.007559799\n",
      "train reg_fs: 0.0016348204808309674\n",
      "Epoch: 2500 train loss=0.005252913 valid loss= 0.006722187\n",
      "train reg_fs: 0.0016125314868986607\n",
      "Epoch: 3000 train loss=0.004920880 valid loss= 0.006545334\n",
      "train reg_fs: 0.0015939661534503102\n",
      "Epoch: 3500 train loss=0.007535804 valid loss= 0.005860214\n",
      "train reg_fs: 0.0015723991673439741\n",
      "Epoch: 4000 train loss=0.002802316 valid loss= 0.005360652\n",
      "train reg_fs: 0.0015472050290554762\n",
      "Epoch: 4500 train loss=0.007677701 valid loss= 0.004060196\n",
      "train reg_fs: 0.0015204405644908547\n",
      "Epoch: 5000 train loss=0.006084928 valid loss= 0.004003750\n",
      "train reg_fs: 0.0014922168338671327\n",
      "Epoch: 5500 train loss=0.003217646 valid loss= 0.003453006\n",
      "train reg_fs: 0.0014722266932949424\n",
      "Epoch: 6000 train loss=0.005758429 valid loss= 0.003861782\n",
      "train reg_fs: 0.001458051847293973\n",
      "Epoch: 6500 train loss=0.003725317 valid loss= 0.003987779\n",
      "train reg_fs: 0.0014470643363893032\n",
      "Epoch: 7000 train loss=0.004115457 valid loss= 0.003599798\n",
      "train reg_fs: 0.0014373998856171966\n",
      "Epoch: 7500 train loss=0.002620655 valid loss= 0.004202363\n",
      "train reg_fs: 0.0014303867937996984\n",
      "Epoch: 8000 train loss=0.003910896 valid loss= 0.003573366\n",
      "train reg_fs: 0.0014242837205529213\n",
      "Epoch: 8500 train loss=0.002390431 valid loss= 0.003802627\n",
      "train reg_fs: 0.0014183984603732824\n",
      "Epoch: 9000 train loss=0.004461247 valid loss= 0.003596741\n",
      "train reg_fs: 0.0014150619972497225\n",
      "Epoch: 9500 train loss=0.009599967 valid loss= 0.003679879\n",
      "train reg_fs: 0.0014108162140473723\n",
      "Epoch: 10000 train loss=0.003121007 valid loss= 0.003702998\n",
      "train reg_fs: 0.0014063988346606493\n",
      "Epoch: 10500 train loss=0.004036667 valid loss= 0.003725251\n",
      "train reg_fs: 0.0014034864725545049\n",
      "Epoch: 11000 train loss=0.002146002 valid loss= 0.003733713\n",
      "train reg_fs: 0.001402982510626316\n",
      "Epoch: 11500 train loss=0.002450169 valid loss= 0.003835157\n",
      "train reg_fs: 0.0014021291863173246\n",
      "Epoch: 12000 train loss=0.004454154 valid loss= 0.003440832\n",
      "train reg_fs: 0.0014008836587890983\n",
      "Epoch: 12500 train loss=0.001999955 valid loss= 0.003957787\n",
      "train reg_fs: 0.0013983998214825988\n",
      "Epoch: 13000 train loss=0.004125591 valid loss= 0.003844561\n",
      "train reg_fs: 0.0013965717516839504\n",
      "Epoch: 13500 train loss=0.001939221 valid loss= 0.003545923\n",
      "train reg_fs: 0.0013951144646853209\n",
      "Epoch: 14000 train loss=0.003894298 valid loss= 0.003282427\n",
      "train reg_fs: 0.0013920452911406755\n",
      "Epoch: 14500 train loss=0.003724465 valid loss= 0.003646435\n",
      "train reg_fs: 0.00139189965557307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:30:12,888]\u001b[0m Trial 39 finished with value: 0.0024270693479992327 and parameters: {'lam': 0.0019388053339815412, 'learning_rate': 0.05338106262173682, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004252170 valid loss= 0.003807864\n",
      "train reg_fs: 0.0013903218787163496\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024270693479992327\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.023282809 valid loss= 0.012102537\n",
      "train reg_fs: 0.004469546023756266\n",
      "Epoch: 1000 train loss=0.011811104 valid loss= 0.011922088\n",
      "train reg_fs: 0.004530505742877722\n",
      "Epoch: 1500 train loss=0.016165692 valid loss= 0.011309410\n",
      "train reg_fs: 0.004562244284898043\n",
      "Epoch: 2000 train loss=0.019343657 valid loss= 0.010809658\n",
      "train reg_fs: 0.004560116212815046\n",
      "Epoch: 2500 train loss=0.008283755 valid loss= 0.010190237\n",
      "train reg_fs: 0.004529296886175871\n",
      "Epoch: 3000 train loss=0.009888120 valid loss= 0.010430162\n",
      "train reg_fs: 0.004480206407606602\n",
      "Epoch: 3500 train loss=0.009578753 valid loss= 0.009983882\n",
      "train reg_fs: 0.004409540444612503\n",
      "Epoch: 4000 train loss=0.014860440 valid loss= 0.008775130\n",
      "train reg_fs: 0.004346985835582018\n",
      "Epoch: 4500 train loss=0.012181696 valid loss= 0.008464012\n",
      "train reg_fs: 0.004284419119358063\n",
      "Epoch: 5000 train loss=0.011444120 valid loss= 0.008001865\n",
      "train reg_fs: 0.0042175063863396645\n",
      "Epoch: 5500 train loss=0.008230999 valid loss= 0.007579275\n",
      "train reg_fs: 0.004152350127696991\n",
      "Epoch: 6000 train loss=0.010390701 valid loss= 0.007009202\n",
      "train reg_fs: 0.0040785400196909904\n",
      "Epoch: 6500 train loss=0.007567849 valid loss= 0.006912795\n",
      "train reg_fs: 0.004000713117420673\n",
      "Epoch: 7000 train loss=0.005818318 valid loss= 0.006953725\n",
      "train reg_fs: 0.003930685576051474\n",
      "Epoch: 7500 train loss=0.007515258 valid loss= 0.006635190\n",
      "train reg_fs: 0.003869035979732871\n",
      "Epoch: 8000 train loss=0.005642937 valid loss= 0.006548160\n",
      "train reg_fs: 0.003809301182627678\n",
      "Epoch: 8500 train loss=0.006013631 valid loss= 0.006506494\n",
      "train reg_fs: 0.003754137549549341\n",
      "Epoch: 9000 train loss=0.008499881 valid loss= 0.006744478\n",
      "train reg_fs: 0.0037031550891697407\n",
      "Epoch: 9500 train loss=0.004053200 valid loss= 0.006123366\n",
      "train reg_fs: 0.0036566529888659716\n",
      "Epoch: 10000 train loss=0.013695091 valid loss= 0.006386209\n",
      "train reg_fs: 0.003610920626670122\n",
      "Epoch: 10500 train loss=0.006708759 valid loss= 0.006118934\n",
      "train reg_fs: 0.0035712127573788166\n",
      "Epoch: 11000 train loss=0.005406799 valid loss= 0.006066792\n",
      "train reg_fs: 0.0035355479922145605\n",
      "Epoch: 11500 train loss=0.004251384 valid loss= 0.005925990\n",
      "train reg_fs: 0.0035004778765141964\n",
      "Epoch: 12000 train loss=0.007502514 valid loss= 0.005910571\n",
      "train reg_fs: 0.0034729312174022198\n",
      "Epoch: 12500 train loss=0.006579064 valid loss= 0.005833247\n",
      "train reg_fs: 0.003446602262556553\n",
      "Epoch: 13000 train loss=0.008882055 valid loss= 0.006246182\n",
      "train reg_fs: 0.0034222551621496677\n",
      "Epoch: 13500 train loss=0.006620298 valid loss= 0.005906995\n",
      "train reg_fs: 0.003400560934096575\n",
      "Epoch: 14000 train loss=0.004041117 valid loss= 0.005875156\n",
      "train reg_fs: 0.0033813330810517073\n",
      "Epoch: 14500 train loss=0.004588801 valid loss= 0.006053547\n",
      "train reg_fs: 0.0033627639058977365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:32:02,149]\u001b[0m Trial 40 finished with value: 0.002762404815191015 and parameters: {'lam': 0.005211885968346816, 'learning_rate': 0.03735066565360419, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006465582 valid loss= 0.006101580\n",
      "train reg_fs: 0.0033468985930085182\n",
      "In trial:---------------------\n",
      "validation mse: 0.002762404815191015\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007114328 valid loss= 0.007091880\n",
      "train reg_fs: 0.0011192434467375278\n",
      "Epoch: 1000 train loss=0.011065379 valid loss= 0.006770146\n",
      "train reg_fs: 0.0011075458023697138\n",
      "Epoch: 1500 train loss=0.008960622 valid loss= 0.006050971\n",
      "train reg_fs: 0.0010792381362989545\n",
      "Epoch: 2000 train loss=0.007722312 valid loss= 0.004625804\n",
      "train reg_fs: 0.001050313119776547\n",
      "Epoch: 2500 train loss=0.004934060 valid loss= 0.003553392\n",
      "train reg_fs: 0.0010179030941799283\n",
      "Epoch: 3000 train loss=0.007990965 valid loss= 0.003873766\n",
      "train reg_fs: 0.000995894311927259\n",
      "Epoch: 3500 train loss=0.002255736 valid loss= 0.003693845\n",
      "train reg_fs: 0.0009771347977221012\n",
      "Epoch: 4000 train loss=0.001693951 valid loss= 0.003762906\n",
      "train reg_fs: 0.0009642601944506168\n",
      "Epoch: 4500 train loss=0.002870029 valid loss= 0.003475758\n",
      "train reg_fs: 0.000953216920606792\n",
      "Epoch: 5000 train loss=0.002480616 valid loss= 0.003373624\n",
      "train reg_fs: 0.000946075830142945\n",
      "Epoch: 5500 train loss=0.001912988 valid loss= 0.003176628\n",
      "train reg_fs: 0.0009392952779307961\n",
      "Epoch: 6000 train loss=0.011150448 valid loss= 0.003237865\n",
      "train reg_fs: 0.0009346312726847827\n",
      "Epoch: 6500 train loss=0.001217319 valid loss= 0.002893477\n",
      "train reg_fs: 0.0009307836880907416\n",
      "Epoch: 7000 train loss=0.002186350 valid loss= 0.003133743\n",
      "train reg_fs: 0.000928429770283401\n",
      "Epoch: 7500 train loss=0.002250001 valid loss= 0.003261813\n",
      "train reg_fs: 0.0009251197916455567\n",
      "Epoch: 8000 train loss=0.004659618 valid loss= 0.003254054\n",
      "train reg_fs: 0.0009225011453963816\n",
      "Epoch: 8500 train loss=0.002010223 valid loss= 0.002938509\n",
      "train reg_fs: 0.0009204104426316917\n",
      "Epoch: 9000 train loss=0.001517082 valid loss= 0.002808846\n",
      "train reg_fs: 0.0009180439519695938\n",
      "Epoch: 9500 train loss=0.005088349 valid loss= 0.003025731\n",
      "train reg_fs: 0.0009169915574602783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:33:15,204]\u001b[0m Trial 41 finished with value: 0.0025355540422155706 and parameters: {'lam': 0.0012831890662506806, 'learning_rate': 0.08128021935416956, 'num_epoch': 10000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003035766 valid loss= 0.003419939\n",
      "train reg_fs: 0.0009155372390523553\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025355540422155706\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005659852 valid loss= 0.005375796\n",
      "train reg_fs: 0.001274771522730589\n",
      "Epoch: 1000 train loss=0.011944079 valid loss= 0.003494301\n",
      "train reg_fs: 0.0012027891352772713\n",
      "Epoch: 1500 train loss=0.003806381 valid loss= 0.003741832\n",
      "train reg_fs: 0.0011951200431212783\n",
      "Epoch: 2000 train loss=0.003138581 valid loss= 0.004176937\n",
      "train reg_fs: 0.0011928001185879111\n",
      "Epoch: 2500 train loss=0.002691549 valid loss= 0.003812263\n",
      "train reg_fs: 0.0011808761628344655\n",
      "Epoch: 3000 train loss=0.002744045 valid loss= 0.003842392\n",
      "train reg_fs: 0.0011635373812168837\n",
      "Epoch: 3500 train loss=0.007756028 valid loss= 0.003337057\n",
      "train reg_fs: 0.0011479350505396724\n",
      "Epoch: 4000 train loss=0.004768771 valid loss= 0.003376342\n",
      "train reg_fs: 0.0011380183277651668\n",
      "Epoch: 4500 train loss=0.001573385 valid loss= 0.003441217\n",
      "train reg_fs: 0.0011317312018945813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:33:52,396]\u001b[0m Trial 42 finished with value: 0.002193659461436619 and parameters: {'lam': 0.0015298667886162111, 'learning_rate': 0.16154614838600498, 'num_epoch': 5000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.001688432 valid loss= 0.003300337\n",
      "train reg_fs: 0.0011231763055548072\n",
      "In trial:---------------------\n",
      "validation mse: 0.002193659461436619\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008766464 valid loss= 0.007364210\n",
      "train reg_fs: 0.0011835212353616953\n",
      "Epoch: 1000 train loss=0.009035303 valid loss= 0.007581231\n",
      "train reg_fs: 0.0011789667187258601\n",
      "Epoch: 1500 train loss=0.004102434 valid loss= 0.006190553\n",
      "train reg_fs: 0.001144046662375331\n",
      "Epoch: 2000 train loss=0.003571138 valid loss= 0.004595810\n",
      "train reg_fs: 0.0011154079111292958\n",
      "Epoch: 2500 train loss=0.005059394 valid loss= 0.003584500\n",
      "train reg_fs: 0.0010904815280809999\n",
      "Epoch: 3000 train loss=0.003786580 valid loss= 0.003936616\n",
      "train reg_fs: 0.001068854471668601\n",
      "Epoch: 3500 train loss=0.003065049 valid loss= 0.003518837\n",
      "train reg_fs: 0.0010511965956538916\n",
      "Epoch: 4000 train loss=0.013890403 valid loss= 0.003926033\n",
      "train reg_fs: 0.0010381964966654778\n",
      "Epoch: 4500 train loss=0.002705644 valid loss= 0.003535513\n",
      "train reg_fs: 0.0010261222487315536\n",
      "Epoch: 5000 train loss=0.003719032 valid loss= 0.003478490\n",
      "train reg_fs: 0.0010165802668780088\n",
      "Epoch: 5500 train loss=0.004615300 valid loss= 0.003558188\n",
      "train reg_fs: 0.0010061223292723298\n",
      "Epoch: 6000 train loss=0.002383386 valid loss= 0.003614041\n",
      "train reg_fs: 0.0009972838452085853\n",
      "Epoch: 6500 train loss=0.002014303 valid loss= 0.003640042\n",
      "train reg_fs: 0.0009908792562782764\n",
      "Epoch: 7000 train loss=0.003016569 valid loss= 0.003718308\n",
      "train reg_fs: 0.0009844357846304774\n",
      "Epoch: 7500 train loss=0.007534279 valid loss= 0.003710767\n",
      "train reg_fs: 0.0009782565757632256\n",
      "Epoch: 8000 train loss=0.005606639 valid loss= 0.003617592\n",
      "train reg_fs: 0.0009703063406050205\n",
      "Epoch: 8500 train loss=0.002420894 valid loss= 0.003729252\n",
      "train reg_fs: 0.0009638488991186023\n",
      "Epoch: 9000 train loss=0.001304652 valid loss= 0.003647775\n",
      "train reg_fs: 0.0009583603823557496\n",
      "Epoch: 9500 train loss=0.003677854 valid loss= 0.003471417\n",
      "train reg_fs: 0.0009555841097608209\n",
      "Epoch: 10000 train loss=0.002507631 valid loss= 0.003550792\n",
      "train reg_fs: 0.0009505224297754467\n",
      "Epoch: 10500 train loss=0.006474382 valid loss= 0.003249212\n",
      "train reg_fs: 0.000945848529227078\n",
      "Epoch: 11000 train loss=0.002811452 valid loss= 0.003897233\n",
      "train reg_fs: 0.000943186751101166\n",
      "Epoch: 11500 train loss=0.001950297 valid loss= 0.003270156\n",
      "train reg_fs: 0.0009396386449225247\n",
      "Epoch: 12000 train loss=0.001422111 valid loss= 0.003513182\n",
      "train reg_fs: 0.0009370386833325028\n",
      "Epoch: 12500 train loss=0.002674405 valid loss= 0.003442155\n",
      "train reg_fs: 0.0009362353011965752\n",
      "Epoch: 13000 train loss=0.002031231 valid loss= 0.003377798\n",
      "train reg_fs: 0.0009342996054328978\n",
      "Epoch: 13500 train loss=0.003377845 valid loss= 0.003433330\n",
      "train reg_fs: 0.000932453665882349\n",
      "Epoch: 14000 train loss=0.001098193 valid loss= 0.003642063\n",
      "train reg_fs: 0.0009315010975115001\n",
      "Epoch: 14500 train loss=0.002589450 valid loss= 0.003460820\n",
      "train reg_fs: 0.000929890142288059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:35:42,171]\u001b[0m Trial 43 finished with value: 0.0024122457627848218 and parameters: {'lam': 0.001349333531149534, 'learning_rate': 0.11312767430209801, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002060309 valid loss= 0.003316130\n",
      "train reg_fs: 0.0009265413391403854\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024122457627848218\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018776383 valid loss= 0.008682309\n",
      "train reg_fs: 0.0025148610584437847\n",
      "Epoch: 1000 train loss=0.007742289 valid loss= 0.009030446\n",
      "train reg_fs: 0.002521986374631524\n",
      "Epoch: 1500 train loss=0.018901758 valid loss= 0.008017326\n",
      "train reg_fs: 0.0024739750660955906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:35:58,138]\u001b[0m Trial 44 finished with value: 0.0036641022008265423 and parameters: {'lam': 0.0029291224789851494, 'learning_rate': 0.06582387598615477, 'num_epoch': 2000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.007608534 valid loss= 0.006126136\n",
      "train reg_fs: 0.002398428274318576\n",
      "In trial:---------------------\n",
      "validation mse: 0.0036641022008265423\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008347100 valid loss= 0.007362146\n",
      "train reg_fs: 0.0008550852653570473\n",
      "Epoch: 1000 train loss=0.017163979 valid loss= 0.005633326\n",
      "train reg_fs: 0.0008303991053253412\n",
      "Epoch: 1500 train loss=0.006645427 valid loss= 0.004216569\n",
      "train reg_fs: 0.0007970876758918166\n",
      "Epoch: 2000 train loss=0.004057988 valid loss= 0.003209583\n",
      "train reg_fs: 0.0007648302125744522\n",
      "Epoch: 2500 train loss=0.003441248 valid loss= 0.003830396\n",
      "train reg_fs: 0.0007381791947409511\n",
      "Epoch: 3000 train loss=0.001769264 valid loss= 0.003519146\n",
      "train reg_fs: 0.0007153719780035317\n",
      "Epoch: 3500 train loss=0.005308218 valid loss= 0.003679971\n",
      "train reg_fs: 0.0006980342441238463\n",
      "Epoch: 4000 train loss=0.004435780 valid loss= 0.003421992\n",
      "train reg_fs: 0.0006834790110588074\n",
      "Epoch: 4500 train loss=0.001890536 valid loss= 0.003222432\n",
      "train reg_fs: 0.0006729289307259023\n",
      "Epoch: 5000 train loss=0.002518141 valid loss= 0.002864873\n",
      "train reg_fs: 0.0006644512759521604\n",
      "Epoch: 5500 train loss=0.001735399 valid loss= 0.003062979\n",
      "train reg_fs: 0.0006575996521860361\n",
      "Epoch: 6000 train loss=0.005692796 valid loss= 0.002983561\n",
      "train reg_fs: 0.0006518479203805327\n",
      "Epoch: 6500 train loss=0.001924074 valid loss= 0.003167987\n",
      "train reg_fs: 0.0006467788480222225\n",
      "Epoch: 7000 train loss=0.003901810 valid loss= 0.003054698\n",
      "train reg_fs: 0.0006425682222470641\n",
      "Epoch: 7500 train loss=0.014519118 valid loss= 0.003137560\n",
      "train reg_fs: 0.0006392571376636624\n",
      "Epoch: 8000 train loss=0.001931664 valid loss= 0.002992320\n",
      "train reg_fs: 0.0006356489611789584\n",
      "Epoch: 8500 train loss=0.001781670 valid loss= 0.002950069\n",
      "train reg_fs: 0.0006330819451250136\n",
      "Epoch: 9000 train loss=0.007400043 valid loss= 0.002816994\n",
      "train reg_fs: 0.0006306731957010925\n",
      "Epoch: 9500 train loss=0.000960046 valid loss= 0.002937243\n",
      "train reg_fs: 0.0006288146250881255\n",
      "Epoch: 10000 train loss=0.000869512 valid loss= 0.003154129\n",
      "train reg_fs: 0.0006265551783144474\n",
      "Epoch: 10500 train loss=0.001543634 valid loss= 0.003335337\n",
      "train reg_fs: 0.0006247484125196934\n",
      "Epoch: 11000 train loss=0.004602836 valid loss= 0.002776800\n",
      "train reg_fs: 0.0006231533479876816\n",
      "Epoch: 11500 train loss=0.002980550 valid loss= 0.003116552\n",
      "train reg_fs: 0.0006217873888090253\n",
      "Epoch: 12000 train loss=0.001323798 valid loss= 0.003062845\n",
      "train reg_fs: 0.0006205003592185676\n",
      "Epoch: 12500 train loss=0.000799368 valid loss= 0.003056718\n",
      "train reg_fs: 0.0006191606516949832\n",
      "Epoch: 13000 train loss=0.001155322 valid loss= 0.002892313\n",
      "train reg_fs: 0.0006180171039886773\n",
      "Epoch: 13500 train loss=0.002305607 valid loss= 0.002819303\n",
      "train reg_fs: 0.00061707419808954\n",
      "Epoch: 14000 train loss=0.002050621 valid loss= 0.002733990\n",
      "train reg_fs: 0.0006160254124552011\n",
      "Epoch: 14500 train loss=0.000927091 valid loss= 0.002798273\n",
      "train reg_fs: 0.0006151569541543722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:37:49,246]\u001b[0m Trial 45 finished with value: 0.002587079552372091 and parameters: {'lam': 0.0010016569342692924, 'learning_rate': 0.09969040368800713, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001785505 valid loss= 0.003190709\n",
      "train reg_fs: 0.0006144146900624037\n",
      "In trial:---------------------\n",
      "validation mse: 0.002587079552372091\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012914618 valid loss= 0.008855571\n",
      "train reg_fs: 0.0022121381480246782\n",
      "Epoch: 1000 train loss=0.009734794 valid loss= 0.007645132\n",
      "train reg_fs: 0.002099113306030631\n",
      "Epoch: 1500 train loss=0.003810452 valid loss= 0.004516244\n",
      "train reg_fs: 0.002015521051362157\n",
      "Epoch: 2000 train loss=0.006842275 valid loss= 0.004553107\n",
      "train reg_fs: 0.0019941588398069143\n",
      "Epoch: 2500 train loss=0.005918269 valid loss= 0.004808899\n",
      "train reg_fs: 0.001975946594029665\n",
      "Epoch: 3000 train loss=0.003408392 valid loss= 0.004763260\n",
      "train reg_fs: 0.001950925448909402\n",
      "Epoch: 3500 train loss=0.003324200 valid loss= 0.004413527\n",
      "train reg_fs: 0.0019300816347822547\n",
      "Epoch: 4000 train loss=0.002807581 valid loss= 0.003846653\n",
      "train reg_fs: 0.0019161147065460682\n",
      "Epoch: 4500 train loss=0.002678390 valid loss= 0.003912071\n",
      "train reg_fs: 0.0019096734467893839\n",
      "Epoch: 5000 train loss=0.003702455 valid loss= 0.003964051\n",
      "train reg_fs: 0.0019023898057639599\n",
      "Epoch: 5500 train loss=0.004502098 valid loss= 0.003541230\n",
      "train reg_fs: 0.0018981389002874494\n",
      "Epoch: 6000 train loss=0.004330326 valid loss= 0.004073010\n",
      "train reg_fs: 0.0018948165234178305\n",
      "Epoch: 6500 train loss=0.013959494 valid loss= 0.003936379\n",
      "train reg_fs: 0.0018925173208117485\n",
      "Epoch: 7000 train loss=0.002297483 valid loss= 0.003866096\n",
      "train reg_fs: 0.0018907159101217985\n",
      "Epoch: 7500 train loss=0.003531286 valid loss= 0.003881774\n",
      "train reg_fs: 0.0018894894747063518\n",
      "Epoch: 8000 train loss=0.006981812 valid loss= 0.003589385\n",
      "train reg_fs: 0.0018867241451516747\n",
      "Epoch: 8500 train loss=0.004494083 valid loss= 0.003462560\n",
      "train reg_fs: 0.0018842883873730898\n",
      "Epoch: 9000 train loss=0.003037583 valid loss= 0.004152803\n",
      "train reg_fs: 0.0018806365551427007\n",
      "Epoch: 9500 train loss=0.003004156 valid loss= 0.003746960\n",
      "train reg_fs: 0.0018774342024698853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:39:03,542]\u001b[0m Trial 46 finished with value: 0.0021432573164599207 and parameters: {'lam': 0.0025471993674542706, 'learning_rate': 0.12360160298471679, 'num_epoch': 10000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002668186 valid loss= 0.003963143\n",
      "train reg_fs: 0.001874026726000011\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021432573164599207\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.004240252 valid loss= 0.004264014\n",
      "train reg_fs: 0.001012423075735569\n",
      "Epoch: 1000 train loss=0.009950579 valid loss= 0.003641361\n",
      "train reg_fs: 0.0009483981993980706\n",
      "Epoch: 1500 train loss=0.004887702 valid loss= 0.003054828\n",
      "train reg_fs: 0.0009317686199210584\n",
      "Epoch: 2000 train loss=0.001876003 valid loss= 0.003232472\n",
      "train reg_fs: 0.0009163303184323013\n",
      "Epoch: 2500 train loss=0.002059801 valid loss= 0.003099581\n",
      "train reg_fs: 0.0009051245870068669\n",
      "Epoch: 3000 train loss=0.001306856 valid loss= 0.003217370\n",
      "train reg_fs: 0.0008983101579360664\n",
      "Epoch: 3500 train loss=0.002378987 valid loss= 0.003311902\n",
      "train reg_fs: 0.0008943738648667932\n",
      "Epoch: 4000 train loss=0.001462013 valid loss= 0.003262085\n",
      "train reg_fs: 0.0008915991056710482\n",
      "Epoch: 4500 train loss=0.003016800 valid loss= 0.002885194\n",
      "train reg_fs: 0.0008900334360077977\n",
      "Epoch: 5000 train loss=0.001608683 valid loss= 0.003068765\n",
      "train reg_fs: 0.0008887188159860671\n",
      "Epoch: 5500 train loss=0.002778216 valid loss= 0.003041410\n",
      "train reg_fs: 0.0008878133958205581\n",
      "Epoch: 6000 train loss=0.001663148 valid loss= 0.002856955\n",
      "train reg_fs: 0.0008874075138010085\n",
      "Epoch: 6500 train loss=0.001527091 valid loss= 0.002787846\n",
      "train reg_fs: 0.0008868924924172461\n",
      "Epoch: 7000 train loss=0.001617654 valid loss= 0.003010804\n",
      "train reg_fs: 0.0008864944102242589\n",
      "Epoch: 7500 train loss=0.002179622 valid loss= 0.002583546\n",
      "train reg_fs: 0.0008861601818352938\n",
      "Epoch: 8000 train loss=0.001309304 valid loss= 0.002772910\n",
      "train reg_fs: 0.0008858581422828138\n",
      "Epoch: 8500 train loss=0.003980639 valid loss= 0.002545477\n",
      "train reg_fs: 0.0008853701292537153\n",
      "Epoch: 9000 train loss=0.002239306 valid loss= 0.002782382\n",
      "train reg_fs: 0.0008854906773194671\n",
      "Epoch: 9500 train loss=0.012264878 valid loss= 0.002539885\n",
      "train reg_fs: 0.0008854865445755422\n",
      "Epoch: 10000 train loss=0.005603910 valid loss= 0.002449852\n",
      "train reg_fs: 0.0008853970211930573\n",
      "Epoch: 10500 train loss=0.002513270 valid loss= 0.002671559\n",
      "train reg_fs: 0.0008852676837705076\n",
      "Epoch: 11000 train loss=0.001636162 valid loss= 0.002779698\n",
      "train reg_fs: 0.0008852768805809319\n",
      "Epoch: 11500 train loss=0.003442715 valid loss= 0.002544766\n",
      "train reg_fs: 0.0008852003957144916\n",
      "Epoch: 12000 train loss=0.004443327 valid loss= 0.002584341\n",
      "train reg_fs: 0.0008843380492180586\n",
      "Epoch: 12500 train loss=0.001180531 valid loss= 0.002478561\n",
      "train reg_fs: 0.000883942237123847\n",
      "Epoch: 13000 train loss=0.004974472 valid loss= 0.002440873\n",
      "train reg_fs: 0.000882977619767189\n",
      "Epoch: 13500 train loss=0.002668748 valid loss= 0.002339422\n",
      "train reg_fs: 0.0008821609662845731\n",
      "Epoch: 14000 train loss=0.004202636 valid loss= 0.002521717\n",
      "train reg_fs: 0.0008813707390800118\n",
      "Epoch: 14500 train loss=0.001989190 valid loss= 0.002451090\n",
      "train reg_fs: 0.0008796813199296594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:40:52,237]\u001b[0m Trial 47 finished with value: 0.0013788881808121495 and parameters: {'lam': 0.001182668665279509, 'learning_rate': 0.15031563834383566, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002324504 valid loss= 0.002238951\n",
      "train reg_fs: 0.0008769018459133804\n",
      "In trial:---------------------\n",
      "validation mse: 0.0013788881808121495\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008857304 valid loss= 0.008450793\n",
      "train reg_fs: 0.001007299986667931\n",
      "Epoch: 1000 train loss=0.021111250 valid loss= 0.008369660\n",
      "train reg_fs: 0.0009675014298409224\n",
      "Epoch: 1500 train loss=0.008025069 valid loss= 0.007300483\n",
      "train reg_fs: 0.0009466870105825365\n",
      "Epoch: 2000 train loss=0.005667123 valid loss= 0.006692373\n",
      "train reg_fs: 0.000941227946896106\n",
      "Epoch: 2500 train loss=0.005140517 valid loss= 0.006108185\n",
      "train reg_fs: 0.0009412702638655901\n",
      "Epoch: 3000 train loss=0.003833042 valid loss= 0.005290196\n",
      "train reg_fs: 0.0009479589643888175\n",
      "Epoch: 3500 train loss=0.005736249 valid loss= 0.004893330\n",
      "train reg_fs: 0.0009489181684330106\n",
      "Epoch: 4000 train loss=0.002960814 valid loss= 0.005216440\n",
      "train reg_fs: 0.0009409586782567203\n",
      "Epoch: 4500 train loss=0.005330241 valid loss= 0.004884041\n",
      "train reg_fs: 0.0009385052835568786\n",
      "Epoch: 5000 train loss=0.004021948 valid loss= 0.004552068\n",
      "train reg_fs: 0.0009351061889901757\n",
      "Epoch: 5500 train loss=0.001675054 valid loss= 0.004528544\n",
      "train reg_fs: 0.0009295982890762389\n",
      "Epoch: 6000 train loss=0.003539273 valid loss= 0.004518081\n",
      "train reg_fs: 0.0009217664483003318\n",
      "Epoch: 6500 train loss=0.001708459 valid loss= 0.004461326\n",
      "train reg_fs: 0.0009131876868195832\n",
      "Epoch: 7000 train loss=0.002925439 valid loss= 0.004451295\n",
      "train reg_fs: 0.0009000705904327333\n",
      "Epoch: 7500 train loss=0.001469833 valid loss= 0.004345747\n",
      "train reg_fs: 0.0008977082907222211\n",
      "Epoch: 8000 train loss=0.002723736 valid loss= 0.004691116\n",
      "train reg_fs: 0.0008880691602826118\n",
      "Epoch: 8500 train loss=0.002171372 valid loss= 0.004306355\n",
      "train reg_fs: 0.0008806920959614217\n",
      "Epoch: 9000 train loss=0.001678318 valid loss= 0.004604780\n",
      "train reg_fs: 0.000873790995683521\n",
      "Epoch: 9500 train loss=0.002025916 valid loss= 0.004772951\n",
      "train reg_fs: 0.0008657504222355783\n",
      "Epoch: 10000 train loss=0.001183584 valid loss= 0.004691730\n",
      "train reg_fs: 0.0008626056951470673\n",
      "Epoch: 10500 train loss=0.001196005 valid loss= 0.004728850\n",
      "train reg_fs: 0.0008551845094189048\n",
      "Epoch: 11000 train loss=0.003830906 valid loss= 0.004322664\n",
      "train reg_fs: 0.0008495452930219471\n",
      "Epoch: 11500 train loss=0.005624318 valid loss= 0.004570254\n",
      "train reg_fs: 0.0008425228879787028\n",
      "Epoch: 12000 train loss=0.001235627 valid loss= 0.004500739\n",
      "train reg_fs: 0.0008344094385392964\n",
      "Epoch: 12500 train loss=0.002558985 valid loss= 0.004665427\n",
      "train reg_fs: 0.0008279968169517815\n",
      "Epoch: 13000 train loss=0.002464113 valid loss= 0.004637539\n",
      "train reg_fs: 0.0008215084089897573\n",
      "Epoch: 13500 train loss=0.004274254 valid loss= 0.004549935\n",
      "train reg_fs: 0.0008150624926201999\n",
      "Epoch: 14000 train loss=0.001347003 valid loss= 0.004582603\n",
      "train reg_fs: 0.0008093222277238965\n",
      "Epoch: 14500 train loss=0.001090035 valid loss= 0.004462955\n",
      "train reg_fs: 0.0008055288926698267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:42:42,322]\u001b[0m Trial 48 finished with value: 0.0035665695403380216 and parameters: {'lam': 0.0011737960507460965, 'learning_rate': 0.16467346530434657, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001722206 valid loss= 0.004349259\n",
      "train reg_fs: 0.0007998170331120491\n",
      "In trial:---------------------\n",
      "validation mse: 0.0035665695403380216\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015995437 valid loss= 0.007857671\n",
      "train reg_fs: 0.0014212751993909478\n",
      "Epoch: 1000 train loss=0.026378904 valid loss= 0.007772865\n",
      "train reg_fs: 0.0014453912153840065\n",
      "Epoch: 1500 train loss=0.012071580 valid loss= 0.008384462\n",
      "train reg_fs: 0.0014564170269295573\n",
      "Epoch: 2000 train loss=0.008097480 valid loss= 0.007383508\n",
      "train reg_fs: 0.0014581360155716538\n",
      "Epoch: 2500 train loss=0.004823558 valid loss= 0.007100588\n",
      "train reg_fs: 0.0014515116345137358\n",
      "Epoch: 3000 train loss=0.018290566 valid loss= 0.006869097\n",
      "train reg_fs: 0.0014342206995934248\n",
      "Epoch: 3500 train loss=0.005803873 valid loss= 0.005361702\n",
      "train reg_fs: 0.001407523755915463\n",
      "Epoch: 4000 train loss=0.008703743 valid loss= 0.004375335\n",
      "train reg_fs: 0.0013765498297289014\n",
      "Epoch: 4500 train loss=0.003358287 valid loss= 0.003500396\n",
      "train reg_fs: 0.00134712690487504\n",
      "Epoch: 5000 train loss=0.004972554 valid loss= 0.003555627\n",
      "train reg_fs: 0.0013249675976112485\n",
      "Epoch: 5500 train loss=0.002118316 valid loss= 0.003411088\n",
      "train reg_fs: 0.0013070357963442802\n",
      "Epoch: 6000 train loss=0.007973885 valid loss= 0.003358491\n",
      "train reg_fs: 0.0012963534099981189\n",
      "Epoch: 6500 train loss=0.004921871 valid loss= 0.003135765\n",
      "train reg_fs: 0.0012902477756142616\n",
      "Epoch: 7000 train loss=0.003028634 valid loss= 0.003346519\n",
      "train reg_fs: 0.0012873780215159059\n",
      "Epoch: 7500 train loss=0.006336510 valid loss= 0.003275140\n",
      "train reg_fs: 0.0012868426274508238\n",
      "Epoch: 8000 train loss=0.003592008 valid loss= 0.003225110\n",
      "train reg_fs: 0.0012875240063294768\n",
      "Epoch: 8500 train loss=0.002878287 valid loss= 0.003054881\n",
      "train reg_fs: 0.001287749852053821\n",
      "Epoch: 9000 train loss=0.002958447 valid loss= 0.003235525\n",
      "train reg_fs: 0.0012871838407590985\n",
      "Epoch: 9500 train loss=0.003755313 valid loss= 0.002724271\n",
      "train reg_fs: 0.0012873176019638777\n",
      "Epoch: 10000 train loss=0.016772281 valid loss= 0.003109414\n",
      "train reg_fs: 0.0012864680029451847\n",
      "Epoch: 10500 train loss=0.005677522 valid loss= 0.003128753\n",
      "train reg_fs: 0.0012842373689636588\n",
      "Epoch: 11000 train loss=0.008815104 valid loss= 0.002817888\n",
      "train reg_fs: 0.00128104817122221\n",
      "Epoch: 11500 train loss=0.003779577 valid loss= 0.002728666\n",
      "train reg_fs: 0.0012777268420904875\n",
      "Epoch: 12000 train loss=0.005591542 valid loss= 0.002463189\n",
      "train reg_fs: 0.0012739206431433558\n",
      "Epoch: 12500 train loss=0.005404775 valid loss= 0.002895799\n",
      "train reg_fs: 0.0012688415590673685\n",
      "Epoch: 13000 train loss=0.001797521 valid loss= 0.002613353\n",
      "train reg_fs: 0.0012635905295610428\n",
      "Epoch: 13500 train loss=0.001922941 valid loss= 0.002979882\n",
      "train reg_fs: 0.001256674062460661\n",
      "Epoch: 14000 train loss=0.003349128 valid loss= 0.002750489\n",
      "train reg_fs: 0.0012501407181844115\n",
      "Epoch: 14500 train loss=0.004106632 valid loss= 0.002403763\n",
      "train reg_fs: 0.0012425855966284871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:44:31,332]\u001b[0m Trial 49 finished with value: 0.001457537674754771 and parameters: {'lam': 0.0016488777089248708, 'learning_rate': 0.04790935303135998, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002285280 valid loss= 0.002704752\n",
      "train reg_fs: 0.0012365321163088083\n",
      "In trial:---------------------\n",
      "validation mse: 0.001457537674754771\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016927579 valid loss= 0.011708168\n",
      "train reg_fs: 0.00612120283767581\n",
      "Epoch: 1000 train loss=0.014147151 valid loss= 0.011046361\n",
      "train reg_fs: 0.005955332424491644\n",
      "Epoch: 1500 train loss=0.008155910 valid loss= 0.008694703\n",
      "train reg_fs: 0.005585595965385437\n",
      "Epoch: 2000 train loss=0.007917277 valid loss= 0.008412774\n",
      "train reg_fs: 0.005357835907489061\n",
      "Epoch: 2500 train loss=0.012745555 valid loss= 0.008764584\n",
      "train reg_fs: 0.005218196660280228\n",
      "Epoch: 3000 train loss=0.006732776 valid loss= 0.009252403\n",
      "train reg_fs: 0.005096544045954943\n",
      "Epoch: 3500 train loss=0.006215232 valid loss= 0.009443332\n",
      "train reg_fs: 0.004979927092790604\n",
      "Epoch: 4000 train loss=0.008821866 valid loss= 0.008764533\n",
      "train reg_fs: 0.004849875345826149\n",
      "Epoch: 4500 train loss=0.007177291 valid loss= 0.008991508\n",
      "train reg_fs: 0.004709911998361349\n",
      "Epoch: 5000 train loss=0.008479234 valid loss= 0.008798268\n",
      "train reg_fs: 0.004575968720018864\n",
      "Epoch: 5500 train loss=0.006431806 valid loss= 0.008456441\n",
      "train reg_fs: 0.004464470315724611\n",
      "Epoch: 6000 train loss=0.006190100 valid loss= 0.008619700\n",
      "train reg_fs: 0.004368736408650875\n",
      "Epoch: 6500 train loss=0.006181241 valid loss= 0.008529817\n",
      "train reg_fs: 0.0043054986745119095\n",
      "Epoch: 7000 train loss=0.007476917 valid loss= 0.008575005\n",
      "train reg_fs: 0.004260636400431395\n",
      "Epoch: 7500 train loss=0.007702203 valid loss= 0.008408116\n",
      "train reg_fs: 0.0042251949198544025\n",
      "Epoch: 8000 train loss=0.009058945 valid loss= 0.008527219\n",
      "train reg_fs: 0.004198485054075718\n",
      "Epoch: 8500 train loss=0.006552519 valid loss= 0.008070908\n",
      "train reg_fs: 0.004175227135419846\n",
      "Epoch: 9000 train loss=0.007089202 valid loss= 0.008625719\n",
      "train reg_fs: 0.004157991614192724\n",
      "Epoch: 9500 train loss=0.009851719 valid loss= 0.008250939\n",
      "train reg_fs: 0.004142505116760731\n",
      "Epoch: 10000 train loss=0.007739523 valid loss= 0.008431047\n",
      "train reg_fs: 0.004129448905587196\n",
      "Epoch: 10500 train loss=0.012637183 valid loss= 0.008143716\n",
      "train reg_fs: 0.004118358250707388\n",
      "Epoch: 11000 train loss=0.007090314 valid loss= 0.008663625\n",
      "train reg_fs: 0.004108974244445562\n",
      "Epoch: 11500 train loss=0.008707426 valid loss= 0.008173252\n",
      "train reg_fs: 0.004100531339645386\n",
      "Epoch: 12000 train loss=0.008837961 valid loss= 0.008150225\n",
      "train reg_fs: 0.0040933298878371716\n",
      "Epoch: 12500 train loss=0.007727944 valid loss= 0.008310603\n",
      "train reg_fs: 0.004087148699909449\n",
      "Epoch: 13000 train loss=0.009010023 valid loss= 0.007832279\n",
      "train reg_fs: 0.004081523511558771\n",
      "Epoch: 13500 train loss=0.009924648 valid loss= 0.008552281\n",
      "train reg_fs: 0.0040763383731245995\n",
      "Epoch: 14000 train loss=0.005881896 valid loss= 0.008384306\n",
      "train reg_fs: 0.0040716975927352905\n",
      "Epoch: 14500 train loss=0.011098484 valid loss= 0.008263359\n",
      "train reg_fs: 0.004067502450197935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:46:21,334]\u001b[0m Trial 50 finished with value: 0.004034936342469627 and parameters: {'lam': 0.007102068029459479, 'learning_rate': 0.09377133103619072, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005738762 valid loss= 0.008258112\n",
      "train reg_fs: 0.004063629079610109\n",
      "In trial:---------------------\n",
      "validation mse: 0.004034936342469627\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011101614 valid loss= 0.008958975\n",
      "train reg_fs: 0.001321134390309453\n",
      "Epoch: 1000 train loss=0.009844468 valid loss= 0.008317980\n",
      "train reg_fs: 0.0013242630520835519\n",
      "Epoch: 1500 train loss=0.010477716 valid loss= 0.008089634\n",
      "train reg_fs: 0.0013128482969477773\n",
      "Epoch: 2000 train loss=0.006497601 valid loss= 0.006804182\n",
      "train reg_fs: 0.0013019454199820757\n",
      "Epoch: 2500 train loss=0.016081609 valid loss= 0.006745831\n",
      "train reg_fs: 0.0012922416208311915\n",
      "Epoch: 3000 train loss=0.009545286 valid loss= 0.006662026\n",
      "train reg_fs: 0.001283630495890975\n",
      "Epoch: 3500 train loss=0.007017479 valid loss= 0.006127014\n",
      "train reg_fs: 0.0012732408940792084\n",
      "Epoch: 4000 train loss=0.009984715 valid loss= 0.006080385\n",
      "train reg_fs: 0.0012599147157743573\n",
      "Epoch: 4500 train loss=0.005554565 valid loss= 0.005739513\n",
      "train reg_fs: 0.001241711201146245\n",
      "Epoch: 5000 train loss=0.002585484 valid loss= 0.005512822\n",
      "train reg_fs: 0.001221463899128139\n",
      "Epoch: 5500 train loss=0.004970247 valid loss= 0.004472118\n",
      "train reg_fs: 0.001193610718473792\n",
      "Epoch: 6000 train loss=0.002973727 valid loss= 0.003820740\n",
      "train reg_fs: 0.0011604286264628172\n",
      "Epoch: 6500 train loss=0.002882953 valid loss= 0.003632901\n",
      "train reg_fs: 0.0011314530856907368\n",
      "Epoch: 7000 train loss=0.003529687 valid loss= 0.004143361\n",
      "train reg_fs: 0.0011078353272750974\n",
      "Epoch: 7500 train loss=0.001301990 valid loss= 0.003591135\n",
      "train reg_fs: 0.0010903289075940847\n",
      "Epoch: 8000 train loss=0.011142927 valid loss= 0.003651121\n",
      "train reg_fs: 0.0010753542883321643\n",
      "Epoch: 8500 train loss=0.002287070 valid loss= 0.003565732\n",
      "train reg_fs: 0.0010624071583151817\n",
      "Epoch: 9000 train loss=0.002237856 valid loss= 0.003304515\n",
      "train reg_fs: 0.0010504270903766155\n",
      "Epoch: 9500 train loss=0.005051247 valid loss= 0.003663746\n",
      "train reg_fs: 0.0010415860451757908\n",
      "Epoch: 10000 train loss=0.005982424 valid loss= 0.003496111\n",
      "train reg_fs: 0.0010325844632461667\n",
      "Epoch: 10500 train loss=0.001846589 valid loss= 0.003282320\n",
      "train reg_fs: 0.0010256667155772448\n",
      "Epoch: 11000 train loss=0.001819105 valid loss= 0.003794650\n",
      "train reg_fs: 0.001019113464280963\n",
      "Epoch: 11500 train loss=0.001800761 valid loss= 0.003322753\n",
      "train reg_fs: 0.0010132610332220793\n",
      "Epoch: 12000 train loss=0.005086796 valid loss= 0.003233470\n",
      "train reg_fs: 0.0010081521468237042\n",
      "Epoch: 12500 train loss=0.005815237 valid loss= 0.003659611\n",
      "train reg_fs: 0.0010028163669630885\n",
      "Epoch: 13000 train loss=0.001561158 valid loss= 0.003448736\n",
      "train reg_fs: 0.000998091185465455\n",
      "Epoch: 13500 train loss=0.002628661 valid loss= 0.003669460\n",
      "train reg_fs: 0.0009941101307049394\n",
      "Epoch: 14000 train loss=0.002826521 valid loss= 0.003295989\n",
      "train reg_fs: 0.000990354805253446\n",
      "Epoch: 14500 train loss=0.003648046 valid loss= 0.003454760\n",
      "train reg_fs: 0.0009873630478978157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:48:11,402]\u001b[0m Trial 51 finished with value: 0.0020547463616546516 and parameters: {'lam': 0.0015493001255200568, 'learning_rate': 0.049400452773562885, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001618256 valid loss= 0.003031740\n",
      "train reg_fs: 0.000984291429631412\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020547463616546516\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007102834 valid loss= 0.007838794\n",
      "train reg_fs: 0.001612753956578672\n",
      "Epoch: 1000 train loss=0.012672204 valid loss= 0.006121788\n",
      "train reg_fs: 0.0016283408040180802\n",
      "Epoch: 1500 train loss=0.005202210 valid loss= 0.006387196\n",
      "train reg_fs: 0.0016127880662679672\n",
      "Epoch: 2000 train loss=0.006701369 valid loss= 0.005670045\n",
      "train reg_fs: 0.0015800572000443935\n",
      "Epoch: 2500 train loss=0.006518143 valid loss= 0.004963398\n",
      "train reg_fs: 0.001543787308037281\n",
      "Epoch: 3000 train loss=0.003083973 valid loss= 0.003825286\n",
      "train reg_fs: 0.001506081665866077\n",
      "Epoch: 3500 train loss=0.006575754 valid loss= 0.003993379\n",
      "train reg_fs: 0.001469902927055955\n",
      "Epoch: 4000 train loss=0.003029784 valid loss= 0.003560116\n",
      "train reg_fs: 0.0014398838393390179\n",
      "Epoch: 4500 train loss=0.003244920 valid loss= 0.003510721\n",
      "train reg_fs: 0.001417631865479052\n",
      "Epoch: 5000 train loss=0.002777136 valid loss= 0.003892651\n",
      "train reg_fs: 0.0014003990218043327\n",
      "Epoch: 5500 train loss=0.002083395 valid loss= 0.003826690\n",
      "train reg_fs: 0.0013876475859433413\n",
      "Epoch: 6000 train loss=0.002216737 valid loss= 0.003621157\n",
      "train reg_fs: 0.0013782433234155178\n",
      "Epoch: 6500 train loss=0.003961331 valid loss= 0.003507196\n",
      "train reg_fs: 0.0013695519883185625\n",
      "Epoch: 7000 train loss=0.002349046 valid loss= 0.003804369\n",
      "train reg_fs: 0.0013627579901367426\n",
      "Epoch: 7500 train loss=0.002026719 valid loss= 0.003759702\n",
      "train reg_fs: 0.0013564038090407848\n",
      "Epoch: 8000 train loss=0.009915486 valid loss= 0.003418828\n",
      "train reg_fs: 0.0013507469557225704\n",
      "Epoch: 8500 train loss=0.003350284 valid loss= 0.003355487\n",
      "train reg_fs: 0.0013463812647387385\n",
      "Epoch: 9000 train loss=0.001983897 valid loss= 0.003416425\n",
      "train reg_fs: 0.0013420269824564457\n",
      "Epoch: 9500 train loss=0.002020085 valid loss= 0.003597362\n",
      "train reg_fs: 0.0013383283512666821\n",
      "Epoch: 10000 train loss=0.003311936 valid loss= 0.003455791\n",
      "train reg_fs: 0.0013345620827749372\n",
      "Epoch: 10500 train loss=0.003429092 valid loss= 0.003300080\n",
      "train reg_fs: 0.001330357394181192\n",
      "Epoch: 11000 train loss=0.002341937 valid loss= 0.003204074\n",
      "train reg_fs: 0.001326509634964168\n",
      "Epoch: 11500 train loss=0.004143695 valid loss= 0.003330440\n",
      "train reg_fs: 0.0013237737584859133\n",
      "Epoch: 12000 train loss=0.003581528 valid loss= 0.003442523\n",
      "train reg_fs: 0.0013207608135417104\n",
      "Epoch: 12500 train loss=0.002877594 valid loss= 0.003352470\n",
      "train reg_fs: 0.0013173245824873447\n",
      "Epoch: 13000 train loss=0.001897581 valid loss= 0.003541823\n",
      "train reg_fs: 0.001314401044510305\n",
      "Epoch: 13500 train loss=0.001931820 valid loss= 0.003338806\n",
      "train reg_fs: 0.001311985426582396\n",
      "Epoch: 14000 train loss=0.004887505 valid loss= 0.003115128\n",
      "train reg_fs: 0.0013088664272800088\n",
      "Epoch: 14500 train loss=0.006662965 valid loss= 0.003558754\n",
      "train reg_fs: 0.0013061459176242352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:50:01,625]\u001b[0m Trial 52 finished with value: 0.0020139269350307842 and parameters: {'lam': 0.0018387610610184008, 'learning_rate': 0.06914479902754421, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.019795820 valid loss= 0.003267375\n",
      "train reg_fs: 0.0013035929296165705\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020139269350307842\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015797082 valid loss= 0.008805590\n",
      "train reg_fs: 0.0014776448952034116\n",
      "Epoch: 1000 train loss=0.008262523 valid loss= 0.008527435\n",
      "train reg_fs: 0.001497692777775228\n",
      "Epoch: 1500 train loss=0.010562088 valid loss= 0.008329723\n",
      "train reg_fs: 0.0015042286831885576\n",
      "Epoch: 2000 train loss=0.011875636 valid loss= 0.008003095\n",
      "train reg_fs: 0.0014987383037805557\n",
      "Epoch: 2500 train loss=0.004650793 valid loss= 0.006759373\n",
      "train reg_fs: 0.001473642885684967\n",
      "Epoch: 3000 train loss=0.005681432 valid loss= 0.005442942\n",
      "train reg_fs: 0.0014319219626486301\n",
      "Epoch: 3500 train loss=0.004490662 valid loss= 0.004545236\n",
      "train reg_fs: 0.001389399403706193\n",
      "Epoch: 4000 train loss=0.003391080 valid loss= 0.003728017\n",
      "train reg_fs: 0.0013563897227868438\n",
      "Epoch: 4500 train loss=0.003705177 valid loss= 0.003937463\n",
      "train reg_fs: 0.001334239263087511\n",
      "Epoch: 5000 train loss=0.006770088 valid loss= 0.004005759\n",
      "train reg_fs: 0.0013161960523575544\n",
      "Epoch: 5500 train loss=0.002236129 valid loss= 0.003011040\n",
      "train reg_fs: 0.0013020068872720003\n",
      "Epoch: 6000 train loss=0.005547994 valid loss= 0.002754721\n",
      "train reg_fs: 0.0012883431045338511\n",
      "Epoch: 6500 train loss=0.003846878 valid loss= 0.003462267\n",
      "train reg_fs: 0.0012759430101141334\n",
      "Epoch: 7000 train loss=0.005233285 valid loss= 0.003395932\n",
      "train reg_fs: 0.0012651786673814058\n",
      "Epoch: 7500 train loss=0.002454989 valid loss= 0.003542846\n",
      "train reg_fs: 0.001253206399269402\n",
      "Epoch: 8000 train loss=0.002373270 valid loss= 0.002841802\n",
      "train reg_fs: 0.0012437464902177453\n",
      "Epoch: 8500 train loss=0.007255588 valid loss= 0.002887204\n",
      "train reg_fs: 0.0012345162685960531\n",
      "Epoch: 9000 train loss=0.007098793 valid loss= 0.003188198\n",
      "train reg_fs: 0.0012251228326931596\n",
      "Epoch: 9500 train loss=0.002423929 valid loss= 0.002771429\n",
      "train reg_fs: 0.0012160524493083358\n",
      "Epoch: 10000 train loss=0.002145575 valid loss= 0.002999991\n",
      "train reg_fs: 0.0012059935834258795\n",
      "Epoch: 10500 train loss=0.003235433 valid loss= 0.003125132\n",
      "train reg_fs: 0.0011977156391367316\n",
      "Epoch: 11000 train loss=0.002847717 valid loss= 0.002767864\n",
      "train reg_fs: 0.0011889917077496648\n",
      "Epoch: 11500 train loss=0.004579162 valid loss= 0.002657561\n",
      "train reg_fs: 0.0011808054987341166\n",
      "Epoch: 12000 train loss=0.001565027 valid loss= 0.002276603\n",
      "train reg_fs: 0.0011735126608982682\n",
      "Epoch: 12500 train loss=0.003817362 valid loss= 0.002574587\n",
      "train reg_fs: 0.001163633307442069\n",
      "Epoch: 13000 train loss=0.001653956 valid loss= 0.002618823\n",
      "train reg_fs: 0.0011547402245923877\n",
      "Epoch: 13500 train loss=0.004403512 valid loss= 0.002728558\n",
      "train reg_fs: 0.0011454509804025292\n",
      "Epoch: 14000 train loss=0.003041174 valid loss= 0.002456187\n",
      "train reg_fs: 0.0011354525340721011\n",
      "Epoch: 14500 train loss=0.001453361 valid loss= 0.002623000\n",
      "train reg_fs: 0.0011260260362178087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:51:52,580]\u001b[0m Trial 53 finished with value: 0.001263485590052121 and parameters: {'lam': 0.0017202456261047943, 'learning_rate': 0.04598669027829281, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002783467 valid loss= 0.002405870\n",
      "train reg_fs: 0.0011174498358741403\n",
      "In trial:---------------------\n",
      "validation mse: 0.001263485590052121\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022883713 valid loss= 0.007312162\n",
      "train reg_fs: 0.0018302742391824722\n",
      "Epoch: 1000 train loss=0.007606649 valid loss= 0.006491120\n",
      "train reg_fs: 0.0018384890863671899\n",
      "Epoch: 1500 train loss=0.013476732 valid loss= 0.006039538\n",
      "train reg_fs: 0.001825797720812261\n",
      "Epoch: 2000 train loss=0.010744034 valid loss= 0.005734664\n",
      "train reg_fs: 0.0017929502064362168\n",
      "Epoch: 2500 train loss=0.011162684 valid loss= 0.004988817\n",
      "train reg_fs: 0.0017563613364472985\n",
      "Epoch: 3000 train loss=0.006264235 valid loss= 0.004245506\n",
      "train reg_fs: 0.0017242375761270523\n",
      "Epoch: 3500 train loss=0.008163602 valid loss= 0.003962563\n",
      "train reg_fs: 0.0016995094483718276\n",
      "Epoch: 4000 train loss=0.010390673 valid loss= 0.004036533\n",
      "train reg_fs: 0.0016825831262394786\n",
      "Epoch: 4500 train loss=0.006107703 valid loss= 0.003969353\n",
      "train reg_fs: 0.0016708369366824627\n",
      "Epoch: 5000 train loss=0.004494906 valid loss= 0.004251543\n",
      "train reg_fs: 0.0016617823857814074\n",
      "Epoch: 5500 train loss=0.004035690 valid loss= 0.004030496\n",
      "train reg_fs: 0.0016528621781617403\n",
      "Epoch: 6000 train loss=0.006471616 valid loss= 0.004111152\n",
      "train reg_fs: 0.0016450966941192746\n",
      "Epoch: 6500 train loss=0.005799355 valid loss= 0.004236635\n",
      "train reg_fs: 0.0016365451738238335\n",
      "Epoch: 7000 train loss=0.003958914 valid loss= 0.003785240\n",
      "train reg_fs: 0.0016280998243018985\n",
      "Epoch: 7500 train loss=0.002244402 valid loss= 0.004094653\n",
      "train reg_fs: 0.00162027170881629\n",
      "Epoch: 8000 train loss=0.003173699 valid loss= 0.004248402\n",
      "train reg_fs: 0.0016125324182212353\n",
      "Epoch: 8500 train loss=0.004560654 valid loss= 0.004188442\n",
      "train reg_fs: 0.0016064912779256701\n",
      "Epoch: 9000 train loss=0.004049439 valid loss= 0.004394541\n",
      "train reg_fs: 0.0016003436176106334\n",
      "Epoch: 9500 train loss=0.006424228 valid loss= 0.003976046\n",
      "train reg_fs: 0.0015939008444547653\n",
      "Epoch: 10000 train loss=0.007711111 valid loss= 0.004062065\n",
      "train reg_fs: 0.0015885772882029414\n",
      "Epoch: 10500 train loss=0.002449065 valid loss= 0.003702568\n",
      "train reg_fs: 0.0015845776069909334\n",
      "Epoch: 11000 train loss=0.003031499 valid loss= 0.003834299\n",
      "train reg_fs: 0.0015796769876033068\n",
      "Epoch: 11500 train loss=0.003828658 valid loss= 0.003834129\n",
      "train reg_fs: 0.0015754036139696836\n",
      "Epoch: 12000 train loss=0.005125211 valid loss= 0.003688483\n",
      "train reg_fs: 0.001571626402437687\n",
      "Epoch: 12500 train loss=0.002082541 valid loss= 0.003840570\n",
      "train reg_fs: 0.0015684464015066624\n",
      "Epoch: 13000 train loss=0.005532491 valid loss= 0.003815569\n",
      "train reg_fs: 0.0015655161114409566\n",
      "Epoch: 13500 train loss=0.005236471 valid loss= 0.003888737\n",
      "train reg_fs: 0.0015624172519892454\n",
      "Epoch: 14000 train loss=0.004083229 valid loss= 0.003898596\n",
      "train reg_fs: 0.0015591166447848082\n",
      "Epoch: 14500 train loss=0.002315712 valid loss= 0.003605078\n",
      "train reg_fs: 0.0015560376923531294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:53:41,796]\u001b[0m Trial 54 finished with value: 0.002319198574320789 and parameters: {'lam': 0.0021270222896547964, 'learning_rate': 0.0397282558731402, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004337568 valid loss= 0.003832832\n",
      "train reg_fs: 0.0015531271928921342\n",
      "In trial:---------------------\n",
      "validation mse: 0.002319198574320789\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.036429338 valid loss= 0.014978568\n",
      "train reg_fs: 0.008591372519731522\n",
      "Epoch: 1000 train loss=0.013050338 valid loss= 0.015428754\n",
      "train reg_fs: 0.00852260086685419\n",
      "Epoch: 1500 train loss=0.025781151 valid loss= 0.014440658\n",
      "train reg_fs: 0.008193890564143658\n",
      "Epoch: 2000 train loss=0.013054565 valid loss= 0.012446428\n",
      "train reg_fs: 0.007780819199979305\n",
      "Epoch: 2500 train loss=0.015002153 valid loss= 0.011282666\n",
      "train reg_fs: 0.007389580365270376\n",
      "Epoch: 3000 train loss=0.007693032 valid loss= 0.010658621\n",
      "train reg_fs: 0.007041711360216141\n",
      "Epoch: 3500 train loss=0.011361105 valid loss= 0.010632493\n",
      "train reg_fs: 0.006782869342714548\n",
      "Epoch: 4000 train loss=0.008922553 valid loss= 0.010490434\n",
      "train reg_fs: 0.006625428330153227\n",
      "Epoch: 4500 train loss=0.007647224 valid loss= 0.010815303\n",
      "train reg_fs: 0.0064966799691319466\n",
      "Epoch: 5000 train loss=0.007852924 valid loss= 0.010726500\n",
      "train reg_fs: 0.006415029987692833\n",
      "Epoch: 5500 train loss=0.007737726 valid loss= 0.010559974\n",
      "train reg_fs: 0.006381738930940628\n",
      "Epoch: 6000 train loss=0.010552317 valid loss= 0.010633558\n",
      "train reg_fs: 0.006363168824464083\n",
      "Epoch: 6500 train loss=0.008646461 valid loss= 0.010029690\n",
      "train reg_fs: 0.006350194104015827\n",
      "Epoch: 7000 train loss=0.013028296 valid loss= 0.010056887\n",
      "train reg_fs: 0.006333745084702969\n",
      "Epoch: 7500 train loss=0.007635103 valid loss= 0.009937417\n",
      "train reg_fs: 0.006313948426395655\n",
      "Epoch: 8000 train loss=0.007754551 valid loss= 0.009856348\n",
      "train reg_fs: 0.006297699641436338\n",
      "Epoch: 8500 train loss=0.008008994 valid loss= 0.009908665\n",
      "train reg_fs: 0.006263379938900471\n",
      "Epoch: 9000 train loss=0.007744079 valid loss= 0.009579121\n",
      "train reg_fs: 0.006229615770280361\n",
      "Epoch: 9500 train loss=0.008826297 valid loss= 0.009747393\n",
      "train reg_fs: 0.0061836084350943565\n",
      "Epoch: 10000 train loss=0.006967441 valid loss= 0.009715018\n",
      "train reg_fs: 0.006134124472737312\n",
      "Epoch: 10500 train loss=0.008111496 valid loss= 0.009894351\n",
      "train reg_fs: 0.006070571485906839\n",
      "Epoch: 11000 train loss=0.007347413 valid loss= 0.009746104\n",
      "train reg_fs: 0.006014338228851557\n",
      "Epoch: 11500 train loss=0.007512424 valid loss= 0.009741032\n",
      "train reg_fs: 0.005959336180239916\n",
      "Epoch: 12000 train loss=0.010423347 valid loss= 0.009790102\n",
      "train reg_fs: 0.005913091357797384\n",
      "Epoch: 12500 train loss=0.006915683 valid loss= 0.009685656\n",
      "train reg_fs: 0.005877310410141945\n",
      "Epoch: 13000 train loss=0.007054894 valid loss= 0.009891187\n",
      "train reg_fs: 0.005840462166815996\n",
      "Epoch: 13500 train loss=0.007240887 valid loss= 0.009666065\n",
      "train reg_fs: 0.005808781832456589\n",
      "Epoch: 14000 train loss=0.007362249 valid loss= 0.009628425\n",
      "train reg_fs: 0.005788109265267849\n",
      "Epoch: 14500 train loss=0.007483437 valid loss= 0.009704772\n",
      "train reg_fs: 0.005767823196947575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:55:32,805]\u001b[0m Trial 55 finished with value: 0.0036978539848265884 and parameters: {'lam': 0.009988955236617776, 'learning_rate': 0.08450275675354381, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007186875 valid loss= 0.009644000\n",
      "train reg_fs: 0.005748235620558262\n",
      "In trial:---------------------\n",
      "validation mse: 0.0036978539848265884\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.024223708 valid loss= 0.009274533\n",
      "train reg_fs: 0.001994114136323333\n",
      "Epoch: 1000 train loss=0.015653938 valid loss= 0.009014776\n",
      "train reg_fs: 0.0020141403656452894\n",
      "Epoch: 1500 train loss=0.013576684 valid loss= 0.008083684\n",
      "train reg_fs: 0.0020228642970323563\n",
      "Epoch: 2000 train loss=0.013545919 valid loss= 0.007654555\n",
      "train reg_fs: 0.0020224282052367926\n",
      "Epoch: 2500 train loss=0.006661304 valid loss= 0.007328008\n",
      "train reg_fs: 0.0020096241496503353\n",
      "Epoch: 3000 train loss=0.008376535 valid loss= 0.007097813\n",
      "train reg_fs: 0.001990173477679491\n",
      "Epoch: 3500 train loss=0.006642267 valid loss= 0.006612540\n",
      "train reg_fs: 0.001966607989743352\n",
      "Epoch: 4000 train loss=0.014304854 valid loss= 0.006231460\n",
      "train reg_fs: 0.0019437357550486922\n",
      "Epoch: 4500 train loss=0.010471260 valid loss= 0.005523930\n",
      "train reg_fs: 0.001923087053000927\n",
      "Epoch: 5000 train loss=0.004987746 valid loss= 0.005097293\n",
      "train reg_fs: 0.0019022440537810326\n",
      "Epoch: 5500 train loss=0.008716756 valid loss= 0.004520276\n",
      "train reg_fs: 0.001882803626358509\n",
      "Epoch: 6000 train loss=0.006578050 valid loss= 0.004057127\n",
      "train reg_fs: 0.0018639644840732217\n",
      "Epoch: 6500 train loss=0.004474366 valid loss= 0.004362254\n",
      "train reg_fs: 0.0018477921839803457\n",
      "Epoch: 7000 train loss=0.005209228 valid loss= 0.004092737\n",
      "train reg_fs: 0.0018333547050133348\n",
      "Epoch: 7500 train loss=0.012510513 valid loss= 0.004356057\n",
      "train reg_fs: 0.0018206043168902397\n",
      "Epoch: 8000 train loss=0.003518424 valid loss= 0.004421299\n",
      "train reg_fs: 0.0018097367137670517\n",
      "Epoch: 8500 train loss=0.004402401 valid loss= 0.004419778\n",
      "train reg_fs: 0.0017993738874793053\n",
      "Epoch: 9000 train loss=0.005033051 valid loss= 0.004480967\n",
      "train reg_fs: 0.0017894208431243896\n",
      "Epoch: 9500 train loss=0.009385442 valid loss= 0.004606267\n",
      "train reg_fs: 0.0017801858484745026\n",
      "Epoch: 10000 train loss=0.003821139 valid loss= 0.004250849\n",
      "train reg_fs: 0.001771480543538928\n",
      "Epoch: 10500 train loss=0.003790534 valid loss= 0.004312345\n",
      "train reg_fs: 0.0017636525444686413\n",
      "Epoch: 11000 train loss=0.008018391 valid loss= 0.004224579\n",
      "train reg_fs: 0.0017561978893354535\n",
      "Epoch: 11500 train loss=0.002536128 valid loss= 0.004130872\n",
      "train reg_fs: 0.0017497725784778595\n",
      "Epoch: 12000 train loss=0.004186517 valid loss= 0.004005225\n",
      "train reg_fs: 0.0017431811429560184\n",
      "Epoch: 12500 train loss=0.003289788 valid loss= 0.004253768\n",
      "train reg_fs: 0.0017365403473377228\n",
      "Epoch: 13000 train loss=0.003290524 valid loss= 0.004240244\n",
      "train reg_fs: 0.0017308444948866963\n",
      "Epoch: 13500 train loss=0.004274856 valid loss= 0.004270380\n",
      "train reg_fs: 0.001726088928990066\n",
      "Epoch: 14000 train loss=0.003445011 valid loss= 0.004245187\n",
      "train reg_fs: 0.0017214000690728426\n",
      "Epoch: 14500 train loss=0.002366832 valid loss= 0.004183207\n",
      "train reg_fs: 0.001717263599857688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:57:22,889]\u001b[0m Trial 56 finished with value: 0.0024346631172175097 and parameters: {'lam': 0.0023329947660507065, 'learning_rate': 0.02441122288624799, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004213350 valid loss= 0.004119793\n",
      "train reg_fs: 0.001712964498437941\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024346631172175097\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005277612 valid loss= 0.009291121\n",
      "train reg_fs: 0.0015339994570240378\n",
      "Epoch: 1000 train loss=0.011830864 valid loss= 0.008602624\n",
      "train reg_fs: 0.0015480408910661936\n",
      "Epoch: 1500 train loss=0.010559635 valid loss= 0.008943313\n",
      "train reg_fs: 0.001533126225695014\n",
      "Epoch: 2000 train loss=0.011748892 valid loss= 0.008057958\n",
      "train reg_fs: 0.001506937318481505\n",
      "Epoch: 2500 train loss=0.006189182 valid loss= 0.007564282\n",
      "train reg_fs: 0.0014818133786320686\n",
      "Epoch: 3000 train loss=0.006959516 valid loss= 0.006788327\n",
      "train reg_fs: 0.0014647884527221322\n",
      "Epoch: 3500 train loss=0.006511160 valid loss= 0.006380504\n",
      "train reg_fs: 0.001451615011319518\n",
      "Epoch: 4000 train loss=0.004500963 valid loss= 0.005622330\n",
      "train reg_fs: 0.0014388246927410364\n",
      "Epoch: 4500 train loss=0.005889876 valid loss= 0.005082558\n",
      "train reg_fs: 0.0014208167558535933\n",
      "Epoch: 5000 train loss=0.003592984 valid loss= 0.004498572\n",
      "train reg_fs: 0.0013988332357257605\n",
      "Epoch: 5500 train loss=0.004907899 valid loss= 0.004102805\n",
      "train reg_fs: 0.0013748554047197104\n",
      "Epoch: 6000 train loss=0.004009972 valid loss= 0.004156868\n",
      "train reg_fs: 0.0013573652831837535\n",
      "Epoch: 6500 train loss=0.002873746 valid loss= 0.004195298\n",
      "train reg_fs: 0.0013428684324026108\n",
      "Epoch: 7000 train loss=0.003741682 valid loss= 0.003976282\n",
      "train reg_fs: 0.001329942257143557\n",
      "Epoch: 7500 train loss=0.002340640 valid loss= 0.004349346\n",
      "train reg_fs: 0.0013180651003494859\n",
      "Epoch: 8000 train loss=0.004495553 valid loss= 0.003978120\n",
      "train reg_fs: 0.0013070307904854417\n",
      "Epoch: 8500 train loss=0.005563337 valid loss= 0.004282652\n",
      "train reg_fs: 0.0012985282810404897\n",
      "Epoch: 9000 train loss=0.004982056 valid loss= 0.003917377\n",
      "train reg_fs: 0.0012892744271084666\n",
      "Epoch: 9500 train loss=0.005045409 valid loss= 0.004074075\n",
      "train reg_fs: 0.001282723736949265\n",
      "Epoch: 10000 train loss=0.003836859 valid loss= 0.004076697\n",
      "train reg_fs: 0.0012735555646941066\n",
      "Epoch: 10500 train loss=0.004369270 valid loss= 0.004377967\n",
      "train reg_fs: 0.0012690461007878184\n",
      "Epoch: 11000 train loss=0.002775681 valid loss= 0.004023146\n",
      "train reg_fs: 0.0012630709679797292\n",
      "Epoch: 11500 train loss=0.002787182 valid loss= 0.003735635\n",
      "train reg_fs: 0.001257925876416266\n",
      "Epoch: 12000 train loss=0.002214069 valid loss= 0.004168328\n",
      "train reg_fs: 0.0012539257295429707\n",
      "Epoch: 12500 train loss=0.002537630 valid loss= 0.004033147\n",
      "train reg_fs: 0.0012512104585766792\n",
      "Epoch: 13000 train loss=0.003024841 valid loss= 0.004197496\n",
      "train reg_fs: 0.0012478616554290056\n",
      "Epoch: 13500 train loss=0.003939727 valid loss= 0.003863814\n",
      "train reg_fs: 0.0012457960983738303\n",
      "Epoch: 14000 train loss=0.002071056 valid loss= 0.003859412\n",
      "train reg_fs: 0.0012441432336345315\n",
      "Epoch: 14500 train loss=0.002487297 valid loss= 0.004098939\n",
      "train reg_fs: 0.0012425306485965848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 14:59:13,591]\u001b[0m Trial 57 finished with value: 0.0029203262464909886 and parameters: {'lam': 0.0017801026090366356, 'learning_rate': 0.05703328290653376, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003830053 valid loss= 0.004156912\n",
      "train reg_fs: 0.0012389272451400757\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029203262464909886\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005953683 valid loss= 0.006693012\n",
      "train reg_fs: 0.0010591403115540743\n",
      "Epoch: 1000 train loss=0.004696945 valid loss= 0.004491483\n",
      "train reg_fs: 0.0009734976338222623\n",
      "Epoch: 1500 train loss=0.003639326 valid loss= 0.003716351\n",
      "train reg_fs: 0.0009129194659180939\n",
      "Epoch: 2000 train loss=0.001249542 valid loss= 0.003642457\n",
      "train reg_fs: 0.0008819011854939163\n",
      "Epoch: 2500 train loss=0.002435061 valid loss= 0.003471364\n",
      "train reg_fs: 0.0008597261621616781\n",
      "Epoch: 3000 train loss=0.002227639 valid loss= 0.003545687\n",
      "train reg_fs: 0.0008414780022576451\n",
      "Epoch: 3500 train loss=0.002236592 valid loss= 0.003428452\n",
      "train reg_fs: 0.0008262762567028403\n",
      "Epoch: 4000 train loss=0.004724401 valid loss= 0.003348232\n",
      "train reg_fs: 0.0008155035320669413\n",
      "Epoch: 4500 train loss=0.002588790 valid loss= 0.003629750\n",
      "train reg_fs: 0.0008051486220210791\n",
      "Epoch: 5000 train loss=0.001204480 valid loss= 0.003095841\n",
      "train reg_fs: 0.0007977737113833427\n",
      "Epoch: 5500 train loss=0.004513640 valid loss= 0.003426168\n",
      "train reg_fs: 0.0007906779646873474\n",
      "Epoch: 6000 train loss=0.001285100 valid loss= 0.003422714\n",
      "train reg_fs: 0.000784055795520544\n",
      "Epoch: 6500 train loss=0.000953153 valid loss= 0.003502458\n",
      "train reg_fs: 0.0007789956871420145\n",
      "Epoch: 7000 train loss=0.001577600 valid loss= 0.003178940\n",
      "train reg_fs: 0.0007745933253318071\n",
      "Epoch: 7500 train loss=0.002959791 valid loss= 0.003187628\n",
      "train reg_fs: 0.0007706587784923613\n",
      "Epoch: 8000 train loss=0.001975451 valid loss= 0.003156433\n",
      "train reg_fs: 0.0007672715000808239\n",
      "Epoch: 8500 train loss=0.000951809 valid loss= 0.003053403\n",
      "train reg_fs: 0.0007642871933057904\n",
      "Epoch: 9000 train loss=0.003938678 valid loss= 0.002943566\n",
      "train reg_fs: 0.0007615094073116779\n",
      "Epoch: 9500 train loss=0.001098408 valid loss= 0.003173406\n",
      "train reg_fs: 0.0007592545007355511\n",
      "Epoch: 10000 train loss=0.001948153 valid loss= 0.003337941\n",
      "train reg_fs: 0.0007571201422251761\n",
      "Epoch: 10500 train loss=0.001097290 valid loss= 0.003036891\n",
      "train reg_fs: 0.0007551668677479029\n",
      "Epoch: 11000 train loss=0.002545974 valid loss= 0.003119825\n",
      "train reg_fs: 0.0007534286705777049\n",
      "Epoch: 11500 train loss=0.003341248 valid loss= 0.003119571\n",
      "train reg_fs: 0.0007521671359427273\n",
      "Epoch: 12000 train loss=0.003703995 valid loss= 0.003351509\n",
      "train reg_fs: 0.0007508459966629744\n",
      "Epoch: 12500 train loss=0.002114525 valid loss= 0.003141108\n",
      "train reg_fs: 0.0007495858008041978\n",
      "Epoch: 13000 train loss=0.005188182 valid loss= 0.003013267\n",
      "train reg_fs: 0.0007485384703613818\n",
      "Epoch: 13500 train loss=0.001382020 valid loss= 0.002930245\n",
      "train reg_fs: 0.0007475626771338284\n",
      "Epoch: 14000 train loss=0.003416130 valid loss= 0.002917596\n",
      "train reg_fs: 0.0007466781535185874\n",
      "Epoch: 14500 train loss=0.001597923 valid loss= 0.002988157\n",
      "train reg_fs: 0.0007458235486410558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:01:04,000]\u001b[0m Trial 58 finished with value: 0.002187835488749979 and parameters: {'lam': 0.0012246095089552865, 'learning_rate': 0.14214017203438836, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001483840 valid loss= 0.002916648\n",
      "train reg_fs: 0.0007449631812050939\n",
      "In trial:---------------------\n",
      "validation mse: 0.002187835488749979\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018075356 valid loss= 0.007246661\n",
      "train reg_fs: 0.001273334608413279\n",
      "Epoch: 1000 train loss=0.006007153 valid loss= 0.005830360\n",
      "train reg_fs: 0.0011936380760744214\n",
      "Epoch: 1500 train loss=0.005508310 valid loss= 0.004540609\n",
      "train reg_fs: 0.0011230959789827466\n",
      "Epoch: 2000 train loss=0.005318266 valid loss= 0.004791858\n",
      "train reg_fs: 0.0010738484561443329\n",
      "Epoch: 2500 train loss=0.005036731 valid loss= 0.004100432\n",
      "train reg_fs: 0.001041626906953752\n",
      "Epoch: 3000 train loss=0.004114413 valid loss= 0.004147194\n",
      "train reg_fs: 0.0010169829474762082\n",
      "Epoch: 3500 train loss=0.001581543 valid loss= 0.003648307\n",
      "train reg_fs: 0.0009994886349886656\n",
      "Epoch: 4000 train loss=0.003432156 valid loss= 0.003725776\n",
      "train reg_fs: 0.000982193392701447\n",
      "Epoch: 4500 train loss=0.002510180 valid loss= 0.003264814\n",
      "train reg_fs: 0.0009635647293180227\n",
      "Epoch: 5000 train loss=0.003706274 valid loss= 0.003530695\n",
      "train reg_fs: 0.0009461286826990545\n",
      "Epoch: 5500 train loss=0.002241093 valid loss= 0.003567510\n",
      "train reg_fs: 0.000934012234210968\n",
      "Epoch: 6000 train loss=0.002829148 valid loss= 0.003368225\n",
      "train reg_fs: 0.0009225264075212181\n",
      "Epoch: 6500 train loss=0.002294061 valid loss= 0.003562685\n",
      "train reg_fs: 0.000914241885766387\n",
      "Epoch: 7000 train loss=0.003397316 valid loss= 0.003463851\n",
      "train reg_fs: 0.0009077407303266227\n",
      "Epoch: 7500 train loss=0.001800413 valid loss= 0.003162130\n",
      "train reg_fs: 0.0009024810278788209\n",
      "Epoch: 8000 train loss=0.002950470 valid loss= 0.003403026\n",
      "train reg_fs: 0.0008984209271147847\n",
      "Epoch: 8500 train loss=0.001035497 valid loss= 0.003238725\n",
      "train reg_fs: 0.0008951033814810216\n",
      "Epoch: 9000 train loss=0.001282799 valid loss= 0.003156967\n",
      "train reg_fs: 0.0008921843254938722\n",
      "Epoch: 9500 train loss=0.005529229 valid loss= 0.003503915\n",
      "train reg_fs: 0.0008897752268239856\n",
      "Epoch: 10000 train loss=0.004358271 valid loss= 0.003277581\n",
      "train reg_fs: 0.0008874570485204458\n",
      "Epoch: 10500 train loss=0.002479706 valid loss= 0.003307784\n",
      "train reg_fs: 0.0008856119238771498\n",
      "Epoch: 11000 train loss=0.004107653 valid loss= 0.003680037\n",
      "train reg_fs: 0.0008840315276756883\n",
      "Epoch: 11500 train loss=0.001987113 valid loss= 0.003153882\n",
      "train reg_fs: 0.0008826556731946766\n",
      "Epoch: 12000 train loss=0.001118395 valid loss= 0.003020476\n",
      "train reg_fs: 0.0008815050823614001\n",
      "Epoch: 12500 train loss=0.003697786 valid loss= 0.003117122\n",
      "train reg_fs: 0.0008804686367511749\n",
      "Epoch: 13000 train loss=0.004664511 valid loss= 0.003186981\n",
      "train reg_fs: 0.00087958067888394\n",
      "Epoch: 13500 train loss=0.004471696 valid loss= 0.003221689\n",
      "train reg_fs: 0.0008787531405687332\n",
      "Epoch: 14000 train loss=0.002483092 valid loss= 0.003051140\n",
      "train reg_fs: 0.0008779318304732442\n",
      "Epoch: 14500 train loss=0.001532983 valid loss= 0.003076168\n",
      "train reg_fs: 0.0008771754801273346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:02:53,312]\u001b[0m Trial 59 finished with value: 0.0022751525023026486 and parameters: {'lam': 0.0014500135270924597, 'learning_rate': 0.17979097294995022, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002295058 valid loss= 0.003130316\n",
      "train reg_fs: 0.0008764801896177232\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022751525023026486\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014133959 valid loss= 0.007045851\n",
      "train reg_fs: 0.0009472538367845118\n",
      "Epoch: 1000 train loss=0.010803123 valid loss= 0.006322902\n",
      "train reg_fs: 0.0009679164504632354\n",
      "Epoch: 1500 train loss=0.008682748 valid loss= 0.006983534\n",
      "train reg_fs: 0.0009750794852152467\n",
      "Epoch: 2000 train loss=0.009174254 valid loss= 0.005679397\n",
      "train reg_fs: 0.0009714720072224736\n",
      "Epoch: 2500 train loss=0.002164079 valid loss= 0.005020529\n",
      "train reg_fs: 0.0009568960522301495\n",
      "Epoch: 3000 train loss=0.006552379 valid loss= 0.004239303\n",
      "train reg_fs: 0.0009405307355336845\n",
      "Epoch: 3500 train loss=0.007222707 valid loss= 0.003514473\n",
      "train reg_fs: 0.0009231282747350633\n",
      "Epoch: 4000 train loss=0.005037779 valid loss= 0.003028953\n",
      "train reg_fs: 0.0009070775704458356\n",
      "Epoch: 4500 train loss=0.004161790 valid loss= 0.002669335\n",
      "train reg_fs: 0.00089028209913522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:03:31,515]\u001b[0m Trial 60 finished with value: 0.001953926370173173 and parameters: {'lam': 0.001085732243088034, 'learning_rate': 0.06022486501430194, 'num_epoch': 5000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004004359 valid loss= 0.002832679\n",
      "train reg_fs: 0.0008769111009314656\n",
      "In trial:---------------------\n",
      "validation mse: 0.001953926370173173\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009999108 valid loss= 0.007788513\n",
      "train reg_fs: 0.0013894999865442514\n",
      "Epoch: 1000 train loss=0.007972575 valid loss= 0.007203537\n",
      "train reg_fs: 0.0014008588623255491\n",
      "Epoch: 1500 train loss=0.015402406 valid loss= 0.007914033\n",
      "train reg_fs: 0.0013959732605144382\n",
      "Epoch: 2000 train loss=0.004652745 valid loss= 0.007456934\n",
      "train reg_fs: 0.00138231017626822\n",
      "Epoch: 2500 train loss=0.003816903 valid loss= 0.006842509\n",
      "train reg_fs: 0.0013669069157913327\n",
      "Epoch: 3000 train loss=0.004421594 valid loss= 0.006487784\n",
      "train reg_fs: 0.001354861306026578\n",
      "Epoch: 3500 train loss=0.008526104 valid loss= 0.006845040\n",
      "train reg_fs: 0.0013474129373207688\n",
      "Epoch: 4000 train loss=0.004502143 valid loss= 0.006515716\n",
      "train reg_fs: 0.0013410418760031462\n",
      "Epoch: 4500 train loss=0.008768513 valid loss= 0.006305833\n",
      "train reg_fs: 0.0013337299460545182\n",
      "Epoch: 5000 train loss=0.004376103 valid loss= 0.005918477\n",
      "train reg_fs: 0.0013284895103424788\n",
      "Epoch: 5500 train loss=0.006056490 valid loss= 0.006120719\n",
      "train reg_fs: 0.0013222816633060575\n",
      "Epoch: 6000 train loss=0.002353168 valid loss= 0.005679105\n",
      "train reg_fs: 0.0013158402871340513\n",
      "Epoch: 6500 train loss=0.007611709 valid loss= 0.005346417\n",
      "train reg_fs: 0.0013132179155945778\n",
      "Epoch: 7000 train loss=0.002818752 valid loss= 0.005566324\n",
      "train reg_fs: 0.0013075551250949502\n",
      "Epoch: 7500 train loss=0.003103019 valid loss= 0.005422157\n",
      "train reg_fs: 0.0013019749894738197\n",
      "Epoch: 8000 train loss=0.008099595 valid loss= 0.005269507\n",
      "train reg_fs: 0.001295499037951231\n",
      "Epoch: 8500 train loss=0.006602487 valid loss= 0.005083879\n",
      "train reg_fs: 0.0012913622194901109\n",
      "Epoch: 9000 train loss=0.003616501 valid loss= 0.005131483\n",
      "train reg_fs: 0.0012864371528849006\n",
      "Epoch: 9500 train loss=0.003611291 valid loss= 0.004997551\n",
      "train reg_fs: 0.0012810842599719763\n",
      "Epoch: 10000 train loss=0.003485662 valid loss= 0.004808097\n",
      "train reg_fs: 0.0012733957264572382\n",
      "Epoch: 10500 train loss=0.005248613 valid loss= 0.005101577\n",
      "train reg_fs: 0.001268039457499981\n",
      "Epoch: 11000 train loss=0.004871462 valid loss= 0.005287704\n",
      "train reg_fs: 0.0012609086697921157\n",
      "Epoch: 11500 train loss=0.002878068 valid loss= 0.005116759\n",
      "train reg_fs: 0.0012528174556791782\n",
      "Epoch: 12000 train loss=0.001526939 valid loss= 0.004960923\n",
      "train reg_fs: 0.0012476334813982248\n",
      "Epoch: 12500 train loss=0.002959392 valid loss= 0.005253770\n",
      "train reg_fs: 0.001240895944647491\n",
      "Epoch: 13000 train loss=0.003219068 valid loss= 0.005394802\n",
      "train reg_fs: 0.0012348257005214691\n",
      "Epoch: 13500 train loss=0.004527607 valid loss= 0.005117258\n",
      "train reg_fs: 0.0012294236803427339\n",
      "Epoch: 14000 train loss=0.002605287 valid loss= 0.005049143\n",
      "train reg_fs: 0.0012231813743710518\n",
      "Epoch: 14500 train loss=0.002757852 valid loss= 0.005224726\n",
      "train reg_fs: 0.0012177780736237764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:05:22,256]\u001b[0m Trial 61 finished with value: 0.003732067685081167 and parameters: {'lam': 0.0016236488290401992, 'learning_rate': 0.047562061592183916, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002996481 valid loss= 0.004978219\n",
      "train reg_fs: 0.0012104710331186652\n",
      "In trial:---------------------\n",
      "validation mse: 0.003732067685081167\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022290852 valid loss= 0.009112764\n",
      "train reg_fs: 0.001690858043730259\n",
      "Epoch: 1000 train loss=0.016689148 valid loss= 0.008440409\n",
      "train reg_fs: 0.0016989344730973244\n",
      "Epoch: 1500 train loss=0.012373328 valid loss= 0.008059493\n",
      "train reg_fs: 0.0016857703449204564\n",
      "Epoch: 2000 train loss=0.004283439 valid loss= 0.006938958\n",
      "train reg_fs: 0.0016599190421402454\n",
      "Epoch: 2500 train loss=0.009602105 valid loss= 0.006029749\n",
      "train reg_fs: 0.0016341988230124116\n",
      "Epoch: 3000 train loss=0.011404525 valid loss= 0.005645126\n",
      "train reg_fs: 0.0016080737113952637\n",
      "Epoch: 3500 train loss=0.004484849 valid loss= 0.004750006\n",
      "train reg_fs: 0.001581482239998877\n",
      "Epoch: 4000 train loss=0.008325920 valid loss= 0.004296862\n",
      "train reg_fs: 0.0015554191777482629\n",
      "Epoch: 4500 train loss=0.006536568 valid loss= 0.004116231\n",
      "train reg_fs: 0.0015333745395764709\n",
      "Epoch: 5000 train loss=0.004218564 valid loss= 0.003925946\n",
      "train reg_fs: 0.00151666603051126\n",
      "Epoch: 5500 train loss=0.002252649 valid loss= 0.004085696\n",
      "train reg_fs: 0.0015014581149443984\n",
      "Epoch: 6000 train loss=0.003736658 valid loss= 0.003928381\n",
      "train reg_fs: 0.0014883301919326186\n",
      "Epoch: 6500 train loss=0.005318375 valid loss= 0.004184096\n",
      "train reg_fs: 0.001475710072554648\n",
      "Epoch: 7000 train loss=0.004397270 valid loss= 0.004431948\n",
      "train reg_fs: 0.0014637543354183435\n",
      "Epoch: 7500 train loss=0.004742422 valid loss= 0.004276098\n",
      "train reg_fs: 0.0014524786965921521\n",
      "Epoch: 8000 train loss=0.001933970 valid loss= 0.003748786\n",
      "train reg_fs: 0.0014410846633836627\n",
      "Epoch: 8500 train loss=0.006039844 valid loss= 0.004067143\n",
      "train reg_fs: 0.001430641976185143\n",
      "Epoch: 9000 train loss=0.002176891 valid loss= 0.003905018\n",
      "train reg_fs: 0.0014213237445801497\n",
      "Epoch: 9500 train loss=0.005047072 valid loss= 0.003951502\n",
      "train reg_fs: 0.0014131785137578845\n",
      "Epoch: 10000 train loss=0.008958679 valid loss= 0.003978658\n",
      "train reg_fs: 0.0014031779719516635\n",
      "Epoch: 10500 train loss=0.006182518 valid loss= 0.003831066\n",
      "train reg_fs: 0.0013946091057732701\n",
      "Epoch: 11000 train loss=0.003757042 valid loss= 0.004059522\n",
      "train reg_fs: 0.001385762938298285\n",
      "Epoch: 11500 train loss=0.004608867 valid loss= 0.004033049\n",
      "train reg_fs: 0.0013776548439636827\n",
      "Epoch: 12000 train loss=0.002275485 valid loss= 0.003973246\n",
      "train reg_fs: 0.0013698088005185127\n",
      "Epoch: 12500 train loss=0.008562727 valid loss= 0.004032602\n",
      "train reg_fs: 0.0013592310715466738\n",
      "Epoch: 13000 train loss=0.007200547 valid loss= 0.003731083\n",
      "train reg_fs: 0.001351058715954423\n",
      "Epoch: 13500 train loss=0.002781367 valid loss= 0.003720159\n",
      "train reg_fs: 0.0013428025413304567\n",
      "Epoch: 14000 train loss=0.002246098 valid loss= 0.003886825\n",
      "train reg_fs: 0.0013338722055777907\n",
      "Epoch: 14500 train loss=0.001953705 valid loss= 0.003818057\n",
      "train reg_fs: 0.001326023368164897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:07:11,943]\u001b[0m Trial 62 finished with value: 0.0025470785259226534 and parameters: {'lam': 0.0019723924235774642, 'learning_rate': 0.04101940612590331, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002363542 valid loss= 0.003856013\n",
      "train reg_fs: 0.0013188173761591315\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025470785259226534\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010231836 valid loss= 0.008883776\n",
      "train reg_fs: 0.0018357760272920132\n",
      "Epoch: 1000 train loss=0.017436389 valid loss= 0.008034900\n",
      "train reg_fs: 0.0018683732487261295\n",
      "Epoch: 1500 train loss=0.009609602 valid loss= 0.007493640\n",
      "train reg_fs: 0.001890519168227911\n",
      "Epoch: 2000 train loss=0.009320125 valid loss= 0.007159131\n",
      "train reg_fs: 0.0019034678116440773\n",
      "Epoch: 2500 train loss=0.014388087 valid loss= 0.007427310\n",
      "train reg_fs: 0.0019084096420556307\n",
      "Epoch: 3000 train loss=0.021717381 valid loss= 0.007154317\n",
      "train reg_fs: 0.0019100347999483347\n",
      "Epoch: 3500 train loss=0.004788479 valid loss= 0.005988682\n",
      "train reg_fs: 0.0019057871541008353\n",
      "Epoch: 4000 train loss=0.008546928 valid loss= 0.006065390\n",
      "train reg_fs: 0.0018976643914356828\n",
      "Epoch: 4500 train loss=0.003950794 valid loss= 0.005343145\n",
      "train reg_fs: 0.0018865058664232492\n",
      "Epoch: 5000 train loss=0.008210076 valid loss= 0.004841829\n",
      "train reg_fs: 0.0018689690623432398\n",
      "Epoch: 5500 train loss=0.007668776 valid loss= 0.004544943\n",
      "train reg_fs: 0.001851255539804697\n",
      "Epoch: 6000 train loss=0.006878279 valid loss= 0.004895002\n",
      "train reg_fs: 0.0018364532152190804\n",
      "Epoch: 6500 train loss=0.005115838 valid loss= 0.004227799\n",
      "train reg_fs: 0.0018184251384809613\n",
      "Epoch: 7000 train loss=0.004468489 valid loss= 0.004008819\n",
      "train reg_fs: 0.0018030045321211219\n",
      "Epoch: 7500 train loss=0.003699611 valid loss= 0.003761115\n",
      "train reg_fs: 0.0017881126841530204\n",
      "Epoch: 8000 train loss=0.004163962 valid loss= 0.004072642\n",
      "train reg_fs: 0.0017744081560522318\n",
      "Epoch: 8500 train loss=0.004737632 valid loss= 0.003808670\n",
      "train reg_fs: 0.0017604510067030787\n",
      "Epoch: 9000 train loss=0.006316002 valid loss= 0.003685757\n",
      "train reg_fs: 0.0017456598579883575\n",
      "Epoch: 9500 train loss=0.004934003 valid loss= 0.003575484\n",
      "train reg_fs: 0.0017308862879872322\n",
      "Epoch: 10000 train loss=0.006834368 valid loss= 0.003654674\n",
      "train reg_fs: 0.0017195334658026695\n",
      "Epoch: 10500 train loss=0.004527674 valid loss= 0.003759888\n",
      "train reg_fs: 0.001708169118501246\n",
      "Epoch: 11000 train loss=0.012202278 valid loss= 0.003589211\n",
      "train reg_fs: 0.001697620959021151\n",
      "Epoch: 11500 train loss=0.003000030 valid loss= 0.003579345\n",
      "train reg_fs: 0.0016890066908672452\n",
      "Epoch: 12000 train loss=0.004685610 valid loss= 0.003748862\n",
      "train reg_fs: 0.0016798324650153518\n",
      "Epoch: 12500 train loss=0.002650411 valid loss= 0.003849735\n",
      "train reg_fs: 0.0016707390313968062\n",
      "Epoch: 13000 train loss=0.004980219 valid loss= 0.003782785\n",
      "train reg_fs: 0.001663355971686542\n",
      "Epoch: 13500 train loss=0.003759037 valid loss= 0.003747036\n",
      "train reg_fs: 0.001656261971220374\n",
      "Epoch: 14000 train loss=0.003904138 valid loss= 0.003487204\n",
      "train reg_fs: 0.0016500296769663692\n",
      "Epoch: 14500 train loss=0.003771206 valid loss= 0.003668140\n",
      "train reg_fs: 0.0016444702632725239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:09:01,023]\u001b[0m Trial 63 finished with value: 0.0019234838387425816 and parameters: {'lam': 0.002137051136949382, 'learning_rate': 0.03400972606371251, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002341950 valid loss= 0.003544454\n",
      "train reg_fs: 0.0016392573015764356\n",
      "In trial:---------------------\n",
      "validation mse: 0.0019234838387425816\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012112609 valid loss= 0.007950828\n",
      "train reg_fs: 0.001526763429865241\n",
      "Epoch: 1000 train loss=0.008261679 valid loss= 0.008286254\n",
      "train reg_fs: 0.0015191190177574754\n",
      "Epoch: 1500 train loss=0.006510762 valid loss= 0.007156729\n",
      "train reg_fs: 0.0014925397699698806\n",
      "Epoch: 2000 train loss=0.005293658 valid loss= 0.006579751\n",
      "train reg_fs: 0.001471256255172193\n",
      "Epoch: 2500 train loss=0.005823656 valid loss= 0.006123609\n",
      "train reg_fs: 0.0014575050445273519\n",
      "Epoch: 3000 train loss=0.007171991 valid loss= 0.006021059\n",
      "train reg_fs: 0.001444198191165924\n",
      "Epoch: 3500 train loss=0.004455716 valid loss= 0.005040731\n",
      "train reg_fs: 0.0014392982702702284\n",
      "Epoch: 4000 train loss=0.006171619 valid loss= 0.005416940\n",
      "train reg_fs: 0.0014306906377896667\n",
      "Epoch: 4500 train loss=0.006113160 valid loss= 0.005248172\n",
      "train reg_fs: 0.0014209465589374304\n",
      "Epoch: 5000 train loss=0.002945423 valid loss= 0.005040841\n",
      "train reg_fs: 0.0014137056423351169\n",
      "Epoch: 5500 train loss=0.003987282 valid loss= 0.005761237\n",
      "train reg_fs: 0.0014064357383176684\n",
      "Epoch: 6000 train loss=0.003848419 valid loss= 0.005737633\n",
      "train reg_fs: 0.0013981973752379417\n",
      "Epoch: 6500 train loss=0.003326578 valid loss= 0.005908465\n",
      "train reg_fs: 0.0013924766099080443\n",
      "Epoch: 7000 train loss=0.004499073 valid loss= 0.005625988\n",
      "train reg_fs: 0.00138457166031003\n",
      "Epoch: 7500 train loss=0.001993336 valid loss= 0.005537202\n",
      "train reg_fs: 0.0013796640560030937\n",
      "Epoch: 8000 train loss=0.003538372 valid loss= 0.005826335\n",
      "train reg_fs: 0.0013720872811973095\n",
      "Epoch: 8500 train loss=0.002467599 valid loss= 0.005746386\n",
      "train reg_fs: 0.0013661928242072463\n",
      "Epoch: 9000 train loss=0.002771178 valid loss= 0.005652539\n",
      "train reg_fs: 0.0013609546003863215\n",
      "Epoch: 9500 train loss=0.005746302 valid loss= 0.006164989\n",
      "train reg_fs: 0.001355517073534429\n",
      "Epoch: 10000 train loss=0.002791000 valid loss= 0.006231194\n",
      "train reg_fs: 0.0013498789630830288\n",
      "Epoch: 10500 train loss=0.004388807 valid loss= 0.006096616\n",
      "train reg_fs: 0.0013432318810373545\n",
      "Epoch: 11000 train loss=0.004114776 valid loss= 0.005963746\n",
      "train reg_fs: 0.0013390870299190283\n",
      "Epoch: 11500 train loss=0.003700065 valid loss= 0.006336208\n",
      "train reg_fs: 0.0013358944561332464\n",
      "Epoch: 12000 train loss=0.003500051 valid loss= 0.005849248\n",
      "train reg_fs: 0.0013326904736459255\n",
      "Epoch: 12500 train loss=0.002293469 valid loss= 0.006091362\n",
      "train reg_fs: 0.0013271952047944069\n",
      "Epoch: 13000 train loss=0.002541404 valid loss= 0.006572965\n",
      "train reg_fs: 0.0013224262511357665\n",
      "Epoch: 13500 train loss=0.004647613 valid loss= 0.006215968\n",
      "train reg_fs: 0.0013182578841224313\n",
      "Epoch: 14000 train loss=0.002654092 valid loss= 0.006253369\n",
      "train reg_fs: 0.0013142504030838609\n",
      "Epoch: 14500 train loss=0.001972499 valid loss= 0.006252983\n",
      "train reg_fs: 0.00131151732057333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:10:51,460]\u001b[0m Trial 64 finished with value: 0.005565813929513825 and parameters: {'lam': 0.0017379048974711716, 'learning_rate': 0.10512388326342884, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004978759 valid loss= 0.006874912\n",
      "train reg_fs: 0.001307550584897399\n",
      "In trial:---------------------\n",
      "validation mse: 0.005565813929513825\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016238354 valid loss= 0.007475507\n",
      "train reg_fs: 0.001368807046674192\n",
      "Epoch: 1000 train loss=0.016289296 valid loss= 0.007414855\n",
      "train reg_fs: 0.0013899273471906781\n",
      "Epoch: 1500 train loss=0.015959201 valid loss= 0.006638374\n",
      "train reg_fs: 0.0014014762127771974\n",
      "Epoch: 2000 train loss=0.005693167 valid loss= 0.006125794\n",
      "train reg_fs: 0.0014068729942664504\n",
      "Epoch: 2500 train loss=0.008951003 valid loss= 0.005922138\n",
      "train reg_fs: 0.0014046416617929935\n",
      "Epoch: 3000 train loss=0.024191499 valid loss= 0.005559896\n",
      "train reg_fs: 0.0013998886570334435\n",
      "Epoch: 3500 train loss=0.005586651 valid loss= 0.005889515\n",
      "train reg_fs: 0.001390765537507832\n",
      "Epoch: 4000 train loss=0.008098624 valid loss= 0.005803940\n",
      "train reg_fs: 0.0013793337857350707\n",
      "Epoch: 4500 train loss=0.005308873 valid loss= 0.004536465\n",
      "train reg_fs: 0.0013651122571900487\n",
      "Epoch: 5000 train loss=0.005408846 valid loss= 0.004231112\n",
      "train reg_fs: 0.0013503908412531018\n",
      "Epoch: 5500 train loss=0.004716817 valid loss= 0.004473704\n",
      "train reg_fs: 0.001337556284852326\n",
      "Epoch: 6000 train loss=0.002335358 valid loss= 0.003985427\n",
      "train reg_fs: 0.0013290010392665863\n",
      "Epoch: 6500 train loss=0.005463501 valid loss= 0.003917696\n",
      "train reg_fs: 0.0013219639658927917\n",
      "Epoch: 7000 train loss=0.005387540 valid loss= 0.003779063\n",
      "train reg_fs: 0.0013148600701242685\n",
      "Epoch: 7500 train loss=0.003681798 valid loss= 0.003822288\n",
      "train reg_fs: 0.0013079909840598702\n",
      "Epoch: 8000 train loss=0.003547671 valid loss= 0.003746321\n",
      "train reg_fs: 0.0013009817339479923\n",
      "Epoch: 8500 train loss=0.005507464 valid loss= 0.003754432\n",
      "train reg_fs: 0.001296347938477993\n",
      "Epoch: 9000 train loss=0.002402112 valid loss= 0.003650401\n",
      "train reg_fs: 0.0012918079737573862\n",
      "Epoch: 9500 train loss=0.003523002 valid loss= 0.003895230\n",
      "train reg_fs: 0.0012871652143076062\n",
      "Epoch: 10000 train loss=0.004486931 valid loss= 0.003666150\n",
      "train reg_fs: 0.001282664597965777\n",
      "Epoch: 10500 train loss=0.004015690 valid loss= 0.003885973\n",
      "train reg_fs: 0.0012786001898348331\n",
      "Epoch: 11000 train loss=0.007952083 valid loss= 0.004231937\n",
      "train reg_fs: 0.001275114482268691\n",
      "Epoch: 11500 train loss=0.005856196 valid loss= 0.003680465\n",
      "train reg_fs: 0.0012708784779533744\n",
      "Epoch: 12000 train loss=0.005676365 valid loss= 0.003939081\n",
      "train reg_fs: 0.0012665136018767953\n",
      "Epoch: 12500 train loss=0.001850848 valid loss= 0.004091337\n",
      "train reg_fs: 0.0012629309203475714\n",
      "Epoch: 13000 train loss=0.002175342 valid loss= 0.004200151\n",
      "train reg_fs: 0.0012598857283592224\n",
      "Epoch: 13500 train loss=0.003404965 valid loss= 0.003869177\n",
      "train reg_fs: 0.0012560694012790918\n",
      "Epoch: 14000 train loss=0.003823457 valid loss= 0.004000158\n",
      "train reg_fs: 0.0012535732239484787\n",
      "Epoch: 14500 train loss=0.002666423 valid loss= 0.004079839\n",
      "train reg_fs: 0.0012507133651524782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:12:41,752]\u001b[0m Trial 65 finished with value: 0.002844374677691318 and parameters: {'lam': 0.001589325046732519, 'learning_rate': 0.04448768715583087, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005218543 valid loss= 0.004109127\n",
      "train reg_fs: 0.0012463264865800738\n",
      "In trial:---------------------\n",
      "validation mse: 0.002844374677691318\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009291269 valid loss= 0.006450188\n",
      "train reg_fs: 0.0021189115941524506\n",
      "Epoch: 1000 train loss=0.004854035 valid loss= 0.004782140\n",
      "train reg_fs: 0.001989206299185753\n",
      "Epoch: 1500 train loss=0.004373148 valid loss= 0.004300691\n",
      "train reg_fs: 0.001896409085020423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:12:57,774]\u001b[0m Trial 66 finished with value: 0.0029087976845000355 and parameters: {'lam': 0.0024117987426491992, 'learning_rate': 0.13099412678283104, 'num_epoch': 2000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.003476455 valid loss= 0.004753827\n",
      "train reg_fs: 0.0018619565526023507\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029087976845000355\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009514228 valid loss= 0.007209223\n",
      "train reg_fs: 0.0023955346550792456\n",
      "Epoch: 1000 train loss=0.006494282 valid loss= 0.006365418\n",
      "train reg_fs: 0.0023914610501378775\n",
      "Epoch: 1500 train loss=0.005583078 valid loss= 0.005009367\n",
      "train reg_fs: 0.0023422387894243\n",
      "Epoch: 2000 train loss=0.010529604 valid loss= 0.004530336\n",
      "train reg_fs: 0.002282214118167758\n",
      "Epoch: 2500 train loss=0.005639122 valid loss= 0.004098307\n",
      "train reg_fs: 0.0022360323928296566\n",
      "Epoch: 3000 train loss=0.004318236 valid loss= 0.003882374\n",
      "train reg_fs: 0.0021991850808262825\n",
      "Epoch: 3500 train loss=0.003189802 valid loss= 0.004219272\n",
      "train reg_fs: 0.0021773672197014093\n",
      "Epoch: 4000 train loss=0.003602002 valid loss= 0.003768254\n",
      "train reg_fs: 0.0021588625386357307\n",
      "Epoch: 4500 train loss=0.004434972 valid loss= 0.003649053\n",
      "train reg_fs: 0.002143032616004348\n",
      "Epoch: 5000 train loss=0.006102317 valid loss= 0.004109846\n",
      "train reg_fs: 0.0021263551898300648\n",
      "Epoch: 5500 train loss=0.008982603 valid loss= 0.003714272\n",
      "train reg_fs: 0.0021109457593411207\n",
      "Epoch: 6000 train loss=0.003880599 valid loss= 0.003703488\n",
      "train reg_fs: 0.0020991030614823103\n",
      "Epoch: 6500 train loss=0.005473810 valid loss= 0.003684607\n",
      "train reg_fs: 0.002083640545606613\n",
      "Epoch: 7000 train loss=0.005974034 valid loss= 0.004016763\n",
      "train reg_fs: 0.0020695358980447054\n",
      "Epoch: 7500 train loss=0.003043058 valid loss= 0.003688175\n",
      "train reg_fs: 0.002057276200503111\n",
      "Epoch: 8000 train loss=0.007043560 valid loss= 0.003490036\n",
      "train reg_fs: 0.00204592221416533\n",
      "Epoch: 8500 train loss=0.002444265 valid loss= 0.004018205\n",
      "train reg_fs: 0.0020351395942270756\n",
      "Epoch: 9000 train loss=0.003004789 valid loss= 0.003636647\n",
      "train reg_fs: 0.002026510890573263\n",
      "Epoch: 9500 train loss=0.004502395 valid loss= 0.003603875\n",
      "train reg_fs: 0.0020162642467767\n",
      "Epoch: 10000 train loss=0.004903203 valid loss= 0.003344649\n",
      "train reg_fs: 0.0020073126070201397\n",
      "Epoch: 10500 train loss=0.002646308 valid loss= 0.003545529\n",
      "train reg_fs: 0.0019950419664382935\n",
      "Epoch: 11000 train loss=0.006522820 valid loss= 0.003335627\n",
      "train reg_fs: 0.0019844581838697195\n",
      "Epoch: 11500 train loss=0.002794916 valid loss= 0.003527236\n",
      "train reg_fs: 0.001975009683519602\n",
      "Epoch: 12000 train loss=0.006332037 valid loss= 0.003480630\n",
      "train reg_fs: 0.001962456852197647\n",
      "Epoch: 12500 train loss=0.003537482 valid loss= 0.003211829\n",
      "train reg_fs: 0.0019498540787026286\n",
      "Epoch: 13000 train loss=0.004224161 valid loss= 0.003710455\n",
      "train reg_fs: 0.0019392325775697827\n",
      "Epoch: 13500 train loss=0.004017705 valid loss= 0.003422700\n",
      "train reg_fs: 0.0019280374981462955\n",
      "Epoch: 14000 train loss=0.002513173 valid loss= 0.003234347\n",
      "train reg_fs: 0.0019172320608049631\n",
      "Epoch: 14500 train loss=0.008777766 valid loss= 0.003697918\n",
      "train reg_fs: 0.001906994148157537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:14:48,413]\u001b[0m Trial 67 finished with value: 0.0013759645358787855 and parameters: {'lam': 0.0027661833414059484, 'learning_rate': 0.07499773600602828, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002817798 valid loss= 0.003241433\n",
      "train reg_fs: 0.0018963945331051946\n",
      "In trial:---------------------\n",
      "validation mse: 0.0013759645358787855\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.025564604 valid loss= 0.008505933\n",
      "train reg_fs: 0.0023450134322047234\n",
      "Epoch: 1000 train loss=0.012474956 valid loss= 0.009254583\n",
      "train reg_fs: 0.002378527307882905\n",
      "Epoch: 1500 train loss=0.013665652 valid loss= 0.008683902\n",
      "train reg_fs: 0.0023806211538612843\n",
      "Epoch: 2000 train loss=0.003723653 valid loss= 0.007945329\n",
      "train reg_fs: 0.0023628699127584696\n",
      "Epoch: 2500 train loss=0.013137164 valid loss= 0.007498213\n",
      "train reg_fs: 0.0023285076022148132\n",
      "Epoch: 3000 train loss=0.006257558 valid loss= 0.006066153\n",
      "train reg_fs: 0.0022859445307403803\n",
      "Epoch: 3500 train loss=0.008872903 valid loss= 0.005850691\n",
      "train reg_fs: 0.0022536718752235174\n",
      "Epoch: 4000 train loss=0.006135952 valid loss= 0.005702507\n",
      "train reg_fs: 0.002226382028311491\n",
      "Epoch: 4500 train loss=0.007689496 valid loss= 0.005282764\n",
      "train reg_fs: 0.002201683819293976\n",
      "Epoch: 5000 train loss=0.009560966 valid loss= 0.005574893\n",
      "train reg_fs: 0.002178656170144677\n",
      "Epoch: 5500 train loss=0.004215726 valid loss= 0.005815553\n",
      "train reg_fs: 0.002158375456929207\n",
      "Epoch: 6000 train loss=0.005418884 valid loss= 0.005522382\n",
      "train reg_fs: 0.0021405620500445366\n",
      "Epoch: 6500 train loss=0.004089882 valid loss= 0.005539165\n",
      "train reg_fs: 0.0021215551532804966\n",
      "Epoch: 7000 train loss=0.009092390 valid loss= 0.005778331\n",
      "train reg_fs: 0.00210304232314229\n",
      "Epoch: 7500 train loss=0.003789824 valid loss= 0.005776453\n",
      "train reg_fs: 0.002085678977891803\n",
      "Epoch: 8000 train loss=0.003861351 valid loss= 0.006109799\n",
      "train reg_fs: 0.002070454880595207\n",
      "Epoch: 8500 train loss=0.003365523 valid loss= 0.005696802\n",
      "train reg_fs: 0.002055866876617074\n",
      "Epoch: 9000 train loss=0.003263308 valid loss= 0.005912193\n",
      "train reg_fs: 0.002042097505182028\n",
      "Epoch: 9500 train loss=0.003877489 valid loss= 0.005733740\n",
      "train reg_fs: 0.0020284303463995457\n",
      "Epoch: 10000 train loss=0.004464449 valid loss= 0.006002462\n",
      "train reg_fs: 0.0020140798296779394\n",
      "Epoch: 10500 train loss=0.004344722 valid loss= 0.005736924\n",
      "train reg_fs: 0.0019997800700366497\n",
      "Epoch: 11000 train loss=0.004518020 valid loss= 0.005992322\n",
      "train reg_fs: 0.0019862838089466095\n",
      "Epoch: 11500 train loss=0.004436817 valid loss= 0.005803117\n",
      "train reg_fs: 0.0019721630960702896\n",
      "Epoch: 12000 train loss=0.002729873 valid loss= 0.005943240\n",
      "train reg_fs: 0.001958917360752821\n",
      "Epoch: 12500 train loss=0.003152836 valid loss= 0.005729192\n",
      "train reg_fs: 0.0019461876945570111\n",
      "Epoch: 13000 train loss=0.003352355 valid loss= 0.005991331\n",
      "train reg_fs: 0.0019315257668495178\n",
      "Epoch: 13500 train loss=0.007295507 valid loss= 0.005792142\n",
      "train reg_fs: 0.0019194049527868629\n",
      "Epoch: 14000 train loss=0.005239197 valid loss= 0.005889188\n",
      "train reg_fs: 0.0019079274497926235\n",
      "Epoch: 14500 train loss=0.008415093 valid loss= 0.005881681\n",
      "train reg_fs: 0.0018970210803672671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:16:38,256]\u001b[0m Trial 68 finished with value: 0.0038078821010361875 and parameters: {'lam': 0.0026786596350092716, 'learning_rate': 0.07551017319621763, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005777721 valid loss= 0.005705424\n",
      "train reg_fs: 0.0018840888515114784\n",
      "In trial:---------------------\n",
      "validation mse: 0.0038078821010361875\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011667190 valid loss= 0.008282358\n",
      "train reg_fs: 0.0025246855802834034\n",
      "Epoch: 1000 train loss=0.017164495 valid loss= 0.007873364\n",
      "train reg_fs: 0.002438986673951149\n",
      "Epoch: 1500 train loss=0.016947862 valid loss= 0.006277627\n",
      "train reg_fs: 0.002308210823684931\n",
      "Epoch: 2000 train loss=0.004190849 valid loss= 0.005470366\n",
      "train reg_fs: 0.0022229182068258524\n",
      "Epoch: 2500 train loss=0.007254147 valid loss= 0.005514654\n",
      "train reg_fs: 0.0021729236468672752\n",
      "Epoch: 3000 train loss=0.003705795 valid loss= 0.005927103\n",
      "train reg_fs: 0.0021368605084717274\n",
      "Epoch: 3500 train loss=0.004689182 valid loss= 0.005846907\n",
      "train reg_fs: 0.0021093811374157667\n",
      "Epoch: 4000 train loss=0.010433749 valid loss= 0.006130587\n",
      "train reg_fs: 0.002087908098474145\n",
      "Epoch: 4500 train loss=0.003449523 valid loss= 0.005333825\n",
      "train reg_fs: 0.002064609667286277\n",
      "Epoch: 5000 train loss=0.005890012 valid loss= 0.005764078\n",
      "train reg_fs: 0.0020348408725112677\n",
      "Epoch: 5500 train loss=0.003665342 valid loss= 0.005561294\n",
      "train reg_fs: 0.0019989272113889456\n",
      "Epoch: 6000 train loss=0.003903602 valid loss= 0.005350001\n",
      "train reg_fs: 0.0019659828394651413\n",
      "Epoch: 6500 train loss=0.003912509 valid loss= 0.005097519\n",
      "train reg_fs: 0.0019356750417500734\n",
      "Epoch: 7000 train loss=0.002566281 valid loss= 0.004857342\n",
      "train reg_fs: 0.001911563565954566\n",
      "Epoch: 7500 train loss=0.006048840 valid loss= 0.005032868\n",
      "train reg_fs: 0.0018929931102320552\n",
      "Epoch: 8000 train loss=0.006072524 valid loss= 0.004295895\n",
      "train reg_fs: 0.0018782741390168667\n",
      "Epoch: 8500 train loss=0.002783882 valid loss= 0.004386948\n",
      "train reg_fs: 0.0018663513474166393\n",
      "Epoch: 9000 train loss=0.002501554 valid loss= 0.004300165\n",
      "train reg_fs: 0.0018568465020507574\n",
      "Epoch: 9500 train loss=0.008168154 valid loss= 0.003995977\n",
      "train reg_fs: 0.0018484405009076\n",
      "Epoch: 10000 train loss=0.002843396 valid loss= 0.004246464\n",
      "train reg_fs: 0.0018416049424558878\n",
      "Epoch: 10500 train loss=0.004584175 valid loss= 0.004364638\n",
      "train reg_fs: 0.0018354282947257161\n",
      "Epoch: 11000 train loss=0.006672076 valid loss= 0.004090915\n",
      "train reg_fs: 0.001830061781220138\n",
      "Epoch: 11500 train loss=0.002644547 valid loss= 0.004276168\n",
      "train reg_fs: 0.0018251754809170961\n",
      "Epoch: 12000 train loss=0.003381265 valid loss= 0.004170932\n",
      "train reg_fs: 0.0018210542621091008\n",
      "Epoch: 12500 train loss=0.002414188 valid loss= 0.003949723\n",
      "train reg_fs: 0.0018173694843426347\n",
      "Epoch: 13000 train loss=0.002754414 valid loss= 0.003935841\n",
      "train reg_fs: 0.001814024057239294\n",
      "Epoch: 13500 train loss=0.008173442 valid loss= 0.004094330\n",
      "train reg_fs: 0.0018108683871105313\n",
      "Epoch: 14000 train loss=0.002776844 valid loss= 0.004121410\n",
      "train reg_fs: 0.0018081176094710827\n",
      "Epoch: 14500 train loss=0.002990296 valid loss= 0.003955072\n",
      "train reg_fs: 0.0018057111883535981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:18:27,226]\u001b[0m Trial 69 finished with value: 0.0023259325786043577 and parameters: {'lam': 0.002949281974235131, 'learning_rate': 0.07035310544849681, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002069514 valid loss= 0.004093123\n",
      "train reg_fs: 0.0018034597160294652\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023259325786043577\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008865963 valid loss= 0.007285440\n",
      "train reg_fs: 0.002380490768700838\n",
      "Epoch: 1000 train loss=0.004991387 valid loss= 0.006752094\n",
      "train reg_fs: 0.002275279723107815\n",
      "Epoch: 1500 train loss=0.007015297 valid loss= 0.004679615\n",
      "train reg_fs: 0.0021301123779267073\n",
      "Epoch: 2000 train loss=0.008240934 valid loss= 0.004848381\n",
      "train reg_fs: 0.0020663549657911062\n",
      "Epoch: 2500 train loss=0.003394231 valid loss= 0.004438356\n",
      "train reg_fs: 0.002027728594839573\n",
      "Epoch: 3000 train loss=0.004132799 valid loss= 0.004606952\n",
      "train reg_fs: 0.0019999162759631872\n",
      "Epoch: 3500 train loss=0.003891674 valid loss= 0.004180012\n",
      "train reg_fs: 0.0019771414808928967\n",
      "Epoch: 4000 train loss=0.002899467 valid loss= 0.004706398\n",
      "train reg_fs: 0.0019593967590481043\n",
      "Epoch: 4500 train loss=0.003274842 valid loss= 0.004012574\n",
      "train reg_fs: 0.0019403781043365598\n",
      "Epoch: 5000 train loss=0.002743012 valid loss= 0.003966415\n",
      "train reg_fs: 0.0019239290850237012\n",
      "Epoch: 5500 train loss=0.002424566 valid loss= 0.004367984\n",
      "train reg_fs: 0.0019012552220374346\n",
      "Epoch: 6000 train loss=0.005761213 valid loss= 0.003963868\n",
      "train reg_fs: 0.0018755585188046098\n",
      "Epoch: 6500 train loss=0.003897528 valid loss= 0.004468816\n",
      "train reg_fs: 0.001847806852310896\n",
      "Epoch: 7000 train loss=0.002578849 valid loss= 0.004340931\n",
      "train reg_fs: 0.0018179997568950057\n",
      "Epoch: 7500 train loss=0.004402834 valid loss= 0.004168971\n",
      "train reg_fs: 0.0017916440265253186\n",
      "Epoch: 8000 train loss=0.002049978 valid loss= 0.004346129\n",
      "train reg_fs: 0.0017680020537227392\n",
      "Epoch: 8500 train loss=0.002500223 valid loss= 0.004043497\n",
      "train reg_fs: 0.0017504164716228843\n",
      "Epoch: 9000 train loss=0.003168349 valid loss= 0.004010163\n",
      "train reg_fs: 0.0017356432508677244\n",
      "Epoch: 9500 train loss=0.007220701 valid loss= 0.004221438\n",
      "train reg_fs: 0.0017235262785106897\n",
      "Epoch: 10000 train loss=0.002502736 valid loss= 0.004185936\n",
      "train reg_fs: 0.0017141971038654447\n",
      "Epoch: 10500 train loss=0.002316319 valid loss= 0.003945084\n",
      "train reg_fs: 0.0017075056675821543\n",
      "Epoch: 11000 train loss=0.003311927 valid loss= 0.003844519\n",
      "train reg_fs: 0.0017009619623422623\n",
      "Epoch: 11500 train loss=0.003097467 valid loss= 0.003739824\n",
      "train reg_fs: 0.00169602211099118\n",
      "Epoch: 12000 train loss=0.001887724 valid loss= 0.004003268\n",
      "train reg_fs: 0.0016912317369133234\n",
      "Epoch: 12500 train loss=0.002828551 valid loss= 0.003779488\n",
      "train reg_fs: 0.001687318435870111\n",
      "Epoch: 13000 train loss=0.002127029 valid loss= 0.003752390\n",
      "train reg_fs: 0.0016840258613228798\n",
      "Epoch: 13500 train loss=0.002887139 valid loss= 0.003971428\n",
      "train reg_fs: 0.0016812195535749197\n",
      "Epoch: 14000 train loss=0.003399522 valid loss= 0.003862557\n",
      "train reg_fs: 0.001678580534644425\n",
      "Epoch: 14500 train loss=0.002561283 valid loss= 0.003828042\n",
      "train reg_fs: 0.0016763036837801337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:20:16,896]\u001b[0m Trial 70 finished with value: 0.002288390841934237 and parameters: {'lam': 0.002748129019840552, 'learning_rate': 0.08878331150384733, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003077671 valid loss= 0.003924702\n",
      "train reg_fs: 0.0016741579165682197\n",
      "In trial:---------------------\n",
      "validation mse: 0.002288390841934237\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009345872 valid loss= 0.005949765\n",
      "train reg_fs: 0.0018180706538259983\n",
      "Epoch: 1000 train loss=0.014516210 valid loss= 0.005810813\n",
      "train reg_fs: 0.0017733139684423804\n",
      "Epoch: 1500 train loss=0.005148615 valid loss= 0.004858133\n",
      "train reg_fs: 0.001691082725301385\n",
      "Epoch: 2000 train loss=0.004765330 valid loss= 0.004428288\n",
      "train reg_fs: 0.0016267331084236503\n",
      "Epoch: 2500 train loss=0.004904673 valid loss= 0.004077095\n",
      "train reg_fs: 0.0015888209454715252\n",
      "Epoch: 3000 train loss=0.005866924 valid loss= 0.004302977\n",
      "train reg_fs: 0.0015656433533877134\n",
      "Epoch: 3500 train loss=0.003405373 valid loss= 0.004160611\n",
      "train reg_fs: 0.0015448981430381536\n",
      "Epoch: 4000 train loss=0.005598937 valid loss= 0.004320939\n",
      "train reg_fs: 0.0015287228161469102\n",
      "Epoch: 4500 train loss=0.007882385 valid loss= 0.004020048\n",
      "train reg_fs: 0.0015157460002228618\n",
      "Epoch: 5000 train loss=0.004314467 valid loss= 0.004262106\n",
      "train reg_fs: 0.0015041260048747063\n",
      "Epoch: 5500 train loss=0.002381480 valid loss= 0.004376251\n",
      "train reg_fs: 0.0014922639820724726\n",
      "Epoch: 6000 train loss=0.002791026 valid loss= 0.003948210\n",
      "train reg_fs: 0.0014812275767326355\n",
      "Epoch: 6500 train loss=0.006216990 valid loss= 0.004788458\n",
      "train reg_fs: 0.0014733667485415936\n",
      "Epoch: 7000 train loss=0.003424160 valid loss= 0.004234202\n",
      "train reg_fs: 0.0014656728599220514\n",
      "Epoch: 7500 train loss=0.007265589 valid loss= 0.004436463\n",
      "train reg_fs: 0.0014572110958397388\n",
      "Epoch: 8000 train loss=0.003781130 valid loss= 0.004486055\n",
      "train reg_fs: 0.0014518098905682564\n",
      "Epoch: 8500 train loss=0.007630886 valid loss= 0.004548613\n",
      "train reg_fs: 0.0014470029855147004\n",
      "Epoch: 9000 train loss=0.008038254 valid loss= 0.004505416\n",
      "train reg_fs: 0.0014413888566195965\n",
      "Epoch: 9500 train loss=0.004249481 valid loss= 0.004487589\n",
      "train reg_fs: 0.0014351728605106473\n",
      "Epoch: 10000 train loss=0.010581307 valid loss= 0.004598197\n",
      "train reg_fs: 0.001430434174835682\n",
      "Epoch: 10500 train loss=0.003580542 valid loss= 0.004677475\n",
      "train reg_fs: 0.0014246114296838641\n",
      "Epoch: 11000 train loss=0.005636537 valid loss= 0.004693491\n",
      "train reg_fs: 0.0014186985790729523\n",
      "Epoch: 11500 train loss=0.003872070 valid loss= 0.004764414\n",
      "train reg_fs: 0.00141333625651896\n",
      "Epoch: 12000 train loss=0.003929462 valid loss= 0.004863702\n",
      "train reg_fs: 0.001408784301020205\n",
      "Epoch: 12500 train loss=0.002705105 valid loss= 0.004543741\n",
      "train reg_fs: 0.0014039321104064584\n",
      "Epoch: 13000 train loss=0.005282252 valid loss= 0.005023418\n",
      "train reg_fs: 0.001399685861542821\n",
      "Epoch: 13500 train loss=0.002984808 valid loss= 0.004657037\n",
      "train reg_fs: 0.0013956581242382526\n",
      "Epoch: 14000 train loss=0.003615898 valid loss= 0.005192967\n",
      "train reg_fs: 0.001391587546095252\n",
      "Epoch: 14500 train loss=0.003259682 valid loss= 0.004925511\n",
      "train reg_fs: 0.0013875404838472605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:22:06,606]\u001b[0m Trial 71 finished with value: 0.0037195977826158313 and parameters: {'lam': 0.0021510892475700392, 'learning_rate': 0.055322222224017455, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005088015 valid loss= 0.005178450\n",
      "train reg_fs: 0.0013841986656188965\n",
      "In trial:---------------------\n",
      "validation mse: 0.0037195977826158313\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007265723 valid loss= 0.008250445\n",
      "train reg_fs: 0.001660080743022263\n",
      "Epoch: 1000 train loss=0.014142828 valid loss= 0.009416564\n",
      "train reg_fs: 0.001682677073404193\n",
      "Epoch: 1500 train loss=0.010289833 valid loss= 0.007726363\n",
      "train reg_fs: 0.0016748914495110512\n",
      "Epoch: 2000 train loss=0.005210928 valid loss= 0.007608426\n",
      "train reg_fs: 0.0016441951738670468\n",
      "Epoch: 2500 train loss=0.006357493 valid loss= 0.007542694\n",
      "train reg_fs: 0.0016023102216422558\n",
      "Epoch: 3000 train loss=0.007775192 valid loss= 0.007559235\n",
      "train reg_fs: 0.0015698723727837205\n",
      "Epoch: 3500 train loss=0.003651456 valid loss= 0.006020670\n",
      "train reg_fs: 0.001549824490211904\n",
      "Epoch: 4000 train loss=0.007771861 valid loss= 0.006061853\n",
      "train reg_fs: 0.0015357632655650377\n",
      "Epoch: 4500 train loss=0.007607327 valid loss= 0.005963543\n",
      "train reg_fs: 0.0015216346364468336\n",
      "Epoch: 5000 train loss=0.004994449 valid loss= 0.005600532\n",
      "train reg_fs: 0.0015111122047528625\n",
      "Epoch: 5500 train loss=0.005382104 valid loss= 0.005304669\n",
      "train reg_fs: 0.0015033921226859093\n",
      "Epoch: 6000 train loss=0.003146846 valid loss= 0.005107804\n",
      "train reg_fs: 0.001490684226155281\n",
      "Epoch: 6500 train loss=0.004773800 valid loss= 0.004661505\n",
      "train reg_fs: 0.001478866790421307\n",
      "Epoch: 7000 train loss=0.003913826 valid loss= 0.004324040\n",
      "train reg_fs: 0.0014611082151532173\n",
      "Epoch: 7500 train loss=0.007203659 valid loss= 0.003732620\n",
      "train reg_fs: 0.001441274886019528\n",
      "Epoch: 8000 train loss=0.004053040 valid loss= 0.003757103\n",
      "train reg_fs: 0.0014243378536775708\n",
      "Epoch: 8500 train loss=0.004189894 valid loss= 0.003785932\n",
      "train reg_fs: 0.001411366742104292\n",
      "Epoch: 9000 train loss=0.002101006 valid loss= 0.003808386\n",
      "train reg_fs: 0.001400304608978331\n",
      "Epoch: 9500 train loss=0.004686810 valid loss= 0.004136823\n",
      "train reg_fs: 0.0013892719289287925\n",
      "Epoch: 10000 train loss=0.010824798 valid loss= 0.004075679\n",
      "train reg_fs: 0.001383231021463871\n",
      "Epoch: 10500 train loss=0.005087913 valid loss= 0.004152996\n",
      "train reg_fs: 0.0013779352884739637\n",
      "Epoch: 11000 train loss=0.003785540 valid loss= 0.003964837\n",
      "train reg_fs: 0.0013725108001381159\n",
      "Epoch: 11500 train loss=0.004138617 valid loss= 0.004062602\n",
      "train reg_fs: 0.0013665810693055391\n",
      "Epoch: 12000 train loss=0.001539351 valid loss= 0.003826886\n",
      "train reg_fs: 0.0013632926857098937\n",
      "Epoch: 12500 train loss=0.003015464 valid loss= 0.003978702\n",
      "train reg_fs: 0.0013592474861070514\n",
      "Epoch: 13000 train loss=0.002545300 valid loss= 0.004232227\n",
      "train reg_fs: 0.0013541156658902764\n",
      "Epoch: 13500 train loss=0.003563951 valid loss= 0.004456589\n",
      "train reg_fs: 0.0013493021251633763\n",
      "Epoch: 14000 train loss=0.002099554 valid loss= 0.003966413\n",
      "train reg_fs: 0.001344520365819335\n",
      "Epoch: 14500 train loss=0.002424426 valid loss= 0.004281208\n",
      "train reg_fs: 0.001339579583145678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:23:56,244]\u001b[0m Trial 72 finished with value: 0.0027964567832378545 and parameters: {'lam': 0.0019064807512820603, 'learning_rate': 0.06315924593191799, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002124904 valid loss= 0.004130881\n",
      "train reg_fs: 0.0013374369591474533\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027964567832378545\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.021009071 valid loss= 0.008022683\n",
      "train reg_fs: 0.0011696344008669257\n",
      "Epoch: 1000 train loss=0.009200543 valid loss= 0.008383373\n",
      "train reg_fs: 0.001188774942420423\n",
      "Epoch: 1500 train loss=0.014861406 valid loss= 0.008554872\n",
      "train reg_fs: 0.00119586696382612\n",
      "Epoch: 2000 train loss=0.008955454 valid loss= 0.007445877\n",
      "train reg_fs: 0.0011950404150411487\n",
      "Epoch: 2500 train loss=0.004735680 valid loss= 0.007901289\n",
      "train reg_fs: 0.00118823884986341\n",
      "Epoch: 3000 train loss=0.004657263 valid loss= 0.007111868\n",
      "train reg_fs: 0.0011743095237761736\n",
      "Epoch: 3500 train loss=0.008015974 valid loss= 0.006830976\n",
      "train reg_fs: 0.0011593957897275686\n",
      "Epoch: 4000 train loss=0.004311050 valid loss= 0.006922473\n",
      "train reg_fs: 0.0011419994989410043\n",
      "Epoch: 4500 train loss=0.009194652 valid loss= 0.005758731\n",
      "train reg_fs: 0.001129072974435985\n",
      "Epoch: 5000 train loss=0.006939068 valid loss= 0.005526901\n",
      "train reg_fs: 0.001116132945753634\n",
      "Epoch: 5500 train loss=0.003590891 valid loss= 0.004827855\n",
      "train reg_fs: 0.0011049066670238972\n",
      "Epoch: 6000 train loss=0.002182684 valid loss= 0.004671326\n",
      "train reg_fs: 0.0010937119368463755\n",
      "Epoch: 6500 train loss=0.007469179 valid loss= 0.004350285\n",
      "train reg_fs: 0.0010825092904269695\n",
      "Epoch: 7000 train loss=0.004567125 valid loss= 0.003717972\n",
      "train reg_fs: 0.001068984973244369\n",
      "Epoch: 7500 train loss=0.004955066 valid loss= 0.003857280\n",
      "train reg_fs: 0.0010552864987403154\n",
      "Epoch: 8000 train loss=0.002397532 valid loss= 0.003782885\n",
      "train reg_fs: 0.0010454878211021423\n",
      "Epoch: 8500 train loss=0.002571981 valid loss= 0.003545397\n",
      "train reg_fs: 0.0010348537471145391\n",
      "Epoch: 9000 train loss=0.005945159 valid loss= 0.003711497\n",
      "train reg_fs: 0.0010262664873152971\n",
      "Epoch: 9500 train loss=0.007397885 valid loss= 0.003553339\n",
      "train reg_fs: 0.0010193887865170836\n",
      "Epoch: 10000 train loss=0.002761098 valid loss= 0.003638023\n",
      "train reg_fs: 0.001013791305013001\n",
      "Epoch: 10500 train loss=0.007651494 valid loss= 0.003359995\n",
      "train reg_fs: 0.0010083351517096162\n",
      "Epoch: 11000 train loss=0.004846583 valid loss= 0.003862032\n",
      "train reg_fs: 0.001004160731099546\n",
      "Epoch: 11500 train loss=0.002413099 valid loss= 0.003254143\n",
      "train reg_fs: 0.0009990223916247487\n",
      "Epoch: 12000 train loss=0.002631943 valid loss= 0.003465083\n",
      "train reg_fs: 0.0009961924515664577\n",
      "Epoch: 12500 train loss=0.002621113 valid loss= 0.003207934\n",
      "train reg_fs: 0.0009927512146532536\n",
      "Epoch: 13000 train loss=0.001387202 valid loss= 0.003540838\n",
      "train reg_fs: 0.0009903500322252512\n",
      "Epoch: 13500 train loss=0.003811527 valid loss= 0.003446373\n",
      "train reg_fs: 0.0009864731691777706\n",
      "Epoch: 14000 train loss=0.001819354 valid loss= 0.003388412\n",
      "train reg_fs: 0.0009842000436037779\n",
      "Epoch: 14500 train loss=0.002466632 valid loss= 0.003537202\n",
      "train reg_fs: 0.000981200486421585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:25:45,710]\u001b[0m Trial 73 finished with value: 0.0024500385659866745 and parameters: {'lam': 0.001355683399436083, 'learning_rate': 0.04822867937657272, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001350069 valid loss= 0.003431871\n",
      "train reg_fs: 0.0009789773030206561\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024500385659866745\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.031349875 valid loss= 0.008464646\n",
      "train reg_fs: 0.0020385519601404667\n",
      "Epoch: 1000 train loss=0.008412746 valid loss= 0.005423485\n",
      "train reg_fs: 0.0019256880041211843\n",
      "Epoch: 1500 train loss=0.010501183 valid loss= 0.005361827\n",
      "train reg_fs: 0.0018446387257426977\n",
      "Epoch: 2000 train loss=0.006273538 valid loss= 0.004715822\n",
      "train reg_fs: 0.0018085308838635683\n",
      "Epoch: 2500 train loss=0.003967382 valid loss= 0.005202954\n",
      "train reg_fs: 0.0017792894504964352\n",
      "Epoch: 3000 train loss=0.009712380 valid loss= 0.005273386\n",
      "train reg_fs: 0.0017547898460179567\n",
      "Epoch: 3500 train loss=0.010780930 valid loss= 0.005074953\n",
      "train reg_fs: 0.0017253987025469542\n",
      "Epoch: 4000 train loss=0.003056175 valid loss= 0.005046550\n",
      "train reg_fs: 0.001690206932835281\n",
      "Epoch: 4500 train loss=0.003182397 valid loss= 0.004684363\n",
      "train reg_fs: 0.0016524827806279063\n",
      "Epoch: 5000 train loss=0.006270148 valid loss= 0.004679547\n",
      "train reg_fs: 0.001623956486582756\n",
      "Epoch: 5500 train loss=0.003002486 valid loss= 0.004575716\n",
      "train reg_fs: 0.0016000017058104277\n",
      "Epoch: 6000 train loss=0.004521315 valid loss= 0.004265197\n",
      "train reg_fs: 0.0015813923673704267\n",
      "Epoch: 6500 train loss=0.003953858 valid loss= 0.004267818\n",
      "train reg_fs: 0.0015667465049773455\n",
      "Epoch: 7000 train loss=0.007927505 valid loss= 0.004096604\n",
      "train reg_fs: 0.001554381800815463\n",
      "Epoch: 7500 train loss=0.002066220 valid loss= 0.004168880\n",
      "train reg_fs: 0.0015440928982570767\n",
      "Epoch: 8000 train loss=0.001743947 valid loss= 0.004144423\n",
      "train reg_fs: 0.0015353549970313907\n",
      "Epoch: 8500 train loss=0.002305231 valid loss= 0.003904589\n",
      "train reg_fs: 0.0015279895160347223\n",
      "Epoch: 9000 train loss=0.002516188 valid loss= 0.003834738\n",
      "train reg_fs: 0.001521908096037805\n",
      "Epoch: 9500 train loss=0.003358015 valid loss= 0.004018682\n",
      "train reg_fs: 0.0015167751116678119\n",
      "Epoch: 10000 train loss=0.004278661 valid loss= 0.003805065\n",
      "train reg_fs: 0.0015121763572096825\n",
      "Epoch: 10500 train loss=0.003281268 valid loss= 0.003967914\n",
      "train reg_fs: 0.0015079480363056064\n",
      "Epoch: 11000 train loss=0.003724623 valid loss= 0.003861005\n",
      "train reg_fs: 0.001503834850154817\n",
      "Epoch: 11500 train loss=0.001987217 valid loss= 0.003911921\n",
      "train reg_fs: 0.0015006698668003082\n",
      "Epoch: 12000 train loss=0.004479158 valid loss= 0.003775722\n",
      "train reg_fs: 0.0014975612284615636\n",
      "Epoch: 12500 train loss=0.001958219 valid loss= 0.004018616\n",
      "train reg_fs: 0.00149493757635355\n",
      "Epoch: 13000 train loss=0.002266134 valid loss= 0.003907924\n",
      "train reg_fs: 0.0014923943672329187\n",
      "Epoch: 13500 train loss=0.002396022 valid loss= 0.003793005\n",
      "train reg_fs: 0.0014901815447956324\n",
      "Epoch: 14000 train loss=0.001691830 valid loss= 0.003708129\n",
      "train reg_fs: 0.0014879814116284251\n",
      "Epoch: 14500 train loss=0.003221737 valid loss= 0.003613557\n",
      "train reg_fs: 0.0014860365772619843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:27:35,688]\u001b[0m Trial 74 finished with value: 0.002396818777474539 and parameters: {'lam': 0.002432364151033432, 'learning_rate': 0.07758888878421065, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001764564 valid loss= 0.003851529\n",
      "train reg_fs: 0.0014843031531199813\n",
      "In trial:---------------------\n",
      "validation mse: 0.002396818777474539\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.023644842 valid loss= 0.010173025\n",
      "train reg_fs: 0.0027328534051775932\n",
      "Epoch: 1000 train loss=0.022623256 valid loss= 0.010324083\n",
      "train reg_fs: 0.0027684944216161966\n",
      "Epoch: 1500 train loss=0.013430398 valid loss= 0.009850914\n",
      "train reg_fs: 0.002796875312924385\n",
      "Epoch: 2000 train loss=0.012932267 valid loss= 0.009539671\n",
      "train reg_fs: 0.002815796062350273\n",
      "Epoch: 2500 train loss=0.010997114 valid loss= 0.009355310\n",
      "train reg_fs: 0.002827475778758526\n",
      "Epoch: 3000 train loss=0.019697979 valid loss= 0.009851837\n",
      "train reg_fs: 0.0028331512585282326\n",
      "Epoch: 3500 train loss=0.011119592 valid loss= 0.009740515\n",
      "train reg_fs: 0.0028331063222140074\n",
      "Epoch: 4000 train loss=0.010184506 valid loss= 0.008942543\n",
      "train reg_fs: 0.002830497920513153\n",
      "Epoch: 4500 train loss=0.010703795 valid loss= 0.008834210\n",
      "train reg_fs: 0.002821811009198427\n",
      "Epoch: 5000 train loss=0.010922084 valid loss= 0.008426677\n",
      "train reg_fs: 0.002804212272167206\n",
      "Epoch: 5500 train loss=0.007950643 valid loss= 0.007787662\n",
      "train reg_fs: 0.002781974384561181\n",
      "Epoch: 6000 train loss=0.014202623 valid loss= 0.008101680\n",
      "train reg_fs: 0.002753923647105694\n",
      "Epoch: 6500 train loss=0.010342359 valid loss= 0.007246814\n",
      "train reg_fs: 0.0027190549299120903\n",
      "Epoch: 7000 train loss=0.011370244 valid loss= 0.006545093\n",
      "train reg_fs: 0.00267559802159667\n",
      "Epoch: 7500 train loss=0.004258121 valid loss= 0.006419739\n",
      "train reg_fs: 0.002632644958794117\n",
      "Epoch: 8000 train loss=0.006961354 valid loss= 0.006021109\n",
      "train reg_fs: 0.0025924728251993656\n",
      "Epoch: 8500 train loss=0.004572953 valid loss= 0.005581223\n",
      "train reg_fs: 0.002559174317866564\n",
      "Epoch: 9000 train loss=0.007290096 valid loss= 0.005592803\n",
      "train reg_fs: 0.002530018799006939\n",
      "Epoch: 9500 train loss=0.004437137 valid loss= 0.005333808\n",
      "train reg_fs: 0.002506775315850973\n",
      "Epoch: 10000 train loss=0.009756712 valid loss= 0.005433501\n",
      "train reg_fs: 0.002488549333065748\n",
      "Epoch: 10500 train loss=0.006389781 valid loss= 0.005378366\n",
      "train reg_fs: 0.002471975749358535\n",
      "Epoch: 11000 train loss=0.006418119 valid loss= 0.005486088\n",
      "train reg_fs: 0.0024585030041635036\n",
      "Epoch: 11500 train loss=0.006928206 valid loss= 0.005715233\n",
      "train reg_fs: 0.002447182545438409\n",
      "Epoch: 12000 train loss=0.005262164 valid loss= 0.005458464\n",
      "train reg_fs: 0.0024366064462810755\n",
      "Epoch: 12500 train loss=0.007196540 valid loss= 0.005681121\n",
      "train reg_fs: 0.0024282310623675585\n",
      "Epoch: 13000 train loss=0.003693609 valid loss= 0.005818788\n",
      "train reg_fs: 0.002418908989056945\n",
      "Epoch: 13500 train loss=0.003654132 valid loss= 0.005791974\n",
      "train reg_fs: 0.0024111620150506496\n",
      "Epoch: 14000 train loss=0.003404187 valid loss= 0.005710768\n",
      "train reg_fs: 0.002403798047453165\n",
      "Epoch: 14500 train loss=0.004139121 valid loss= 0.005832830\n",
      "train reg_fs: 0.0023979605175554752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:29:26,237]\u001b[0m Trial 75 finished with value: 0.0032368654720990537 and parameters: {'lam': 0.003202470196556766, 'learning_rate': 0.026964368425927854, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.008272896 valid loss= 0.005678766\n",
      "train reg_fs: 0.0023913001641631126\n",
      "In trial:---------------------\n",
      "validation mse: 0.0032368654720990537\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010761329 valid loss= 0.006949471\n",
      "train reg_fs: 0.0014736662851646543\n",
      "Epoch: 1000 train loss=0.015149243 valid loss= 0.006762436\n",
      "train reg_fs: 0.001485709915868938\n",
      "Epoch: 1500 train loss=0.005089403 valid loss= 0.006942280\n",
      "train reg_fs: 0.0014717915328219533\n",
      "Epoch: 2000 train loss=0.006153557 valid loss= 0.006252373\n",
      "train reg_fs: 0.0014385689282789826\n",
      "Epoch: 2500 train loss=0.004477592 valid loss= 0.005418657\n",
      "train reg_fs: 0.0014169542118906975\n",
      "Epoch: 3000 train loss=0.005934721 valid loss= 0.005211233\n",
      "train reg_fs: 0.0014042790280655026\n",
      "Epoch: 3500 train loss=0.005136881 valid loss= 0.004626935\n",
      "train reg_fs: 0.001400280394591391\n",
      "Epoch: 4000 train loss=0.002350816 valid loss= 0.004824687\n",
      "train reg_fs: 0.00138812733348459\n",
      "Epoch: 4500 train loss=0.004432067 valid loss= 0.004816175\n",
      "train reg_fs: 0.0013819695450365543\n",
      "Epoch: 5000 train loss=0.002059794 valid loss= 0.005011912\n",
      "train reg_fs: 0.0013769587967544794\n",
      "Epoch: 5500 train loss=0.002186036 valid loss= 0.004758084\n",
      "train reg_fs: 0.0013735877582803369\n",
      "Epoch: 6000 train loss=0.003324898 valid loss= 0.004785903\n",
      "train reg_fs: 0.0013684197328984737\n",
      "Epoch: 6500 train loss=0.003669300 valid loss= 0.004856140\n",
      "train reg_fs: 0.0013638357631862164\n",
      "Epoch: 7000 train loss=0.002999614 valid loss= 0.005095528\n",
      "train reg_fs: 0.0013598711229860783\n",
      "Epoch: 7500 train loss=0.003214624 valid loss= 0.004863318\n",
      "train reg_fs: 0.0013569737784564495\n",
      "Epoch: 8000 train loss=0.004425644 valid loss= 0.005476899\n",
      "train reg_fs: 0.0013521361397579312\n",
      "Epoch: 8500 train loss=0.002239581 valid loss= 0.005297532\n",
      "train reg_fs: 0.00134796102065593\n",
      "Epoch: 9000 train loss=0.006522945 valid loss= 0.005604174\n",
      "train reg_fs: 0.0013460025656968355\n",
      "Epoch: 9500 train loss=0.006211089 valid loss= 0.005434434\n",
      "train reg_fs: 0.0013430560939013958\n",
      "Epoch: 10000 train loss=0.002548085 valid loss= 0.005635504\n",
      "train reg_fs: 0.0013406132347881794\n",
      "Epoch: 10500 train loss=0.002697016 valid loss= 0.005190476\n",
      "train reg_fs: 0.0013360638404265046\n",
      "Epoch: 11000 train loss=0.004501397 valid loss= 0.005681387\n",
      "train reg_fs: 0.0013307251501828432\n",
      "Epoch: 11500 train loss=0.002722278 valid loss= 0.006011752\n",
      "train reg_fs: 0.0013251348864287138\n",
      "Epoch: 12000 train loss=0.005595209 valid loss= 0.005729697\n",
      "train reg_fs: 0.001322334399446845\n",
      "Epoch: 12500 train loss=0.002285488 valid loss= 0.005932094\n",
      "train reg_fs: 0.0013183604460209608\n",
      "Epoch: 13000 train loss=0.002947396 valid loss= 0.006105591\n",
      "train reg_fs: 0.00131330918520689\n",
      "Epoch: 13500 train loss=0.003013397 valid loss= 0.006248521\n",
      "train reg_fs: 0.001308782142587006\n",
      "Epoch: 14000 train loss=0.002241472 valid loss= 0.005941852\n",
      "train reg_fs: 0.0013095671311020851\n",
      "Epoch: 14500 train loss=0.002431878 valid loss= 0.006163483\n",
      "train reg_fs: 0.0013028682442381978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:31:16,784]\u001b[0m Trial 76 finished with value: 0.004676639783753914 and parameters: {'lam': 0.0016824185489995043, 'learning_rate': 0.10355785836694524, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003365291 valid loss= 0.005998809\n",
      "train reg_fs: 0.0013008438982069492\n",
      "In trial:---------------------\n",
      "validation mse: 0.004676639783753914\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012867855 valid loss= 0.009098788\n",
      "train reg_fs: 0.0012995407450944185\n",
      "Epoch: 1000 train loss=0.006672354 valid loss= 0.008368855\n",
      "train reg_fs: 0.0013024251675233245\n",
      "Epoch: 1500 train loss=0.004238530 valid loss= 0.006350028\n",
      "train reg_fs: 0.001271108747459948\n",
      "Epoch: 2000 train loss=0.010565251 valid loss= 0.005049643\n",
      "train reg_fs: 0.0012388445902615786\n",
      "Epoch: 2500 train loss=0.008303936 valid loss= 0.003755807\n",
      "train reg_fs: 0.001206965884193778\n",
      "Epoch: 3000 train loss=0.004844930 valid loss= 0.003823936\n",
      "train reg_fs: 0.0011828886345028877\n",
      "Epoch: 3500 train loss=0.011107083 valid loss= 0.003630803\n",
      "train reg_fs: 0.0011681434698402882\n",
      "Epoch: 4000 train loss=0.002361602 valid loss= 0.003550963\n",
      "train reg_fs: 0.0011548837646842003\n",
      "Epoch: 4500 train loss=0.004175657 valid loss= 0.003289383\n",
      "train reg_fs: 0.0011438644723966718\n",
      "Epoch: 5000 train loss=0.002236332 valid loss= 0.003728577\n",
      "train reg_fs: 0.0011336064198985696\n",
      "Epoch: 5500 train loss=0.005927049 valid loss= 0.003530710\n",
      "train reg_fs: 0.0011250789975747466\n",
      "Epoch: 6000 train loss=0.002338219 valid loss= 0.003493080\n",
      "train reg_fs: 0.0011179381981492043\n",
      "Epoch: 6500 train loss=0.005658232 valid loss= 0.003192795\n",
      "train reg_fs: 0.0011129999766126275\n",
      "Epoch: 7000 train loss=0.003151754 valid loss= 0.003605973\n",
      "train reg_fs: 0.001109641045331955\n",
      "Epoch: 7500 train loss=0.001454522 valid loss= 0.002812025\n",
      "train reg_fs: 0.0011069715255871415\n",
      "Epoch: 8000 train loss=0.005926067 valid loss= 0.003294104\n",
      "train reg_fs: 0.0011047656880691648\n",
      "Epoch: 8500 train loss=0.005199977 valid loss= 0.003404103\n",
      "train reg_fs: 0.0011033699847757816\n",
      "Epoch: 9000 train loss=0.001954327 valid loss= 0.003538214\n",
      "train reg_fs: 0.0011009732261300087\n",
      "Epoch: 9500 train loss=0.005256019 valid loss= 0.003309076\n",
      "train reg_fs: 0.0010988801950588822\n",
      "Epoch: 10000 train loss=0.002846945 valid loss= 0.003023309\n",
      "train reg_fs: 0.0010972353629767895\n",
      "Epoch: 10500 train loss=0.003975007 valid loss= 0.002832539\n",
      "train reg_fs: 0.0010951048461720347\n",
      "Epoch: 11000 train loss=0.001463140 valid loss= 0.003044129\n",
      "train reg_fs: 0.0010926653631031513\n",
      "Epoch: 11500 train loss=0.002310361 valid loss= 0.003071737\n",
      "train reg_fs: 0.001090835314244032\n",
      "Epoch: 12000 train loss=0.001526808 valid loss= 0.003131504\n",
      "train reg_fs: 0.0010887837270274758\n",
      "Epoch: 12500 train loss=0.005743214 valid loss= 0.002986615\n",
      "train reg_fs: 0.001086946576833725\n",
      "Epoch: 13000 train loss=0.002363975 valid loss= 0.003141273\n",
      "train reg_fs: 0.0010854193242266774\n",
      "Epoch: 13500 train loss=0.003178095 valid loss= 0.002889811\n",
      "train reg_fs: 0.0010837510926648974\n",
      "Epoch: 14000 train loss=0.004118178 valid loss= 0.003059369\n",
      "train reg_fs: 0.0010824896162375808\n",
      "Epoch: 14500 train loss=0.011208170 valid loss= 0.003214712\n",
      "train reg_fs: 0.001080657122656703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:33:08,058]\u001b[0m Trial 77 finished with value: 0.0022529167179816613 and parameters: {'lam': 0.0014913171446600721, 'learning_rate': 0.081285054537604, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002269130 valid loss= 0.003296889\n",
      "train reg_fs: 0.0010790755040943623\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022529167179816613\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010494006 valid loss= 0.005918724\n",
      "train reg_fs: 0.0010883192298933864\n",
      "Epoch: 1000 train loss=0.006509271 valid loss= 0.004883995\n",
      "train reg_fs: 0.0010811443207785487\n",
      "Epoch: 1500 train loss=0.005683054 valid loss= 0.004076700\n",
      "train reg_fs: 0.0010539848590269685\n",
      "Epoch: 2000 train loss=0.004182077 valid loss= 0.003504958\n",
      "train reg_fs: 0.0010354167316108942\n",
      "Epoch: 2500 train loss=0.003612971 valid loss= 0.002634226\n",
      "train reg_fs: 0.0010240261908620596\n",
      "Epoch: 3000 train loss=0.003733702 valid loss= 0.003075234\n",
      "train reg_fs: 0.001014729030430317\n",
      "Epoch: 3500 train loss=0.002565765 valid loss= 0.003140064\n",
      "train reg_fs: 0.0010058573679998517\n",
      "Epoch: 4000 train loss=0.004009156 valid loss= 0.003124777\n",
      "train reg_fs: 0.0010004551149904728\n",
      "Epoch: 4500 train loss=0.004073375 valid loss= 0.002874881\n",
      "train reg_fs: 0.0009952043183147907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:33:45,930]\u001b[0m Trial 78 finished with value: 0.0016638608235956824 and parameters: {'lam': 0.0012390409853788279, 'learning_rate': 0.11818610042375502, 'num_epoch': 5000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002872644 valid loss= 0.002655435\n",
      "train reg_fs: 0.0009894465329125524\n",
      "In trial:---------------------\n",
      "validation mse: 0.0016638608235956824\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009712689 valid loss= 0.008089907\n",
      "train reg_fs: 0.0015914469258859754\n",
      "Epoch: 1000 train loss=0.009942129 valid loss= 0.007446486\n",
      "train reg_fs: 0.0015689373249188066\n",
      "Epoch: 1500 train loss=0.017228801 valid loss= 0.006547183\n",
      "train reg_fs: 0.0015315733617171645\n",
      "Epoch: 2000 train loss=0.008727587 valid loss= 0.005805839\n",
      "train reg_fs: 0.0014949595788493752\n",
      "Epoch: 2500 train loss=0.007039992 valid loss= 0.004626886\n",
      "train reg_fs: 0.0014581989962607622\n",
      "Epoch: 3000 train loss=0.002749509 valid loss= 0.004360567\n",
      "train reg_fs: 0.0014278293820098042\n",
      "Epoch: 3500 train loss=0.004676113 valid loss= 0.004440400\n",
      "train reg_fs: 0.0014039120869711041\n",
      "Epoch: 4000 train loss=0.005495691 valid loss= 0.004883272\n",
      "train reg_fs: 0.0013822488253936172\n",
      "Epoch: 4500 train loss=0.003698571 valid loss= 0.004743975\n",
      "train reg_fs: 0.0013655498623847961\n",
      "Epoch: 5000 train loss=0.003584680 valid loss= 0.004547929\n",
      "train reg_fs: 0.0013441134942695498\n",
      "Epoch: 5500 train loss=0.003827582 valid loss= 0.004370433\n",
      "train reg_fs: 0.0013231310294941068\n",
      "Epoch: 6000 train loss=0.002512395 valid loss= 0.004381594\n",
      "train reg_fs: 0.0013017586898058653\n",
      "Epoch: 6500 train loss=0.002521180 valid loss= 0.004167126\n",
      "train reg_fs: 0.0012839395785704255\n",
      "Epoch: 7000 train loss=0.002831610 valid loss= 0.004018301\n",
      "train reg_fs: 0.001267166226170957\n",
      "Epoch: 7500 train loss=0.003666515 valid loss= 0.003952762\n",
      "train reg_fs: 0.0012533951085060835\n",
      "Epoch: 8000 train loss=0.002707174 valid loss= 0.003920203\n",
      "train reg_fs: 0.0012405144516378641\n",
      "Epoch: 8500 train loss=0.002656728 valid loss= 0.003812560\n",
      "train reg_fs: 0.0012292085448279977\n",
      "Epoch: 9000 train loss=0.005218297 valid loss= 0.003654256\n",
      "train reg_fs: 0.0012194978771731257\n",
      "Epoch: 9500 train loss=0.003194219 valid loss= 0.003736854\n",
      "train reg_fs: 0.0012112343683838844\n",
      "Epoch: 10000 train loss=0.002256994 valid loss= 0.003942993\n",
      "train reg_fs: 0.0012040073052048683\n",
      "Epoch: 10500 train loss=0.001614765 valid loss= 0.003628900\n",
      "train reg_fs: 0.0011970596387982368\n",
      "Epoch: 11000 train loss=0.002183050 valid loss= 0.003567341\n",
      "train reg_fs: 0.0011913094203919172\n",
      "Epoch: 11500 train loss=0.003507575 valid loss= 0.003653706\n",
      "train reg_fs: 0.001185764092952013\n",
      "Epoch: 12000 train loss=0.004087973 valid loss= 0.003790319\n",
      "train reg_fs: 0.0011810481082648039\n",
      "Epoch: 12500 train loss=0.006810185 valid loss= 0.003688807\n",
      "train reg_fs: 0.0011769242119044065\n",
      "Epoch: 13000 train loss=0.001632620 valid loss= 0.003667640\n",
      "train reg_fs: 0.0011730437399819493\n",
      "Epoch: 13500 train loss=0.001857514 valid loss= 0.003400102\n",
      "train reg_fs: 0.0011696249712258577\n",
      "Epoch: 14000 train loss=0.003137103 valid loss= 0.003695512\n",
      "train reg_fs: 0.0011666419450193644\n",
      "Epoch: 14500 train loss=0.004465164 valid loss= 0.003749696\n",
      "train reg_fs: 0.0011638241121545434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:35:37,382]\u001b[0m Trial 79 finished with value: 0.0023333288702743543 and parameters: {'lam': 0.001863930072215396, 'learning_rate': 0.06872536802407042, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002766332 valid loss= 0.003479294\n",
      "train reg_fs: 0.0011611904483288527\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023333288702743543\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009418777 valid loss= 0.008224311\n",
      "train reg_fs: 0.0018410570919513702\n",
      "Epoch: 1000 train loss=0.006521638 valid loss= 0.008647253\n",
      "train reg_fs: 0.0017999924020841718\n",
      "Epoch: 1500 train loss=0.005465371 valid loss= 0.006832365\n",
      "train reg_fs: 0.0017231263918802142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:35:53,520]\u001b[0m Trial 80 finished with value: 0.004095957910668643 and parameters: {'lam': 0.002059950176491971, 'learning_rate': 0.1466752620753388, 'num_epoch': 2000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.002631398 valid loss= 0.005765004\n",
      "train reg_fs: 0.0016550397267565131\n",
      "In trial:---------------------\n",
      "validation mse: 0.004095957910668643\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009347832 valid loss= 0.006978425\n",
      "train reg_fs: 0.001068674842827022\n",
      "Epoch: 1000 train loss=0.009928024 valid loss= 0.005425699\n",
      "train reg_fs: 0.0010301914298906922\n",
      "Epoch: 1500 train loss=0.006790053 valid loss= 0.003673693\n",
      "train reg_fs: 0.0009700836380943656\n",
      "Epoch: 2000 train loss=0.002984855 valid loss= 0.002848878\n",
      "train reg_fs: 0.0009428337216377258\n",
      "Epoch: 2500 train loss=0.002748231 valid loss= 0.003233962\n",
      "train reg_fs: 0.0009279840742237866\n",
      "Epoch: 3000 train loss=0.004699735 valid loss= 0.003434151\n",
      "train reg_fs: 0.0009186500101350248\n",
      "Epoch: 3500 train loss=0.001409671 valid loss= 0.003029601\n",
      "train reg_fs: 0.0009126534569077194\n",
      "Epoch: 4000 train loss=0.001565087 valid loss= 0.003127860\n",
      "train reg_fs: 0.0009093772387132049\n",
      "Epoch: 4500 train loss=0.004014936 valid loss= 0.002939495\n",
      "train reg_fs: 0.000906945439055562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:36:31,666]\u001b[0m Trial 81 finished with value: 0.0017613731969698366 and parameters: {'lam': 0.0012123331087900572, 'learning_rate': 0.11853078623481007, 'num_epoch': 5000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003162464 valid loss= 0.002647790\n",
      "train reg_fs: 0.0009051582892425358\n",
      "In trial:---------------------\n",
      "validation mse: 0.0017613731969698366\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022706045 valid loss= 0.008036165\n",
      "train reg_fs: 0.0009310021414421499\n",
      "Epoch: 1000 train loss=0.009778047 valid loss= 0.008041662\n",
      "train reg_fs: 0.0009263677638955414\n",
      "Epoch: 1500 train loss=0.005008605 valid loss= 0.006971810\n",
      "train reg_fs: 0.0009060854208655655\n",
      "Epoch: 2000 train loss=0.004103926 valid loss= 0.005720675\n",
      "train reg_fs: 0.0008968524634838104\n",
      "Epoch: 2500 train loss=0.005867384 valid loss= 0.005262224\n",
      "train reg_fs: 0.0008881834801286459\n",
      "Epoch: 3000 train loss=0.003674434 valid loss= 0.004298827\n",
      "train reg_fs: 0.0008751252898946404\n",
      "Epoch: 3500 train loss=0.003732578 valid loss= 0.003318599\n",
      "train reg_fs: 0.0008581427973695099\n",
      "Epoch: 4000 train loss=0.002435983 valid loss= 0.003410730\n",
      "train reg_fs: 0.0008475681534036994\n",
      "Epoch: 4500 train loss=0.002845848 valid loss= 0.003468169\n",
      "train reg_fs: 0.0008390144794248044\n",
      "Epoch: 5000 train loss=0.001942313 valid loss= 0.003560005\n",
      "train reg_fs: 0.0008297152817249298\n",
      "Epoch: 5500 train loss=0.003600257 valid loss= 0.003480808\n",
      "train reg_fs: 0.0008215825655497611\n",
      "Epoch: 6000 train loss=0.003478879 valid loss= 0.003360038\n",
      "train reg_fs: 0.0008138820412568748\n",
      "Epoch: 6500 train loss=0.002999515 valid loss= 0.003115900\n",
      "train reg_fs: 0.0008077849633991718\n",
      "Epoch: 7000 train loss=0.003587829 valid loss= 0.003481620\n",
      "train reg_fs: 0.0008023911505006254\n",
      "Epoch: 7500 train loss=0.002323419 valid loss= 0.003214671\n",
      "train reg_fs: 0.0007985493284650147\n",
      "Epoch: 8000 train loss=0.003628461 valid loss= 0.003014321\n",
      "train reg_fs: 0.000795141386333853\n",
      "Epoch: 8500 train loss=0.001954440 valid loss= 0.002777346\n",
      "train reg_fs: 0.0007923601078800857\n",
      "Epoch: 9000 train loss=0.001524923 valid loss= 0.003373784\n",
      "train reg_fs: 0.0007894518785178661\n",
      "Epoch: 9500 train loss=0.005040427 valid loss= 0.003401785\n",
      "train reg_fs: 0.0007865701918490231\n",
      "Epoch: 10000 train loss=0.004325954 valid loss= 0.003609912\n",
      "train reg_fs: 0.0007844167412258685\n",
      "Epoch: 10500 train loss=0.001081578 valid loss= 0.003171480\n",
      "train reg_fs: 0.000782296119723469\n",
      "Epoch: 11000 train loss=0.001642335 valid loss= 0.003047727\n",
      "train reg_fs: 0.0007800401072017848\n",
      "Epoch: 11500 train loss=0.001302566 valid loss= 0.003088048\n",
      "train reg_fs: 0.0007777155260555446\n",
      "Epoch: 12000 train loss=0.001404197 valid loss= 0.003307419\n",
      "train reg_fs: 0.0007755585829727352\n",
      "Epoch: 12500 train loss=0.003081109 valid loss= 0.002788803\n",
      "train reg_fs: 0.0007735264371149242\n",
      "Epoch: 13000 train loss=0.001033916 valid loss= 0.003313913\n",
      "train reg_fs: 0.0007717958651483059\n",
      "Epoch: 13500 train loss=0.007464550 valid loss= 0.002785741\n",
      "train reg_fs: 0.0007701644208282232\n",
      "Epoch: 14000 train loss=0.001244316 valid loss= 0.003002271\n",
      "train reg_fs: 0.0007682007853873074\n",
      "Epoch: 14500 train loss=0.001178156 valid loss= 0.003073762\n",
      "train reg_fs: 0.000766835524700582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:38:21,881]\u001b[0m Trial 82 finished with value: 0.002404522976850677 and parameters: {'lam': 0.0010602803472020217, 'learning_rate': 0.09571729485776721, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001343666 valid loss= 0.003145312\n",
      "train reg_fs: 0.0007645494188182056\n",
      "In trial:---------------------\n",
      "validation mse: 0.002404522976850677\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015058235 valid loss= 0.006865848\n",
      "train reg_fs: 0.0011871391907334328\n",
      "Epoch: 1000 train loss=0.010156217 valid loss= 0.005213562\n",
      "train reg_fs: 0.0011574929812923074\n",
      "Epoch: 1500 train loss=0.002459563 valid loss= 0.003757273\n",
      "train reg_fs: 0.0011017887154594064\n",
      "Epoch: 2000 train loss=0.006182333 valid loss= 0.003989041\n",
      "train reg_fs: 0.0010795015841722488\n",
      "Epoch: 2500 train loss=0.003503843 valid loss= 0.003827347\n",
      "train reg_fs: 0.001071091741323471\n",
      "Epoch: 3000 train loss=0.004690831 valid loss= 0.003918182\n",
      "train reg_fs: 0.0010629304451867938\n",
      "Epoch: 3500 train loss=0.005016487 valid loss= 0.003463905\n",
      "train reg_fs: 0.0010512388544157147\n",
      "Epoch: 4000 train loss=0.002918503 valid loss= 0.003614309\n",
      "train reg_fs: 0.0010386491194367409\n",
      "Epoch: 4500 train loss=0.004501128 valid loss= 0.003352624\n",
      "train reg_fs: 0.0010296773398295045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:38:59,711]\u001b[0m Trial 83 finished with value: 0.0023838927587970147 and parameters: {'lam': 0.0013527852630931484, 'learning_rate': 0.1269855248988867, 'num_epoch': 5000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.006085495 valid loss= 0.003387845\n",
      "train reg_fs: 0.0010216115042567253\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023838927587970147\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022668997 valid loss= 0.007593235\n",
      "train reg_fs: 0.0010913530131801963\n",
      "Epoch: 1000 train loss=0.009041227 valid loss= 0.006553105\n",
      "train reg_fs: 0.0011039815144613385\n",
      "Epoch: 1500 train loss=0.007562771 valid loss= 0.006117080\n",
      "train reg_fs: 0.0011060924734920263\n",
      "Epoch: 2000 train loss=0.007632426 valid loss= 0.006338754\n",
      "train reg_fs: 0.0010995838092640042\n",
      "Epoch: 2500 train loss=0.009383564 valid loss= 0.005804038\n",
      "train reg_fs: 0.0010865643853321671\n",
      "Epoch: 3000 train loss=0.005859725 valid loss= 0.005396968\n",
      "train reg_fs: 0.0010674564400687814\n",
      "Epoch: 3500 train loss=0.003569016 valid loss= 0.004483614\n",
      "train reg_fs: 0.001047338591888547\n",
      "Epoch: 4000 train loss=0.006258023 valid loss= 0.003915734\n",
      "train reg_fs: 0.0010306235635653138\n",
      "Epoch: 4500 train loss=0.002747297 valid loss= 0.003646217\n",
      "train reg_fs: 0.001018762239255011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:39:37,012]\u001b[0m Trial 84 finished with value: 0.0025030784899020926 and parameters: {'lam': 0.0012759373818726544, 'learning_rate': 0.03539011698557918, 'num_epoch': 5000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005148984 valid loss= 0.003529644\n",
      "train reg_fs: 0.0010096398182213306\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025030784899020926\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012972416 valid loss= 0.007033754\n",
      "train reg_fs: 0.000881594605743885\n",
      "Epoch: 1000 train loss=0.009787123 valid loss= 0.006049598\n",
      "train reg_fs: 0.0008658088627271354\n",
      "Epoch: 1500 train loss=0.005124565 valid loss= 0.003093497\n",
      "train reg_fs: 0.0008172437082976103\n",
      "Epoch: 2000 train loss=0.007438086 valid loss= 0.003403014\n",
      "train reg_fs: 0.0007986692944541574\n",
      "Epoch: 2500 train loss=0.002666654 valid loss= 0.003639729\n",
      "train reg_fs: 0.0007885316153988242\n",
      "Epoch: 3000 train loss=0.002496899 valid loss= 0.002959895\n",
      "train reg_fs: 0.0007796219433657825\n",
      "Epoch: 3500 train loss=0.004638413 valid loss= 0.003468465\n",
      "train reg_fs: 0.0007701069698669016\n",
      "Epoch: 4000 train loss=0.004596232 valid loss= 0.003129518\n",
      "train reg_fs: 0.0007639040122739971\n",
      "Epoch: 4500 train loss=0.004010024 valid loss= 0.002524205\n",
      "train reg_fs: 0.0007598436204716563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:40:14,599]\u001b[0m Trial 85 finished with value: 0.0021153256008828655 and parameters: {'lam': 0.0010010811241944902, 'learning_rate': 0.11279643900846778, 'num_epoch': 5000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.001493998 valid loss= 0.002861524\n",
      "train reg_fs: 0.0007570559391751885\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021153256008828655\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.035572141 valid loss= 0.010035575\n",
      "train reg_fs: 0.004168224520981312\n",
      "Epoch: 1000 train loss=0.010141462 valid loss= 0.010162600\n",
      "train reg_fs: 0.0037574151065200567\n",
      "Epoch: 1500 train loss=0.006922849 valid loss= 0.006984252\n",
      "train reg_fs: 0.003410157049074769\n",
      "Epoch: 2000 train loss=0.006019550 valid loss= 0.007158333\n",
      "train reg_fs: 0.003202046500518918\n",
      "Epoch: 2500 train loss=0.004426252 valid loss= 0.007412357\n",
      "train reg_fs: 0.0030956449918448925\n",
      "Epoch: 3000 train loss=0.013607643 valid loss= 0.007761384\n",
      "train reg_fs: 0.003018157323822379\n",
      "Epoch: 3500 train loss=0.005055657 valid loss= 0.007377874\n",
      "train reg_fs: 0.002970748580992222\n",
      "Epoch: 4000 train loss=0.004586087 valid loss= 0.007089243\n",
      "train reg_fs: 0.0029339035972952843\n",
      "Epoch: 4500 train loss=0.005057517 valid loss= 0.007176115\n",
      "train reg_fs: 0.002906587440520525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:40:52,244]\u001b[0m Trial 86 finished with value: 0.004517247252092254 and parameters: {'lam': 0.0048883777978715555, 'learning_rate': 0.15426959716448818, 'num_epoch': 5000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005754082 valid loss= 0.007538748\n",
      "train reg_fs: 0.0028856839053332806\n",
      "In trial:---------------------\n",
      "validation mse: 0.004517247252092254\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010505365 valid loss= 0.009365899\n",
      "train reg_fs: 0.0009919063886627555\n",
      "Epoch: 1000 train loss=0.006826920 valid loss= 0.007502961\n",
      "train reg_fs: 0.0009560316684655845\n",
      "Epoch: 1500 train loss=0.007806841 valid loss= 0.006629485\n",
      "train reg_fs: 0.0009199926280416548\n",
      "Epoch: 2000 train loss=0.005899413 valid loss= 0.005007299\n",
      "train reg_fs: 0.0008860995294526219\n",
      "Epoch: 2500 train loss=0.003124952 valid loss= 0.003291771\n",
      "train reg_fs: 0.0008430069428868592\n",
      "Epoch: 3000 train loss=0.002643418 valid loss= 0.003598274\n",
      "train reg_fs: 0.0008155554533004761\n",
      "Epoch: 3500 train loss=0.002743105 valid loss= 0.003702729\n",
      "train reg_fs: 0.0007962217787280679\n",
      "Epoch: 4000 train loss=0.002194894 valid loss= 0.003786843\n",
      "train reg_fs: 0.0007867904496379197\n",
      "Epoch: 4500 train loss=0.001628281 valid loss= 0.003952084\n",
      "train reg_fs: 0.0007806060020811856\n",
      "Epoch: 5000 train loss=0.001866114 valid loss= 0.004187657\n",
      "train reg_fs: 0.0007746346527710557\n",
      "Epoch: 5500 train loss=0.003304268 valid loss= 0.003267410\n",
      "train reg_fs: 0.0007698912522755563\n",
      "Epoch: 6000 train loss=0.002010795 valid loss= 0.003525263\n",
      "train reg_fs: 0.0007648292812518775\n",
      "Epoch: 6500 train loss=0.004844658 valid loss= 0.003724840\n",
      "train reg_fs: 0.0007615341455675662\n",
      "Epoch: 7000 train loss=0.002807864 valid loss= 0.003399835\n",
      "train reg_fs: 0.0007613822817802429\n",
      "Epoch: 7500 train loss=0.003817076 valid loss= 0.003749459\n",
      "train reg_fs: 0.0007592148031108081\n",
      "Epoch: 8000 train loss=0.004764507 valid loss= 0.003386740\n",
      "train reg_fs: 0.000758080743253231\n",
      "Epoch: 8500 train loss=0.002209479 valid loss= 0.003562483\n",
      "train reg_fs: 0.0007558360230177641\n",
      "Epoch: 9000 train loss=0.003123940 valid loss= 0.003720174\n",
      "train reg_fs: 0.0007563278777524829\n",
      "Epoch: 9500 train loss=0.002109016 valid loss= 0.003442489\n",
      "train reg_fs: 0.0007521118386648595\n",
      "Epoch: 10000 train loss=0.002038988 valid loss= 0.003107879\n",
      "train reg_fs: 0.0007497079786844552\n",
      "Epoch: 10500 train loss=0.000953305 valid loss= 0.003355623\n",
      "train reg_fs: 0.0007509547285735607\n",
      "Epoch: 11000 train loss=0.002946150 valid loss= 0.003443647\n",
      "train reg_fs: 0.0007492731674574316\n",
      "Epoch: 11500 train loss=0.002036870 valid loss= 0.003312485\n",
      "train reg_fs: 0.0007503965753130615\n",
      "Epoch: 12000 train loss=0.001261801 valid loss= 0.003278898\n",
      "train reg_fs: 0.0007479065097868443\n",
      "Epoch: 12500 train loss=0.002118722 valid loss= 0.003260917\n",
      "train reg_fs: 0.0007479707128368318\n",
      "Epoch: 13000 train loss=0.001017835 valid loss= 0.003063302\n",
      "train reg_fs: 0.0007479635532945395\n",
      "Epoch: 13500 train loss=0.001851519 valid loss= 0.003020622\n",
      "train reg_fs: 0.0007483142544515431\n",
      "Epoch: 14000 train loss=0.002466284 valid loss= 0.003218818\n",
      "train reg_fs: 0.0007464681402780116\n",
      "Epoch: 14500 train loss=0.001213135 valid loss= 0.003354054\n",
      "train reg_fs: 0.0007464021327905357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:42:43,735]\u001b[0m Trial 87 finished with value: 0.0022785152010467128 and parameters: {'lam': 0.0011147156773371127, 'learning_rate': 0.17518442477606042, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001084451 valid loss= 0.003011472\n",
      "train reg_fs: 0.0007461656350642443\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022785152010467128\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013040214 valid loss= 0.007419570\n",
      "train reg_fs: 0.0019276587991043925\n",
      "Epoch: 1000 train loss=0.019862149 valid loss= 0.007600552\n",
      "train reg_fs: 0.0018866807222366333\n",
      "Epoch: 1500 train loss=0.011081588 valid loss= 0.005182874\n",
      "train reg_fs: 0.0018174515571445227\n",
      "Epoch: 2000 train loss=0.006612937 valid loss= 0.005065483\n",
      "train reg_fs: 0.0017669062362983823\n",
      "Epoch: 2500 train loss=0.015761320 valid loss= 0.005070136\n",
      "train reg_fs: 0.001729315728880465\n",
      "Epoch: 3000 train loss=0.005676292 valid loss= 0.004869440\n",
      "train reg_fs: 0.0017042673425748944\n",
      "Epoch: 3500 train loss=0.003980686 valid loss= 0.005164722\n",
      "train reg_fs: 0.0016880084294825792\n",
      "Epoch: 4000 train loss=0.004824637 valid loss= 0.004993388\n",
      "train reg_fs: 0.0016757252160459757\n",
      "Epoch: 4500 train loss=0.003474382 valid loss= 0.005150769\n",
      "train reg_fs: 0.001663540955632925\n",
      "Epoch: 5000 train loss=0.004880927 valid loss= 0.005625547\n",
      "train reg_fs: 0.0016512790462002158\n",
      "Epoch: 5500 train loss=0.003043881 valid loss= 0.005407553\n",
      "train reg_fs: 0.0016365154879167676\n",
      "Epoch: 6000 train loss=0.003504511 valid loss= 0.004915447\n",
      "train reg_fs: 0.001616442808881402\n",
      "Epoch: 6500 train loss=0.006536060 valid loss= 0.005119394\n",
      "train reg_fs: 0.0015949634835124016\n",
      "Epoch: 7000 train loss=0.005009512 valid loss= 0.004956970\n",
      "train reg_fs: 0.001570234540849924\n",
      "Epoch: 7500 train loss=0.002871370 valid loss= 0.004791719\n",
      "train reg_fs: 0.0015467777848243713\n",
      "Epoch: 8000 train loss=0.002081171 valid loss= 0.004591255\n",
      "train reg_fs: 0.0015236797044053674\n",
      "Epoch: 8500 train loss=0.002179038 valid loss= 0.004580179\n",
      "train reg_fs: 0.0015050895744934678\n",
      "Epoch: 9000 train loss=0.001835445 valid loss= 0.004053323\n",
      "train reg_fs: 0.0014886284479871392\n",
      "Epoch: 9500 train loss=0.003186469 valid loss= 0.004374843\n",
      "train reg_fs: 0.0014747927198186517\n",
      "Epoch: 10000 train loss=0.002447962 valid loss= 0.004069301\n",
      "train reg_fs: 0.001462229061871767\n",
      "Epoch: 10500 train loss=0.007692175 valid loss= 0.004137269\n",
      "train reg_fs: 0.0014519128017127514\n",
      "Epoch: 11000 train loss=0.004164804 valid loss= 0.004030678\n",
      "train reg_fs: 0.0014429717557504773\n",
      "Epoch: 11500 train loss=0.002672444 valid loss= 0.004054666\n",
      "train reg_fs: 0.0014346007956191897\n",
      "Epoch: 12000 train loss=0.003782466 valid loss= 0.003767993\n",
      "train reg_fs: 0.0014275985304266214\n",
      "Epoch: 12500 train loss=0.003006044 valid loss= 0.003922788\n",
      "train reg_fs: 0.0014221516903489828\n",
      "Epoch: 13000 train loss=0.002773894 valid loss= 0.003889170\n",
      "train reg_fs: 0.0014167707413434982\n",
      "Epoch: 13500 train loss=0.002358377 valid loss= 0.004154357\n",
      "train reg_fs: 0.0014118807157501578\n",
      "Epoch: 14000 train loss=0.003735277 valid loss= 0.004246184\n",
      "train reg_fs: 0.0014076030347496271\n",
      "Epoch: 14500 train loss=0.001994001 valid loss= 0.003905293\n",
      "train reg_fs: 0.0014038903173059225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:44:34,067]\u001b[0m Trial 88 finished with value: 0.002408363287643771 and parameters: {'lam': 0.0022526001324948974, 'learning_rate': 0.060479199501701913, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001572668 valid loss= 0.003790955\n",
      "train reg_fs: 0.0014004214899614453\n",
      "In trial:---------------------\n",
      "validation mse: 0.002408363287643771\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009863206 valid loss= 0.007163450\n",
      "train reg_fs: 0.0010065734386444092\n",
      "Epoch: 1000 train loss=0.003770694 valid loss= 0.006437893\n",
      "train reg_fs: 0.001021284842863679\n",
      "Epoch: 1500 train loss=0.011618627 valid loss= 0.006274226\n",
      "train reg_fs: 0.0010224956786260009\n",
      "Epoch: 2000 train loss=0.008706438 valid loss= 0.006481653\n",
      "train reg_fs: 0.0010124860564246774\n",
      "Epoch: 2500 train loss=0.007877901 valid loss= 0.004869490\n",
      "train reg_fs: 0.0009896695846691728\n",
      "Epoch: 3000 train loss=0.011768847 valid loss= 0.003722002\n",
      "train reg_fs: 0.0009596887975931168\n",
      "Epoch: 3500 train loss=0.006262467 valid loss= 0.002852165\n",
      "train reg_fs: 0.0009318526717834175\n",
      "Epoch: 4000 train loss=0.007462560 valid loss= 0.002846832\n",
      "train reg_fs: 0.0009112522238865495\n",
      "Epoch: 4500 train loss=0.001569976 valid loss= 0.002952893\n",
      "train reg_fs: 0.0008989224443212152\n",
      "Epoch: 5000 train loss=0.002627236 valid loss= 0.003132132\n",
      "train reg_fs: 0.0008897937368601561\n",
      "Epoch: 5500 train loss=0.003586031 valid loss= 0.002762667\n",
      "train reg_fs: 0.0008840675582177937\n",
      "Epoch: 6000 train loss=0.002422212 valid loss= 0.002580182\n",
      "train reg_fs: 0.0008793657761998475\n",
      "Epoch: 6500 train loss=0.003984566 valid loss= 0.002296086\n",
      "train reg_fs: 0.0008759614429436624\n",
      "Epoch: 7000 train loss=0.002253943 valid loss= 0.002482900\n",
      "train reg_fs: 0.0008729675319045782\n",
      "Epoch: 7500 train loss=0.003648517 valid loss= 0.003015551\n",
      "train reg_fs: 0.0008708637906238437\n",
      "Epoch: 8000 train loss=0.002000871 valid loss= 0.002673798\n",
      "train reg_fs: 0.0008690186659805477\n",
      "Epoch: 8500 train loss=0.005124628 valid loss= 0.003731530\n",
      "train reg_fs: 0.0008675028802827001\n",
      "Epoch: 9000 train loss=0.001853012 valid loss= 0.002792188\n",
      "train reg_fs: 0.0008659654995426536\n",
      "Epoch: 9500 train loss=0.003794435 valid loss= 0.002533162\n",
      "train reg_fs: 0.0008647212525829673\n",
      "Epoch: 10000 train loss=0.003472784 valid loss= 0.002824744\n",
      "train reg_fs: 0.0008635709527879953\n",
      "Epoch: 10500 train loss=0.002182940 valid loss= 0.002665305\n",
      "train reg_fs: 0.0008627839270047843\n",
      "Epoch: 11000 train loss=0.004317536 valid loss= 0.002775526\n",
      "train reg_fs: 0.000861811509821564\n",
      "Epoch: 11500 train loss=0.002683227 valid loss= 0.003003055\n",
      "train reg_fs: 0.0008611251832917333\n",
      "Epoch: 12000 train loss=0.001516316 valid loss= 0.002666250\n",
      "train reg_fs: 0.0008605968905612826\n",
      "Epoch: 12500 train loss=0.002046239 valid loss= 0.002992732\n",
      "train reg_fs: 0.0008598832646384835\n",
      "Epoch: 13000 train loss=0.001040625 valid loss= 0.002968543\n",
      "train reg_fs: 0.0008591905352659523\n",
      "Epoch: 13500 train loss=0.001372827 valid loss= 0.002642369\n",
      "train reg_fs: 0.0008586564217694104\n",
      "Epoch: 14000 train loss=0.001930704 valid loss= 0.002627027\n",
      "train reg_fs: 0.0008580993162468076\n",
      "Epoch: 14500 train loss=0.001130851 valid loss= 0.002776582\n",
      "train reg_fs: 0.0008576691034249961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:46:24,854]\u001b[0m Trial 89 finished with value: 0.0017516879925047202 and parameters: {'lam': 0.0011547415042152365, 'learning_rate': 0.050813627139878484, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001755126 valid loss= 0.002592915\n",
      "train reg_fs: 0.0008570587961003184\n",
      "In trial:---------------------\n",
      "validation mse: 0.0017516879925047202\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013191887 valid loss= 0.008526463\n",
      "train reg_fs: 0.0035692814271897078\n",
      "Epoch: 1000 train loss=0.009133251 valid loss= 0.005611264\n",
      "train reg_fs: 0.0031995167955756187\n",
      "Epoch: 1500 train loss=0.007282214 valid loss= 0.005059403\n",
      "train reg_fs: 0.0030373618938028812\n",
      "Epoch: 2000 train loss=0.004303207 valid loss= 0.005009167\n",
      "train reg_fs: 0.0028665480203926563\n",
      "Epoch: 2500 train loss=0.005827362 valid loss= 0.004990074\n",
      "train reg_fs: 0.0027101561427116394\n",
      "Epoch: 3000 train loss=0.007688870 valid loss= 0.004781025\n",
      "train reg_fs: 0.0026053909678012133\n",
      "Epoch: 3500 train loss=0.004582841 valid loss= 0.004094273\n",
      "train reg_fs: 0.0025391459930688143\n",
      "Epoch: 4000 train loss=0.006148058 valid loss= 0.004444816\n",
      "train reg_fs: 0.0024955400731414557\n",
      "Epoch: 4500 train loss=0.008813888 valid loss= 0.004164841\n",
      "train reg_fs: 0.0024662355426698923\n",
      "Epoch: 5000 train loss=0.002941525 valid loss= 0.005141678\n",
      "train reg_fs: 0.0024472090881317854\n",
      "Epoch: 5500 train loss=0.004965829 valid loss= 0.003776871\n",
      "train reg_fs: 0.002431693486869335\n",
      "Epoch: 6000 train loss=0.003224758 valid loss= 0.004742735\n",
      "train reg_fs: 0.002421235665678978\n",
      "Epoch: 6500 train loss=0.003477029 valid loss= 0.004003465\n",
      "train reg_fs: 0.0024127827491611242\n",
      "Epoch: 7000 train loss=0.005394718 valid loss= 0.003988237\n",
      "train reg_fs: 0.0024065396282821894\n",
      "Epoch: 7500 train loss=0.003456655 valid loss= 0.004226221\n",
      "train reg_fs: 0.0024016329552978277\n",
      "Epoch: 8000 train loss=0.002585327 valid loss= 0.004569403\n",
      "train reg_fs: 0.0023972978815436363\n",
      "Epoch: 8500 train loss=0.004974356 valid loss= 0.004186528\n",
      "train reg_fs: 0.0023937004152685404\n",
      "Epoch: 9000 train loss=0.002790273 valid loss= 0.004096642\n",
      "train reg_fs: 0.0023907343856990337\n",
      "Epoch: 9500 train loss=0.002566510 valid loss= 0.003891933\n",
      "train reg_fs: 0.0023881339002400637\n",
      "Epoch: 10000 train loss=0.002980310 valid loss= 0.003607492\n",
      "train reg_fs: 0.002385965082794428\n",
      "Epoch: 10500 train loss=0.003530189 valid loss= 0.004768543\n",
      "train reg_fs: 0.002383995335549116\n",
      "Epoch: 11000 train loss=0.002616164 valid loss= 0.003869091\n",
      "train reg_fs: 0.002382369013503194\n",
      "Epoch: 11500 train loss=0.002902312 valid loss= 0.003838483\n",
      "train reg_fs: 0.0023809245321899652\n",
      "Epoch: 12000 train loss=0.004104143 valid loss= 0.003972523\n",
      "train reg_fs: 0.002379609504714608\n",
      "Epoch: 12500 train loss=0.007163673 valid loss= 0.004717946\n",
      "train reg_fs: 0.0023784395307302475\n",
      "Epoch: 13000 train loss=0.002832975 valid loss= 0.004234451\n",
      "train reg_fs: 0.0023774022702127695\n",
      "Epoch: 13500 train loss=0.004546160 valid loss= 0.004112978\n",
      "train reg_fs: 0.002376416465267539\n",
      "Epoch: 14000 train loss=0.002708126 valid loss= 0.004464210\n",
      "train reg_fs: 0.0023755126167088747\n",
      "Epoch: 14500 train loss=0.003576300 valid loss= 0.003995160\n",
      "train reg_fs: 0.002374678384512663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:48:15,808]\u001b[0m Trial 90 finished with value: 0.001143812391944917 and parameters: {'lam': 0.0041972078895597805, 'learning_rate': 0.19974470510712075, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002546550 valid loss= 0.003604768\n",
      "train reg_fs: 0.002373956609517336\n",
      "In trial:---------------------\n",
      "validation mse: 0.001143812391944917\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010504268 valid loss= 0.008470265\n",
      "train reg_fs: 0.003270543646067381\n",
      "Epoch: 1000 train loss=0.008559368 valid loss= 0.006495711\n",
      "train reg_fs: 0.003186240093782544\n",
      "Epoch: 1500 train loss=0.005672917 valid loss= 0.005058691\n",
      "train reg_fs: 0.0030410909093916416\n",
      "Epoch: 2000 train loss=0.007623534 valid loss= 0.004211734\n",
      "train reg_fs: 0.0029069245792925358\n",
      "Epoch: 2500 train loss=0.004893461 valid loss= 0.004581947\n",
      "train reg_fs: 0.0028147734701633453\n",
      "Epoch: 3000 train loss=0.003420587 valid loss= 0.004190470\n",
      "train reg_fs: 0.002740090247243643\n",
      "Epoch: 3500 train loss=0.003489329 valid loss= 0.004094701\n",
      "train reg_fs: 0.00268623698502779\n",
      "Epoch: 4000 train loss=0.004122067 valid loss= 0.004787924\n",
      "train reg_fs: 0.00264168344438076\n",
      "Epoch: 4500 train loss=0.003158918 valid loss= 0.003717190\n",
      "train reg_fs: 0.0026087560690939426\n",
      "Epoch: 5000 train loss=0.002971028 valid loss= 0.003659804\n",
      "train reg_fs: 0.00258098216727376\n",
      "Epoch: 5500 train loss=0.003200468 valid loss= 0.003960408\n",
      "train reg_fs: 0.002560110529884696\n",
      "Epoch: 6000 train loss=0.007139809 valid loss= 0.003531395\n",
      "train reg_fs: 0.002546132542192936\n",
      "Epoch: 6500 train loss=0.003479395 valid loss= 0.003184616\n",
      "train reg_fs: 0.002533499849960208\n",
      "Epoch: 7000 train loss=0.003149058 valid loss= 0.003191879\n",
      "train reg_fs: 0.002522581722587347\n",
      "Epoch: 7500 train loss=0.003456757 valid loss= 0.003401990\n",
      "train reg_fs: 0.002513360697776079\n",
      "Epoch: 8000 train loss=0.005643076 valid loss= 0.003211288\n",
      "train reg_fs: 0.002506073098629713\n",
      "Epoch: 8500 train loss=0.003824734 valid loss= 0.003541232\n",
      "train reg_fs: 0.0024993789847940207\n",
      "Epoch: 9000 train loss=0.004023440 valid loss= 0.003178416\n",
      "train reg_fs: 0.0024886156897991896\n",
      "Epoch: 9500 train loss=0.004228911 valid loss= 0.003457019\n",
      "train reg_fs: 0.0024822885170578957\n",
      "Epoch: 10000 train loss=0.003364915 valid loss= 0.003882370\n",
      "train reg_fs: 0.002475320128723979\n",
      "Epoch: 10500 train loss=0.003237039 valid loss= 0.003333451\n",
      "train reg_fs: 0.0024687827099114656\n",
      "Epoch: 11000 train loss=0.004918761 valid loss= 0.003226275\n",
      "train reg_fs: 0.002462128410115838\n",
      "Epoch: 11500 train loss=0.003114087 valid loss= 0.003262975\n",
      "train reg_fs: 0.00245597492903471\n",
      "Epoch: 12000 train loss=0.005494118 valid loss= 0.003684647\n",
      "train reg_fs: 0.0024477641563862562\n",
      "Epoch: 12500 train loss=0.003142344 valid loss= 0.003750091\n",
      "train reg_fs: 0.002441748743876815\n",
      "Epoch: 13000 train loss=0.003191965 valid loss= 0.003196724\n",
      "train reg_fs: 0.0024315223563462496\n",
      "Epoch: 13500 train loss=0.010869880 valid loss= 0.003506427\n",
      "train reg_fs: 0.0024250599090009928\n",
      "Epoch: 14000 train loss=0.002875000 valid loss= 0.003877435\n",
      "train reg_fs: 0.002417522482573986\n",
      "Epoch: 14500 train loss=0.004805141 valid loss= 0.003634600\n",
      "train reg_fs: 0.002412983914837241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:50:05,149]\u001b[0m Trial 91 finished with value: 0.0018354163666305242 and parameters: {'lam': 0.0037363416035622096, 'learning_rate': 0.13902235411937444, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.008380869 valid loss= 0.004232703\n",
      "train reg_fs: 0.0024071456864476204\n",
      "In trial:---------------------\n",
      "validation mse: 0.0018354163666305242\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012321874 valid loss= 0.010850768\n",
      "train reg_fs: 0.0069986023008823395\n",
      "Epoch: 1000 train loss=0.012955609 valid loss= 0.010366915\n",
      "train reg_fs: 0.006167690269649029\n",
      "Epoch: 1500 train loss=0.011614312 valid loss= 0.010313637\n",
      "train reg_fs: 0.005773917771875858\n",
      "Epoch: 2000 train loss=0.010264538 valid loss= 0.010555301\n",
      "train reg_fs: 0.005568495485931635\n",
      "Epoch: 2500 train loss=0.008410126 valid loss= 0.009905918\n",
      "train reg_fs: 0.005462980829179287\n",
      "Epoch: 3000 train loss=0.007629928 valid loss= 0.009632694\n",
      "train reg_fs: 0.005403983872383833\n",
      "Epoch: 3500 train loss=0.007990768 valid loss= 0.009649094\n",
      "train reg_fs: 0.0053653898648917675\n",
      "Epoch: 4000 train loss=0.009217506 valid loss= 0.009540573\n",
      "train reg_fs: 0.005337920505553484\n",
      "Epoch: 4500 train loss=0.008571213 valid loss= 0.009497978\n",
      "train reg_fs: 0.005317881237715483\n",
      "Epoch: 5000 train loss=0.007485282 valid loss= 0.009988034\n",
      "train reg_fs: 0.005303028970956802\n",
      "Epoch: 5500 train loss=0.008705373 valid loss= 0.009949676\n",
      "train reg_fs: 0.005291126202791929\n",
      "Epoch: 6000 train loss=0.007679359 valid loss= 0.009927949\n",
      "train reg_fs: 0.005281724501401186\n",
      "Epoch: 6500 train loss=0.007938114 valid loss= 0.009286948\n",
      "train reg_fs: 0.005273960065096617\n",
      "Epoch: 7000 train loss=0.008680855 valid loss= 0.010099717\n",
      "train reg_fs: 0.005267632193863392\n",
      "Epoch: 7500 train loss=0.008153234 valid loss= 0.009808524\n",
      "train reg_fs: 0.00526197487488389\n",
      "Epoch: 8000 train loss=0.008283520 valid loss= 0.010063675\n",
      "train reg_fs: 0.005257379729300737\n",
      "Epoch: 8500 train loss=0.007990930 valid loss= 0.009953525\n",
      "train reg_fs: 0.005253143608570099\n",
      "Epoch: 9000 train loss=0.006928637 valid loss= 0.009699376\n",
      "train reg_fs: 0.005249663721770048\n",
      "Epoch: 9500 train loss=0.006607895 valid loss= 0.009620242\n",
      "train reg_fs: 0.005246407352387905\n",
      "Epoch: 10000 train loss=0.007007902 valid loss= 0.009111759\n",
      "train reg_fs: 0.00524381035938859\n",
      "Epoch: 10500 train loss=0.013679689 valid loss= 0.009704315\n",
      "train reg_fs: 0.005241302773356438\n",
      "Epoch: 11000 train loss=0.008066274 valid loss= 0.009613493\n",
      "train reg_fs: 0.005239179823547602\n",
      "Epoch: 11500 train loss=0.009458423 valid loss= 0.009832467\n",
      "train reg_fs: 0.005237356759607792\n",
      "Epoch: 12000 train loss=0.007445430 valid loss= 0.010053549\n",
      "train reg_fs: 0.005235685501247644\n",
      "Epoch: 12500 train loss=0.007073950 valid loss= 0.009694895\n",
      "train reg_fs: 0.005234179086983204\n",
      "Epoch: 13000 train loss=0.006422020 valid loss= 0.009842234\n",
      "train reg_fs: 0.005232793744653463\n",
      "Epoch: 13500 train loss=0.006846150 valid loss= 0.009687257\n",
      "train reg_fs: 0.0052315169014036655\n",
      "Epoch: 14000 train loss=0.007433974 valid loss= 0.009499503\n",
      "train reg_fs: 0.005230314563959837\n",
      "Epoch: 14500 train loss=0.016803468 valid loss= 0.009408122\n",
      "train reg_fs: 0.005229287315160036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:51:54,902]\u001b[0m Trial 92 finished with value: 0.004421922604244606 and parameters: {'lam': 0.009262217020817058, 'learning_rate': 0.19335462446648463, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007490677 valid loss= 0.009841458\n",
      "train reg_fs: 0.005228220950812101\n",
      "In trial:---------------------\n",
      "validation mse: 0.004421922604244606\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007923894 valid loss= 0.009668518\n",
      "train reg_fs: 0.0033553000539541245\n",
      "Epoch: 1000 train loss=0.009397588 valid loss= 0.007076647\n",
      "train reg_fs: 0.003146038157865405\n",
      "Epoch: 1500 train loss=0.008426933 valid loss= 0.006334078\n",
      "train reg_fs: 0.002964681014418602\n",
      "Epoch: 2000 train loss=0.005258109 valid loss= 0.006159351\n",
      "train reg_fs: 0.0028391850646585226\n",
      "Epoch: 2500 train loss=0.006745484 valid loss= 0.006444091\n",
      "train reg_fs: 0.0027432222850620747\n",
      "Epoch: 3000 train loss=0.003975172 valid loss= 0.005291152\n",
      "train reg_fs: 0.0026645560283213854\n",
      "Epoch: 3500 train loss=0.003587816 valid loss= 0.005533552\n",
      "train reg_fs: 0.002609858987852931\n",
      "Epoch: 4000 train loss=0.003827975 valid loss= 0.005135515\n",
      "train reg_fs: 0.0025707522872835398\n",
      "Epoch: 4500 train loss=0.005780754 valid loss= 0.005549642\n",
      "train reg_fs: 0.0025412412360310555\n",
      "Epoch: 5000 train loss=0.005352143 valid loss= 0.005030801\n",
      "train reg_fs: 0.002519988687708974\n",
      "Epoch: 5500 train loss=0.004478618 valid loss= 0.005178976\n",
      "train reg_fs: 0.002502478426322341\n",
      "Epoch: 6000 train loss=0.003447173 valid loss= 0.005071122\n",
      "train reg_fs: 0.00248799379914999\n",
      "Epoch: 6500 train loss=0.003895360 valid loss= 0.004779480\n",
      "train reg_fs: 0.002476004185155034\n",
      "Epoch: 7000 train loss=0.005563838 valid loss= 0.005402181\n",
      "train reg_fs: 0.002466402016580105\n",
      "Epoch: 7500 train loss=0.005304883 valid loss= 0.004679097\n",
      "train reg_fs: 0.002458171686157584\n",
      "Epoch: 8000 train loss=0.003238258 valid loss= 0.004762896\n",
      "train reg_fs: 0.0024510433431714773\n",
      "Epoch: 8500 train loss=0.003546003 valid loss= 0.004844566\n",
      "train reg_fs: 0.0024451680947095156\n",
      "Epoch: 9000 train loss=0.003123304 valid loss= 0.004652095\n",
      "train reg_fs: 0.002440140349790454\n",
      "Epoch: 9500 train loss=0.006098977 valid loss= 0.004937874\n",
      "train reg_fs: 0.0024356392677873373\n",
      "Epoch: 10000 train loss=0.003452990 valid loss= 0.004616185\n",
      "train reg_fs: 0.002431682078167796\n",
      "Epoch: 10500 train loss=0.005061940 valid loss= 0.004488266\n",
      "train reg_fs: 0.002428047126159072\n",
      "Epoch: 11000 train loss=0.002994146 valid loss= 0.004561846\n",
      "train reg_fs: 0.0024249423295259476\n",
      "Epoch: 11500 train loss=0.002692907 valid loss= 0.004761425\n",
      "train reg_fs: 0.0024219562765210867\n",
      "Epoch: 12000 train loss=0.002857667 valid loss= 0.004402756\n",
      "train reg_fs: 0.0024194694124162197\n",
      "Epoch: 12500 train loss=0.002819814 valid loss= 0.004581798\n",
      "train reg_fs: 0.0024171017576009035\n",
      "Epoch: 13000 train loss=0.004241529 valid loss= 0.004758588\n",
      "train reg_fs: 0.002415142022073269\n",
      "Epoch: 13500 train loss=0.003485947 valid loss= 0.004666513\n",
      "train reg_fs: 0.0024132998660206795\n",
      "Epoch: 14000 train loss=0.004140827 valid loss= 0.004550943\n",
      "train reg_fs: 0.0024115266278386116\n",
      "Epoch: 14500 train loss=0.002770124 valid loss= 0.004427426\n",
      "train reg_fs: 0.0024098751600831747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:53:46,587]\u001b[0m Trial 93 finished with value: 0.0023497492265387417 and parameters: {'lam': 0.003988495752958526, 'learning_rate': 0.09086700416968782, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003777266 valid loss= 0.004697590\n",
      "train reg_fs: 0.0024084702599793673\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023497492265387417\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.023903925 valid loss= 0.012698293\n",
      "train reg_fs: 0.005667965859174728\n",
      "Epoch: 1000 train loss=0.011435570 valid loss= 0.013437675\n",
      "train reg_fs: 0.005460984539240599\n",
      "Epoch: 1500 train loss=0.012845639 valid loss= 0.009785905\n",
      "train reg_fs: 0.00510591734200716\n",
      "Epoch: 2000 train loss=0.009462851 valid loss= 0.009056718\n",
      "train reg_fs: 0.004750227089971304\n",
      "Epoch: 2500 train loss=0.013030859 valid loss= 0.008195978\n",
      "train reg_fs: 0.004473939072340727\n",
      "Epoch: 3000 train loss=0.008071512 valid loss= 0.008753113\n",
      "train reg_fs: 0.004304044414311647\n",
      "Epoch: 3500 train loss=0.007990933 valid loss= 0.008335540\n",
      "train reg_fs: 0.004178721457719803\n",
      "Epoch: 4000 train loss=0.005331784 valid loss= 0.008137368\n",
      "train reg_fs: 0.0040890988893806934\n",
      "Epoch: 4500 train loss=0.007652222 valid loss= 0.008125319\n",
      "train reg_fs: 0.004025502596050501\n",
      "Epoch: 5000 train loss=0.011893502 valid loss= 0.008080428\n",
      "train reg_fs: 0.00397550780326128\n",
      "Epoch: 5500 train loss=0.008545851 valid loss= 0.008331325\n",
      "train reg_fs: 0.003937947563827038\n",
      "Epoch: 6000 train loss=0.005383226 valid loss= 0.008484241\n",
      "train reg_fs: 0.003908385057002306\n",
      "Epoch: 6500 train loss=0.006735480 valid loss= 0.008260991\n",
      "train reg_fs: 0.003883920144289732\n",
      "Epoch: 7000 train loss=0.010421439 valid loss= 0.007995822\n",
      "train reg_fs: 0.003864948870614171\n",
      "Epoch: 7500 train loss=0.005680352 valid loss= 0.008043107\n",
      "train reg_fs: 0.003848450956866145\n",
      "Epoch: 8000 train loss=0.008783512 valid loss= 0.008139696\n",
      "train reg_fs: 0.003835199633613229\n",
      "Epoch: 8500 train loss=0.006494032 valid loss= 0.008223936\n",
      "train reg_fs: 0.003823485691100359\n",
      "Epoch: 9000 train loss=0.006180968 valid loss= 0.008204218\n",
      "train reg_fs: 0.0038142986595630646\n",
      "Epoch: 9500 train loss=0.005887843 valid loss= 0.008337123\n",
      "train reg_fs: 0.0038060834631323814\n",
      "Epoch: 10000 train loss=0.006029750 valid loss= 0.008736519\n",
      "train reg_fs: 0.0037987474352121353\n",
      "Epoch: 10500 train loss=0.005515316 valid loss= 0.008365097\n",
      "train reg_fs: 0.0037921578623354435\n",
      "Epoch: 11000 train loss=0.006190774 valid loss= 0.008064702\n",
      "train reg_fs: 0.003786445129662752\n",
      "Epoch: 11500 train loss=0.006883942 valid loss= 0.008371923\n",
      "train reg_fs: 0.0037808704655617476\n",
      "Epoch: 12000 train loss=0.005183016 valid loss= 0.008462787\n",
      "train reg_fs: 0.003776010125875473\n",
      "Epoch: 12500 train loss=0.005622519 valid loss= 0.008408178\n",
      "train reg_fs: 0.003771851072087884\n",
      "Epoch: 13000 train loss=0.010749513 valid loss= 0.008227263\n",
      "train reg_fs: 0.0037677292712032795\n",
      "Epoch: 13500 train loss=0.004713197 valid loss= 0.008275697\n",
      "train reg_fs: 0.003764454275369644\n",
      "Epoch: 14000 train loss=0.005469091 valid loss= 0.008202109\n",
      "train reg_fs: 0.003761433996260166\n",
      "Epoch: 14500 train loss=0.006108722 valid loss= 0.008518204\n",
      "train reg_fs: 0.0037587257102131844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:55:35,952]\u001b[0m Trial 94 finished with value: 0.004583976597047957 and parameters: {'lam': 0.006579050141894025, 'learning_rate': 0.10279291358078434, 'num_epoch': 15000}. Best is trial 36 with value: 0.0008029169352910764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005788902 valid loss= 0.008487161\n",
      "train reg_fs: 0.0037559501361101866\n",
      "In trial:---------------------\n",
      "validation mse: 0.004583976597047957\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011281299 valid loss= 0.007802087\n",
      "train reg_fs: 0.0017700131284072995\n",
      "Epoch: 1000 train loss=0.009816313 valid loss= 0.006701035\n",
      "train reg_fs: 0.0017562102293595672\n",
      "Epoch: 1500 train loss=0.003040016 valid loss= 0.004921868\n",
      "train reg_fs: 0.0016810561064630747\n",
      "Epoch: 2000 train loss=0.002034112 valid loss= 0.003847168\n",
      "train reg_fs: 0.0016117129707708955\n",
      "Epoch: 2500 train loss=0.007093130 valid loss= 0.003688716\n",
      "train reg_fs: 0.0015696784248575568\n",
      "Epoch: 3000 train loss=0.003197451 valid loss= 0.004177060\n",
      "train reg_fs: 0.0015437538968399167\n",
      "Epoch: 3500 train loss=0.003334750 valid loss= 0.003475818\n",
      "train reg_fs: 0.0015270739095285535\n",
      "Epoch: 4000 train loss=0.002575970 valid loss= 0.003753003\n",
      "train reg_fs: 0.0015177270397543907\n",
      "Epoch: 4500 train loss=0.008273253 valid loss= 0.003944927\n",
      "train reg_fs: 0.001508920919150114\n",
      "Epoch: 5000 train loss=0.002857408 valid loss= 0.003085815\n",
      "train reg_fs: 0.001502200961112976\n",
      "Epoch: 5500 train loss=0.003294889 valid loss= 0.003343387\n",
      "train reg_fs: 0.0014973030192777514\n",
      "Epoch: 6000 train loss=0.010432246 valid loss= 0.003394939\n",
      "train reg_fs: 0.0014927396550774574\n",
      "Epoch: 6500 train loss=0.003113741 valid loss= 0.003177375\n",
      "train reg_fs: 0.0014870371669530869\n",
      "Epoch: 7000 train loss=0.003343698 valid loss= 0.003347149\n",
      "train reg_fs: 0.0014800613280385733\n",
      "Epoch: 7500 train loss=0.007333719 valid loss= 0.003200656\n",
      "train reg_fs: 0.001472549862228334\n",
      "Epoch: 8000 train loss=0.002653347 valid loss= 0.003109603\n",
      "train reg_fs: 0.0014658919535577297\n",
      "Epoch: 8500 train loss=0.003382271 valid loss= 0.002404328\n",
      "train reg_fs: 0.001458689570426941\n",
      "Epoch: 9000 train loss=0.004612708 valid loss= 0.003216621\n",
      "train reg_fs: 0.0014504524879157543\n",
      "Epoch: 9500 train loss=0.002273570 valid loss= 0.003133848\n",
      "train reg_fs: 0.0014408539282158017\n",
      "Epoch: 10000 train loss=0.001536410 valid loss= 0.002927618\n",
      "train reg_fs: 0.0014306835364550352\n",
      "Epoch: 10500 train loss=0.005308719 valid loss= 0.002354508\n",
      "train reg_fs: 0.0014222339959815145\n",
      "Epoch: 11000 train loss=0.002537490 valid loss= 0.002376878\n",
      "train reg_fs: 0.0014141949359327555\n",
      "Epoch: 11500 train loss=0.001856464 valid loss= 0.002255248\n",
      "train reg_fs: 0.0014065905706956983\n",
      "Epoch: 12000 train loss=0.003017434 valid loss= 0.002258774\n",
      "train reg_fs: 0.00140014395583421\n",
      "Epoch: 12500 train loss=0.004129091 valid loss= 0.002062537\n",
      "train reg_fs: 0.0013932910514995456\n",
      "Epoch: 13000 train loss=0.002783135 valid loss= 0.002033566\n",
      "train reg_fs: 0.0013883907813578844\n",
      "Epoch: 13500 train loss=0.002033495 valid loss= 0.002066955\n",
      "train reg_fs: 0.001384048257023096\n",
      "Epoch: 14000 train loss=0.002818581 valid loss= 0.002179771\n",
      "train reg_fs: 0.0013800041051581502\n",
      "Epoch: 14500 train loss=0.001734291 valid loss= 0.001776938\n",
      "train reg_fs: 0.001376864849589765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:57:24,929]\u001b[0m Trial 95 finished with value: 0.0003421789326401047 and parameters: {'lam': 0.0020272650185100835, 'learning_rate': 0.08246487334068153, 'num_epoch': 15000}. Best is trial 95 with value: 0.0003421789326401047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003981351 valid loss= 0.001719951\n",
      "train reg_fs: 0.0013738127890974283\n",
      "In trial:---------------------\n",
      "validation mse: 0.0003421789326401047\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014417034 valid loss= 0.006268058\n",
      "train reg_fs: 0.0017324623186141253\n",
      "Epoch: 1000 train loss=0.009905988 valid loss= 0.004934944\n",
      "train reg_fs: 0.0016538240015506744\n",
      "Epoch: 1500 train loss=0.004720076 valid loss= 0.003577826\n",
      "train reg_fs: 0.0015901596052572131\n",
      "Epoch: 2000 train loss=0.002729041 valid loss= 0.003909513\n",
      "train reg_fs: 0.0015560530591756105\n",
      "Epoch: 2500 train loss=0.003624211 valid loss= 0.004143662\n",
      "train reg_fs: 0.0015314184129238129\n",
      "Epoch: 3000 train loss=0.003588913 valid loss= 0.004262287\n",
      "train reg_fs: 0.0015140606556087732\n",
      "Epoch: 3500 train loss=0.002387253 valid loss= 0.003955032\n",
      "train reg_fs: 0.001499213743954897\n",
      "Epoch: 4000 train loss=0.003198107 valid loss= 0.003609384\n",
      "train reg_fs: 0.0014875968918204308\n",
      "Epoch: 4500 train loss=0.004363539 valid loss= 0.003705604\n",
      "train reg_fs: 0.0014768217224627733\n",
      "Epoch: 5000 train loss=0.002497036 valid loss= 0.003439083\n",
      "train reg_fs: 0.001465342822484672\n",
      "Epoch: 5500 train loss=0.002287320 valid loss= 0.003496868\n",
      "train reg_fs: 0.0014552517095580697\n",
      "Epoch: 6000 train loss=0.006914211 valid loss= 0.003610405\n",
      "train reg_fs: 0.0014423872344195843\n",
      "Epoch: 6500 train loss=0.003364157 valid loss= 0.003426407\n",
      "train reg_fs: 0.001430719974450767\n",
      "Epoch: 7000 train loss=0.003296645 valid loss= 0.003565788\n",
      "train reg_fs: 0.001413743826560676\n",
      "Epoch: 7500 train loss=0.002314682 valid loss= 0.003483744\n",
      "train reg_fs: 0.0013919587945565581\n",
      "Epoch: 8000 train loss=0.003504788 valid loss= 0.003694024\n",
      "train reg_fs: 0.0013723433949053288\n",
      "Epoch: 8500 train loss=0.003518318 valid loss= 0.003816583\n",
      "train reg_fs: 0.0013521932996809483\n",
      "Epoch: 9000 train loss=0.002420089 valid loss= 0.003960488\n",
      "train reg_fs: 0.001332712359726429\n",
      "Epoch: 9500 train loss=0.003161339 valid loss= 0.003590737\n",
      "train reg_fs: 0.0013172882609069347\n",
      "Epoch: 10000 train loss=0.001924947 valid loss= 0.003414284\n",
      "train reg_fs: 0.0013033036375418305\n",
      "Epoch: 10500 train loss=0.004364131 valid loss= 0.003839019\n",
      "train reg_fs: 0.0012933562975376844\n",
      "Epoch: 11000 train loss=0.002490197 valid loss= 0.003667969\n",
      "train reg_fs: 0.0012843506410717964\n",
      "Epoch: 11500 train loss=0.002886424 valid loss= 0.003610831\n",
      "train reg_fs: 0.0012760850368067622\n",
      "Epoch: 12000 train loss=0.008124708 valid loss= 0.003544851\n",
      "train reg_fs: 0.0012698734644800425\n",
      "Epoch: 12500 train loss=0.003208584 valid loss= 0.003656399\n",
      "train reg_fs: 0.0012649813434109092\n",
      "Epoch: 13000 train loss=0.007050087 valid loss= 0.003517026\n",
      "train reg_fs: 0.0012604324147105217\n",
      "Epoch: 13500 train loss=0.001905431 valid loss= 0.003498107\n",
      "train reg_fs: 0.001256440533325076\n",
      "Epoch: 14000 train loss=0.009416356 valid loss= 0.003410366\n",
      "train reg_fs: 0.0012528367806226015\n",
      "Epoch: 14500 train loss=0.001998730 valid loss= 0.003687282\n",
      "train reg_fs: 0.0012496248818933964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 15:59:16,259]\u001b[0m Trial 96 finished with value: 0.002402720418795053 and parameters: {'lam': 0.0020222468788348717, 'learning_rate': 0.08484324436056782, 'num_epoch': 15000}. Best is trial 95 with value: 0.0003421789326401047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002439916 valid loss= 0.003626855\n",
      "train reg_fs: 0.0012468385975807905\n",
      "In trial:---------------------\n",
      "validation mse: 0.002402720418795053\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018198177 valid loss= 0.010053359\n",
      "train reg_fs: 0.0029631233774125576\n",
      "Epoch: 1000 train loss=0.013771039 valid loss= 0.009993512\n",
      "train reg_fs: 0.0029874159954488277\n",
      "Epoch: 1500 train loss=0.008825107 valid loss= 0.010107704\n",
      "train reg_fs: 0.0029497561044991016\n",
      "Epoch: 2000 train loss=0.010109819 valid loss= 0.008961466\n",
      "train reg_fs: 0.0028864124324172735\n",
      "Epoch: 2500 train loss=0.007571585 valid loss= 0.008531876\n",
      "train reg_fs: 0.002842755988240242\n",
      "Epoch: 3000 train loss=0.008003715 valid loss= 0.007968181\n",
      "train reg_fs: 0.0028103156946599483\n",
      "Epoch: 3500 train loss=0.007688421 valid loss= 0.007097732\n",
      "train reg_fs: 0.0027772956527769566\n",
      "Epoch: 4000 train loss=0.003833181 valid loss= 0.006457367\n",
      "train reg_fs: 0.0027340142987668514\n",
      "Epoch: 4500 train loss=0.005124614 valid loss= 0.005914290\n",
      "train reg_fs: 0.002672152826562524\n",
      "Epoch: 5000 train loss=0.007168092 valid loss= 0.005376306\n",
      "train reg_fs: 0.002623641397804022\n",
      "Epoch: 5500 train loss=0.004743016 valid loss= 0.005211604\n",
      "train reg_fs: 0.0025827381759881973\n",
      "Epoch: 6000 train loss=0.007523717 valid loss= 0.005398274\n",
      "train reg_fs: 0.0025447385851293802\n",
      "Epoch: 6500 train loss=0.004276534 valid loss= 0.005390829\n",
      "train reg_fs: 0.0025062295608222485\n",
      "Epoch: 7000 train loss=0.003327161 valid loss= 0.005580186\n",
      "train reg_fs: 0.002469592960551381\n",
      "Epoch: 7500 train loss=0.003813695 valid loss= 0.005510608\n",
      "train reg_fs: 0.0024377095978707075\n",
      "Epoch: 8000 train loss=0.003805568 valid loss= 0.005490776\n",
      "train reg_fs: 0.002402504673227668\n",
      "Epoch: 8500 train loss=0.003838137 valid loss= 0.005289680\n",
      "train reg_fs: 0.002370474860072136\n",
      "Epoch: 9000 train loss=0.003468261 valid loss= 0.005142371\n",
      "train reg_fs: 0.0023373961448669434\n",
      "Epoch: 9500 train loss=0.002708663 valid loss= 0.005057506\n",
      "train reg_fs: 0.0023052701726555824\n",
      "Epoch: 10000 train loss=0.003461906 valid loss= 0.004853225\n",
      "train reg_fs: 0.0022773505188524723\n",
      "Epoch: 10500 train loss=0.004143195 valid loss= 0.004975055\n",
      "train reg_fs: 0.0022554006427526474\n",
      "Epoch: 11000 train loss=0.009116073 valid loss= 0.004798902\n",
      "train reg_fs: 0.002235599560663104\n",
      "Epoch: 11500 train loss=0.006862000 valid loss= 0.004835822\n",
      "train reg_fs: 0.002216876717284322\n",
      "Epoch: 12000 train loss=0.003928890 valid loss= 0.004819797\n",
      "train reg_fs: 0.0021990477107465267\n",
      "Epoch: 12500 train loss=0.004865787 valid loss= 0.004923512\n",
      "train reg_fs: 0.002184464130550623\n",
      "Epoch: 13000 train loss=0.003338172 valid loss= 0.004815077\n",
      "train reg_fs: 0.002170785330235958\n",
      "Epoch: 13500 train loss=0.002772708 valid loss= 0.004736135\n",
      "train reg_fs: 0.002159964060410857\n",
      "Epoch: 14000 train loss=0.005070114 valid loss= 0.004493163\n",
      "train reg_fs: 0.0021506533958017826\n",
      "Epoch: 14500 train loss=0.003121620 valid loss= 0.005032342\n",
      "train reg_fs: 0.002140975324437022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 16:01:06,119]\u001b[0m Trial 97 finished with value: 0.0024123612430362973 and parameters: {'lam': 0.0034117228222746506, 'learning_rate': 0.0666007720683016, 'num_epoch': 15000}. Best is trial 95 with value: 0.0003421789326401047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003732816 valid loss= 0.004523041\n",
      "train reg_fs: 0.0021332844626158476\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024123612430362973\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011716840 valid loss= 0.012304091\n",
      "train reg_fs: 0.006493268068879843\n",
      "Epoch: 1000 train loss=0.017071363 valid loss= 0.013091714\n",
      "train reg_fs: 0.006424612365663052\n",
      "Epoch: 1500 train loss=0.013023757 valid loss= 0.013366715\n",
      "train reg_fs: 0.006278687156736851\n",
      "Epoch: 2000 train loss=0.009394637 valid loss= 0.012023455\n",
      "train reg_fs: 0.006156205199658871\n",
      "Epoch: 2500 train loss=0.009923256 valid loss= 0.011942275\n",
      "train reg_fs: 0.006077426020056009\n",
      "Epoch: 3000 train loss=0.007696636 valid loss= 0.011816096\n",
      "train reg_fs: 0.006038798950612545\n",
      "Epoch: 3500 train loss=0.010012492 valid loss= 0.011401113\n",
      "train reg_fs: 0.005978143308311701\n",
      "Epoch: 4000 train loss=0.008160966 valid loss= 0.010704972\n",
      "train reg_fs: 0.005944143049418926\n",
      "Epoch: 4500 train loss=0.013209680 valid loss= 0.010309534\n",
      "train reg_fs: 0.005899250041693449\n",
      "Epoch: 5000 train loss=0.008511382 valid loss= 0.010547802\n",
      "train reg_fs: 0.005829797592014074\n",
      "Epoch: 5500 train loss=0.009496773 valid loss= 0.010492325\n",
      "train reg_fs: 0.005756524857133627\n",
      "Epoch: 6000 train loss=0.006874143 valid loss= 0.010522244\n",
      "train reg_fs: 0.005674442276358604\n",
      "Epoch: 6500 train loss=0.011230792 valid loss= 0.010572180\n",
      "train reg_fs: 0.005595415830612183\n",
      "Epoch: 7000 train loss=0.007544231 valid loss= 0.010373024\n",
      "train reg_fs: 0.00550971319898963\n",
      "Epoch: 7500 train loss=0.009103438 valid loss= 0.010475358\n",
      "train reg_fs: 0.005425802897661924\n",
      "Epoch: 8000 train loss=0.006888695 valid loss= 0.010783017\n",
      "train reg_fs: 0.005347022786736488\n",
      "Epoch: 8500 train loss=0.006850000 valid loss= 0.010860583\n",
      "train reg_fs: 0.00526056345552206\n",
      "Epoch: 9000 train loss=0.006125938 valid loss= 0.010799171\n",
      "train reg_fs: 0.005183559842407703\n",
      "Epoch: 9500 train loss=0.008377625 valid loss= 0.010448478\n",
      "train reg_fs: 0.0051074400544166565\n",
      "Epoch: 10000 train loss=0.006512475 valid loss= 0.010598039\n",
      "train reg_fs: 0.005032574292272329\n",
      "Epoch: 10500 train loss=0.008404961 valid loss= 0.010810977\n",
      "train reg_fs: 0.004959053359925747\n",
      "Epoch: 11000 train loss=0.009240197 valid loss= 0.010439216\n",
      "train reg_fs: 0.004882970359176397\n",
      "Epoch: 11500 train loss=0.005800283 valid loss= 0.010643912\n",
      "train reg_fs: 0.004809598904103041\n",
      "Epoch: 12000 train loss=0.006988263 valid loss= 0.010611987\n",
      "train reg_fs: 0.0047403317876160145\n",
      "Epoch: 12500 train loss=0.005807257 valid loss= 0.010883893\n",
      "train reg_fs: 0.0046704672276973724\n",
      "Epoch: 13000 train loss=0.005417427 valid loss= 0.010875748\n",
      "train reg_fs: 0.004607340786606073\n",
      "Epoch: 13500 train loss=0.006949640 valid loss= 0.010989374\n",
      "train reg_fs: 0.0045551639050245285\n",
      "Epoch: 14000 train loss=0.006001534 valid loss= 0.010662805\n",
      "train reg_fs: 0.0044954558834433556\n",
      "Epoch: 14500 train loss=0.005453061 valid loss= 0.010980097\n",
      "train reg_fs: 0.004444037564098835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 16:02:56,487]\u001b[0m Trial 98 finished with value: 0.0064290962762891335 and parameters: {'lam': 0.007557841086390725, 'learning_rate': 0.07704430083470586, 'num_epoch': 15000}. Best is trial 95 with value: 0.0003421789326401047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005749658 valid loss= 0.010939404\n",
      "train reg_fs: 0.00439526978880167\n",
      "In trial:---------------------\n",
      "validation mse: 0.0064290962762891335\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013170080 valid loss= 0.011420080\n",
      "train reg_fs: 0.005185103043913841\n",
      "Epoch: 1000 train loss=0.010031940 valid loss= 0.012542065\n",
      "train reg_fs: 0.005229081027209759\n",
      "Epoch: 1500 train loss=0.014854264 valid loss= 0.011265216\n",
      "train reg_fs: 0.005178947001695633\n",
      "Epoch: 2000 train loss=0.014128022 valid loss= 0.010126436\n",
      "train reg_fs: 0.005056467372924089\n",
      "Epoch: 2500 train loss=0.006208764 valid loss= 0.009297005\n",
      "train reg_fs: 0.00489971786737442\n",
      "Epoch: 3000 train loss=0.009447508 valid loss= 0.007971566\n",
      "train reg_fs: 0.004759218078106642\n",
      "Epoch: 3500 train loss=0.007887245 valid loss= 0.007564758\n",
      "train reg_fs: 0.004634139593690634\n",
      "Epoch: 4000 train loss=0.005413746 valid loss= 0.008008751\n",
      "train reg_fs: 0.004537093918770552\n",
      "Epoch: 4500 train loss=0.005741008 valid loss= 0.007985772\n",
      "train reg_fs: 0.004447366576641798\n",
      "Epoch: 5000 train loss=0.011951108 valid loss= 0.008184372\n",
      "train reg_fs: 0.004373716656118631\n",
      "Epoch: 5500 train loss=0.008881032 valid loss= 0.008368845\n",
      "train reg_fs: 0.004304368980228901\n",
      "Epoch: 6000 train loss=0.005410525 valid loss= 0.008400407\n",
      "train reg_fs: 0.004245983436703682\n",
      "Epoch: 6500 train loss=0.006322329 valid loss= 0.008445079\n",
      "train reg_fs: 0.004196092486381531\n",
      "Epoch: 7000 train loss=0.006727526 valid loss= 0.008267168\n",
      "train reg_fs: 0.004158693831413984\n",
      "Epoch: 7500 train loss=0.007607727 valid loss= 0.008181656\n",
      "train reg_fs: 0.004115179181098938\n",
      "Epoch: 8000 train loss=0.004473677 valid loss= 0.008212079\n",
      "train reg_fs: 0.004077471327036619\n",
      "Epoch: 8500 train loss=0.005039368 valid loss= 0.008086957\n",
      "train reg_fs: 0.0040490394458174706\n",
      "Epoch: 9000 train loss=0.004503135 valid loss= 0.008256059\n",
      "train reg_fs: 0.0040167332626879215\n",
      "Epoch: 9500 train loss=0.010556748 valid loss= 0.007923992\n",
      "train reg_fs: 0.003994483035057783\n",
      "Epoch: 10000 train loss=0.009341563 valid loss= 0.008134050\n",
      "train reg_fs: 0.0039624860510230064\n",
      "Epoch: 10500 train loss=0.005757375 valid loss= 0.007995485\n",
      "train reg_fs: 0.003931023180484772\n",
      "Epoch: 11000 train loss=0.004262786 valid loss= 0.007827518\n",
      "train reg_fs: 0.00391283119097352\n",
      "Epoch: 11500 train loss=0.004709414 valid loss= 0.007801907\n",
      "train reg_fs: 0.0038874561432749033\n",
      "Epoch: 12000 train loss=0.005418905 valid loss= 0.007866198\n",
      "train reg_fs: 0.003867348423227668\n",
      "Epoch: 12500 train loss=0.004812818 valid loss= 0.007678782\n",
      "train reg_fs: 0.003843295155093074\n",
      "Epoch: 13000 train loss=0.004646629 valid loss= 0.007840740\n",
      "train reg_fs: 0.0038257776759564877\n",
      "Epoch: 13500 train loss=0.005297409 valid loss= 0.007856555\n",
      "train reg_fs: 0.0038088257424533367\n",
      "Epoch: 14000 train loss=0.005047176 valid loss= 0.007800342\n",
      "train reg_fs: 0.003787900786846876\n",
      "Epoch: 14500 train loss=0.004165924 valid loss= 0.007777090\n",
      "train reg_fs: 0.003770318115130067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 16:04:46,639]\u001b[0m Trial 99 finished with value: 0.0038077590397219492 and parameters: {'lam': 0.005943432456600843, 'learning_rate': 0.07158809157981152, 'num_epoch': 15000}. Best is trial 95 with value: 0.0003421789326401047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007396598 valid loss= 0.007620705\n",
      "train reg_fs: 0.0037525382358580828\n",
      "In trial:---------------------\n",
      "validation mse: 0.0038077590397219492\n"
     ]
    }
   ],
   "source": [
    "# optimize the model via Optuna and obtain the best model with smallest validation mse\n",
    "best_model = None\n",
    "model = None\n",
    "study = optuna.create_study(pruner=None)\n",
    "study.optimize(llspin_objective, n_trials=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training gate matrix\n",
    "gate_mat_train = best_model.get_prob_alpha(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = study.best_params['learning_rate']\n",
    "best_epoch = study.best_params['num_epoch']\n",
    "best_lam = study.best_params['lam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Finished*************\n",
      "Best model's lambda: 0.0020272650185100835\n",
      "Best model's learning rate: 0.08246487334068153\n",
      "Best model's num of epochs: 15000\n",
      "Test mse : 0.0003238273992719494\n",
      "Test r2 : 0.9921859496525943\n"
     ]
    }
   ],
   "source": [
    "# test the best model\n",
    "y_pred_llspin = best_model.test(X_test)[0]\n",
    "            \n",
    "print(\"Trial Finished*************\")\n",
    "print(\"Best model's lambda: {}\".format(best_lam))\n",
    "print(\"Best model's learning rate: {}\".format(best_lr))\n",
    "print(\"Best model's num of epochs: {}\".format(best_epoch))\n",
    "print(\"Test mse : {}\".format(mean_squared_error(y_test.reshape(-1),y_pred_llspin.reshape(-1))))\n",
    "print(\"Test r2 : {}\".format(r2_score(y_test.reshape(-1),y_pred_llspin.reshape(-1),multioutput='raw_values')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the training gates to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.Blues\n",
    "bounds=[0,0.5,1]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "title_size = 30\n",
    "xtick_size = 20\n",
    "ytick_size = 20\n",
    "xlabel_size = 35\n",
    "ylabel_size = 35\n",
    "colorbar_tick_size = 20\n",
    "title_pad = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "sorted_order = np.concatenate((np.where(train_label == 1)[0],np.where(train_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_train[sorted_order,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([1,3,5,7,9])\n",
    "axes[0].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "im2 = axes[1].imshow(gate_mat_train[sorted_order,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([1,3,5,7,9])\n",
    "axes[1].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the test gates to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_mat_test = best_model.get_prob_alpha(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "fig.subplots_adjust(bottom=0.01)\n",
    "\n",
    "sorted_order_test = np.concatenate((np.where(test_label == 1)[0],np.where(test_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_test[sorted_order_test,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([0,9,19,29,39,49])\n",
    "axes[0].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "    \n",
    "im2 = axes[1].imshow(gate_mat_test[sorted_order_test,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([0,9,19,29,39,49])\n",
    "axes[1].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "    \n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
