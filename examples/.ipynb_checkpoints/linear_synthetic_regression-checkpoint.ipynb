{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from lspin.lspin_model import Model\n",
    "from lspin.utils import DataSet\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm,colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if need to use GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear synthetic data generation\n",
    "\n",
    "Group 1: $X$ ~ $N(1,0.5)$,  $Y = -2X_1 + X_2 - 0.5X_3$\n",
    "\n",
    "Group 2: $X$ ~ $N(-1,0.5)$, $Y = -0.5X_3 + X_4 - 2X_5$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "Xs1 = np.random.normal(loc=1,scale=0.5,size=(300,5))\n",
    "Ys1 = -2*Xs1[:,0]+1*Xs1[:,1]-0.5*Xs1[:,2]\n",
    "\n",
    "Xs2 = np.random.normal(loc=-1,scale=0.5,size=(300,5))\n",
    "Ys2 = -0.5*Xs2[:,2]+1*Xs2[:,3]-2*Xs2[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate((Xs1,Xs2),axis=0)\n",
    "Y_data = np.concatenate((Ys1.reshape(-1,1),Ys2.reshape(-1,1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = Y_data-Y_data.min()\n",
    "Y_data=Y_data/Y_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ground truth group label of each sample\n",
    "case_labels = np.concatenate((np.array([1]*300),np.array([2]*300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = np.concatenate((Y_data,case_labels.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% for validation, 10% for test \n",
    "X_train,X_remain,yc_train,yc_remain = train_test_split(X_data,Y_data,train_size=0.8,shuffle=True,random_state=34)\n",
    "X_valid,X_test,yc_valid,yc_test = train_test_split(X_remain,yc_remain,train_size=0.5,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 10 samples used for training\n",
    "X_train,_,yc_train,_ = train_test_split(X_train,yc_train,train_size=10,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes:\n",
      "10 60 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample sizes:\")\n",
    "print(X_train.shape[0],X_valid.shape[0],X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = yc_train[:,0].reshape(-1,1)\n",
    "y_valid = yc_valid[:,0].reshape(-1,1)\n",
    "y_test = yc_test[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = yc_train[:,1]\n",
    "valid_label = yc_valid[:,1]\n",
    "test_label= yc_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 6, 1.0: 4})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 29, 1.0: 31})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(**{'_data':X_train, '_labels':y_train,\n",
    "                '_valid_data':X_valid, '_valid_labels':y_valid,\n",
    "                '_test_data':X_test, '_test_labels':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference ground truth feature matrix (training/test)\n",
    "ref_feat_mat_train = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in train_label])\n",
    "ref_feat_mat_test = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in test_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLSPIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function for optuna hyper-parameter optimization\n",
    "def llspin_objective(trial):  \n",
    "    global model\n",
    "    \n",
    "    # hyper-parameter specification\n",
    "    params = {     \n",
    "        \"input_node\" : X_train.shape[1],       # input dimension for the prediction network\n",
    "        \"hidden_layers_node\" : [100,100,10,1], # number of nodes for each hidden layer of the prediction net\n",
    "        \"output_node\" : 1,                     # number of nodes for the output layer of the prediction net\n",
    "        \"feature_selection\" : True,            # if using the gating net\n",
    "        \"gating_net_hidden_layers_node\": [10], # number of nodes for each hidden layer of the gating net\n",
    "        \"display_step\" : 500                   # number of epochs to output info\n",
    "    }\n",
    "    params['activation']= 'none' # linear prediction\n",
    "    params['batch_size']= X_train.shape[0]\n",
    "    \n",
    "    # hyper-parameter to optimize: lambda, learning rate, number of epochs\n",
    "    params['lam'] = trial.suggest_loguniform('lam',1e-3,1e-2)\n",
    "    params['learning_rate'] = trial.suggest_loguniform('learning_rate', 1e-2, 2e-1)\n",
    "    num_epoch = trial.suggest_categorical('num_epoch', [2000,5000,10000,15000])\n",
    "\n",
    "    # specify the model with these parameters and train the model\n",
    "    model_dir =None\n",
    "    model = Model(**params)\n",
    "    train_acces, train_losses, val_acces, val_losses = model.train(trial, dataset, model_dir, num_epoch=num_epoch)\n",
    "\n",
    "    print(\"In trial:---------------------\")\n",
    "    val_prediction = model.test(X_valid)[0]\n",
    "    mse = mean_squared_error(y_valid.reshape(-1),val_prediction.reshape(-1))\n",
    "    print(\"validation mse: {}\".format(mse))\n",
    "    \n",
    "    loss= mse\n",
    "            \n",
    "    return loss\n",
    "        \n",
    "def callback(study,trial):\n",
    "    global best_model\n",
    "    if study.best_trial == trial:\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:17:43,635]\u001b[0m A new study created in memory with name: no-name-f0870a63-9041-4b96-bdc7-98c0edb21a63\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:54: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:70: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:259: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:107: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:139: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:179: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:189: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:189: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:191: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:198: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:199: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/lspin/lspin_model.py:216: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018438540 valid loss= 0.015716955\n",
      "train reg_fs: 0.00835622102022171\n",
      "Epoch: 1000 train loss=0.017322838 valid loss= 0.014847589\n",
      "train reg_fs: 0.008436045609414577\n",
      "Epoch: 1500 train loss=0.013249367 valid loss= 0.014965270\n",
      "train reg_fs: 0.008463893085718155\n",
      "Epoch: 2000 train loss=0.013308635 valid loss= 0.014766754\n",
      "train reg_fs: 0.008432308211922646\n",
      "Epoch: 2500 train loss=0.022618454 valid loss= 0.013934918\n",
      "train reg_fs: 0.008332078345119953\n",
      "Epoch: 3000 train loss=0.020706382 valid loss= 0.013845423\n",
      "train reg_fs: 0.008191204629838467\n",
      "Epoch: 3500 train loss=0.017901119 valid loss= 0.013689952\n",
      "train reg_fs: 0.008047297596931458\n",
      "Epoch: 4000 train loss=0.015222468 valid loss= 0.012752678\n",
      "train reg_fs: 0.007920250296592712\n",
      "Epoch: 4500 train loss=0.012846570 valid loss= 0.012683224\n",
      "train reg_fs: 0.007813874632120132\n",
      "Epoch: 5000 train loss=0.015321994 valid loss= 0.012089747\n",
      "train reg_fs: 0.007717558648437262\n",
      "Epoch: 5500 train loss=0.010444927 valid loss= 0.011790607\n",
      "train reg_fs: 0.007618620526045561\n",
      "Epoch: 6000 train loss=0.016008632 valid loss= 0.011569601\n",
      "train reg_fs: 0.007517676800489426\n",
      "Epoch: 6500 train loss=0.014242304 valid loss= 0.011250427\n",
      "train reg_fs: 0.0074079604819417\n",
      "Epoch: 7000 train loss=0.011410270 valid loss= 0.010565024\n",
      "train reg_fs: 0.0072885537520051\n",
      "Epoch: 7500 train loss=0.010159596 valid loss= 0.010145476\n",
      "train reg_fs: 0.007162268739193678\n",
      "Epoch: 8000 train loss=0.012925003 valid loss= 0.010060066\n",
      "train reg_fs: 0.007038096431642771\n",
      "Epoch: 8500 train loss=0.010899695 valid loss= 0.010018094\n",
      "train reg_fs: 0.00692709581926465\n",
      "Epoch: 9000 train loss=0.009824811 valid loss= 0.009676840\n",
      "train reg_fs: 0.006827197968959808\n",
      "Epoch: 9500 train loss=0.009737278 valid loss= 0.009806108\n",
      "train reg_fs: 0.0067354487255215645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:18:56,664]\u001b[0m Trial 0 finished with value: 0.0033712446149224717 and parameters: {'lam': 0.009752238715323224, 'learning_rate': 0.037202381457833125, 'num_epoch': 10000}. Best is trial 0 with value: 0.0033712446149224717.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.009440141 valid loss= 0.010259671\n",
      "train reg_fs: 0.006647790782153606\n",
      "In trial:---------------------\n",
      "validation mse: 0.0033712446149224717\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010520695 valid loss= 0.007611860\n",
      "train reg_fs: 0.002909703878685832\n",
      "Epoch: 1000 train loss=0.007106877 valid loss= 0.005934773\n",
      "train reg_fs: 0.0026609706692397594\n",
      "Epoch: 1500 train loss=0.005921209 valid loss= 0.006283443\n",
      "train reg_fs: 0.002572235418483615\n",
      "Epoch: 2000 train loss=0.004481396 valid loss= 0.006310771\n",
      "train reg_fs: 0.0025088870897889137\n",
      "Epoch: 2500 train loss=0.007562572 valid loss= 0.006246453\n",
      "train reg_fs: 0.002459912095218897\n",
      "Epoch: 3000 train loss=0.008592620 valid loss= 0.007075344\n",
      "train reg_fs: 0.002406116807833314\n",
      "Epoch: 3500 train loss=0.011139070 valid loss= 0.006633325\n",
      "train reg_fs: 0.0023615097161382437\n",
      "Epoch: 4000 train loss=0.008272804 valid loss= 0.006300204\n",
      "train reg_fs: 0.0023388671688735485\n",
      "Epoch: 4500 train loss=0.008820269 valid loss= 0.006560373\n",
      "train reg_fs: 0.0023258617147803307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:19:31,611]\u001b[0m Trial 1 finished with value: 0.003907184721213148 and parameters: {'lam': 0.003638998674347051, 'learning_rate': 0.16825524136744502, 'num_epoch': 5000}. Best is trial 0 with value: 0.0033712446149224717.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004747927 valid loss= 0.006302666\n",
      "train reg_fs: 0.002323672641068697\n",
      "In trial:---------------------\n",
      "validation mse: 0.003907184721213148\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008530087 valid loss= 0.009467341\n",
      "train reg_fs: 0.0036447152961045504\n",
      "Epoch: 1000 train loss=0.011600923 valid loss= 0.009464120\n",
      "train reg_fs: 0.003639901988208294\n",
      "Epoch: 1500 train loss=0.005960410 valid loss= 0.009498433\n",
      "train reg_fs: 0.0035575288347899914\n",
      "Epoch: 2000 train loss=0.007393973 valid loss= 0.007877385\n",
      "train reg_fs: 0.0034340156707912683\n",
      "Epoch: 2500 train loss=0.010790829 valid loss= 0.006247856\n",
      "train reg_fs: 0.0033023098949342966\n",
      "Epoch: 3000 train loss=0.007266559 valid loss= 0.005844221\n",
      "train reg_fs: 0.0031709950417280197\n",
      "Epoch: 3500 train loss=0.005704085 valid loss= 0.005959241\n",
      "train reg_fs: 0.0030743288807570934\n",
      "Epoch: 4000 train loss=0.005379365 valid loss= 0.005928935\n",
      "train reg_fs: 0.0029898195061832666\n",
      "Epoch: 4500 train loss=0.009836741 valid loss= 0.006265990\n",
      "train reg_fs: 0.0029165521264076233\n",
      "Epoch: 5000 train loss=0.005873661 valid loss= 0.006234926\n",
      "train reg_fs: 0.0028591312002390623\n",
      "Epoch: 5500 train loss=0.005439979 valid loss= 0.005391942\n",
      "train reg_fs: 0.002807180630043149\n",
      "Epoch: 6000 train loss=0.003383511 valid loss= 0.005328766\n",
      "train reg_fs: 0.0027648299001157284\n",
      "Epoch: 6500 train loss=0.002922095 valid loss= 0.005219575\n",
      "train reg_fs: 0.0027299777138978243\n",
      "Epoch: 7000 train loss=0.007080143 valid loss= 0.005522217\n",
      "train reg_fs: 0.0026993562933057547\n",
      "Epoch: 7500 train loss=0.004505828 valid loss= 0.004995442\n",
      "train reg_fs: 0.0026753873098641634\n",
      "Epoch: 8000 train loss=0.004212331 valid loss= 0.004995875\n",
      "train reg_fs: 0.0026562176644802094\n",
      "Epoch: 8500 train loss=0.004893725 valid loss= 0.005185337\n",
      "train reg_fs: 0.0026410743594169617\n",
      "Epoch: 9000 train loss=0.003318919 valid loss= 0.005023414\n",
      "train reg_fs: 0.002628037938848138\n",
      "Epoch: 9500 train loss=0.005055363 valid loss= 0.004962764\n",
      "train reg_fs: 0.002617397578433156\n",
      "Epoch: 10000 train loss=0.008266259 valid loss= 0.004842313\n",
      "train reg_fs: 0.002608857350423932\n",
      "Epoch: 10500 train loss=0.003746611 valid loss= 0.005086631\n",
      "train reg_fs: 0.002601022133603692\n",
      "Epoch: 11000 train loss=0.002736479 valid loss= 0.004740021\n",
      "train reg_fs: 0.002593770157545805\n",
      "Epoch: 11500 train loss=0.003152127 valid loss= 0.005004868\n",
      "train reg_fs: 0.0025871903635561466\n",
      "Epoch: 12000 train loss=0.002729292 valid loss= 0.004567341\n",
      "train reg_fs: 0.002581592882052064\n",
      "Epoch: 12500 train loss=0.004342232 valid loss= 0.004931231\n",
      "train reg_fs: 0.002576634753495455\n",
      "Epoch: 13000 train loss=0.004232483 valid loss= 0.004955755\n",
      "train reg_fs: 0.002572006080299616\n",
      "Epoch: 13500 train loss=0.003469751 valid loss= 0.004923403\n",
      "train reg_fs: 0.00256814225576818\n",
      "Epoch: 14000 train loss=0.002826929 valid loss= 0.004625550\n",
      "train reg_fs: 0.002564410213381052\n",
      "Epoch: 14500 train loss=0.007892210 valid loss= 0.004936907\n",
      "train reg_fs: 0.0025610460434108973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:21:12,127]\u001b[0m Trial 2 finished with value: 0.002232049022448978 and parameters: {'lam': 0.004196013265374776, 'learning_rate': 0.06791179800176345, 'num_epoch': 15000}. Best is trial 2 with value: 0.002232049022448978.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007581359 valid loss= 0.004735713\n",
      "train reg_fs: 0.0025580190122127533\n",
      "In trial:---------------------\n",
      "validation mse: 0.002232049022448978\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007411654 valid loss= 0.008568435\n",
      "train reg_fs: 0.0028035887517035007\n",
      "Epoch: 1000 train loss=0.007297157 valid loss= 0.007146023\n",
      "train reg_fs: 0.0027148278895765543\n",
      "Epoch: 1500 train loss=0.008437198 valid loss= 0.005534595\n",
      "train reg_fs: 0.002616224344819784\n",
      "Epoch: 2000 train loss=0.003570025 valid loss= 0.004601599\n",
      "train reg_fs: 0.002501643029972911\n",
      "Epoch: 2500 train loss=0.005905373 valid loss= 0.004676788\n",
      "train reg_fs: 0.0024286345578730106\n",
      "Epoch: 3000 train loss=0.003398034 valid loss= 0.004473395\n",
      "train reg_fs: 0.002380663761869073\n",
      "Epoch: 3500 train loss=0.003421435 valid loss= 0.004163796\n",
      "train reg_fs: 0.00234427722170949\n",
      "Epoch: 4000 train loss=0.004390486 valid loss= 0.004227537\n",
      "train reg_fs: 0.0023115351796150208\n",
      "Epoch: 4500 train loss=0.004934733 valid loss= 0.004284174\n",
      "train reg_fs: 0.002264562528580427\n",
      "Epoch: 5000 train loss=0.005485779 valid loss= 0.004582495\n",
      "train reg_fs: 0.002210135105997324\n",
      "Epoch: 5500 train loss=0.004705963 valid loss= 0.004246124\n",
      "train reg_fs: 0.002155886497348547\n",
      "Epoch: 6000 train loss=0.003093662 valid loss= 0.004326363\n",
      "train reg_fs: 0.002112058224156499\n",
      "Epoch: 6500 train loss=0.003711784 valid loss= 0.004082977\n",
      "train reg_fs: 0.00207641557790339\n",
      "Epoch: 7000 train loss=0.006442836 valid loss= 0.003997136\n",
      "train reg_fs: 0.0020470386371016502\n",
      "Epoch: 7500 train loss=0.002220468 valid loss= 0.003749419\n",
      "train reg_fs: 0.0020176758989691734\n",
      "Epoch: 8000 train loss=0.004436263 valid loss= 0.004002862\n",
      "train reg_fs: 0.001993117853999138\n",
      "Epoch: 8500 train loss=0.002679497 valid loss= 0.003474713\n",
      "train reg_fs: 0.001972768222913146\n",
      "Epoch: 9000 train loss=0.005302760 valid loss= 0.003559470\n",
      "train reg_fs: 0.0019548707641661167\n",
      "Epoch: 9500 train loss=0.002311485 valid loss= 0.004057938\n",
      "train reg_fs: 0.0019399193115532398\n",
      "Epoch: 10000 train loss=0.006093962 valid loss= 0.004470566\n",
      "train reg_fs: 0.0019273083889856935\n",
      "Epoch: 10500 train loss=0.003743472 valid loss= 0.003833335\n",
      "train reg_fs: 0.0019163964316248894\n",
      "Epoch: 11000 train loss=0.006078528 valid loss= 0.003529377\n",
      "train reg_fs: 0.001906792283989489\n",
      "Epoch: 11500 train loss=0.004349716 valid loss= 0.004243464\n",
      "train reg_fs: 0.0018985860515385866\n",
      "Epoch: 12000 train loss=0.005986176 valid loss= 0.003055999\n",
      "train reg_fs: 0.0018921290757134557\n",
      "Epoch: 12500 train loss=0.002874621 valid loss= 0.003981934\n",
      "train reg_fs: 0.001886635785922408\n",
      "Epoch: 13000 train loss=0.002050290 valid loss= 0.003695102\n",
      "train reg_fs: 0.00188150885514915\n",
      "Epoch: 13500 train loss=0.002474833 valid loss= 0.003561385\n",
      "train reg_fs: 0.0018774778582155704\n",
      "Epoch: 14000 train loss=0.002479084 valid loss= 0.003259878\n",
      "train reg_fs: 0.0018734682817012072\n",
      "Epoch: 14500 train loss=0.002179247 valid loss= 0.003704345\n",
      "train reg_fs: 0.001869914005510509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:22:56,414]\u001b[0m Trial 3 finished with value: 0.0019119739482977478 and parameters: {'lam': 0.0032441113194873286, 'learning_rate': 0.10286293635225624, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003879320 valid loss= 0.003846798\n",
      "train reg_fs: 0.001866811071522534\n",
      "In trial:---------------------\n",
      "validation mse: 0.0019119739482977478\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009712338 valid loss= 0.009524901\n",
      "train reg_fs: 0.001998903462663293\n",
      "Epoch: 1000 train loss=0.015956739 valid loss= 0.009310525\n",
      "train reg_fs: 0.002016984159126878\n",
      "Epoch: 1500 train loss=0.025129378 valid loss= 0.009095894\n",
      "train reg_fs: 0.0020321011543273926\n",
      "Epoch: 2000 train loss=0.009460340 valid loss= 0.009065986\n",
      "train reg_fs: 0.0020441454835236073\n",
      "Epoch: 2500 train loss=0.023406960 valid loss= 0.008765414\n",
      "train reg_fs: 0.0020547169260680676\n",
      "Epoch: 3000 train loss=0.009098036 valid loss= 0.008618538\n",
      "train reg_fs: 0.0020633444655686617\n",
      "Epoch: 3500 train loss=0.007043782 valid loss= 0.008037766\n",
      "train reg_fs: 0.002067859750241041\n",
      "Epoch: 4000 train loss=0.008630361 valid loss= 0.008360387\n",
      "train reg_fs: 0.002071092603728175\n",
      "Epoch: 4500 train loss=0.011324105 valid loss= 0.007886417\n",
      "train reg_fs: 0.0020719768945127726\n",
      "Epoch: 5000 train loss=0.014821081 valid loss= 0.008008687\n",
      "train reg_fs: 0.0020717948209494352\n",
      "Epoch: 5500 train loss=0.008425702 valid loss= 0.007577650\n",
      "train reg_fs: 0.002069961978122592\n",
      "Epoch: 6000 train loss=0.006814992 valid loss= 0.007385835\n",
      "train reg_fs: 0.0020662874449044466\n",
      "Epoch: 6500 train loss=0.006676391 valid loss= 0.007399699\n",
      "train reg_fs: 0.0020616096444427967\n",
      "Epoch: 7000 train loss=0.006738308 valid loss= 0.007259222\n",
      "train reg_fs: 0.002054010983556509\n",
      "Epoch: 7500 train loss=0.010910493 valid loss= 0.007116060\n",
      "train reg_fs: 0.0020461129024624825\n",
      "Epoch: 8000 train loss=0.004804041 valid loss= 0.007002117\n",
      "train reg_fs: 0.0020378967747092247\n",
      "Epoch: 8500 train loss=0.005746371 valid loss= 0.007212760\n",
      "train reg_fs: 0.002028666902333498\n",
      "Epoch: 9000 train loss=0.006905264 valid loss= 0.006710349\n",
      "train reg_fs: 0.002018436323851347\n",
      "Epoch: 9500 train loss=0.012217224 valid loss= 0.006905715\n",
      "train reg_fs: 0.0020081831607967615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:24:11,616]\u001b[0m Trial 4 finished with value: 0.004252717614673269 and parameters: {'lam': 0.0023669480390311826, 'learning_rate': 0.01450002609306495, 'num_epoch': 10000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006596512 valid loss= 0.006282179\n",
      "train reg_fs: 0.0019978287164121866\n",
      "In trial:---------------------\n",
      "validation mse: 0.004252717614673269\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018378820 valid loss= 0.010700858\n",
      "train reg_fs: 0.003738424275070429\n",
      "Epoch: 1000 train loss=0.009357732 valid loss= 0.010640025\n",
      "train reg_fs: 0.0036262597423046827\n",
      "Epoch: 1500 train loss=0.013079351 valid loss= 0.008754339\n",
      "train reg_fs: 0.0034440227318555117\n",
      "Epoch: 2000 train loss=0.007951460 valid loss= 0.007292965\n",
      "train reg_fs: 0.0032682018354535103\n",
      "Epoch: 2500 train loss=0.004485925 valid loss= 0.007058794\n",
      "train reg_fs: 0.003123880596831441\n",
      "Epoch: 3000 train loss=0.008699980 valid loss= 0.006939309\n",
      "train reg_fs: 0.003021953394636512\n",
      "Epoch: 3500 train loss=0.008847468 valid loss= 0.007215286\n",
      "train reg_fs: 0.002942192368209362\n",
      "Epoch: 4000 train loss=0.004839740 valid loss= 0.006686901\n",
      "train reg_fs: 0.0028763432055711746\n",
      "Epoch: 4500 train loss=0.006617716 valid loss= 0.006894165\n",
      "train reg_fs: 0.0028237970545887947\n",
      "Epoch: 5000 train loss=0.011209169 valid loss= 0.006973919\n",
      "train reg_fs: 0.0027815119829028845\n",
      "Epoch: 5500 train loss=0.007185190 valid loss= 0.007347964\n",
      "train reg_fs: 0.0027437428943812847\n",
      "Epoch: 6000 train loss=0.007406527 valid loss= 0.006950850\n",
      "train reg_fs: 0.002711762208491564\n",
      "Epoch: 6500 train loss=0.006062953 valid loss= 0.006964787\n",
      "train reg_fs: 0.002684800187125802\n",
      "Epoch: 7000 train loss=0.004223882 valid loss= 0.006566205\n",
      "train reg_fs: 0.002661303151398897\n",
      "Epoch: 7500 train loss=0.005228318 valid loss= 0.006979793\n",
      "train reg_fs: 0.002641521394252777\n",
      "Epoch: 8000 train loss=0.015723243 valid loss= 0.006933942\n",
      "train reg_fs: 0.002624554093927145\n",
      "Epoch: 8500 train loss=0.004123723 valid loss= 0.007135881\n",
      "train reg_fs: 0.0026095667853951454\n",
      "Epoch: 9000 train loss=0.007573831 valid loss= 0.006862744\n",
      "train reg_fs: 0.0025969098787754774\n",
      "Epoch: 9500 train loss=0.006102618 valid loss= 0.006789409\n",
      "train reg_fs: 0.0025853209663182497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:25:24,235]\u001b[0m Trial 5 finished with value: 0.004094986132649523 and parameters: {'lam': 0.004339033590638614, 'learning_rate': 0.08737207372493697, 'num_epoch': 10000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007230869 valid loss= 0.006785532\n",
      "train reg_fs: 0.0025753562804311514\n",
      "In trial:---------------------\n",
      "validation mse: 0.004094986132649523\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.021309737 valid loss= 0.014178891\n",
      "train reg_fs: 0.007376149296760559\n",
      "Epoch: 1000 train loss=0.020777324 valid loss= 0.014100261\n",
      "train reg_fs: 0.007440496236085892\n",
      "Epoch: 1500 train loss=0.020182770 valid loss= 0.013333611\n",
      "train reg_fs: 0.007499519269913435\n",
      "Epoch: 2000 train loss=0.020171257 valid loss= 0.013150550\n",
      "train reg_fs: 0.007547160144895315\n",
      "Epoch: 2500 train loss=0.013978522 valid loss= 0.013085840\n",
      "train reg_fs: 0.007575965020805597\n",
      "Epoch: 3000 train loss=0.016699493 valid loss= 0.012766205\n",
      "train reg_fs: 0.007591468282043934\n",
      "Epoch: 3500 train loss=0.015936606 valid loss= 0.012515575\n",
      "train reg_fs: 0.007595913950353861\n",
      "Epoch: 4000 train loss=0.017040806 valid loss= 0.012539815\n",
      "train reg_fs: 0.00759788928553462\n",
      "Epoch: 4500 train loss=0.018361259 valid loss= 0.013109365\n",
      "train reg_fs: 0.0075858402997255325\n",
      "Epoch: 5000 train loss=0.017918376 valid loss= 0.012950219\n",
      "train reg_fs: 0.00756504712626338\n",
      "Epoch: 5500 train loss=0.013548309 valid loss= 0.012468126\n",
      "train reg_fs: 0.007537987548857927\n",
      "Epoch: 6000 train loss=0.013159458 valid loss= 0.011851242\n",
      "train reg_fs: 0.007499680854380131\n",
      "Epoch: 6500 train loss=0.020876523 valid loss= 0.012214733\n",
      "train reg_fs: 0.007456223014742136\n",
      "Epoch: 7000 train loss=0.009668611 valid loss= 0.011348538\n",
      "train reg_fs: 0.007401179987937212\n",
      "Epoch: 7500 train loss=0.011255093 valid loss= 0.011811662\n",
      "train reg_fs: 0.007342181168496609\n",
      "Epoch: 8000 train loss=0.020193884 valid loss= 0.011441773\n",
      "train reg_fs: 0.0072813560254871845\n",
      "Epoch: 8500 train loss=0.011619024 valid loss= 0.011210575\n",
      "train reg_fs: 0.007216825149953365\n",
      "Epoch: 9000 train loss=0.013129624 valid loss= 0.011058034\n",
      "train reg_fs: 0.007150228600949049\n",
      "Epoch: 9500 train loss=0.012496225 valid loss= 0.010739533\n",
      "train reg_fs: 0.00708438316360116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:26:31,894]\u001b[0m Trial 6 finished with value: 0.0037036138933585973 and parameters: {'lam': 0.008682087518008606, 'learning_rate': 0.019770993223804628, 'num_epoch': 10000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.010184160 valid loss= 0.010792912\n",
      "train reg_fs: 0.007020289544016123\n",
      "In trial:---------------------\n",
      "validation mse: 0.0037036138933585973\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011083837 valid loss= 0.009001713\n",
      "train reg_fs: 0.002301086438819766\n",
      "Epoch: 1000 train loss=0.007652648 valid loss= 0.008427436\n",
      "train reg_fs: 0.0023106758017092943\n",
      "Epoch: 1500 train loss=0.017195091 valid loss= 0.007905794\n",
      "train reg_fs: 0.002274842467159033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:26:48,322]\u001b[0m Trial 7 finished with value: 0.004588537737262545 and parameters: {'lam': 0.00267618043134795, 'learning_rate': 0.044528615007668484, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.004543095 valid loss= 0.006851582\n",
      "train reg_fs: 0.002230241196230054\n",
      "In trial:---------------------\n",
      "validation mse: 0.004588537737262545\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014097854 valid loss= 0.009919522\n",
      "train reg_fs: 0.004085814114660025\n",
      "Epoch: 1000 train loss=0.009198876 valid loss= 0.008363171\n",
      "train reg_fs: 0.004091187845915556\n",
      "Epoch: 1500 train loss=0.012117873 valid loss= 0.008152429\n",
      "train reg_fs: 0.004019593819975853\n",
      "Epoch: 2000 train loss=0.012158480 valid loss= 0.006859762\n",
      "train reg_fs: 0.00391038041561842\n",
      "Epoch: 2500 train loss=0.010705290 valid loss= 0.006560984\n",
      "train reg_fs: 0.003797783050686121\n",
      "Epoch: 3000 train loss=0.006687652 valid loss= 0.006293603\n",
      "train reg_fs: 0.003717102576047182\n",
      "Epoch: 3500 train loss=0.007892331 valid loss= 0.006780007\n",
      "train reg_fs: 0.0036680251359939575\n",
      "Epoch: 4000 train loss=0.006611255 valid loss= 0.006649890\n",
      "train reg_fs: 0.003630788065493107\n",
      "Epoch: 4500 train loss=0.009481823 valid loss= 0.006406636\n",
      "train reg_fs: 0.0035997589584439993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:27:23,225]\u001b[0m Trial 8 finished with value: 0.0028987879553517863 and parameters: {'lam': 0.004766197941502131, 'learning_rate': 0.041662382664848056, 'num_epoch': 5000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005242334 valid loss= 0.006524335\n",
      "train reg_fs: 0.0035725217312574387\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028987879553517863\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013255943 valid loss= 0.008202463\n",
      "train reg_fs: 0.0008732426795177162\n",
      "Epoch: 1000 train loss=0.007151373 valid loss= 0.008501876\n",
      "train reg_fs: 0.0008882137481123209\n",
      "Epoch: 1500 train loss=0.009346577 valid loss= 0.007519900\n",
      "train reg_fs: 0.0008946108282543719\n",
      "Epoch: 2000 train loss=0.008406430 valid loss= 0.007938777\n",
      "train reg_fs: 0.0008938300888985395\n",
      "Epoch: 2500 train loss=0.009064333 valid loss= 0.006385395\n",
      "train reg_fs: 0.000887042551767081\n",
      "Epoch: 3000 train loss=0.014901621 valid loss= 0.005543323\n",
      "train reg_fs: 0.0008764942176640034\n",
      "Epoch: 3500 train loss=0.008434590 valid loss= 0.005323824\n",
      "train reg_fs: 0.0008620475418865681\n",
      "Epoch: 4000 train loss=0.003968457 valid loss= 0.004615495\n",
      "train reg_fs: 0.0008426580461673439\n",
      "Epoch: 4500 train loss=0.003784739 valid loss= 0.004036378\n",
      "train reg_fs: 0.0008221124298870564\n",
      "Epoch: 5000 train loss=0.006013502 valid loss= 0.003916361\n",
      "train reg_fs: 0.0008047211449593306\n",
      "Epoch: 5500 train loss=0.008089941 valid loss= 0.003973961\n",
      "train reg_fs: 0.0007920775096863508\n",
      "Epoch: 6000 train loss=0.002422861 valid loss= 0.003473707\n",
      "train reg_fs: 0.0007822753395885229\n",
      "Epoch: 6500 train loss=0.002065332 valid loss= 0.003766846\n",
      "train reg_fs: 0.0007744246395304799\n",
      "Epoch: 7000 train loss=0.001745005 valid loss= 0.003787798\n",
      "train reg_fs: 0.0007686965400353074\n",
      "Epoch: 7500 train loss=0.003748755 valid loss= 0.003546202\n",
      "train reg_fs: 0.0007635759538970888\n",
      "Epoch: 8000 train loss=0.005503962 valid loss= 0.003479331\n",
      "train reg_fs: 0.0007592178299091756\n",
      "Epoch: 8500 train loss=0.002031895 valid loss= 0.003319665\n",
      "train reg_fs: 0.0007559868972748518\n",
      "Epoch: 9000 train loss=0.002016675 valid loss= 0.003223195\n",
      "train reg_fs: 0.0007528931018896401\n",
      "Epoch: 9500 train loss=0.002092554 valid loss= 0.003408985\n",
      "train reg_fs: 0.000750007398892194\n",
      "Epoch: 10000 train loss=0.001645496 valid loss= 0.003010245\n",
      "train reg_fs: 0.0007477620965801179\n",
      "Epoch: 10500 train loss=0.003187897 valid loss= 0.003000953\n",
      "train reg_fs: 0.0007455276208929718\n",
      "Epoch: 11000 train loss=0.004857399 valid loss= 0.003558584\n",
      "train reg_fs: 0.0007443787180818617\n",
      "Epoch: 11500 train loss=0.001512779 valid loss= 0.003107949\n",
      "train reg_fs: 0.0007427299860864878\n",
      "Epoch: 12000 train loss=0.001489418 valid loss= 0.002946923\n",
      "train reg_fs: 0.000740989635232836\n",
      "Epoch: 12500 train loss=0.003452190 valid loss= 0.003105926\n",
      "train reg_fs: 0.0007392268162220716\n",
      "Epoch: 13000 train loss=0.003076522 valid loss= 0.002698001\n",
      "train reg_fs: 0.0007378517184406519\n",
      "Epoch: 13500 train loss=0.008837072 valid loss= 0.003087756\n",
      "train reg_fs: 0.0007364342454820871\n",
      "Epoch: 14000 train loss=0.001617919 valid loss= 0.002779766\n",
      "train reg_fs: 0.0007348884246312082\n",
      "Epoch: 14500 train loss=0.001871863 valid loss= 0.002930545\n",
      "train reg_fs: 0.000733511580619961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:29:07,984]\u001b[0m Trial 9 finished with value: 0.0024926197304423275 and parameters: {'lam': 0.0010070899241633065, 'learning_rate': 0.04577327699912481, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001191756 valid loss= 0.003209797\n",
      "train reg_fs: 0.0007321091252379119\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024926197304423275\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005576918 valid loss= 0.005532420\n",
      "train reg_fs: 0.0013146544806659222\n",
      "Epoch: 1000 train loss=0.003199724 valid loss= 0.004316331\n",
      "train reg_fs: 0.0012365110451355577\n",
      "Epoch: 1500 train loss=0.009360437 valid loss= 0.003822366\n",
      "train reg_fs: 0.0012047105701640248\n",
      "Epoch: 2000 train loss=0.004773162 valid loss= 0.003975778\n",
      "train reg_fs: 0.0011777544859796762\n",
      "Epoch: 2500 train loss=0.002091066 valid loss= 0.003804302\n",
      "train reg_fs: 0.0011592262890189886\n",
      "Epoch: 3000 train loss=0.001747643 valid loss= 0.003834059\n",
      "train reg_fs: 0.001147650764323771\n",
      "Epoch: 3500 train loss=0.002018709 valid loss= 0.003961815\n",
      "train reg_fs: 0.001140520558692515\n",
      "Epoch: 4000 train loss=0.003948289 valid loss= 0.003883759\n",
      "train reg_fs: 0.0011345607927069068\n",
      "Epoch: 4500 train loss=0.001564947 valid loss= 0.003137233\n",
      "train reg_fs: 0.0011299930047243834\n",
      "Epoch: 5000 train loss=0.002299350 valid loss= 0.003235020\n",
      "train reg_fs: 0.0011267773807048798\n",
      "Epoch: 5500 train loss=0.002558338 valid loss= 0.003139817\n",
      "train reg_fs: 0.001123518799431622\n",
      "Epoch: 6000 train loss=0.004383314 valid loss= 0.003116594\n",
      "train reg_fs: 0.0011214311234652996\n",
      "Epoch: 6500 train loss=0.001472643 valid loss= 0.003361620\n",
      "train reg_fs: 0.0011198101565241814\n",
      "Epoch: 7000 train loss=0.006696441 valid loss= 0.002992679\n",
      "train reg_fs: 0.0011180309811607003\n",
      "Epoch: 7500 train loss=0.002647981 valid loss= 0.003228202\n",
      "train reg_fs: 0.0011160529684275389\n",
      "Epoch: 8000 train loss=0.002180916 valid loss= 0.003795379\n",
      "train reg_fs: 0.0011148870689794421\n",
      "Epoch: 8500 train loss=0.002335424 valid loss= 0.003011922\n",
      "train reg_fs: 0.0011134452652186155\n",
      "Epoch: 9000 train loss=0.002194917 valid loss= 0.003303585\n",
      "train reg_fs: 0.0011123658623546362\n",
      "Epoch: 9500 train loss=0.004216483 valid loss= 0.003498044\n",
      "train reg_fs: 0.0011114493245258927\n",
      "Epoch: 10000 train loss=0.002597204 valid loss= 0.003165131\n",
      "train reg_fs: 0.0011103342985734344\n",
      "Epoch: 10500 train loss=0.001800861 valid loss= 0.003194596\n",
      "train reg_fs: 0.0011096791131421924\n",
      "Epoch: 11000 train loss=0.001322914 valid loss= 0.002965023\n",
      "train reg_fs: 0.001109572360292077\n",
      "Epoch: 11500 train loss=0.002525559 valid loss= 0.003034525\n",
      "train reg_fs: 0.0011088467435911298\n",
      "Epoch: 12000 train loss=0.001736236 valid loss= 0.003071553\n",
      "train reg_fs: 0.001108383759856224\n",
      "Epoch: 12500 train loss=0.001778956 valid loss= 0.003019435\n",
      "train reg_fs: 0.0011079907417297363\n",
      "Epoch: 13000 train loss=0.002255062 valid loss= 0.002857570\n",
      "train reg_fs: 0.001107484451495111\n",
      "Epoch: 13500 train loss=0.002706020 valid loss= 0.003204225\n",
      "train reg_fs: 0.0011062894482165575\n",
      "Epoch: 14000 train loss=0.002747078 valid loss= 0.003473938\n",
      "train reg_fs: 0.001105453004129231\n",
      "Epoch: 14500 train loss=0.001727948 valid loss= 0.003015719\n",
      "train reg_fs: 0.0011048534652218223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:30:52,915]\u001b[0m Trial 10 finished with value: 0.002074169586097092 and parameters: {'lam': 0.0015784129728877358, 'learning_rate': 0.19030788914717484, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004861198 valid loss= 0.003124453\n",
      "train reg_fs: 0.0011042742989957333\n",
      "In trial:---------------------\n",
      "validation mse: 0.002074169586097092\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.004941588 valid loss= 0.006374695\n",
      "train reg_fs: 0.001081109861843288\n",
      "Epoch: 1000 train loss=0.010940592 valid loss= 0.004899424\n",
      "train reg_fs: 0.0009956660214811563\n",
      "Epoch: 1500 train loss=0.001903020 valid loss= 0.003610517\n",
      "train reg_fs: 0.0009817329701036215\n",
      "Epoch: 2000 train loss=0.007320695 valid loss= 0.003710801\n",
      "train reg_fs: 0.0009840986458584666\n",
      "Epoch: 2500 train loss=0.005103612 valid loss= 0.004228543\n",
      "train reg_fs: 0.000973123125731945\n",
      "Epoch: 3000 train loss=0.007033626 valid loss= 0.004114025\n",
      "train reg_fs: 0.0009395980159752071\n",
      "Epoch: 3500 train loss=0.002118075 valid loss= 0.004403666\n",
      "train reg_fs: 0.0008998442790471017\n",
      "Epoch: 4000 train loss=0.003755659 valid loss= 0.003624070\n",
      "train reg_fs: 0.0008719840552657843\n",
      "Epoch: 4500 train loss=0.001486405 valid loss= 0.003537706\n",
      "train reg_fs: 0.0008528385660611093\n",
      "Epoch: 5000 train loss=0.004345017 valid loss= 0.003482207\n",
      "train reg_fs: 0.0008388828136958182\n",
      "Epoch: 5500 train loss=0.003267953 valid loss= 0.002994064\n",
      "train reg_fs: 0.0008277761517092586\n",
      "Epoch: 6000 train loss=0.002174918 valid loss= 0.003156862\n",
      "train reg_fs: 0.000819992390461266\n",
      "Epoch: 6500 train loss=0.001106226 valid loss= 0.003606049\n",
      "train reg_fs: 0.0008135703974403441\n",
      "Epoch: 7000 train loss=0.005147437 valid loss= 0.002867187\n",
      "train reg_fs: 0.0008087593014352024\n",
      "Epoch: 7500 train loss=0.003331502 valid loss= 0.003150738\n",
      "train reg_fs: 0.0008046343573369086\n",
      "Epoch: 8000 train loss=0.001393922 valid loss= 0.003018116\n",
      "train reg_fs: 0.0008014538907445967\n",
      "Epoch: 8500 train loss=0.005256637 valid loss= 0.003221634\n",
      "train reg_fs: 0.0007984982803463936\n",
      "Epoch: 9000 train loss=0.001830189 valid loss= 0.002775170\n",
      "train reg_fs: 0.0007958420319482684\n",
      "Epoch: 9500 train loss=0.001525850 valid loss= 0.002975628\n",
      "train reg_fs: 0.0007937615737318993\n",
      "Epoch: 10000 train loss=0.000980474 valid loss= 0.002987647\n",
      "train reg_fs: 0.0007920167408883572\n",
      "Epoch: 10500 train loss=0.002276910 valid loss= 0.002919662\n",
      "train reg_fs: 0.0007904343074187636\n",
      "Epoch: 11000 train loss=0.001958920 valid loss= 0.002919986\n",
      "train reg_fs: 0.0007890553679317236\n",
      "Epoch: 11500 train loss=0.001583194 valid loss= 0.002920581\n",
      "train reg_fs: 0.0007878186297602952\n",
      "Epoch: 12000 train loss=0.003035341 valid loss= 0.003075900\n",
      "train reg_fs: 0.0007867585518397391\n",
      "Epoch: 12500 train loss=0.002246727 valid loss= 0.002875742\n",
      "train reg_fs: 0.0007858375320211053\n",
      "Epoch: 13000 train loss=0.001524897 valid loss= 0.003117321\n",
      "train reg_fs: 0.0007850545807741582\n",
      "Epoch: 13500 train loss=0.001043366 valid loss= 0.003361291\n",
      "train reg_fs: 0.0007843414787203074\n",
      "Epoch: 14000 train loss=0.003782819 valid loss= 0.002932399\n",
      "train reg_fs: 0.0007836483418941498\n",
      "Epoch: 14500 train loss=0.004878647 valid loss= 0.003129596\n",
      "train reg_fs: 0.0007830553804524243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:32:46,156]\u001b[0m Trial 11 finished with value: 0.0022951291477237307 and parameters: {'lam': 0.0012959987028041832, 'learning_rate': 0.1897563308358445, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005120096 valid loss= 0.003058132\n",
      "train reg_fs: 0.0007825408247299492\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022951291477237307\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009546218 valid loss= 0.007545885\n",
      "train reg_fs: 0.001477036508731544\n",
      "Epoch: 1000 train loss=0.002977921 valid loss= 0.008121718\n",
      "train reg_fs: 0.0014321018243208528\n",
      "Epoch: 1500 train loss=0.008728495 valid loss= 0.005245520\n",
      "train reg_fs: 0.0013709957711398602\n",
      "Epoch: 2000 train loss=0.013623122 valid loss= 0.004531220\n",
      "train reg_fs: 0.0013186249416321516\n",
      "Epoch: 2500 train loss=0.009311271 valid loss= 0.004203792\n",
      "train reg_fs: 0.0012965118512511253\n",
      "Epoch: 3000 train loss=0.003625361 valid loss= 0.004076757\n",
      "train reg_fs: 0.0012710427399724722\n",
      "Epoch: 3500 train loss=0.004473628 valid loss= 0.004248850\n",
      "train reg_fs: 0.001246376894414425\n",
      "Epoch: 4000 train loss=0.002035970 valid loss= 0.004114811\n",
      "train reg_fs: 0.0012241819640621543\n",
      "Epoch: 4500 train loss=0.010276875 valid loss= 0.003932409\n",
      "train reg_fs: 0.0012071311939507723\n",
      "Epoch: 5000 train loss=0.004963292 valid loss= 0.003572665\n",
      "train reg_fs: 0.001192256691865623\n",
      "Epoch: 5500 train loss=0.002619882 valid loss= 0.003323079\n",
      "train reg_fs: 0.0011743430513888597\n",
      "Epoch: 6000 train loss=0.002587920 valid loss= 0.003710847\n",
      "train reg_fs: 0.0011573289521038532\n",
      "Epoch: 6500 train loss=0.001601050 valid loss= 0.003574715\n",
      "train reg_fs: 0.001137643470428884\n",
      "Epoch: 7000 train loss=0.002111458 valid loss= 0.003486538\n",
      "train reg_fs: 0.0011151586659252644\n",
      "Epoch: 7500 train loss=0.004725073 valid loss= 0.003683861\n",
      "train reg_fs: 0.001101944362744689\n",
      "Epoch: 8000 train loss=0.003912429 valid loss= 0.003749674\n",
      "train reg_fs: 0.0010893677826970816\n",
      "Epoch: 8500 train loss=0.002373600 valid loss= 0.003722098\n",
      "train reg_fs: 0.0010776907438412309\n",
      "Epoch: 9000 train loss=0.002152479 valid loss= 0.003786438\n",
      "train reg_fs: 0.0010675269877538085\n",
      "Epoch: 9500 train loss=0.002551904 valid loss= 0.003384605\n",
      "train reg_fs: 0.0010604774579405785\n",
      "Epoch: 10000 train loss=0.001348065 valid loss= 0.003337803\n",
      "train reg_fs: 0.001055206055752933\n",
      "Epoch: 10500 train loss=0.001636188 valid loss= 0.003459438\n",
      "train reg_fs: 0.0010509444400668144\n",
      "Epoch: 11000 train loss=0.001347544 valid loss= 0.003580886\n",
      "train reg_fs: 0.0010469806147739291\n",
      "Epoch: 11500 train loss=0.005127162 valid loss= 0.003100204\n",
      "train reg_fs: 0.0010438234312459826\n",
      "Epoch: 12000 train loss=0.009218439 valid loss= 0.003308346\n",
      "train reg_fs: 0.0010412127012386918\n",
      "Epoch: 12500 train loss=0.003256150 valid loss= 0.003023187\n",
      "train reg_fs: 0.0010387498186901212\n",
      "Epoch: 13000 train loss=0.002799399 valid loss= 0.003583038\n",
      "train reg_fs: 0.0010365024209022522\n",
      "Epoch: 13500 train loss=0.002560407 valid loss= 0.003558000\n",
      "train reg_fs: 0.0010344648035243154\n",
      "Epoch: 14000 train loss=0.003085913 valid loss= 0.003189984\n",
      "train reg_fs: 0.0010329248616471887\n",
      "Epoch: 14500 train loss=0.003046272 valid loss= 0.003127419\n",
      "train reg_fs: 0.0010315520921722054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:34:41,503]\u001b[0m Trial 12 finished with value: 0.0023802806321535264 and parameters: {'lam': 0.0016894996531690242, 'learning_rate': 0.11633008294362888, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001952269 valid loss= 0.003387487\n",
      "train reg_fs: 0.001030190964229405\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023802806321535264\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010332836 valid loss= 0.007523694\n",
      "train reg_fs: 0.0016473338473588228\n",
      "Epoch: 1000 train loss=0.004502397 valid loss= 0.004461618\n",
      "train reg_fs: 0.0015328872250393033\n",
      "Epoch: 1500 train loss=0.013547260 valid loss= 0.004037859\n",
      "train reg_fs: 0.0014508772874251008\n",
      "Epoch: 2000 train loss=0.006415908 valid loss= 0.004296919\n",
      "train reg_fs: 0.0013926218962296844\n",
      "Epoch: 2500 train loss=0.005750671 valid loss= 0.004231054\n",
      "train reg_fs: 0.0013496280880644917\n",
      "Epoch: 3000 train loss=0.003090461 valid loss= 0.003518715\n",
      "train reg_fs: 0.0013163624098524451\n",
      "Epoch: 3500 train loss=0.005906074 valid loss= 0.003814430\n",
      "train reg_fs: 0.001290242071263492\n",
      "Epoch: 4000 train loss=0.002249575 valid loss= 0.003347493\n",
      "train reg_fs: 0.001271712826564908\n",
      "Epoch: 4500 train loss=0.002528336 valid loss= 0.003786617\n",
      "train reg_fs: 0.0012556978035718203\n",
      "Epoch: 5000 train loss=0.005462381 valid loss= 0.003718795\n",
      "train reg_fs: 0.001244192011654377\n",
      "Epoch: 5500 train loss=0.001780254 valid loss= 0.003547321\n",
      "train reg_fs: 0.0012326875003054738\n",
      "Epoch: 6000 train loss=0.001878205 valid loss= 0.003602918\n",
      "train reg_fs: 0.0012232412118464708\n",
      "Epoch: 6500 train loss=0.003902626 valid loss= 0.003633562\n",
      "train reg_fs: 0.00121488596778363\n",
      "Epoch: 7000 train loss=0.001433619 valid loss= 0.003569325\n",
      "train reg_fs: 0.0012072230456396937\n",
      "Epoch: 7500 train loss=0.003101769 valid loss= 0.003400460\n",
      "train reg_fs: 0.0012006765464320779\n",
      "Epoch: 8000 train loss=0.002230864 valid loss= 0.003931379\n",
      "train reg_fs: 0.0011949170148000121\n",
      "Epoch: 8500 train loss=0.001414805 valid loss= 0.003694734\n",
      "train reg_fs: 0.0011900787940248847\n",
      "Epoch: 9000 train loss=0.002007939 valid loss= 0.003505343\n",
      "train reg_fs: 0.0011856730561703444\n",
      "Epoch: 9500 train loss=0.001974166 valid loss= 0.003473668\n",
      "train reg_fs: 0.0011823952663689852\n",
      "Epoch: 10000 train loss=0.003721283 valid loss= 0.003560898\n",
      "train reg_fs: 0.0011793943122029305\n",
      "Epoch: 10500 train loss=0.003882924 valid loss= 0.003484283\n",
      "train reg_fs: 0.001176807563751936\n",
      "Epoch: 11000 train loss=0.001982715 valid loss= 0.003588681\n",
      "train reg_fs: 0.0011745127849280834\n",
      "Epoch: 11500 train loss=0.002211098 valid loss= 0.003211347\n",
      "train reg_fs: 0.0011724424548447132\n",
      "Epoch: 12000 train loss=0.002226155 valid loss= 0.003520966\n",
      "train reg_fs: 0.0011705897049978375\n",
      "Epoch: 12500 train loss=0.004821759 valid loss= 0.003512153\n",
      "train reg_fs: 0.0011689314851537347\n",
      "Epoch: 13000 train loss=0.002543693 valid loss= 0.003489446\n",
      "train reg_fs: 0.0011674497509375215\n",
      "Epoch: 13500 train loss=0.002631180 valid loss= 0.003330784\n",
      "train reg_fs: 0.0011660867603495717\n",
      "Epoch: 14000 train loss=0.002123912 valid loss= 0.003459431\n",
      "train reg_fs: 0.001164921442978084\n",
      "Epoch: 14500 train loss=0.003804613 valid loss= 0.003428052\n",
      "train reg_fs: 0.001163798850029707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:36:35,712]\u001b[0m Trial 13 finished with value: 0.002413069690215932 and parameters: {'lam': 0.001919502354009068, 'learning_rate': 0.13550162736147767, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002765048 valid loss= 0.003548427\n",
      "train reg_fs: 0.001162726548500359\n",
      "In trial:---------------------\n",
      "validation mse: 0.002413069690215932\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010412834 valid loss= 0.008723092\n",
      "train reg_fs: 0.00451783649623394\n",
      "Epoch: 1000 train loss=0.007132572 valid loss= 0.006827449\n",
      "train reg_fs: 0.004040224943310022\n",
      "Epoch: 1500 train loss=0.007966442 valid loss= 0.006470822\n",
      "train reg_fs: 0.0038299462758004665\n",
      "Epoch: 2000 train loss=0.007260585 valid loss= 0.005531370\n",
      "train reg_fs: 0.003647358389571309\n",
      "Epoch: 2500 train loss=0.011576775 valid loss= 0.005175321\n",
      "train reg_fs: 0.0034835690166801214\n",
      "Epoch: 3000 train loss=0.005028879 valid loss= 0.005109350\n",
      "train reg_fs: 0.00335579551756382\n",
      "Epoch: 3500 train loss=0.008768670 valid loss= 0.004946684\n",
      "train reg_fs: 0.0032534105703234673\n",
      "Epoch: 4000 train loss=0.004902858 valid loss= 0.004982436\n",
      "train reg_fs: 0.003166417358443141\n",
      "Epoch: 4500 train loss=0.006599727 valid loss= 0.005303815\n",
      "train reg_fs: 0.003098488552495837\n",
      "Epoch: 5000 train loss=0.012182931 valid loss= 0.005054654\n",
      "train reg_fs: 0.003069605678319931\n",
      "Epoch: 5500 train loss=0.005573428 valid loss= 0.004899974\n",
      "train reg_fs: 0.00303501239977777\n",
      "Epoch: 6000 train loss=0.007645150 valid loss= 0.004992408\n",
      "train reg_fs: 0.003013146808370948\n",
      "Epoch: 6500 train loss=0.004448639 valid loss= 0.005216950\n",
      "train reg_fs: 0.002995707094669342\n",
      "Epoch: 7000 train loss=0.005792052 valid loss= 0.004778828\n",
      "train reg_fs: 0.002978600561618805\n",
      "Epoch: 7500 train loss=0.005393203 valid loss= 0.005215714\n",
      "train reg_fs: 0.0029677762649953365\n",
      "Epoch: 8000 train loss=0.005584187 valid loss= 0.004735522\n",
      "train reg_fs: 0.0029564520809799433\n",
      "Epoch: 8500 train loss=0.009705757 valid loss= 0.005192384\n",
      "train reg_fs: 0.0029493961483240128\n",
      "Epoch: 9000 train loss=0.005907768 valid loss= 0.004743501\n",
      "train reg_fs: 0.0029436240438371897\n",
      "Epoch: 9500 train loss=0.008101072 valid loss= 0.004828270\n",
      "train reg_fs: 0.0029348302632570267\n",
      "Epoch: 10000 train loss=0.005485298 valid loss= 0.005036902\n",
      "train reg_fs: 0.002930072136223316\n",
      "Epoch: 10500 train loss=0.004663819 valid loss= 0.005131914\n",
      "train reg_fs: 0.002924900036305189\n",
      "Epoch: 11000 train loss=0.005350642 valid loss= 0.005101816\n",
      "train reg_fs: 0.002920775907114148\n",
      "Epoch: 11500 train loss=0.011282594 valid loss= 0.004957623\n",
      "train reg_fs: 0.0029173605144023895\n",
      "Epoch: 12000 train loss=0.005639111 valid loss= 0.005420341\n",
      "train reg_fs: 0.002913492964580655\n",
      "Epoch: 12500 train loss=0.005417253 valid loss= 0.004761798\n",
      "train reg_fs: 0.0029111525509506464\n",
      "Epoch: 13000 train loss=0.009450803 valid loss= 0.005206399\n",
      "train reg_fs: 0.0029086486902087927\n",
      "Epoch: 13500 train loss=0.004729752 valid loss= 0.004883237\n",
      "train reg_fs: 0.002905908739194274\n",
      "Epoch: 14000 train loss=0.005238009 valid loss= 0.005172738\n",
      "train reg_fs: 0.002903642365708947\n",
      "Epoch: 14500 train loss=0.005470230 valid loss= 0.005281553\n",
      "train reg_fs: 0.002901697065681219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:38:22,255]\u001b[0m Trial 14 finished with value: 0.002296355347707305 and parameters: {'lam': 0.0054117921680726395, 'learning_rate': 0.19493924325034886, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005795862 valid loss= 0.005517680\n",
      "train reg_fs: 0.0028998826164752245\n",
      "In trial:---------------------\n",
      "validation mse: 0.002296355347707305\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016752174 valid loss= 0.010761242\n",
      "train reg_fs: 0.005523844622075558\n",
      "Epoch: 1000 train loss=0.011779992 valid loss= 0.008985055\n",
      "train reg_fs: 0.0053619761019945145\n",
      "Epoch: 1500 train loss=0.008421335 valid loss= 0.008177083\n",
      "train reg_fs: 0.005031258333474398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:38:37,925]\u001b[0m Trial 15 finished with value: 0.0031919081795058024 and parameters: {'lam': 0.0063657810272257165, 'learning_rate': 0.0932285057589025, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.011655265 valid loss= 0.008054218\n",
      "train reg_fs: 0.0048631587997078896\n",
      "In trial:---------------------\n",
      "validation mse: 0.0031919081795058024\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012747709 valid loss= 0.008705600\n",
      "train reg_fs: 0.002595963655039668\n",
      "Epoch: 1000 train loss=0.010566334 valid loss= 0.008482608\n",
      "train reg_fs: 0.0026012312155216932\n",
      "Epoch: 1500 train loss=0.009987625 valid loss= 0.007856146\n",
      "train reg_fs: 0.002566172741353512\n",
      "Epoch: 2000 train loss=0.006496692 valid loss= 0.007427849\n",
      "train reg_fs: 0.0025183078832924366\n",
      "Epoch: 2500 train loss=0.007401329 valid loss= 0.006601307\n",
      "train reg_fs: 0.002481306903064251\n",
      "Epoch: 3000 train loss=0.008031512 valid loss= 0.006146440\n",
      "train reg_fs: 0.0024539921432733536\n",
      "Epoch: 3500 train loss=0.003526096 valid loss= 0.005780276\n",
      "train reg_fs: 0.0024233825970441103\n",
      "Epoch: 4000 train loss=0.004765121 valid loss= 0.005454064\n",
      "train reg_fs: 0.0023866049014031887\n",
      "Epoch: 4500 train loss=0.006540990 valid loss= 0.005024284\n",
      "train reg_fs: 0.002355980221182108\n",
      "Epoch: 5000 train loss=0.007359479 valid loss= 0.004921784\n",
      "train reg_fs: 0.0023291094694286585\n",
      "Epoch: 5500 train loss=0.005807587 valid loss= 0.005164506\n",
      "train reg_fs: 0.0022973371669650078\n",
      "Epoch: 6000 train loss=0.006939865 valid loss= 0.004857248\n",
      "train reg_fs: 0.0022714899387210608\n",
      "Epoch: 6500 train loss=0.005323118 valid loss= 0.004903851\n",
      "train reg_fs: 0.0022501519415527582\n",
      "Epoch: 7000 train loss=0.005365779 valid loss= 0.004567705\n",
      "train reg_fs: 0.002228961791843176\n",
      "Epoch: 7500 train loss=0.003340736 valid loss= 0.004704150\n",
      "train reg_fs: 0.00220966967754066\n",
      "Epoch: 8000 train loss=0.002986470 valid loss= 0.004914286\n",
      "train reg_fs: 0.002189313294366002\n",
      "Epoch: 8500 train loss=0.005431854 valid loss= 0.004774348\n",
      "train reg_fs: 0.002169939922168851\n",
      "Epoch: 9000 train loss=0.005969108 valid loss= 0.004740161\n",
      "train reg_fs: 0.0021552545949816704\n",
      "Epoch: 9500 train loss=0.003968717 valid loss= 0.004569536\n",
      "train reg_fs: 0.002142674056813121\n",
      "Epoch: 10000 train loss=0.002892045 valid loss= 0.004405360\n",
      "train reg_fs: 0.0021271442528814077\n",
      "Epoch: 10500 train loss=0.003156546 valid loss= 0.004633772\n",
      "train reg_fs: 0.0021161679178476334\n",
      "Epoch: 11000 train loss=0.003104004 valid loss= 0.004446861\n",
      "train reg_fs: 0.0021039366256445646\n",
      "Epoch: 11500 train loss=0.006846201 valid loss= 0.004491106\n",
      "train reg_fs: 0.0020913202315568924\n",
      "Epoch: 12000 train loss=0.002809349 valid loss= 0.004469877\n",
      "train reg_fs: 0.0020812624134123325\n",
      "Epoch: 12500 train loss=0.003170833 valid loss= 0.004794067\n",
      "train reg_fs: 0.002074344316497445\n",
      "Epoch: 13000 train loss=0.002440593 valid loss= 0.004517544\n",
      "train reg_fs: 0.0020611609797924757\n",
      "Epoch: 13500 train loss=0.007934148 valid loss= 0.004572682\n",
      "train reg_fs: 0.0020509895402938128\n",
      "Epoch: 14000 train loss=0.004042970 valid loss= 0.004184074\n",
      "train reg_fs: 0.0020411768928170204\n",
      "Epoch: 14500 train loss=0.005498881 valid loss= 0.003919240\n",
      "train reg_fs: 0.0020320850890129805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:40:27,784]\u001b[0m Trial 16 finished with value: 0.0022188574004205503 and parameters: {'lam': 0.00300940957228136, 'learning_rate': 0.07016455061423726, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004023930 valid loss= 0.004273156\n",
      "train reg_fs: 0.002025045920163393\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022188574004205503\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007892313 valid loss= 0.005827641\n",
      "train reg_fs: 0.0009113551350310445\n",
      "Epoch: 1000 train loss=0.012622997 valid loss= 0.003426445\n",
      "train reg_fs: 0.0008494026842527092\n",
      "Epoch: 1500 train loss=0.002804300 valid loss= 0.002799195\n",
      "train reg_fs: 0.0008258544257842004\n",
      "Epoch: 2000 train loss=0.003666538 valid loss= 0.003567406\n",
      "train reg_fs: 0.0008121322025544941\n",
      "Epoch: 2500 train loss=0.003871771 valid loss= 0.003317067\n",
      "train reg_fs: 0.0008004153496585786\n",
      "Epoch: 3000 train loss=0.001360551 valid loss= 0.002982992\n",
      "train reg_fs: 0.0007952965679578483\n",
      "Epoch: 3500 train loss=0.002860926 valid loss= 0.002546645\n",
      "train reg_fs: 0.0007916894392110407\n",
      "Epoch: 4000 train loss=0.002460250 valid loss= 0.002908207\n",
      "train reg_fs: 0.0007903462974354625\n",
      "Epoch: 4500 train loss=0.001615841 valid loss= 0.002950855\n",
      "train reg_fs: 0.0007891415152698755\n",
      "Epoch: 5000 train loss=0.010168883 valid loss= 0.002836276\n",
      "train reg_fs: 0.0007884854567237198\n",
      "Epoch: 5500 train loss=0.006378990 valid loss= 0.002548270\n",
      "train reg_fs: 0.00078750861575827\n",
      "Epoch: 6000 train loss=0.001836893 valid loss= 0.003113344\n",
      "train reg_fs: 0.0007868065731599927\n",
      "Epoch: 6500 train loss=0.001701065 valid loss= 0.002713582\n",
      "train reg_fs: 0.0007855473086237907\n",
      "Epoch: 7000 train loss=0.001744247 valid loss= 0.002795690\n",
      "train reg_fs: 0.0007844207575544715\n",
      "Epoch: 7500 train loss=0.003003244 valid loss= 0.002809651\n",
      "train reg_fs: 0.0007832342525944114\n",
      "Epoch: 8000 train loss=0.001467422 valid loss= 0.002707265\n",
      "train reg_fs: 0.0007818383164703846\n",
      "Epoch: 8500 train loss=0.002262546 valid loss= 0.002679013\n",
      "train reg_fs: 0.0007802053005434573\n",
      "Epoch: 9000 train loss=0.001703116 valid loss= 0.002808937\n",
      "train reg_fs: 0.0007785960333421826\n",
      "Epoch: 9500 train loss=0.001908847 valid loss= 0.002744836\n",
      "train reg_fs: 0.0007764840847812593\n",
      "Epoch: 10000 train loss=0.004708531 valid loss= 0.002569700\n",
      "train reg_fs: 0.0007750453078188002\n",
      "Epoch: 10500 train loss=0.001341584 valid loss= 0.003101240\n",
      "train reg_fs: 0.0007728677592240274\n",
      "Epoch: 11000 train loss=0.001549721 valid loss= 0.002821327\n",
      "train reg_fs: 0.000771217979490757\n",
      "Epoch: 11500 train loss=0.010416108 valid loss= 0.002636326\n",
      "train reg_fs: 0.0007695978856645525\n",
      "Epoch: 12000 train loss=0.002580703 valid loss= 0.002926594\n",
      "train reg_fs: 0.0007683114963583648\n",
      "Epoch: 12500 train loss=0.001101902 valid loss= 0.002793027\n",
      "train reg_fs: 0.0007667223108001053\n",
      "Epoch: 13000 train loss=0.001559900 valid loss= 0.002952729\n",
      "train reg_fs: 0.0007651156047359109\n",
      "Epoch: 13500 train loss=0.003164350 valid loss= 0.002934656\n",
      "train reg_fs: 0.0007635777001269162\n",
      "Epoch: 14000 train loss=0.001684407 valid loss= 0.002869062\n",
      "train reg_fs: 0.0007621404365636408\n",
      "Epoch: 14500 train loss=0.001523440 valid loss= 0.002912542\n",
      "train reg_fs: 0.0007604961283504963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:42:11,779]\u001b[0m Trial 17 finished with value: 0.0019574173873282428 and parameters: {'lam': 0.0010600568155233253, 'learning_rate': 0.13660532207933826, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003672963 valid loss= 0.002685210\n",
      "train reg_fs: 0.0007591308676637709\n",
      "In trial:---------------------\n",
      "validation mse: 0.0019574173873282428\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007881273 valid loss= 0.008417940\n",
      "train reg_fs: 0.0009099066955968738\n",
      "Epoch: 1000 train loss=0.005880639 valid loss= 0.005356520\n",
      "train reg_fs: 0.0008810619474388659\n",
      "Epoch: 1500 train loss=0.010058093 valid loss= 0.003289791\n",
      "train reg_fs: 0.000823174836114049\n",
      "Epoch: 2000 train loss=0.002303506 valid loss= 0.002944850\n",
      "train reg_fs: 0.0007968178833834827\n",
      "Epoch: 2500 train loss=0.001958915 valid loss= 0.003403335\n",
      "train reg_fs: 0.0007840513135306537\n",
      "Epoch: 3000 train loss=0.005711653 valid loss= 0.003071256\n",
      "train reg_fs: 0.0007773612160235643\n",
      "Epoch: 3500 train loss=0.001463680 valid loss= 0.003094494\n",
      "train reg_fs: 0.0007733030361123383\n",
      "Epoch: 4000 train loss=0.002962610 valid loss= 0.002947336\n",
      "train reg_fs: 0.0007704369490966201\n",
      "Epoch: 4500 train loss=0.001206211 valid loss= 0.002919983\n",
      "train reg_fs: 0.0007685121381655335\n",
      "Epoch: 5000 train loss=0.001387399 valid loss= 0.003401663\n",
      "train reg_fs: 0.0007668751059100032\n",
      "Epoch: 5500 train loss=0.003938770 valid loss= 0.002953967\n",
      "train reg_fs: 0.000765578995924443\n",
      "Epoch: 6000 train loss=0.002052372 valid loss= 0.002559760\n",
      "train reg_fs: 0.0007640945841558278\n",
      "Epoch: 6500 train loss=0.002307009 valid loss= 0.003066954\n",
      "train reg_fs: 0.0007629556930623949\n",
      "Epoch: 7000 train loss=0.002482608 valid loss= 0.003061239\n",
      "train reg_fs: 0.0007615289650857449\n",
      "Epoch: 7500 train loss=0.001092973 valid loss= 0.002864775\n",
      "train reg_fs: 0.0007601560791954398\n",
      "Epoch: 8000 train loss=0.003393868 valid loss= 0.003109245\n",
      "train reg_fs: 0.0007588154985569417\n",
      "Epoch: 8500 train loss=0.004645452 valid loss= 0.002831751\n",
      "train reg_fs: 0.0007572427857667208\n",
      "Epoch: 9000 train loss=0.001712200 valid loss= 0.003011307\n",
      "train reg_fs: 0.0007556005148217082\n",
      "Epoch: 9500 train loss=0.001049221 valid loss= 0.002977250\n",
      "train reg_fs: 0.0007543661631643772\n",
      "Epoch: 10000 train loss=0.002217660 valid loss= 0.002991011\n",
      "train reg_fs: 0.0007530754082836211\n",
      "Epoch: 10500 train loss=0.002063868 valid loss= 0.002611822\n",
      "train reg_fs: 0.0007515049655921757\n",
      "Epoch: 11000 train loss=0.005576028 valid loss= 0.003068367\n",
      "train reg_fs: 0.0007496853941120207\n",
      "Epoch: 11500 train loss=0.003271945 valid loss= 0.002619346\n",
      "train reg_fs: 0.0007480911444872618\n",
      "Epoch: 12000 train loss=0.002119061 valid loss= 0.002850460\n",
      "train reg_fs: 0.0007464315858669579\n",
      "Epoch: 12500 train loss=0.001256733 valid loss= 0.003144550\n",
      "train reg_fs: 0.0007452182471752167\n",
      "Epoch: 13000 train loss=0.003685954 valid loss= 0.002994969\n",
      "train reg_fs: 0.0007437524618580937\n",
      "Epoch: 13500 train loss=0.002749383 valid loss= 0.002761183\n",
      "train reg_fs: 0.0007421002956107259\n",
      "Epoch: 14000 train loss=0.002338236 valid loss= 0.003632649\n",
      "train reg_fs: 0.0007406286313198507\n",
      "Epoch: 14500 train loss=0.001029566 valid loss= 0.002750040\n",
      "train reg_fs: 0.0007391201215796173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:43:59,587]\u001b[0m Trial 18 finished with value: 0.002397960006265617 and parameters: {'lam': 0.0010277409037446666, 'learning_rate': 0.13189567183508352, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001354518 valid loss= 0.003106718\n",
      "train reg_fs: 0.0007380226161330938\n",
      "In trial:---------------------\n",
      "validation mse: 0.002397960006265617\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010394884 valid loss= 0.009547153\n",
      "train reg_fs: 0.0019395377021282911\n",
      "Epoch: 1000 train loss=0.012911992 valid loss= 0.009730201\n",
      "train reg_fs: 0.001960155786946416\n",
      "Epoch: 1500 train loss=0.005663646 valid loss= 0.008788165\n",
      "train reg_fs: 0.001968307653442025\n",
      "Epoch: 2000 train loss=0.007333798 valid loss= 0.008194807\n",
      "train reg_fs: 0.001966731855645776\n",
      "Epoch: 2500 train loss=0.014554224 valid loss= 0.008488945\n",
      "train reg_fs: 0.0019511424470692873\n",
      "Epoch: 3000 train loss=0.007679864 valid loss= 0.007852846\n",
      "train reg_fs: 0.0019311095820739865\n",
      "Epoch: 3500 train loss=0.010124422 valid loss= 0.007354287\n",
      "train reg_fs: 0.0019060746999457479\n",
      "Epoch: 4000 train loss=0.007998408 valid loss= 0.007035967\n",
      "train reg_fs: 0.0018839059630408883\n",
      "Epoch: 4500 train loss=0.017747425 valid loss= 0.006670534\n",
      "train reg_fs: 0.0018672606674954295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:44:37,594]\u001b[0m Trial 19 finished with value: 0.004721167531564698 and parameters: {'lam': 0.002285163700138243, 'learning_rate': 0.028278597233981396, 'num_epoch': 5000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005730452 valid loss= 0.006629115\n",
      "train reg_fs: 0.001849964028224349\n",
      "In trial:---------------------\n",
      "validation mse: 0.004721167531564698\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018019542 valid loss= 0.012222299\n",
      "train reg_fs: 0.006173531524837017\n",
      "Epoch: 1000 train loss=0.011843421 valid loss= 0.012502164\n",
      "train reg_fs: 0.006260863970965147\n",
      "Epoch: 1500 train loss=0.010610083 valid loss= 0.012143742\n",
      "train reg_fs: 0.006249450147151947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:44:53,279]\u001b[0m Trial 20 finished with value: 0.005847398180294729 and parameters: {'lam': 0.0071369871365200965, 'learning_rate': 0.060629534023094324, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.013771764 valid loss= 0.012085645\n",
      "train reg_fs: 0.006160810589790344\n",
      "In trial:---------------------\n",
      "validation mse: 0.005847398180294729\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006200796 valid loss= 0.006782461\n",
      "train reg_fs: 0.0012189927510917187\n",
      "Epoch: 1000 train loss=0.004991467 valid loss= 0.006593082\n",
      "train reg_fs: 0.001220420585013926\n",
      "Epoch: 1500 train loss=0.005627916 valid loss= 0.006479907\n",
      "train reg_fs: 0.0012002353323623538\n",
      "Epoch: 2000 train loss=0.004150445 valid loss= 0.005883846\n",
      "train reg_fs: 0.0011785412207245827\n",
      "Epoch: 2500 train loss=0.003213904 valid loss= 0.006111869\n",
      "train reg_fs: 0.0011552867945283651\n",
      "Epoch: 3000 train loss=0.002018261 valid loss= 0.005562483\n",
      "train reg_fs: 0.0011417987989261746\n",
      "Epoch: 3500 train loss=0.013313800 valid loss= 0.005899913\n",
      "train reg_fs: 0.001129161100834608\n",
      "Epoch: 4000 train loss=0.004525078 valid loss= 0.006067776\n",
      "train reg_fs: 0.001118078944273293\n",
      "Epoch: 4500 train loss=0.003147169 valid loss= 0.006179418\n",
      "train reg_fs: 0.0011099317343905568\n",
      "Epoch: 5000 train loss=0.002976482 valid loss= 0.006478275\n",
      "train reg_fs: 0.001103097922168672\n",
      "Epoch: 5500 train loss=0.002782584 valid loss= 0.006662343\n",
      "train reg_fs: 0.0010977486381307244\n",
      "Epoch: 6000 train loss=0.003651381 valid loss= 0.006607500\n",
      "train reg_fs: 0.0010903103975579143\n",
      "Epoch: 6500 train loss=0.005488060 valid loss= 0.006647156\n",
      "train reg_fs: 0.0010844956850633025\n",
      "Epoch: 7000 train loss=0.002123546 valid loss= 0.007088581\n",
      "train reg_fs: 0.0010804280173033476\n",
      "Epoch: 7500 train loss=0.002231408 valid loss= 0.007112831\n",
      "train reg_fs: 0.0010686555178835988\n",
      "Epoch: 8000 train loss=0.003957555 valid loss= 0.007103509\n",
      "train reg_fs: 0.0010657324455678463\n",
      "Epoch: 8500 train loss=0.001740390 valid loss= 0.007328889\n",
      "train reg_fs: 0.0010617072694003582\n",
      "Epoch: 9000 train loss=0.001868010 valid loss= 0.007435890\n",
      "train reg_fs: 0.0010549795115366578\n",
      "Epoch: 9500 train loss=0.001665700 valid loss= 0.007270170\n",
      "train reg_fs: 0.0010511031141504645\n",
      "Epoch: 10000 train loss=0.001996787 valid loss= 0.007805631\n",
      "train reg_fs: 0.0010415626456961036\n",
      "Epoch: 10500 train loss=0.001851500 valid loss= 0.007811921\n",
      "train reg_fs: 0.0010407199151813984\n",
      "Epoch: 11000 train loss=0.003364114 valid loss= 0.007913603\n",
      "train reg_fs: 0.0010348112555220723\n",
      "Epoch: 11500 train loss=0.004013806 valid loss= 0.007624349\n",
      "train reg_fs: 0.00103193917311728\n",
      "Epoch: 12000 train loss=0.002089289 valid loss= 0.008129532\n",
      "train reg_fs: 0.0010282016592100263\n",
      "Epoch: 12500 train loss=0.004920912 valid loss= 0.008315927\n",
      "train reg_fs: 0.0010216680821031332\n",
      "Epoch: 13000 train loss=0.002392386 valid loss= 0.008384037\n",
      "train reg_fs: 0.0010186870349571109\n",
      "Epoch: 13500 train loss=0.004211603 valid loss= 0.008337177\n",
      "train reg_fs: 0.0010200884426012635\n",
      "Epoch: 14000 train loss=0.002020428 valid loss= 0.008259512\n",
      "train reg_fs: 0.0010158619843423367\n",
      "Epoch: 14500 train loss=0.001993772 valid loss= 0.008301184\n",
      "train reg_fs: 0.0010123421670868993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:46:46,041]\u001b[0m Trial 21 finished with value: 0.0073885243974804275 and parameters: {'lam': 0.0013687502355616786, 'learning_rate': 0.15927112653311984, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002632620 valid loss= 0.008399197\n",
      "train reg_fs: 0.001010204665362835\n",
      "In trial:---------------------\n",
      "validation mse: 0.0073885243974804275\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011852589 valid loss= 0.008939554\n",
      "train reg_fs: 0.0011574322124943137\n",
      "Epoch: 1000 train loss=0.009822959 valid loss= 0.009593370\n",
      "train reg_fs: 0.0011779783526435494\n",
      "Epoch: 1500 train loss=0.014235538 valid loss= 0.008384665\n",
      "train reg_fs: 0.0011763961520045996\n",
      "Epoch: 2000 train loss=0.005449486 valid loss= 0.006297727\n",
      "train reg_fs: 0.0011530687334015965\n",
      "Epoch: 2500 train loss=0.006821063 valid loss= 0.005472131\n",
      "train reg_fs: 0.0011051604524254799\n",
      "Epoch: 3000 train loss=0.007386752 valid loss= 0.004122196\n",
      "train reg_fs: 0.0010631002951413393\n",
      "Epoch: 3500 train loss=0.003186460 valid loss= 0.004480056\n",
      "train reg_fs: 0.0010396880097687244\n",
      "Epoch: 4000 train loss=0.008121077 valid loss= 0.004677494\n",
      "train reg_fs: 0.001027559395879507\n",
      "Epoch: 4500 train loss=0.003975769 valid loss= 0.004593078\n",
      "train reg_fs: 0.0010213127825409174\n",
      "Epoch: 5000 train loss=0.004219946 valid loss= 0.004167018\n",
      "train reg_fs: 0.0010199676034972072\n",
      "Epoch: 5500 train loss=0.003151443 valid loss= 0.004256119\n",
      "train reg_fs: 0.0010195208014920354\n",
      "Epoch: 6000 train loss=0.004247485 valid loss= 0.004077587\n",
      "train reg_fs: 0.0010180751560255885\n",
      "Epoch: 6500 train loss=0.001955545 valid loss= 0.004173208\n",
      "train reg_fs: 0.001017006579786539\n",
      "Epoch: 7000 train loss=0.001869102 valid loss= 0.004310885\n",
      "train reg_fs: 0.0010142159881070256\n",
      "Epoch: 7500 train loss=0.004883680 valid loss= 0.004228411\n",
      "train reg_fs: 0.0010103845270350575\n",
      "Epoch: 8000 train loss=0.001504375 valid loss= 0.003922623\n",
      "train reg_fs: 0.001004834775812924\n",
      "Epoch: 8500 train loss=0.003485215 valid loss= 0.004322582\n",
      "train reg_fs: 0.000998546602204442\n",
      "Epoch: 9000 train loss=0.004890317 valid loss= 0.004166401\n",
      "train reg_fs: 0.0009955137502402067\n",
      "Epoch: 9500 train loss=0.002429544 valid loss= 0.003943934\n",
      "train reg_fs: 0.0009910030057653785\n",
      "Epoch: 10000 train loss=0.001412536 valid loss= 0.004169924\n",
      "train reg_fs: 0.0009835108648985624\n",
      "Epoch: 10500 train loss=0.003037483 valid loss= 0.004153933\n",
      "train reg_fs: 0.000978938420303166\n",
      "Epoch: 11000 train loss=0.005004342 valid loss= 0.004069530\n",
      "train reg_fs: 0.0009762250119820237\n",
      "Epoch: 11500 train loss=0.002615913 valid loss= 0.003704919\n",
      "train reg_fs: 0.0009728062432259321\n",
      "Epoch: 12000 train loss=0.004401026 valid loss= 0.004100765\n",
      "train reg_fs: 0.0009687744895927608\n",
      "Epoch: 12500 train loss=0.002601114 valid loss= 0.003637962\n",
      "train reg_fs: 0.0009652888984419405\n",
      "Epoch: 13000 train loss=0.004000523 valid loss= 0.003966922\n",
      "train reg_fs: 0.0009629989508539438\n",
      "Epoch: 13500 train loss=0.001161306 valid loss= 0.003869327\n",
      "train reg_fs: 0.0009590098052285612\n",
      "Epoch: 14000 train loss=0.004257987 valid loss= 0.003700254\n",
      "train reg_fs: 0.0009553655982017517\n",
      "Epoch: 14500 train loss=0.001545496 valid loss= 0.003887042\n",
      "train reg_fs: 0.000953543174546212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:48:37,670]\u001b[0m Trial 22 finished with value: 0.00269033218997891 and parameters: {'lam': 0.0013150624658620825, 'learning_rate': 0.10367891995389796, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003660613 valid loss= 0.003640484\n",
      "train reg_fs: 0.0009506989736109972\n",
      "In trial:---------------------\n",
      "validation mse: 0.00269033218997891\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013383875 valid loss= 0.008256570\n",
      "train reg_fs: 0.0015110127860680223\n",
      "Epoch: 1000 train loss=0.003981820 valid loss= 0.008197643\n",
      "train reg_fs: 0.0015067750355228782\n",
      "Epoch: 1500 train loss=0.004598740 valid loss= 0.008476080\n",
      "train reg_fs: 0.0014625409385189414\n",
      "Epoch: 2000 train loss=0.004288622 valid loss= 0.007160685\n",
      "train reg_fs: 0.001441806904040277\n",
      "Epoch: 2500 train loss=0.002628624 valid loss= 0.006378389\n",
      "train reg_fs: 0.0014363168738782406\n",
      "Epoch: 3000 train loss=0.005035839 valid loss= 0.005961573\n",
      "train reg_fs: 0.0014253867557272315\n",
      "Epoch: 3500 train loss=0.005713036 valid loss= 0.006207273\n",
      "train reg_fs: 0.0014203909086063504\n",
      "Epoch: 4000 train loss=0.004105903 valid loss= 0.006228741\n",
      "train reg_fs: 0.0014155255630612373\n",
      "Epoch: 4500 train loss=0.004243325 valid loss= 0.005953430\n",
      "train reg_fs: 0.0014100425178185105\n",
      "Epoch: 5000 train loss=0.001849496 valid loss= 0.006063507\n",
      "train reg_fs: 0.001404654118232429\n",
      "Epoch: 5500 train loss=0.002483449 valid loss= 0.006735828\n",
      "train reg_fs: 0.0014006431447342038\n",
      "Epoch: 6000 train loss=0.003301089 valid loss= 0.006933420\n",
      "train reg_fs: 0.001388650736771524\n",
      "Epoch: 6500 train loss=0.003910478 valid loss= 0.006790934\n",
      "train reg_fs: 0.0013813585974276066\n",
      "Epoch: 7000 train loss=0.002342655 valid loss= 0.007200517\n",
      "train reg_fs: 0.0013735579559579492\n",
      "Epoch: 7500 train loss=0.001849566 valid loss= 0.007119152\n",
      "train reg_fs: 0.0013632123591378331\n",
      "Epoch: 8000 train loss=0.002326408 valid loss= 0.007036841\n",
      "train reg_fs: 0.0013584704138338566\n",
      "Epoch: 8500 train loss=0.002030709 valid loss= 0.007563526\n",
      "train reg_fs: 0.0013499371707439423\n",
      "Epoch: 9000 train loss=0.001956234 valid loss= 0.007388780\n",
      "train reg_fs: 0.001341507420875132\n",
      "Epoch: 9500 train loss=0.002849076 valid loss= 0.007168669\n",
      "train reg_fs: 0.0013366964412853122\n",
      "Epoch: 10000 train loss=0.002357141 valid loss= 0.007548763\n",
      "train reg_fs: 0.0013286116300150752\n",
      "Epoch: 10500 train loss=0.003656473 valid loss= 0.007364791\n",
      "train reg_fs: 0.0013224990107119083\n",
      "Epoch: 11000 train loss=0.002328708 valid loss= 0.007403119\n",
      "train reg_fs: 0.0013175145722925663\n",
      "Epoch: 11500 train loss=0.001767432 valid loss= 0.007736650\n",
      "train reg_fs: 0.0013117771595716476\n",
      "Epoch: 12000 train loss=0.002094985 valid loss= 0.007660930\n",
      "train reg_fs: 0.001305662444792688\n",
      "Epoch: 12500 train loss=0.001537513 valid loss= 0.007692898\n",
      "train reg_fs: 0.0013004369102418423\n",
      "Epoch: 13000 train loss=0.002469451 valid loss= 0.007675364\n",
      "train reg_fs: 0.0012944367481395602\n",
      "Epoch: 13500 train loss=0.001911548 valid loss= 0.007434995\n",
      "train reg_fs: 0.001289901789277792\n",
      "Epoch: 14000 train loss=0.002232318 valid loss= 0.007627060\n",
      "train reg_fs: 0.0012859824346378446\n",
      "Epoch: 14500 train loss=0.001703599 valid loss= 0.007637752\n",
      "train reg_fs: 0.0012808353640139103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:50:29,321]\u001b[0m Trial 23 finished with value: 0.0064466824668016065 and parameters: {'lam': 0.0016711592475801066, 'learning_rate': 0.19067661022166768, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002284489 valid loss= 0.007719127\n",
      "train reg_fs: 0.0012764092534780502\n",
      "In trial:---------------------\n",
      "validation mse: 0.0064466824668016065\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015469729 valid loss= 0.005605690\n",
      "train reg_fs: 0.0009553973795846105\n",
      "Epoch: 1000 train loss=0.007073063 valid loss= 0.004236475\n",
      "train reg_fs: 0.0009266643319278955\n",
      "Epoch: 1500 train loss=0.009125990 valid loss= 0.002928915\n",
      "train reg_fs: 0.0009028231143020093\n",
      "Epoch: 2000 train loss=0.005227909 valid loss= 0.002452067\n",
      "train reg_fs: 0.0008825574186630547\n",
      "Epoch: 2500 train loss=0.003352774 valid loss= 0.002583522\n",
      "train reg_fs: 0.0008720760815776885\n",
      "Epoch: 3000 train loss=0.002322963 valid loss= 0.002706712\n",
      "train reg_fs: 0.0008645610068924725\n",
      "Epoch: 3500 train loss=0.002395339 valid loss= 0.002686133\n",
      "train reg_fs: 0.0008579979185014963\n",
      "Epoch: 4000 train loss=0.001337433 valid loss= 0.002759193\n",
      "train reg_fs: 0.0008498432580381632\n",
      "Epoch: 4500 train loss=0.004509608 valid loss= 0.002727516\n",
      "train reg_fs: 0.0008414617041125894\n",
      "Epoch: 5000 train loss=0.001905221 valid loss= 0.002615795\n",
      "train reg_fs: 0.0008354777237400413\n",
      "Epoch: 5500 train loss=0.001504678 valid loss= 0.002687355\n",
      "train reg_fs: 0.0008287891396321356\n",
      "Epoch: 6000 train loss=0.003219402 valid loss= 0.002744040\n",
      "train reg_fs: 0.000824982300400734\n",
      "Epoch: 6500 train loss=0.001538041 valid loss= 0.002813145\n",
      "train reg_fs: 0.0008183253230527043\n",
      "Epoch: 7000 train loss=0.001114124 valid loss= 0.002688013\n",
      "train reg_fs: 0.0008131078793667257\n",
      "Epoch: 7500 train loss=0.002402481 valid loss= 0.003095815\n",
      "train reg_fs: 0.0008088246104307473\n",
      "Epoch: 8000 train loss=0.003415184 valid loss= 0.003038110\n",
      "train reg_fs: 0.0008034176426008344\n",
      "Epoch: 8500 train loss=0.001104907 valid loss= 0.003050924\n",
      "train reg_fs: 0.0007987658609636128\n",
      "Epoch: 9000 train loss=0.001324056 valid loss= 0.002837818\n",
      "train reg_fs: 0.000797068583779037\n",
      "Epoch: 9500 train loss=0.001740321 valid loss= 0.002912216\n",
      "train reg_fs: 0.0007946992991492152\n",
      "Epoch: 10000 train loss=0.003105866 valid loss= 0.002957542\n",
      "train reg_fs: 0.0007899084594100714\n",
      "Epoch: 10500 train loss=0.001837677 valid loss= 0.003051972\n",
      "train reg_fs: 0.0007874292205087841\n",
      "Epoch: 11000 train loss=0.001099900 valid loss= 0.003070632\n",
      "train reg_fs: 0.0007842420018278062\n",
      "Epoch: 11500 train loss=0.001222076 valid loss= 0.002720332\n",
      "train reg_fs: 0.0007816281286068261\n",
      "Epoch: 12000 train loss=0.003857552 valid loss= 0.003183653\n",
      "train reg_fs: 0.0007805044879205525\n",
      "Epoch: 12500 train loss=0.003542826 valid loss= 0.003093405\n",
      "train reg_fs: 0.0007770978263579309\n",
      "Epoch: 13000 train loss=0.003158198 valid loss= 0.002975071\n",
      "train reg_fs: 0.0007755446713417768\n",
      "Epoch: 13500 train loss=0.002069898 valid loss= 0.003167064\n",
      "train reg_fs: 0.0007746143382973969\n",
      "Epoch: 14000 train loss=0.001504931 valid loss= 0.003253630\n",
      "train reg_fs: 0.0007722352747805417\n",
      "Epoch: 14500 train loss=0.003710429 valid loss= 0.003399472\n",
      "train reg_fs: 0.0007696349057368934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:52:22,184]\u001b[0m Trial 24 finished with value: 0.0024115606331635733 and parameters: {'lam': 0.001107307840141672, 'learning_rate': 0.14225116844453922, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001637285 valid loss= 0.003170347\n",
      "train reg_fs: 0.0007663246360607445\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024115606331635733\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009420546 valid loss= 0.009040989\n",
      "train reg_fs: 0.002954656956717372\n",
      "Epoch: 1000 train loss=0.012287925 valid loss= 0.008927095\n",
      "train reg_fs: 0.0028977671172469854\n",
      "Epoch: 1500 train loss=0.008886676 valid loss= 0.007070396\n",
      "train reg_fs: 0.002731621265411377\n",
      "Epoch: 2000 train loss=0.006964747 valid loss= 0.005316946\n",
      "train reg_fs: 0.002586167538538575\n",
      "Epoch: 2500 train loss=0.009991333 valid loss= 0.005366490\n",
      "train reg_fs: 0.0024856419768184423\n",
      "Epoch: 3000 train loss=0.003004946 valid loss= 0.005147526\n",
      "train reg_fs: 0.0024119503796100616\n",
      "Epoch: 3500 train loss=0.007988982 valid loss= 0.004939136\n",
      "train reg_fs: 0.0023534861393272877\n",
      "Epoch: 4000 train loss=0.002744718 valid loss= 0.004700501\n",
      "train reg_fs: 0.0023079286329448223\n",
      "Epoch: 4500 train loss=0.006036821 valid loss= 0.004803377\n",
      "train reg_fs: 0.002275245962664485\n",
      "Epoch: 5000 train loss=0.006628518 valid loss= 0.004977617\n",
      "train reg_fs: 0.002253234852105379\n",
      "Epoch: 5500 train loss=0.002470668 valid loss= 0.004779851\n",
      "train reg_fs: 0.002235119929537177\n",
      "Epoch: 6000 train loss=0.004699921 valid loss= 0.004561923\n",
      "train reg_fs: 0.0022208718582987785\n",
      "Epoch: 6500 train loss=0.011166181 valid loss= 0.004556253\n",
      "train reg_fs: 0.0022095730528235435\n",
      "Epoch: 7000 train loss=0.005649770 valid loss= 0.004102549\n",
      "train reg_fs: 0.0021987820509821177\n",
      "Epoch: 7500 train loss=0.003243483 valid loss= 0.004368817\n",
      "train reg_fs: 0.002189730294048786\n",
      "Epoch: 8000 train loss=0.002614575 valid loss= 0.004420871\n",
      "train reg_fs: 0.0021816410589963198\n",
      "Epoch: 8500 train loss=0.002760054 valid loss= 0.004618591\n",
      "train reg_fs: 0.002173804212361574\n",
      "Epoch: 9000 train loss=0.003472608 valid loss= 0.004481091\n",
      "train reg_fs: 0.0021659047342836857\n",
      "Epoch: 9500 train loss=0.002533725 valid loss= 0.004180802\n",
      "train reg_fs: 0.002158449264243245\n",
      "Epoch: 10000 train loss=0.006410601 valid loss= 0.004482086\n",
      "train reg_fs: 0.0021511653903871775\n",
      "Epoch: 10500 train loss=0.005735424 valid loss= 0.004347655\n",
      "train reg_fs: 0.002144348109140992\n",
      "Epoch: 11000 train loss=0.004273141 valid loss= 0.004240993\n",
      "train reg_fs: 0.0021374665666371584\n",
      "Epoch: 11500 train loss=0.003118650 valid loss= 0.004142547\n",
      "train reg_fs: 0.0021312066819518805\n",
      "Epoch: 12000 train loss=0.002968591 valid loss= 0.004601165\n",
      "train reg_fs: 0.002124784281477332\n",
      "Epoch: 12500 train loss=0.005761939 valid loss= 0.004150766\n",
      "train reg_fs: 0.0021193567663431168\n",
      "Epoch: 13000 train loss=0.003525117 valid loss= 0.004476991\n",
      "train reg_fs: 0.002114116447046399\n",
      "Epoch: 13500 train loss=0.003213424 valid loss= 0.004821884\n",
      "train reg_fs: 0.0021092300303280354\n",
      "Epoch: 14000 train loss=0.002490325 valid loss= 0.004451421\n",
      "train reg_fs: 0.002104182029142976\n",
      "Epoch: 14500 train loss=0.003823552 valid loss= 0.004544619\n",
      "train reg_fs: 0.002099699806421995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:54:14,369]\u001b[0m Trial 25 finished with value: 0.0024355710285127196 and parameters: {'lam': 0.0034124477102156097, 'learning_rate': 0.08441207346761086, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003387355 valid loss= 0.004492875\n",
      "train reg_fs: 0.0020955833606421947\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024355710285127196\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016279653 valid loss= 0.006646747\n",
      "train reg_fs: 0.0017706746002659202\n",
      "Epoch: 1000 train loss=0.009908953 valid loss= 0.005051098\n",
      "train reg_fs: 0.0016812578542158008\n",
      "Epoch: 1500 train loss=0.009719472 valid loss= 0.003573696\n",
      "train reg_fs: 0.0016063569346442819\n",
      "Epoch: 2000 train loss=0.005940461 valid loss= 0.003834061\n",
      "train reg_fs: 0.0015723705291748047\n",
      "Epoch: 2500 train loss=0.004241446 valid loss= 0.003888870\n",
      "train reg_fs: 0.0015495694242417812\n",
      "Epoch: 3000 train loss=0.004777881 valid loss= 0.003723329\n",
      "train reg_fs: 0.0015334408963099122\n",
      "Epoch: 3500 train loss=0.005441002 valid loss= 0.003797914\n",
      "train reg_fs: 0.0015225247479975224\n",
      "Epoch: 4000 train loss=0.002149836 valid loss= 0.004011374\n",
      "train reg_fs: 0.00151496147736907\n",
      "Epoch: 4500 train loss=0.002243712 valid loss= 0.003572566\n",
      "train reg_fs: 0.0015095992712303996\n",
      "Epoch: 5000 train loss=0.002751616 valid loss= 0.003571797\n",
      "train reg_fs: 0.0015043080784380436\n",
      "Epoch: 5500 train loss=0.003078645 valid loss= 0.004191770\n",
      "train reg_fs: 0.0014987570466473699\n",
      "Epoch: 6000 train loss=0.004447890 valid loss= 0.003574041\n",
      "train reg_fs: 0.00149397028144449\n",
      "Epoch: 6500 train loss=0.002433892 valid loss= 0.003670969\n",
      "train reg_fs: 0.0014891375321894884\n",
      "Epoch: 7000 train loss=0.006296227 valid loss= 0.003526476\n",
      "train reg_fs: 0.0014847582206130028\n",
      "Epoch: 7500 train loss=0.001749553 valid loss= 0.004038072\n",
      "train reg_fs: 0.001479990198276937\n",
      "Epoch: 8000 train loss=0.002794747 valid loss= 0.003423719\n",
      "train reg_fs: 0.0014753027353435755\n",
      "Epoch: 8500 train loss=0.001715739 valid loss= 0.003680763\n",
      "train reg_fs: 0.0014707056106999516\n",
      "Epoch: 9000 train loss=0.002949202 valid loss= 0.003386033\n",
      "train reg_fs: 0.0014656855491921306\n",
      "Epoch: 9500 train loss=0.003116490 valid loss= 0.003693366\n",
      "train reg_fs: 0.0014611606020480394\n",
      "Epoch: 10000 train loss=0.001891604 valid loss= 0.003680724\n",
      "train reg_fs: 0.001456889440305531\n",
      "Epoch: 10500 train loss=0.003389235 valid loss= 0.003794377\n",
      "train reg_fs: 0.001453344477340579\n",
      "Epoch: 11000 train loss=0.006412321 valid loss= 0.003752255\n",
      "train reg_fs: 0.00145001953933388\n",
      "Epoch: 11500 train loss=0.006185189 valid loss= 0.003679373\n",
      "train reg_fs: 0.0014464916894212365\n",
      "Epoch: 12000 train loss=0.002726564 valid loss= 0.003460473\n",
      "train reg_fs: 0.0014436125056818128\n",
      "Epoch: 12500 train loss=0.005342566 valid loss= 0.003576663\n",
      "train reg_fs: 0.0014413270400837064\n",
      "Epoch: 13000 train loss=0.008703630 valid loss= 0.003901116\n",
      "train reg_fs: 0.0014389086281880736\n",
      "Epoch: 13500 train loss=0.001982659 valid loss= 0.003544060\n",
      "train reg_fs: 0.0014372559962794185\n",
      "Epoch: 14000 train loss=0.002346869 valid loss= 0.003243201\n",
      "train reg_fs: 0.0014354860177263618\n",
      "Epoch: 14500 train loss=0.001749357 valid loss= 0.003619409\n",
      "train reg_fs: 0.0014337151078507304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:56:08,031]\u001b[0m Trial 26 finished with value: 0.002175510377508798 and parameters: {'lam': 0.002022303682827022, 'learning_rate': 0.11826750338849615, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001840415 valid loss= 0.003545324\n",
      "train reg_fs: 0.0014322776114568114\n",
      "In trial:---------------------\n",
      "validation mse: 0.002175510377508798\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009045027 valid loss= 0.009260069\n",
      "train reg_fs: 0.0025557486806064844\n",
      "Epoch: 1000 train loss=0.006814470 valid loss= 0.007634170\n",
      "train reg_fs: 0.0024086928460747004\n",
      "Epoch: 1500 train loss=0.003996436 valid loss= 0.006959261\n",
      "train reg_fs: 0.002350803464651108\n",
      "Epoch: 2000 train loss=0.006463810 valid loss= 0.006501290\n",
      "train reg_fs: 0.0023428574204444885\n",
      "Epoch: 2500 train loss=0.004133494 valid loss= 0.006291104\n",
      "train reg_fs: 0.002309319796040654\n",
      "Epoch: 3000 train loss=0.004070926 valid loss= 0.006203867\n",
      "train reg_fs: 0.002277292078360915\n",
      "Epoch: 3500 train loss=0.004693797 valid loss= 0.006306817\n",
      "train reg_fs: 0.0022404897026717663\n",
      "Epoch: 4000 train loss=0.003836956 valid loss= 0.006674048\n",
      "train reg_fs: 0.0022095637395977974\n",
      "Epoch: 4500 train loss=0.005297960 valid loss= 0.006382447\n",
      "train reg_fs: 0.002171055180951953\n",
      "Epoch: 5000 train loss=0.005234698 valid loss= 0.006700925\n",
      "train reg_fs: 0.002137467497959733\n",
      "Epoch: 5500 train loss=0.003874004 valid loss= 0.006927648\n",
      "train reg_fs: 0.0021022064611315727\n",
      "Epoch: 6000 train loss=0.003332481 valid loss= 0.007209810\n",
      "train reg_fs: 0.0020701284520328045\n",
      "Epoch: 6500 train loss=0.004967267 valid loss= 0.007137868\n",
      "train reg_fs: 0.0020399377681314945\n",
      "Epoch: 7000 train loss=0.004018740 valid loss= 0.007561006\n",
      "train reg_fs: 0.0020141189452260733\n",
      "Epoch: 7500 train loss=0.003076973 valid loss= 0.007600836\n",
      "train reg_fs: 0.0019903695210814476\n",
      "Epoch: 8000 train loss=0.005276246 valid loss= 0.007432688\n",
      "train reg_fs: 0.0019679146353155375\n",
      "Epoch: 8500 train loss=0.003927351 valid loss= 0.007620101\n",
      "train reg_fs: 0.001948353718034923\n",
      "Epoch: 9000 train loss=0.002998360 valid loss= 0.007950042\n",
      "train reg_fs: 0.0019322861917316914\n",
      "Epoch: 9500 train loss=0.003292973 valid loss= 0.007994375\n",
      "train reg_fs: 0.0019149375148117542\n",
      "Epoch: 10000 train loss=0.002752236 valid loss= 0.008112082\n",
      "train reg_fs: 0.0019002074841409922\n",
      "Epoch: 10500 train loss=0.003603387 valid loss= 0.008252345\n",
      "train reg_fs: 0.001886693760752678\n",
      "Epoch: 11000 train loss=0.004115831 valid loss= 0.008315309\n",
      "train reg_fs: 0.0018772511975839734\n",
      "Epoch: 11500 train loss=0.002888267 valid loss= 0.008539043\n",
      "train reg_fs: 0.0018657154869288206\n",
      "Epoch: 12000 train loss=0.002278782 valid loss= 0.008728050\n",
      "train reg_fs: 0.001855935319326818\n",
      "Epoch: 12500 train loss=0.003755599 valid loss= 0.007862463\n",
      "train reg_fs: 0.0018458091653883457\n",
      "Epoch: 13000 train loss=0.002313768 valid loss= 0.008025999\n",
      "train reg_fs: 0.0018383635906502604\n",
      "Epoch: 13500 train loss=0.002218798 valid loss= 0.008534699\n",
      "train reg_fs: 0.0018293006578460336\n",
      "Epoch: 14000 train loss=0.002569169 valid loss= 0.008424997\n",
      "train reg_fs: 0.0018222739454358816\n",
      "Epoch: 14500 train loss=0.002965509 valid loss= 0.008173644\n",
      "train reg_fs: 0.0018156537553295493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:57:51,872]\u001b[0m Trial 27 finished with value: 0.006629916570016183 and parameters: {'lam': 0.002908055343116219, 'learning_rate': 0.19494187853650582, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002808162 valid loss= 0.008539232\n",
      "train reg_fs: 0.001806535990908742\n",
      "In trial:---------------------\n",
      "validation mse: 0.006629916570016183\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007496004 valid loss= 0.007190080\n",
      "train reg_fs: 0.0014628252247348428\n",
      "Epoch: 1000 train loss=0.008274710 valid loss= 0.007310632\n",
      "train reg_fs: 0.001426412258297205\n",
      "Epoch: 1500 train loss=0.005753425 valid loss= 0.005917922\n",
      "train reg_fs: 0.0013987967977300286\n",
      "Epoch: 2000 train loss=0.005233570 valid loss= 0.005368091\n",
      "train reg_fs: 0.0013885109219700098\n",
      "Epoch: 2500 train loss=0.005794073 valid loss= 0.005199386\n",
      "train reg_fs: 0.001377962646074593\n",
      "Epoch: 3000 train loss=0.002719226 valid loss= 0.004921568\n",
      "train reg_fs: 0.0013713352382183075\n",
      "Epoch: 3500 train loss=0.002549948 valid loss= 0.004532565\n",
      "train reg_fs: 0.0013659456744790077\n",
      "Epoch: 4000 train loss=0.003301891 valid loss= 0.004869809\n",
      "train reg_fs: 0.0013523077359423041\n",
      "Epoch: 4500 train loss=0.004207287 valid loss= 0.005248107\n",
      "train reg_fs: 0.00134463410358876\n",
      "Epoch: 5000 train loss=0.002652863 valid loss= 0.005389004\n",
      "train reg_fs: 0.001333026448264718\n",
      "Epoch: 5500 train loss=0.003547171 valid loss= 0.005040883\n",
      "train reg_fs: 0.0013233963400125504\n",
      "Epoch: 6000 train loss=0.003161998 valid loss= 0.005170449\n",
      "train reg_fs: 0.0013095404719933867\n",
      "Epoch: 6500 train loss=0.002531078 valid loss= 0.004976392\n",
      "train reg_fs: 0.0012999805621802807\n",
      "Epoch: 7000 train loss=0.002203468 valid loss= 0.005544002\n",
      "train reg_fs: 0.0012880645226687193\n",
      "Epoch: 7500 train loss=0.002583127 valid loss= 0.005199111\n",
      "train reg_fs: 0.0012818718096241355\n",
      "Epoch: 8000 train loss=0.003140015 valid loss= 0.005237016\n",
      "train reg_fs: 0.0012695330660790205\n",
      "Epoch: 8500 train loss=0.002765152 valid loss= 0.005278216\n",
      "train reg_fs: 0.0012630848214030266\n",
      "Epoch: 9000 train loss=0.003532721 valid loss= 0.005366743\n",
      "train reg_fs: 0.0012560298200696707\n",
      "Epoch: 9500 train loss=0.001884850 valid loss= 0.005569475\n",
      "train reg_fs: 0.001244914485141635\n",
      "Epoch: 10000 train loss=0.003207028 valid loss= 0.005384687\n",
      "train reg_fs: 0.0012350879842415452\n",
      "Epoch: 10500 train loss=0.001872493 valid loss= 0.005805069\n",
      "train reg_fs: 0.001230296678841114\n",
      "Epoch: 11000 train loss=0.001583781 valid loss= 0.005347673\n",
      "train reg_fs: 0.0012293035397306085\n",
      "Epoch: 11500 train loss=0.002607296 valid loss= 0.005282633\n",
      "train reg_fs: 0.0012179912300780416\n",
      "Epoch: 12000 train loss=0.003885730 valid loss= 0.005420480\n",
      "train reg_fs: 0.0012155127478763461\n",
      "Epoch: 12500 train loss=0.002913406 valid loss= 0.005673550\n",
      "train reg_fs: 0.0012119809398427606\n",
      "Epoch: 13000 train loss=0.001741073 valid loss= 0.005750847\n",
      "train reg_fs: 0.0012079316657036543\n",
      "Epoch: 13500 train loss=0.002291870 valid loss= 0.005862794\n",
      "train reg_fs: 0.001203519874252379\n",
      "Epoch: 14000 train loss=0.002560643 valid loss= 0.005531509\n",
      "train reg_fs: 0.0012001459253951907\n",
      "Epoch: 14500 train loss=0.002906460 valid loss= 0.005637283\n",
      "train reg_fs: 0.001196257071569562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 16:59:43,680]\u001b[0m Trial 28 finished with value: 0.004654958742942089 and parameters: {'lam': 0.00164813863760748, 'learning_rate': 0.15360882515078852, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002576500 valid loss= 0.005848797\n",
      "train reg_fs: 0.0011898716911673546\n",
      "In trial:---------------------\n",
      "validation mse: 0.004654958742942089\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012286318 valid loss= 0.009617325\n",
      "train reg_fs: 0.0021420051343739033\n",
      "Epoch: 1000 train loss=0.012253284 valid loss= 0.009968621\n",
      "train reg_fs: 0.002140364143997431\n",
      "Epoch: 1500 train loss=0.008251613 valid loss= 0.010068679\n",
      "train reg_fs: 0.002084453124552965\n",
      "Epoch: 2000 train loss=0.006620901 valid loss= 0.008318754\n",
      "train reg_fs: 0.002017282648012042\n",
      "Epoch: 2500 train loss=0.010022260 valid loss= 0.008054052\n",
      "train reg_fs: 0.001970752840861678\n",
      "Epoch: 3000 train loss=0.007987307 valid loss= 0.006321252\n",
      "train reg_fs: 0.0019279086263850331\n",
      "Epoch: 3500 train loss=0.003213239 valid loss= 0.005218945\n",
      "train reg_fs: 0.001887167221866548\n",
      "Epoch: 4000 train loss=0.004691808 valid loss= 0.004670087\n",
      "train reg_fs: 0.0018519768491387367\n",
      "Epoch: 4500 train loss=0.004112240 valid loss= 0.004803026\n",
      "train reg_fs: 0.0018331065075471997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:00:23,031]\u001b[0m Trial 29 finished with value: 0.003041673272113167 and parameters: {'lam': 0.0025348116981175435, 'learning_rate': 0.060704091140237906, 'num_epoch': 5000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.009590182 valid loss= 0.004927162\n",
      "train reg_fs: 0.001822879770770669\n",
      "In trial:---------------------\n",
      "validation mse: 0.003041673272113167\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010145595 valid loss= 0.006733996\n",
      "train reg_fs: 0.0009911494562402368\n",
      "Epoch: 1000 train loss=0.010170380 valid loss= 0.003494097\n",
      "train reg_fs: 0.000904356362298131\n",
      "Epoch: 1500 train loss=0.001589687 valid loss= 0.003099791\n",
      "train reg_fs: 0.0008628900395706296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:00:39,523]\u001b[0m Trial 30 finished with value: 0.0019637457660353443 and parameters: {'lam': 0.0011712281433246103, 'learning_rate': 0.10494365352267356, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.003376325 valid loss= 0.002814436\n",
      "train reg_fs: 0.0008340817294083536\n",
      "In trial:---------------------\n",
      "validation mse: 0.0019637457660353443\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.024245910 valid loss= 0.007710839\n",
      "train reg_fs: 0.0010423959465697408\n",
      "Epoch: 1000 train loss=0.010616788 valid loss= 0.007469854\n",
      "train reg_fs: 0.001041862415149808\n",
      "Epoch: 1500 train loss=0.011867110 valid loss= 0.006999251\n",
      "train reg_fs: 0.0010088513372465968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:00:55,678]\u001b[0m Trial 31 finished with value: 0.004302513953282423 and parameters: {'lam': 0.0011810973786755136, 'learning_rate': 0.10947970550951613, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.005457756 valid loss= 0.005299259\n",
      "train reg_fs: 0.0009785201400518417\n",
      "In trial:---------------------\n",
      "validation mse: 0.004302513953282423\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007795386 valid loss= 0.007971732\n",
      "train reg_fs: 0.0012371422490105033\n",
      "Epoch: 1000 train loss=0.014059269 valid loss= 0.007585077\n",
      "train reg_fs: 0.0012273199390619993\n",
      "Epoch: 1500 train loss=0.007446650 valid loss= 0.005205072\n",
      "train reg_fs: 0.0011624242179095745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:01:11,910]\u001b[0m Trial 32 finished with value: 0.003033494833882626 and parameters: {'lam': 0.0014151145989903162, 'learning_rate': 0.0778971224534244, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.003756654 valid loss= 0.004156695\n",
      "train reg_fs: 0.0011134309461340308\n",
      "In trial:---------------------\n",
      "validation mse: 0.003033494833882626\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020263184 valid loss= 0.007086319\n",
      "train reg_fs: 0.0008899177191779017\n",
      "Epoch: 1000 train loss=0.011111448 valid loss= 0.006835545\n",
      "train reg_fs: 0.0008932893397286534\n",
      "Epoch: 1500 train loss=0.005641836 valid loss= 0.007069094\n",
      "train reg_fs: 0.0008715378935448825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:01:28,363]\u001b[0m Trial 33 finished with value: 0.0048139973018614755 and parameters: {'lam': 0.0010093692929931054, 'learning_rate': 0.1004676934194616, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.013554436 valid loss= 0.005677085\n",
      "train reg_fs: 0.0008453517802990973\n",
      "In trial:---------------------\n",
      "validation mse: 0.0048139973018614755\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018786043 valid loss= 0.009979739\n",
      "train reg_fs: 0.002975388430058956\n",
      "Epoch: 1000 train loss=0.016432008 valid loss= 0.009262696\n",
      "train reg_fs: 0.0029929198790341616\n",
      "Epoch: 1500 train loss=0.008283346 valid loss= 0.008224092\n",
      "train reg_fs: 0.0029567533638328314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:01:45,252]\u001b[0m Trial 34 finished with value: 0.004793817633545167 and parameters: {'lam': 0.0034716033753524785, 'learning_rate': 0.0542710429211111, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.005871948 valid loss= 0.007756951\n",
      "train reg_fs: 0.002896377583965659\n",
      "In trial:---------------------\n",
      "validation mse: 0.004793817633545167\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007827248 valid loss= 0.009211878\n",
      "train reg_fs: 0.0033985814079642296\n",
      "Epoch: 1000 train loss=0.009244563 valid loss= 0.008648375\n",
      "train reg_fs: 0.0033106778282672167\n",
      "Epoch: 1500 train loss=0.011307819 valid loss= 0.006848777\n",
      "train reg_fs: 0.003252378199249506\n",
      "Epoch: 2000 train loss=0.005241683 valid loss= 0.006419123\n",
      "train reg_fs: 0.003181014209985733\n",
      "Epoch: 2500 train loss=0.006308259 valid loss= 0.006524414\n",
      "train reg_fs: 0.0031022026669234037\n",
      "Epoch: 3000 train loss=0.005754887 valid loss= 0.006604324\n",
      "train reg_fs: 0.003009174717590213\n",
      "Epoch: 3500 train loss=0.006658580 valid loss= 0.006112549\n",
      "train reg_fs: 0.0029171768110245466\n",
      "Epoch: 4000 train loss=0.005817218 valid loss= 0.006267385\n",
      "train reg_fs: 0.0028510037809610367\n",
      "Epoch: 4500 train loss=0.004239118 valid loss= 0.006360325\n",
      "train reg_fs: 0.0027949016075581312\n",
      "Epoch: 5000 train loss=0.004535837 valid loss= 0.006571666\n",
      "train reg_fs: 0.0027561967726796865\n",
      "Epoch: 5500 train loss=0.003020484 valid loss= 0.006613094\n",
      "train reg_fs: 0.0027194966096431017\n",
      "Epoch: 6000 train loss=0.005038733 valid loss= 0.006579532\n",
      "train reg_fs: 0.0026829561684280634\n",
      "Epoch: 6500 train loss=0.003188326 valid loss= 0.006553455\n",
      "train reg_fs: 0.002656345022842288\n",
      "Epoch: 7000 train loss=0.003822189 valid loss= 0.006722914\n",
      "train reg_fs: 0.002628675661981106\n",
      "Epoch: 7500 train loss=0.005008191 valid loss= 0.006810547\n",
      "train reg_fs: 0.0026068745646625757\n",
      "Epoch: 8000 train loss=0.006277798 valid loss= 0.006775517\n",
      "train reg_fs: 0.0025909568648785353\n",
      "Epoch: 8500 train loss=0.003190425 valid loss= 0.006511377\n",
      "train reg_fs: 0.002570841461420059\n",
      "Epoch: 9000 train loss=0.006234516 valid loss= 0.006742412\n",
      "train reg_fs: 0.0025496797170490026\n",
      "Epoch: 9500 train loss=0.003421308 valid loss= 0.006660055\n",
      "train reg_fs: 0.002535617910325527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:03:00,774]\u001b[0m Trial 35 finished with value: 0.0042312384002082485 and parameters: {'lam': 0.003904012471515696, 'learning_rate': 0.15995437360072715, 'num_epoch': 10000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006151535 valid loss= 0.006702605\n",
      "train reg_fs: 0.0025289244949817657\n",
      "In trial:---------------------\n",
      "validation mse: 0.0042312384002082485\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011417260 valid loss= 0.009221297\n",
      "train reg_fs: 0.0018131349934265018\n",
      "Epoch: 1000 train loss=0.012949032 valid loss= 0.008288736\n",
      "train reg_fs: 0.0018328275764361024\n",
      "Epoch: 1500 train loss=0.008500876 valid loss= 0.007993957\n",
      "train reg_fs: 0.0018361939582973719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:03:17,566]\u001b[0m Trial 36 finished with value: 0.005535882882421653 and parameters: {'lam': 0.002118614290954684, 'learning_rate': 0.03153035113537948, 'num_epoch': 2000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.017388389 valid loss= 0.007376285\n",
      "train reg_fs: 0.0018274654867127538\n",
      "In trial:---------------------\n",
      "validation mse: 0.005535882882421653\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006321870 valid loss= 0.006428045\n",
      "train reg_fs: 0.001304035889916122\n",
      "Epoch: 1000 train loss=0.013613960 valid loss= 0.004263521\n",
      "train reg_fs: 0.0012211337452754378\n",
      "Epoch: 1500 train loss=0.004812690 valid loss= 0.004255433\n",
      "train reg_fs: 0.0011824250686913729\n",
      "Epoch: 2000 train loss=0.001573693 valid loss= 0.004163981\n",
      "train reg_fs: 0.0011659091105684638\n",
      "Epoch: 2500 train loss=0.004372786 valid loss= 0.004211146\n",
      "train reg_fs: 0.0011429155711084604\n",
      "Epoch: 3000 train loss=0.003749380 valid loss= 0.003767565\n",
      "train reg_fs: 0.0011174840619787574\n",
      "Epoch: 3500 train loss=0.001968035 valid loss= 0.003385763\n",
      "train reg_fs: 0.0010891038691625\n",
      "Epoch: 4000 train loss=0.003327942 valid loss= 0.003753789\n",
      "train reg_fs: 0.001062555587850511\n",
      "Epoch: 4500 train loss=0.002506929 valid loss= 0.003613362\n",
      "train reg_fs: 0.0010368939256295562\n",
      "Epoch: 5000 train loss=0.009230392 valid loss= 0.003071888\n",
      "train reg_fs: 0.0010161609388887882\n",
      "Epoch: 5500 train loss=0.001435809 valid loss= 0.003889654\n",
      "train reg_fs: 0.0009977506706491113\n",
      "Epoch: 6000 train loss=0.002156070 valid loss= 0.003103401\n",
      "train reg_fs: 0.0009830511407926679\n",
      "Epoch: 6500 train loss=0.002937668 valid loss= 0.003533820\n",
      "train reg_fs: 0.00097291124984622\n",
      "Epoch: 7000 train loss=0.006074319 valid loss= 0.003377712\n",
      "train reg_fs: 0.0009646976250223815\n",
      "Epoch: 7500 train loss=0.001950379 valid loss= 0.003330507\n",
      "train reg_fs: 0.000958960794378072\n",
      "Epoch: 8000 train loss=0.001853867 valid loss= 0.003383604\n",
      "train reg_fs: 0.0009530751267448068\n",
      "Epoch: 8500 train loss=0.004300743 valid loss= 0.003351859\n",
      "train reg_fs: 0.0009485984337516129\n",
      "Epoch: 9000 train loss=0.002161374 valid loss= 0.003162341\n",
      "train reg_fs: 0.0009444280876778066\n",
      "Epoch: 9500 train loss=0.003255384 valid loss= 0.003538101\n",
      "train reg_fs: 0.0009408757905475795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:04:33,621]\u001b[0m Trial 37 finished with value: 0.002430373631552884 and parameters: {'lam': 0.001518371148215836, 'learning_rate': 0.13042784579295383, 'num_epoch': 10000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001760719 valid loss= 0.003352673\n",
      "train reg_fs: 0.0009379431721754372\n",
      "In trial:---------------------\n",
      "validation mse: 0.002430373631552884\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018101597 valid loss= 0.006732078\n",
      "train reg_fs: 0.001000798074528575\n",
      "Epoch: 1000 train loss=0.007884601 valid loss= 0.004512380\n",
      "train reg_fs: 0.0009588886750862002\n",
      "Epoch: 1500 train loss=0.006313150 valid loss= 0.003570361\n",
      "train reg_fs: 0.000921564525924623\n",
      "Epoch: 2000 train loss=0.009452056 valid loss= 0.003260442\n",
      "train reg_fs: 0.0009076205315068364\n",
      "Epoch: 2500 train loss=0.002998423 valid loss= 0.003548204\n",
      "train reg_fs: 0.0008973547373898327\n",
      "Epoch: 3000 train loss=0.010871353 valid loss= 0.003675378\n",
      "train reg_fs: 0.0008884788840077817\n",
      "Epoch: 3500 train loss=0.002905758 valid loss= 0.003199016\n",
      "train reg_fs: 0.0008809822029434144\n",
      "Epoch: 4000 train loss=0.002212686 valid loss= 0.003420809\n",
      "train reg_fs: 0.0008748500840738416\n",
      "Epoch: 4500 train loss=0.011549583 valid loss= 0.003084406\n",
      "train reg_fs: 0.0008701973129063845\n",
      "Epoch: 5000 train loss=0.003980631 valid loss= 0.003221435\n",
      "train reg_fs: 0.00086687266593799\n",
      "Epoch: 5500 train loss=0.001333419 valid loss= 0.003046443\n",
      "train reg_fs: 0.0008643293986096978\n",
      "Epoch: 6000 train loss=0.003937641 valid loss= 0.003048572\n",
      "train reg_fs: 0.0008621939341537654\n",
      "Epoch: 6500 train loss=0.002334531 valid loss= 0.002925638\n",
      "train reg_fs: 0.0008602187735959888\n",
      "Epoch: 7000 train loss=0.002932310 valid loss= 0.002770458\n",
      "train reg_fs: 0.0008587812772020698\n",
      "Epoch: 7500 train loss=0.001785269 valid loss= 0.002823905\n",
      "train reg_fs: 0.0008573433733545244\n",
      "Epoch: 8000 train loss=0.002803040 valid loss= 0.002769693\n",
      "train reg_fs: 0.0008560732821933925\n",
      "Epoch: 8500 train loss=0.001618064 valid loss= 0.003069552\n",
      "train reg_fs: 0.0008545551099814475\n",
      "Epoch: 9000 train loss=0.002053712 valid loss= 0.003198609\n",
      "train reg_fs: 0.0008529560873284936\n",
      "Epoch: 9500 train loss=0.001955227 valid loss= 0.003157082\n",
      "train reg_fs: 0.0008514037472195923\n",
      "Epoch: 10000 train loss=0.001138778 valid loss= 0.002748763\n",
      "train reg_fs: 0.0008500494877807796\n",
      "Epoch: 10500 train loss=0.003527075 valid loss= 0.002988154\n",
      "train reg_fs: 0.0008487931918352842\n",
      "Epoch: 11000 train loss=0.012834302 valid loss= 0.002845048\n",
      "train reg_fs: 0.0008471543551422656\n",
      "Epoch: 11500 train loss=0.001554856 valid loss= 0.002679317\n",
      "train reg_fs: 0.0008455858333036304\n",
      "Epoch: 12000 train loss=0.003999817 valid loss= 0.002572848\n",
      "train reg_fs: 0.0008443204569630325\n",
      "Epoch: 12500 train loss=0.002400651 valid loss= 0.002918449\n",
      "train reg_fs: 0.0008428207947872579\n",
      "Epoch: 13000 train loss=0.002077735 valid loss= 0.002694579\n",
      "train reg_fs: 0.0008413385367020965\n",
      "Epoch: 13500 train loss=0.001302840 valid loss= 0.002957504\n",
      "train reg_fs: 0.000840031891129911\n",
      "Epoch: 14000 train loss=0.001947831 valid loss= 0.002588045\n",
      "train reg_fs: 0.0008388780988752842\n",
      "Epoch: 14500 train loss=0.001193600 valid loss= 0.002865823\n",
      "train reg_fs: 0.0008377039339393377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:06:27,727]\u001b[0m Trial 38 finished with value: 0.0019979400758398276 and parameters: {'lam': 0.001159246544233856, 'learning_rate': 0.08126959062481201, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001110250 valid loss= 0.002804928\n",
      "train reg_fs: 0.0008364688837900758\n",
      "In trial:---------------------\n",
      "validation mse: 0.0019979400758398276\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008125040 valid loss= 0.007716889\n",
      "train reg_fs: 0.001015053945593536\n",
      "Epoch: 1000 train loss=0.012433294 valid loss= 0.007814053\n",
      "train reg_fs: 0.0010196720249950886\n",
      "Epoch: 1500 train loss=0.006736852 valid loss= 0.007129299\n",
      "train reg_fs: 0.0009918541181832552\n",
      "Epoch: 2000 train loss=0.005717639 valid loss= 0.005033745\n",
      "train reg_fs: 0.0009615713497623801\n",
      "Epoch: 2500 train loss=0.006076473 valid loss= 0.003512606\n",
      "train reg_fs: 0.0009314371854998171\n",
      "Epoch: 3000 train loss=0.002577344 valid loss= 0.003122080\n",
      "train reg_fs: 0.0009003712912090123\n",
      "Epoch: 3500 train loss=0.003879830 valid loss= 0.003848010\n",
      "train reg_fs: 0.0008816870977170765\n",
      "Epoch: 4000 train loss=0.006200055 valid loss= 0.003487293\n",
      "train reg_fs: 0.0008682147017680109\n",
      "Epoch: 4500 train loss=0.003022976 valid loss= 0.003247585\n",
      "train reg_fs: 0.0008583404705859721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:07:05,802]\u001b[0m Trial 39 finished with value: 0.0022140070896167472 and parameters: {'lam': 0.0011522842920580624, 'learning_rate': 0.08702532320123463, 'num_epoch': 5000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.001639358 valid loss= 0.003046711\n",
      "train reg_fs: 0.0008502782438881695\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022140070896167472\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.025353637 valid loss= 0.010893651\n",
      "train reg_fs: 0.003784602042287588\n",
      "Epoch: 1000 train loss=0.019939020 valid loss= 0.009749167\n",
      "train reg_fs: 0.003757497062906623\n",
      "Epoch: 1500 train loss=0.012466874 valid loss= 0.007270067\n",
      "train reg_fs: 0.0036330600269138813\n",
      "Epoch: 2000 train loss=0.011400321 valid loss= 0.005992848\n",
      "train reg_fs: 0.003497546073049307\n",
      "Epoch: 2500 train loss=0.012151484 valid loss= 0.005558033\n",
      "train reg_fs: 0.0034116089809685946\n",
      "Epoch: 3000 train loss=0.005787473 valid loss= 0.005587170\n",
      "train reg_fs: 0.003361279144883156\n",
      "Epoch: 3500 train loss=0.005255924 valid loss= 0.005365563\n",
      "train reg_fs: 0.0033189200330525637\n",
      "Epoch: 4000 train loss=0.004995394 valid loss= 0.005652715\n",
      "train reg_fs: 0.0032828235998749733\n",
      "Epoch: 4500 train loss=0.004919808 valid loss= 0.005373313\n",
      "train reg_fs: 0.003253799630329013\n",
      "Epoch: 5000 train loss=0.004526666 valid loss= 0.005212938\n",
      "train reg_fs: 0.0032311955001205206\n",
      "Epoch: 5500 train loss=0.004147588 valid loss= 0.005526472\n",
      "train reg_fs: 0.0032136456575244665\n",
      "Epoch: 6000 train loss=0.003979677 valid loss= 0.005326798\n",
      "train reg_fs: 0.0031978492625057697\n",
      "Epoch: 6500 train loss=0.003746783 valid loss= 0.005653078\n",
      "train reg_fs: 0.003183417022228241\n",
      "Epoch: 7000 train loss=0.003870632 valid loss= 0.005052378\n",
      "train reg_fs: 0.003171794582158327\n",
      "Epoch: 7500 train loss=0.004871671 valid loss= 0.004994546\n",
      "train reg_fs: 0.00316027388907969\n",
      "Epoch: 8000 train loss=0.003447015 valid loss= 0.005539420\n",
      "train reg_fs: 0.003151067066937685\n",
      "Epoch: 8500 train loss=0.004766991 valid loss= 0.005206520\n",
      "train reg_fs: 0.00314148748293519\n",
      "Epoch: 9000 train loss=0.008178528 valid loss= 0.005767356\n",
      "train reg_fs: 0.003133198479190469\n",
      "Epoch: 9500 train loss=0.006859883 valid loss= 0.005125052\n",
      "train reg_fs: 0.0031255155336111784\n",
      "Epoch: 10000 train loss=0.004329405 valid loss= 0.005088527\n",
      "train reg_fs: 0.0031189247965812683\n",
      "Epoch: 10500 train loss=0.003757142 valid loss= 0.004983550\n",
      "train reg_fs: 0.003113105893135071\n",
      "Epoch: 11000 train loss=0.004910065 valid loss= 0.005231281\n",
      "train reg_fs: 0.003108019707724452\n",
      "Epoch: 11500 train loss=0.003683086 valid loss= 0.005033188\n",
      "train reg_fs: 0.0031027551740407944\n",
      "Epoch: 12000 train loss=0.004026835 valid loss= 0.005269815\n",
      "train reg_fs: 0.0030984855256974697\n",
      "Epoch: 12500 train loss=0.003690367 valid loss= 0.004897973\n",
      "train reg_fs: 0.0030945625621825457\n",
      "Epoch: 13000 train loss=0.003901462 valid loss= 0.005029071\n",
      "train reg_fs: 0.0030910384375602007\n",
      "Epoch: 13500 train loss=0.004082051 valid loss= 0.005356896\n",
      "train reg_fs: 0.0030875294469296932\n",
      "Epoch: 14000 train loss=0.006541864 valid loss= 0.005073162\n",
      "train reg_fs: 0.003084492636844516\n",
      "Epoch: 14500 train loss=0.003717513 valid loss= 0.005407558\n",
      "train reg_fs: 0.0030817280057817698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:09:01,312]\u001b[0m Trial 40 finished with value: 0.0021233592220773903 and parameters: {'lam': 0.004362312823446613, 'learning_rate': 0.07463188195320321, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007288734 valid loss= 0.005059338\n",
      "train reg_fs: 0.0030792371835559607\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021233592220773903\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016828677 valid loss= 0.008703444\n",
      "train reg_fs: 0.0010155010968446732\n",
      "Epoch: 1000 train loss=0.009748944 valid loss= 0.007988364\n",
      "train reg_fs: 0.0010219999821856618\n",
      "Epoch: 1500 train loss=0.014362111 valid loss= 0.008372788\n",
      "train reg_fs: 0.001027726917527616\n",
      "Epoch: 2000 train loss=0.016929379 valid loss= 0.007830408\n",
      "train reg_fs: 0.0010327274212613702\n",
      "Epoch: 2500 train loss=0.010023104 valid loss= 0.007566744\n",
      "train reg_fs: 0.0010368673829361796\n",
      "Epoch: 3000 train loss=0.007315549 valid loss= 0.007157423\n",
      "train reg_fs: 0.0010394146665930748\n",
      "Epoch: 3500 train loss=0.008553131 valid loss= 0.007541319\n",
      "train reg_fs: 0.0010408724192529917\n",
      "Epoch: 4000 train loss=0.008472283 valid loss= 0.007294297\n",
      "train reg_fs: 0.0010412734700366855\n",
      "Epoch: 4500 train loss=0.012873764 valid loss= 0.006846572\n",
      "train reg_fs: 0.0010410442482680082\n",
      "Epoch: 5000 train loss=0.015034454 valid loss= 0.006813680\n",
      "train reg_fs: 0.0010400753235444427\n",
      "Epoch: 5500 train loss=0.005170068 valid loss= 0.006450277\n",
      "train reg_fs: 0.0010378729784861207\n",
      "Epoch: 6000 train loss=0.006832397 valid loss= 0.006613424\n",
      "train reg_fs: 0.0010349791264161468\n",
      "Epoch: 6500 train loss=0.006939725 valid loss= 0.006762230\n",
      "train reg_fs: 0.0010316896950826049\n",
      "Epoch: 7000 train loss=0.004023144 valid loss= 0.006482502\n",
      "train reg_fs: 0.0010277172550559044\n",
      "Epoch: 7500 train loss=0.005579069 valid loss= 0.006174139\n",
      "train reg_fs: 0.001022410811856389\n",
      "Epoch: 8000 train loss=0.004178906 valid loss= 0.006231779\n",
      "train reg_fs: 0.0010165905114263296\n",
      "Epoch: 8500 train loss=0.009349355 valid loss= 0.006063903\n",
      "train reg_fs: 0.0010110834846273065\n",
      "Epoch: 9000 train loss=0.002122661 valid loss= 0.005612718\n",
      "train reg_fs: 0.0010054245358332992\n",
      "Epoch: 9500 train loss=0.003773898 valid loss= 0.005272005\n",
      "train reg_fs: 0.0009997530141845345\n",
      "Epoch: 10000 train loss=0.004125374 valid loss= 0.005226007\n",
      "train reg_fs: 0.0009940140880644321\n",
      "Epoch: 10500 train loss=0.006394107 valid loss= 0.004880200\n",
      "train reg_fs: 0.000988724292255938\n",
      "Epoch: 11000 train loss=0.007236863 valid loss= 0.004531532\n",
      "train reg_fs: 0.0009838371770456433\n",
      "Epoch: 11500 train loss=0.004565511 valid loss= 0.004438466\n",
      "train reg_fs: 0.0009788023307919502\n",
      "Epoch: 12000 train loss=0.003477005 valid loss= 0.004126196\n",
      "train reg_fs: 0.0009739111410453916\n",
      "Epoch: 12500 train loss=0.013054800 valid loss= 0.004156499\n",
      "train reg_fs: 0.0009692843304947019\n",
      "Epoch: 13000 train loss=0.004367738 valid loss= 0.003845688\n",
      "train reg_fs: 0.0009649558924138546\n",
      "Epoch: 13500 train loss=0.005570228 valid loss= 0.003775537\n",
      "train reg_fs: 0.0009611684363335371\n",
      "Epoch: 14000 train loss=0.004405732 valid loss= 0.003721562\n",
      "train reg_fs: 0.0009576069423928857\n",
      "Epoch: 14500 train loss=0.003101518 valid loss= 0.003514847\n",
      "train reg_fs: 0.0009543352061882615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:10:54,259]\u001b[0m Trial 41 finished with value: 0.0027171837344634546 and parameters: {'lam': 0.0011961658878054718, 'learning_rate': 0.011220213324716226, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004356679 valid loss= 0.003675017\n",
      "train reg_fs: 0.0009512398391962051\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027171837344634546\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009059818 valid loss= 0.006106894\n",
      "train reg_fs: 0.0008896039798855782\n",
      "Epoch: 1000 train loss=0.007740915 valid loss= 0.005419677\n",
      "train reg_fs: 0.00084185681771487\n",
      "Epoch: 1500 train loss=0.003734222 valid loss= 0.004499350\n",
      "train reg_fs: 0.000795910891611129\n",
      "Epoch: 2000 train loss=0.004873758 valid loss= 0.004243224\n",
      "train reg_fs: 0.0007733022212050855\n",
      "Epoch: 2500 train loss=0.011157393 valid loss= 0.004898300\n",
      "train reg_fs: 0.000755501096136868\n",
      "Epoch: 3000 train loss=0.002328396 valid loss= 0.004361755\n",
      "train reg_fs: 0.0007379541639238596\n",
      "Epoch: 3500 train loss=0.002934149 valid loss= 0.004259409\n",
      "train reg_fs: 0.0007182802073657513\n",
      "Epoch: 4000 train loss=0.002044801 valid loss= 0.004136097\n",
      "train reg_fs: 0.0007041376084089279\n",
      "Epoch: 4500 train loss=0.004201278 valid loss= 0.004061176\n",
      "train reg_fs: 0.0006910616648383439\n",
      "Epoch: 5000 train loss=0.001843522 valid loss= 0.003606380\n",
      "train reg_fs: 0.0006805798038840294\n",
      "Epoch: 5500 train loss=0.001357775 valid loss= 0.003396960\n",
      "train reg_fs: 0.000673003843985498\n",
      "Epoch: 6000 train loss=0.001352074 valid loss= 0.003238201\n",
      "train reg_fs: 0.0006669628201052547\n",
      "Epoch: 6500 train loss=0.007083700 valid loss= 0.003623208\n",
      "train reg_fs: 0.0006619765772484243\n",
      "Epoch: 7000 train loss=0.003387271 valid loss= 0.003288430\n",
      "train reg_fs: 0.0006573425489477813\n",
      "Epoch: 7500 train loss=0.000785852 valid loss= 0.003092523\n",
      "train reg_fs: 0.0006540092290379107\n",
      "Epoch: 8000 train loss=0.003901919 valid loss= 0.003018976\n",
      "train reg_fs: 0.0006514613633044064\n",
      "Epoch: 8500 train loss=0.007666526 valid loss= 0.002962854\n",
      "train reg_fs: 0.0006489688530564308\n",
      "Epoch: 9000 train loss=0.001117847 valid loss= 0.002714174\n",
      "train reg_fs: 0.0006467727362178266\n",
      "Epoch: 9500 train loss=0.001367279 valid loss= 0.003192537\n",
      "train reg_fs: 0.0006450595683418214\n",
      "Epoch: 10000 train loss=0.006833870 valid loss= 0.003054259\n",
      "train reg_fs: 0.00064325105631724\n",
      "Epoch: 10500 train loss=0.003774215 valid loss= 0.003088153\n",
      "train reg_fs: 0.0006418387056328356\n",
      "Epoch: 11000 train loss=0.005031018 valid loss= 0.003071652\n",
      "train reg_fs: 0.0006405621534213424\n",
      "Epoch: 11500 train loss=0.001183476 valid loss= 0.002988228\n",
      "train reg_fs: 0.0006393912481144071\n",
      "Epoch: 12000 train loss=0.003260371 valid loss= 0.003155787\n",
      "train reg_fs: 0.0006382836727425456\n",
      "Epoch: 12500 train loss=0.001153054 valid loss= 0.002996998\n",
      "train reg_fs: 0.000637207820545882\n",
      "Epoch: 13000 train loss=0.004943931 valid loss= 0.003194936\n",
      "train reg_fs: 0.0006362330750562251\n",
      "Epoch: 13500 train loss=0.004386006 valid loss= 0.002635203\n",
      "train reg_fs: 0.0006354330689646304\n",
      "Epoch: 14000 train loss=0.001312642 valid loss= 0.002967515\n",
      "train reg_fs: 0.0006346231675706804\n",
      "Epoch: 14500 train loss=0.004025103 valid loss= 0.002878506\n",
      "train reg_fs: 0.0006339439423754811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:12:49,120]\u001b[0m Trial 42 finished with value: 0.0020467052421042956 and parameters: {'lam': 0.001037844827992118, 'learning_rate': 0.11786550391952405, 'num_epoch': 15000}. Best is trial 3 with value: 0.0019119739482977478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003182341 valid loss= 0.002666804\n",
      "train reg_fs: 0.0006332789780572057\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020467052421042956\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011064606 valid loss= 0.007033543\n",
      "train reg_fs: 0.0009036316769197583\n",
      "Epoch: 1000 train loss=0.010999217 valid loss= 0.008142608\n",
      "train reg_fs: 0.0009132461855188012\n",
      "Epoch: 1500 train loss=0.002544283 valid loss= 0.005506898\n",
      "train reg_fs: 0.0008951215422712266\n",
      "Epoch: 2000 train loss=0.003075307 valid loss= 0.004615648\n",
      "train reg_fs: 0.0008611482917331159\n",
      "Epoch: 2500 train loss=0.003365751 valid loss= 0.003321634\n",
      "train reg_fs: 0.0008270104881376028\n",
      "Epoch: 3000 train loss=0.005530737 valid loss= 0.002872854\n",
      "train reg_fs: 0.0008056065998971462\n",
      "Epoch: 3500 train loss=0.003488756 valid loss= 0.003423112\n",
      "train reg_fs: 0.0007929048151709139\n",
      "Epoch: 4000 train loss=0.003062961 valid loss= 0.003050177\n",
      "train reg_fs: 0.0007848739624023438\n",
      "Epoch: 4500 train loss=0.003177660 valid loss= 0.002945577\n",
      "train reg_fs: 0.0007798817241564393\n",
      "Epoch: 5000 train loss=0.002266714 valid loss= 0.002787852\n",
      "train reg_fs: 0.0007756015402264893\n",
      "Epoch: 5500 train loss=0.001308756 valid loss= 0.002992402\n",
      "train reg_fs: 0.0007735440158285201\n",
      "Epoch: 6000 train loss=0.001464388 valid loss= 0.002751526\n",
      "train reg_fs: 0.0007721420261077583\n",
      "Epoch: 6500 train loss=0.002945688 valid loss= 0.002902157\n",
      "train reg_fs: 0.000770050217397511\n",
      "Epoch: 7000 train loss=0.001559655 valid loss= 0.003244718\n",
      "train reg_fs: 0.0007682608556933701\n",
      "Epoch: 7500 train loss=0.001552177 valid loss= 0.002929847\n",
      "train reg_fs: 0.0007670985069125891\n",
      "Epoch: 8000 train loss=0.002115127 valid loss= 0.002684066\n",
      "train reg_fs: 0.000765552802477032\n",
      "Epoch: 8500 train loss=0.001364250 valid loss= 0.003094718\n",
      "train reg_fs: 0.0007649764302186668\n",
      "Epoch: 9000 train loss=0.001122467 valid loss= 0.003202580\n",
      "train reg_fs: 0.0007646004669368267\n",
      "Epoch: 9500 train loss=0.002588322 valid loss= 0.002572075\n",
      "train reg_fs: 0.0007634016801603138\n",
      "Epoch: 10000 train loss=0.001128760 valid loss= 0.002564600\n",
      "train reg_fs: 0.0007626652368344367\n",
      "Epoch: 10500 train loss=0.005024609 valid loss= 0.002770998\n",
      "train reg_fs: 0.0007626714068464935\n",
      "Epoch: 11000 train loss=0.000999356 valid loss= 0.002608326\n",
      "train reg_fs: 0.000762295676395297\n",
      "Epoch: 11500 train loss=0.000972170 valid loss= 0.002217715\n",
      "train reg_fs: 0.0007608862360939384\n",
      "Epoch: 12000 train loss=0.005207785 valid loss= 0.002515088\n",
      "train reg_fs: 0.0007596780196763575\n",
      "Epoch: 12500 train loss=0.002263341 valid loss= 0.002592988\n",
      "train reg_fs: 0.0007587712607346475\n",
      "Epoch: 13000 train loss=0.001715899 valid loss= 0.002456520\n",
      "train reg_fs: 0.0007578024524264038\n",
      "Epoch: 13500 train loss=0.002863719 valid loss= 0.003221757\n",
      "train reg_fs: 0.000757022004108876\n",
      "Epoch: 14000 train loss=0.001830418 valid loss= 0.002612613\n",
      "train reg_fs: 0.0007563043618574739\n",
      "Epoch: 14500 train loss=0.001278743 valid loss= 0.002284488\n",
      "train reg_fs: 0.0007553863106295466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:14:40,789]\u001b[0m Trial 43 finished with value: 0.001723085639239685 and parameters: {'lam': 0.001025295093628777, 'learning_rate': 0.09591157984689266, 'num_epoch': 15000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001613417 valid loss= 0.002467784\n",
      "train reg_fs: 0.0007542087696492672\n",
      "In trial:---------------------\n",
      "validation mse: 0.001723085639239685\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013260603 valid loss= 0.008160269\n",
      "train reg_fs: 0.0010630650212988257\n",
      "Epoch: 1000 train loss=0.017161900 valid loss= 0.006821823\n",
      "train reg_fs: 0.0010743173770606518\n",
      "Epoch: 1500 train loss=0.016009394 valid loss= 0.007508966\n",
      "train reg_fs: 0.0010586652206256986\n",
      "Epoch: 2000 train loss=0.003060853 valid loss= 0.005783869\n",
      "train reg_fs: 0.001032454427331686\n",
      "Epoch: 2500 train loss=0.004893013 valid loss= 0.004908983\n",
      "train reg_fs: 0.001009188825264573\n",
      "Epoch: 3000 train loss=0.007550775 valid loss= 0.003666770\n",
      "train reg_fs: 0.0009839863050729036\n",
      "Epoch: 3500 train loss=0.007393475 valid loss= 0.003583411\n",
      "train reg_fs: 0.000959605211392045\n",
      "Epoch: 4000 train loss=0.002224508 valid loss= 0.003236702\n",
      "train reg_fs: 0.0009414917440153658\n",
      "Epoch: 4500 train loss=0.002626860 valid loss= 0.003375154\n",
      "train reg_fs: 0.000928517896682024\n",
      "Epoch: 5000 train loss=0.002982821 valid loss= 0.003604559\n",
      "train reg_fs: 0.0009169509285129607\n",
      "Epoch: 5500 train loss=0.003653774 valid loss= 0.003325522\n",
      "train reg_fs: 0.0009074128465726972\n",
      "Epoch: 6000 train loss=0.003244305 valid loss= 0.003274526\n",
      "train reg_fs: 0.000899744511116296\n",
      "Epoch: 6500 train loss=0.002068100 valid loss= 0.003747128\n",
      "train reg_fs: 0.0008919587126001716\n",
      "Epoch: 7000 train loss=0.010869458 valid loss= 0.003138365\n",
      "train reg_fs: 0.0008854286861605942\n",
      "Epoch: 7500 train loss=0.005453860 valid loss= 0.003080002\n",
      "train reg_fs: 0.0008785657119005919\n",
      "Epoch: 8000 train loss=0.010781089 valid loss= 0.003291167\n",
      "train reg_fs: 0.0008739276090636849\n",
      "Epoch: 8500 train loss=0.007754927 valid loss= 0.003472916\n",
      "train reg_fs: 0.0008671813411638141\n",
      "Epoch: 9000 train loss=0.001640523 valid loss= 0.003087531\n",
      "train reg_fs: 0.0008608054486103356\n",
      "Epoch: 9500 train loss=0.002495309 valid loss= 0.003201118\n",
      "train reg_fs: 0.0008547564502805471\n",
      "Epoch: 10000 train loss=0.002628915 valid loss= 0.003474910\n",
      "train reg_fs: 0.0008481850381940603\n",
      "Epoch: 10500 train loss=0.002669734 valid loss= 0.003160006\n",
      "train reg_fs: 0.0008411263697780669\n",
      "Epoch: 11000 train loss=0.002521661 valid loss= 0.003297943\n",
      "train reg_fs: 0.0008339705527760088\n",
      "Epoch: 11500 train loss=0.002355660 valid loss= 0.003498890\n",
      "train reg_fs: 0.0008273956482298672\n",
      "Epoch: 12000 train loss=0.002713948 valid loss= 0.003150271\n",
      "train reg_fs: 0.0008214815170504153\n",
      "Epoch: 12500 train loss=0.002656355 valid loss= 0.003267031\n",
      "train reg_fs: 0.0008153303642757237\n",
      "Epoch: 13000 train loss=0.001555827 valid loss= 0.003333003\n",
      "train reg_fs: 0.00081077148206532\n",
      "Epoch: 13500 train loss=0.004556542 valid loss= 0.003087386\n",
      "train reg_fs: 0.0008051471086218953\n",
      "Epoch: 14000 train loss=0.001024508 valid loss= 0.003157279\n",
      "train reg_fs: 0.0007996488129720092\n",
      "Epoch: 14500 train loss=0.001212478 valid loss= 0.003243992\n",
      "train reg_fs: 0.000795219442807138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:16:33,419]\u001b[0m Trial 44 finished with value: 0.0023178988703758782 and parameters: {'lam': 0.0012161537745406308, 'learning_rate': 0.06475827663393825, 'num_epoch': 15000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003697706 valid loss= 0.003102598\n",
      "train reg_fs: 0.0007907297112978995\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023178988703758782\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015835833 valid loss= 0.008005773\n",
      "train reg_fs: 0.0015926450723782182\n",
      "Epoch: 1000 train loss=0.009531212 valid loss= 0.008699833\n",
      "train reg_fs: 0.0016216352814808488\n",
      "Epoch: 1500 train loss=0.015718043 valid loss= 0.007544403\n",
      "train reg_fs: 0.0016359512228518724\n",
      "Epoch: 2000 train loss=0.010186793 valid loss= 0.007371034\n",
      "train reg_fs: 0.00163955835159868\n",
      "Epoch: 2500 train loss=0.008211687 valid loss= 0.006554466\n",
      "train reg_fs: 0.0016303907614201307\n",
      "Epoch: 3000 train loss=0.010295358 valid loss= 0.006695267\n",
      "train reg_fs: 0.0016181869432330132\n",
      "Epoch: 3500 train loss=0.005227591 valid loss= 0.005897000\n",
      "train reg_fs: 0.0016014357097446918\n",
      "Epoch: 4000 train loss=0.004944705 valid loss= 0.005772611\n",
      "train reg_fs: 0.0015798246022313833\n",
      "Epoch: 4500 train loss=0.004562076 valid loss= 0.005717009\n",
      "train reg_fs: 0.0015540010062977672\n",
      "Epoch: 5000 train loss=0.010184580 valid loss= 0.005579976\n",
      "train reg_fs: 0.0015262528322637081\n",
      "Epoch: 5500 train loss=0.002860522 valid loss= 0.005141384\n",
      "train reg_fs: 0.001499692676588893\n",
      "Epoch: 6000 train loss=0.003716000 valid loss= 0.004968055\n",
      "train reg_fs: 0.0014778705080971122\n",
      "Epoch: 6500 train loss=0.004213063 valid loss= 0.004474692\n",
      "train reg_fs: 0.0014577335678040981\n",
      "Epoch: 7000 train loss=0.003513664 valid loss= 0.004481046\n",
      "train reg_fs: 0.001438130158931017\n",
      "Epoch: 7500 train loss=0.003528749 valid loss= 0.004295073\n",
      "train reg_fs: 0.0014240252785384655\n",
      "Epoch: 8000 train loss=0.002080428 valid loss= 0.004492803\n",
      "train reg_fs: 0.0014104542788118124\n",
      "Epoch: 8500 train loss=0.002530972 valid loss= 0.004558465\n",
      "train reg_fs: 0.001398304128088057\n",
      "Epoch: 9000 train loss=0.003771938 valid loss= 0.004332780\n",
      "train reg_fs: 0.0013859315076842904\n",
      "Epoch: 9500 train loss=0.002414220 valid loss= 0.004632788\n",
      "train reg_fs: 0.00137818802613765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:17:46,596]\u001b[0m Trial 45 finished with value: 0.003012716260950445 and parameters: {'lam': 0.0018367603796572772, 'learning_rate': 0.05011897105867436, 'num_epoch': 10000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007026561 valid loss= 0.004387329\n",
      "train reg_fs: 0.0013687766622751951\n",
      "In trial:---------------------\n",
      "validation mse: 0.003012716260950445\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013715152 valid loss= 0.007471397\n",
      "train reg_fs: 0.0012942020548507571\n",
      "Epoch: 1000 train loss=0.009775604 valid loss= 0.007617087\n",
      "train reg_fs: 0.0012835778761655092\n",
      "Epoch: 1500 train loss=0.007615829 valid loss= 0.007631794\n",
      "train reg_fs: 0.0012461055302992463\n",
      "Epoch: 2000 train loss=0.003523996 valid loss= 0.006341166\n",
      "train reg_fs: 0.0012234323658049107\n",
      "Epoch: 2500 train loss=0.007169516 valid loss= 0.006094374\n",
      "train reg_fs: 0.0012090428499504924\n",
      "Epoch: 3000 train loss=0.004154047 valid loss= 0.005108371\n",
      "train reg_fs: 0.0012006644392386079\n",
      "Epoch: 3500 train loss=0.006421434 valid loss= 0.005231558\n",
      "train reg_fs: 0.0011910664616152644\n",
      "Epoch: 4000 train loss=0.009734917 valid loss= 0.004773680\n",
      "train reg_fs: 0.0011780444765463471\n",
      "Epoch: 4500 train loss=0.004454184 valid loss= 0.004168936\n",
      "train reg_fs: 0.001163937384262681\n",
      "Epoch: 5000 train loss=0.004948648 valid loss= 0.004023394\n",
      "train reg_fs: 0.001145380549132824\n",
      "Epoch: 5500 train loss=0.005000515 valid loss= 0.004468706\n",
      "train reg_fs: 0.0011297081364318728\n",
      "Epoch: 6000 train loss=0.003107239 valid loss= 0.003992700\n",
      "train reg_fs: 0.0011089396430179477\n",
      "Epoch: 6500 train loss=0.003246896 valid loss= 0.003999266\n",
      "train reg_fs: 0.0010946211405098438\n",
      "Epoch: 7000 train loss=0.002921664 valid loss= 0.004354663\n",
      "train reg_fs: 0.0010799654992297292\n",
      "Epoch: 7500 train loss=0.001762805 valid loss= 0.004357586\n",
      "train reg_fs: 0.001068140845745802\n",
      "Epoch: 8000 train loss=0.009204883 valid loss= 0.004464801\n",
      "train reg_fs: 0.0010567678837105632\n",
      "Epoch: 8500 train loss=0.001501764 valid loss= 0.004539574\n",
      "train reg_fs: 0.0010465732775628567\n",
      "Epoch: 9000 train loss=0.002337422 valid loss= 0.004453012\n",
      "train reg_fs: 0.0010370335076004267\n",
      "Epoch: 9500 train loss=0.002874900 valid loss= 0.004753351\n",
      "train reg_fs: 0.0010276198154315352\n",
      "Epoch: 10000 train loss=0.002326641 valid loss= 0.004769804\n",
      "train reg_fs: 0.0010208383901044726\n",
      "Epoch: 10500 train loss=0.002559711 valid loss= 0.004715406\n",
      "train reg_fs: 0.001012883149087429\n",
      "Epoch: 11000 train loss=0.001356312 valid loss= 0.004867958\n",
      "train reg_fs: 0.0010061494540423155\n",
      "Epoch: 11500 train loss=0.001748423 valid loss= 0.004980223\n",
      "train reg_fs: 0.0009989668615162373\n",
      "Epoch: 12000 train loss=0.002101090 valid loss= 0.005105348\n",
      "train reg_fs: 0.000992168323136866\n",
      "Epoch: 12500 train loss=0.003337899 valid loss= 0.005110661\n",
      "train reg_fs: 0.0009873508242890239\n",
      "Epoch: 13000 train loss=0.001681542 valid loss= 0.004909077\n",
      "train reg_fs: 0.0009821250569075346\n",
      "Epoch: 13500 train loss=0.002089864 valid loss= 0.005044063\n",
      "train reg_fs: 0.0009777410887181759\n",
      "Epoch: 14000 train loss=0.002426210 valid loss= 0.005139535\n",
      "train reg_fs: 0.0009722736431285739\n",
      "Epoch: 14500 train loss=0.003246596 valid loss= 0.005007758\n",
      "train reg_fs: 0.0009679488139227033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:19:35,411]\u001b[0m Trial 46 finished with value: 0.004194217989067722 and parameters: {'lam': 0.0014919655398465484, 'learning_rate': 0.09530061898904141, 'num_epoch': 15000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002266692 valid loss= 0.005188356\n",
      "train reg_fs: 0.0009636713075451553\n",
      "In trial:---------------------\n",
      "validation mse: 0.004194217989067722\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011111177 valid loss= 0.006323041\n",
      "train reg_fs: 0.0009460024302825332\n",
      "Epoch: 1000 train loss=0.005533342 valid loss= 0.005672316\n",
      "train reg_fs: 0.0009205479873344302\n",
      "Epoch: 1500 train loss=0.014052014 valid loss= 0.003729986\n",
      "train reg_fs: 0.0008781433571130037\n",
      "Epoch: 2000 train loss=0.003425569 valid loss= 0.004080697\n",
      "train reg_fs: 0.0008512609056197107\n",
      "Epoch: 2500 train loss=0.002699003 valid loss= 0.003684266\n",
      "train reg_fs: 0.0008374183089472353\n",
      "Epoch: 3000 train loss=0.002883414 valid loss= 0.003531083\n",
      "train reg_fs: 0.0008246010402217507\n",
      "Epoch: 3500 train loss=0.001757243 valid loss= 0.003950144\n",
      "train reg_fs: 0.0008099093101918697\n",
      "Epoch: 4000 train loss=0.001972356 valid loss= 0.003853435\n",
      "train reg_fs: 0.0007947953417897224\n",
      "Epoch: 4500 train loss=0.002190907 valid loss= 0.003454678\n",
      "train reg_fs: 0.0007795749115757644\n",
      "Epoch: 5000 train loss=0.009570484 valid loss= 0.003850346\n",
      "train reg_fs: 0.0007645286968909204\n",
      "Epoch: 5500 train loss=0.001401217 valid loss= 0.003348674\n",
      "train reg_fs: 0.0007532372255809605\n",
      "Epoch: 6000 train loss=0.001882847 valid loss= 0.003087441\n",
      "train reg_fs: 0.0007432881975546479\n",
      "Epoch: 6500 train loss=0.002038610 valid loss= 0.003529001\n",
      "train reg_fs: 0.0007354642148129642\n",
      "Epoch: 7000 train loss=0.002499347 valid loss= 0.003206009\n",
      "train reg_fs: 0.0007282666047103703\n",
      "Epoch: 7500 train loss=0.001149919 valid loss= 0.003104286\n",
      "train reg_fs: 0.0007223428692668676\n",
      "Epoch: 8000 train loss=0.001700791 valid loss= 0.003237675\n",
      "train reg_fs: 0.0007171337492763996\n",
      "Epoch: 8500 train loss=0.001029047 valid loss= 0.003036818\n",
      "train reg_fs: 0.0007126883137971163\n",
      "Epoch: 9000 train loss=0.005097179 valid loss= 0.003259689\n",
      "train reg_fs: 0.0007084792014211416\n",
      "Epoch: 9500 train loss=0.001868194 valid loss= 0.003052545\n",
      "train reg_fs: 0.0007050540298223495\n",
      "Epoch: 10000 train loss=0.003498067 valid loss= 0.003316111\n",
      "train reg_fs: 0.0007018318283371627\n",
      "Epoch: 10500 train loss=0.003690932 valid loss= 0.003185655\n",
      "train reg_fs: 0.000699027965310961\n",
      "Epoch: 11000 train loss=0.002080799 valid loss= 0.003396831\n",
      "train reg_fs: 0.0006963781779631972\n",
      "Epoch: 11500 train loss=0.001595907 valid loss= 0.003069749\n",
      "train reg_fs: 0.0006938688457012177\n",
      "Epoch: 12000 train loss=0.002444785 valid loss= 0.003096500\n",
      "train reg_fs: 0.0006916509009897709\n",
      "Epoch: 12500 train loss=0.002659338 valid loss= 0.002963706\n",
      "train reg_fs: 0.0006893944810144603\n",
      "Epoch: 13000 train loss=0.010433579 valid loss= 0.003069748\n",
      "train reg_fs: 0.0006875447579659522\n",
      "Epoch: 13500 train loss=0.003506889 valid loss= 0.002734470\n",
      "train reg_fs: 0.0006859833956696093\n",
      "Epoch: 14000 train loss=0.000918092 valid loss= 0.003160983\n",
      "train reg_fs: 0.0006843329174444079\n",
      "Epoch: 14500 train loss=0.003746210 valid loss= 0.003182515\n",
      "train reg_fs: 0.000682826794218272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:21:25,643]\u001b[0m Trial 47 finished with value: 0.0021925577443057597 and parameters: {'lam': 0.0010984414216803028, 'learning_rate': 0.08108928739800478, 'num_epoch': 15000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002221260 valid loss= 0.002864717\n",
      "train reg_fs: 0.0006814424996264279\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021925577443057597\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012621040 valid loss= 0.008273821\n",
      "train reg_fs: 0.0024415585212409496\n",
      "Epoch: 1000 train loss=0.009922260 valid loss= 0.008033072\n",
      "train reg_fs: 0.0024623582139611244\n",
      "Epoch: 1500 train loss=0.008610829 valid loss= 0.006543682\n",
      "train reg_fs: 0.0024396174121648073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:21:39,999]\u001b[0m Trial 48 finished with value: 0.0044812487582021835 and parameters: {'lam': 0.00275397811201166, 'learning_rate': 0.11801902054384042, 'num_epoch': 2000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.004395868 valid loss= 0.006900598\n",
      "train reg_fs: 0.002404651837423444\n",
      "In trial:---------------------\n",
      "validation mse: 0.0044812487582021835\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012930850 valid loss= 0.009201839\n",
      "train reg_fs: 0.0043775662779808044\n",
      "Epoch: 1000 train loss=0.014710696 valid loss= 0.008828107\n",
      "train reg_fs: 0.004235353320837021\n",
      "Epoch: 1500 train loss=0.010910696 valid loss= 0.006581491\n",
      "train reg_fs: 0.004017066676169634\n",
      "Epoch: 2000 train loss=0.009026833 valid loss= 0.006331631\n",
      "train reg_fs: 0.0038845553062856197\n",
      "Epoch: 2500 train loss=0.010545660 valid loss= 0.006153146\n",
      "train reg_fs: 0.003813608782365918\n",
      "Epoch: 3000 train loss=0.010854440 valid loss= 0.006338631\n",
      "train reg_fs: 0.0037699833046644926\n",
      "Epoch: 3500 train loss=0.006550487 valid loss= 0.006679676\n",
      "train reg_fs: 0.0037337124813348055\n",
      "Epoch: 4000 train loss=0.005854597 valid loss= 0.006681055\n",
      "train reg_fs: 0.00369240646250546\n",
      "Epoch: 4500 train loss=0.006072040 valid loss= 0.006506461\n",
      "train reg_fs: 0.0036508559715002775\n",
      "Epoch: 5000 train loss=0.006703847 valid loss= 0.006763496\n",
      "train reg_fs: 0.003612964414060116\n",
      "Epoch: 5500 train loss=0.007751481 valid loss= 0.007067085\n",
      "train reg_fs: 0.0035752044059336185\n",
      "Epoch: 6000 train loss=0.006145737 valid loss= 0.007007210\n",
      "train reg_fs: 0.0035302855540066957\n",
      "Epoch: 6500 train loss=0.008648571 valid loss= 0.006939434\n",
      "train reg_fs: 0.0034940270707011223\n",
      "Epoch: 7000 train loss=0.004898081 valid loss= 0.007055265\n",
      "train reg_fs: 0.0034681069664657116\n",
      "Epoch: 7500 train loss=0.005136345 valid loss= 0.007293322\n",
      "train reg_fs: 0.003444852540269494\n",
      "Epoch: 8000 train loss=0.005876308 valid loss= 0.007242390\n",
      "train reg_fs: 0.0034236398059874773\n",
      "Epoch: 8500 train loss=0.004242346 valid loss= 0.007056579\n",
      "train reg_fs: 0.003402619855478406\n",
      "Epoch: 9000 train loss=0.003905654 valid loss= 0.006829712\n",
      "train reg_fs: 0.003382674651220441\n",
      "Epoch: 9500 train loss=0.004330453 valid loss= 0.007128585\n",
      "train reg_fs: 0.003360026516020298\n",
      "Epoch: 10000 train loss=0.008476995 valid loss= 0.006595633\n",
      "train reg_fs: 0.003339567221701145\n",
      "Epoch: 10500 train loss=0.003696183 valid loss= 0.006672512\n",
      "train reg_fs: 0.0033222667407244444\n",
      "Epoch: 11000 train loss=0.007223946 valid loss= 0.006528796\n",
      "train reg_fs: 0.003304006764665246\n",
      "Epoch: 11500 train loss=0.004744501 valid loss= 0.006641048\n",
      "train reg_fs: 0.0032875286415219307\n",
      "Epoch: 12000 train loss=0.005651873 valid loss= 0.006683160\n",
      "train reg_fs: 0.0032740195747464895\n",
      "Epoch: 12500 train loss=0.004309874 valid loss= 0.006414537\n",
      "train reg_fs: 0.003263171063736081\n",
      "Epoch: 13000 train loss=0.004101790 valid loss= 0.006505681\n",
      "train reg_fs: 0.003244643798097968\n",
      "Epoch: 13500 train loss=0.003887747 valid loss= 0.006556353\n",
      "train reg_fs: 0.003231767565011978\n",
      "Epoch: 14000 train loss=0.005571342 valid loss= 0.006629182\n",
      "train reg_fs: 0.0032180394046008587\n",
      "Epoch: 14500 train loss=0.004832468 valid loss= 0.006668521\n",
      "train reg_fs: 0.0032063855323940516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:23:30,048]\u001b[0m Trial 49 finished with value: 0.0032137442841946367 and parameters: {'lam': 0.00507337541764997, 'learning_rate': 0.0950580315875701, 'num_epoch': 15000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004111354 valid loss= 0.006502925\n",
      "train reg_fs: 0.0031926799565553665\n",
      "In trial:---------------------\n",
      "validation mse: 0.0032137442841946367\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008918284 valid loss= 0.005548774\n",
      "train reg_fs: 0.0008647497743368149\n",
      "Epoch: 1000 train loss=0.006307492 valid loss= 0.004450226\n",
      "train reg_fs: 0.0008501444244757295\n",
      "Epoch: 1500 train loss=0.003096544 valid loss= 0.004315443\n",
      "train reg_fs: 0.000815195613540709\n",
      "Epoch: 2000 train loss=0.003068485 valid loss= 0.003805289\n",
      "train reg_fs: 0.0007882242789492011\n",
      "Epoch: 2500 train loss=0.005528885 valid loss= 0.003546641\n",
      "train reg_fs: 0.0007736098486930132\n",
      "Epoch: 3000 train loss=0.002148121 valid loss= 0.003467384\n",
      "train reg_fs: 0.0007619924726895988\n",
      "Epoch: 3500 train loss=0.004094348 valid loss= 0.003557678\n",
      "train reg_fs: 0.0007510537980124354\n",
      "Epoch: 4000 train loss=0.002912216 valid loss= 0.003267714\n",
      "train reg_fs: 0.0007408791570924222\n",
      "Epoch: 4500 train loss=0.001599431 valid loss= 0.003090749\n",
      "train reg_fs: 0.0007311198860406876\n",
      "Epoch: 5000 train loss=0.001956136 valid loss= 0.003296524\n",
      "train reg_fs: 0.0007232575444504619\n",
      "Epoch: 5500 train loss=0.001900106 valid loss= 0.002949942\n",
      "train reg_fs: 0.0007156326319091022\n",
      "Epoch: 6000 train loss=0.002904327 valid loss= 0.003472434\n",
      "train reg_fs: 0.0007076916517689824\n",
      "Epoch: 6500 train loss=0.001485285 valid loss= 0.003417883\n",
      "train reg_fs: 0.0007003036444075406\n",
      "Epoch: 7000 train loss=0.001195255 valid loss= 0.003064706\n",
      "train reg_fs: 0.0006924323388375342\n",
      "Epoch: 7500 train loss=0.002416078 valid loss= 0.003233967\n",
      "train reg_fs: 0.0006849464843980968\n",
      "Epoch: 8000 train loss=0.001883716 valid loss= 0.003192529\n",
      "train reg_fs: 0.0006772385677322745\n",
      "Epoch: 8500 train loss=0.001237729 valid loss= 0.003099768\n",
      "train reg_fs: 0.0006714042974635959\n",
      "Epoch: 9000 train loss=0.001567660 valid loss= 0.002674280\n",
      "train reg_fs: 0.0006657182821072638\n",
      "Epoch: 9500 train loss=0.002787918 valid loss= 0.003483018\n",
      "train reg_fs: 0.0006605701637454331\n",
      "Epoch: 10000 train loss=0.002235972 valid loss= 0.002956928\n",
      "train reg_fs: 0.0006561038899235427\n",
      "Epoch: 10500 train loss=0.001181930 valid loss= 0.002833168\n",
      "train reg_fs: 0.0006520287715829909\n",
      "Epoch: 11000 train loss=0.001816663 valid loss= 0.003099717\n",
      "train reg_fs: 0.0006485455669462681\n",
      "Epoch: 11500 train loss=0.002582775 valid loss= 0.002850409\n",
      "train reg_fs: 0.0006451764493249357\n",
      "Epoch: 12000 train loss=0.004572624 valid loss= 0.003219584\n",
      "train reg_fs: 0.0006421972066164017\n",
      "Epoch: 12500 train loss=0.000973801 valid loss= 0.003296258\n",
      "train reg_fs: 0.0006396488752216101\n",
      "Epoch: 13000 train loss=0.004256955 valid loss= 0.003117780\n",
      "train reg_fs: 0.000637657183688134\n",
      "Epoch: 13500 train loss=0.001483411 valid loss= 0.003179883\n",
      "train reg_fs: 0.0006352661876007915\n",
      "Epoch: 14000 train loss=0.016384872 valid loss= 0.003253063\n",
      "train reg_fs: 0.0006330289761535823\n",
      "Epoch: 14500 train loss=0.001319689 valid loss= 0.002780414\n",
      "train reg_fs: 0.0006311152828857303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:25:08,672]\u001b[0m Trial 50 finished with value: 0.002637456246224324 and parameters: {'lam': 0.0010002070438323268, 'learning_rate': 0.07208660992183004, 'num_epoch': 15000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001802486 valid loss= 0.003259127\n",
      "train reg_fs: 0.0006294827326200902\n",
      "In trial:---------------------\n",
      "validation mse: 0.002637456246224324\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012550692 valid loss= 0.007890301\n",
      "train reg_fs: 0.0009380635456182063\n",
      "Epoch: 1000 train loss=0.005890850 valid loss= 0.008117921\n",
      "train reg_fs: 0.0009499642765149474\n",
      "Epoch: 1500 train loss=0.009357761 valid loss= 0.007155944\n",
      "train reg_fs: 0.0009381443960592151\n",
      "Epoch: 2000 train loss=0.007242325 valid loss= 0.006109572\n",
      "train reg_fs: 0.000915739219635725\n",
      "Epoch: 2500 train loss=0.005272841 valid loss= 0.005803443\n",
      "train reg_fs: 0.0008999189594760537\n",
      "Epoch: 3000 train loss=0.002927808 valid loss= 0.005817011\n",
      "train reg_fs: 0.0008919640094973147\n",
      "Epoch: 3500 train loss=0.001733248 valid loss= 0.005191167\n",
      "train reg_fs: 0.000888208276592195\n",
      "Epoch: 4000 train loss=0.003989981 valid loss= 0.004817706\n",
      "train reg_fs: 0.0008883961127139628\n",
      "Epoch: 4500 train loss=0.003057578 valid loss= 0.004727179\n",
      "train reg_fs: 0.0008843556861393154\n",
      "Epoch: 5000 train loss=0.004294313 valid loss= 0.004852312\n",
      "train reg_fs: 0.000880588311702013\n",
      "Epoch: 5500 train loss=0.004017213 valid loss= 0.004800648\n",
      "train reg_fs: 0.0008765415986999869\n",
      "Epoch: 6000 train loss=0.006879415 valid loss= 0.005170526\n",
      "train reg_fs: 0.0008746410603635013\n",
      "Epoch: 6500 train loss=0.005183659 valid loss= 0.005306687\n",
      "train reg_fs: 0.0008706522639840841\n",
      "Epoch: 7000 train loss=0.005570655 valid loss= 0.005390729\n",
      "train reg_fs: 0.0008684508502483368\n",
      "Epoch: 7500 train loss=0.002351317 valid loss= 0.005929867\n",
      "train reg_fs: 0.0008660086314193904\n",
      "Epoch: 8000 train loss=0.002356726 valid loss= 0.005642299\n",
      "train reg_fs: 0.0008620620355941355\n",
      "Epoch: 8500 train loss=0.001327168 valid loss= 0.006032354\n",
      "train reg_fs: 0.0008615536498837173\n",
      "Epoch: 9000 train loss=0.004633212 valid loss= 0.006019792\n",
      "train reg_fs: 0.0008605403709225357\n",
      "Epoch: 9500 train loss=0.001928295 valid loss= 0.005982589\n",
      "train reg_fs: 0.0008577530970796943\n",
      "Epoch: 10000 train loss=0.002124937 valid loss= 0.005833134\n",
      "train reg_fs: 0.0008565119351260364\n",
      "Epoch: 10500 train loss=0.001505456 valid loss= 0.006474279\n",
      "train reg_fs: 0.0008551703067496419\n",
      "Epoch: 11000 train loss=0.002023970 valid loss= 0.007099010\n",
      "train reg_fs: 0.0008529071346856654\n",
      "Epoch: 11500 train loss=0.001753801 valid loss= 0.007213814\n",
      "train reg_fs: 0.0008517794776707888\n",
      "Epoch: 12000 train loss=0.002332052 valid loss= 0.006679907\n",
      "train reg_fs: 0.0008497958770021796\n",
      "Epoch: 12500 train loss=0.002230208 valid loss= 0.006992799\n",
      "train reg_fs: 0.0008492821943946183\n",
      "Epoch: 13000 train loss=0.002597754 valid loss= 0.007010106\n",
      "train reg_fs: 0.0008472679764963686\n",
      "Epoch: 13500 train loss=0.001393782 valid loss= 0.006921797\n",
      "train reg_fs: 0.0008452397305518389\n",
      "Epoch: 14000 train loss=0.003729945 valid loss= 0.007221622\n",
      "train reg_fs: 0.0008439784869551659\n",
      "Epoch: 14500 train loss=0.003038857 valid loss= 0.006984799\n",
      "train reg_fs: 0.0008420240483246744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:26:44,121]\u001b[0m Trial 51 finished with value: 0.006161720182905103 and parameters: {'lam': 0.0010612427880881494, 'learning_rate': 0.1218317429074103, 'num_epoch': 15000}. Best is trial 43 with value: 0.001723085639239685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003454675 valid loss= 0.007018254\n",
      "train reg_fs: 0.0008406066917814314\n",
      "In trial:---------------------\n",
      "validation mse: 0.006161720182905103\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006324640 valid loss= 0.005191664\n",
      "train reg_fs: 0.001094815437681973\n",
      "Epoch: 1000 train loss=0.002457028 valid loss= 0.003196653\n",
      "train reg_fs: 0.001017305301502347\n",
      "Epoch: 1500 train loss=0.001254077 valid loss= 0.003263639\n",
      "train reg_fs: 0.0009897119598463178\n",
      "Epoch: 2000 train loss=0.004463192 valid loss= 0.002821974\n",
      "train reg_fs: 0.0009741854155436158\n",
      "Epoch: 2500 train loss=0.001978706 valid loss= 0.002995444\n",
      "train reg_fs: 0.00096366205252707\n",
      "Epoch: 3000 train loss=0.002503518 valid loss= 0.003282242\n",
      "train reg_fs: 0.0009573647403158247\n",
      "Epoch: 3500 train loss=0.001165520 valid loss= 0.002913462\n",
      "train reg_fs: 0.0009536095312796533\n",
      "Epoch: 4000 train loss=0.002486203 valid loss= 0.002609610\n",
      "train reg_fs: 0.0009513293043710291\n",
      "Epoch: 4500 train loss=0.002960461 valid loss= 0.002905177\n",
      "train reg_fs: 0.0009494048426859081\n",
      "Epoch: 5000 train loss=0.009337644 valid loss= 0.003041803\n",
      "train reg_fs: 0.0009476804407313466\n",
      "Epoch: 5500 train loss=0.005980743 valid loss= 0.002864361\n",
      "train reg_fs: 0.0009461898007430136\n",
      "Epoch: 6000 train loss=0.001373225 valid loss= 0.002347929\n",
      "train reg_fs: 0.0009448598721064627\n",
      "Epoch: 6500 train loss=0.001826872 valid loss= 0.003047571\n",
      "train reg_fs: 0.0009434538660570979\n",
      "Epoch: 7000 train loss=0.003318482 valid loss= 0.002549671\n",
      "train reg_fs: 0.0009412309154868126\n",
      "Epoch: 7500 train loss=0.001616190 valid loss= 0.002635715\n",
      "train reg_fs: 0.0009389988845214248\n",
      "Epoch: 8000 train loss=0.001558429 valid loss= 0.002400188\n",
      "train reg_fs: 0.000936844211537391\n",
      "Epoch: 8500 train loss=0.003777032 valid loss= 0.002641155\n",
      "train reg_fs: 0.000933285744395107\n",
      "Epoch: 9000 train loss=0.006370264 valid loss= 0.002290258\n",
      "train reg_fs: 0.0009295119671151042\n",
      "Epoch: 9500 train loss=0.001881949 valid loss= 0.002261983\n",
      "train reg_fs: 0.0009245029650628567\n",
      "Epoch: 10000 train loss=0.001443919 valid loss= 0.002165102\n",
      "train reg_fs: 0.0009177321917377412\n",
      "Epoch: 10500 train loss=0.002309150 valid loss= 0.002160980\n",
      "train reg_fs: 0.0009107074001803994\n",
      "Epoch: 11000 train loss=0.001686679 valid loss= 0.002325790\n",
      "train reg_fs: 0.0009039634023793042\n",
      "Epoch: 11500 train loss=0.001443422 valid loss= 0.002520029\n",
      "train reg_fs: 0.0008956451783888042\n",
      "Epoch: 12000 train loss=0.001675910 valid loss= 0.001713264\n",
      "train reg_fs: 0.0008894449565559626\n",
      "Epoch: 12500 train loss=0.001689710 valid loss= 0.001926633\n",
      "train reg_fs: 0.0008835425833240151\n",
      "Epoch: 13000 train loss=0.003549455 valid loss= 0.001777809\n",
      "train reg_fs: 0.0008789105922915041\n",
      "Epoch: 13500 train loss=0.001599896 valid loss= 0.001152917\n",
      "train reg_fs: 0.0008737880853004754\n",
      "Epoch: 14000 train loss=0.001397391 valid loss= 0.001461512\n",
      "train reg_fs: 0.0008703113999217749\n",
      "Epoch: 14500 train loss=0.003249925 valid loss= 0.001551673\n",
      "train reg_fs: 0.0008672858821228147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:28:20,662]\u001b[0m Trial 52 finished with value: 0.0004479713151502902 and parameters: {'lam': 0.0012749254225682, 'learning_rate': 0.14365154241426814, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001353198 valid loss= 0.001313634\n",
      "train reg_fs: 0.0008651551324874163\n",
      "In trial:---------------------\n",
      "validation mse: 0.0004479713151502902\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008794841 valid loss= 0.007030687\n",
      "train reg_fs: 0.0011042042169719934\n",
      "Epoch: 1000 train loss=0.013664585 valid loss= 0.006150428\n",
      "train reg_fs: 0.0010740035213530064\n",
      "Epoch: 1500 train loss=0.004705765 valid loss= 0.004547217\n",
      "train reg_fs: 0.0010206984588876367\n",
      "Epoch: 2000 train loss=0.002981705 valid loss= 0.004022726\n",
      "train reg_fs: 0.0009829065529629588\n",
      "Epoch: 2500 train loss=0.004072207 valid loss= 0.003822467\n",
      "train reg_fs: 0.0009552543051540852\n",
      "Epoch: 3000 train loss=0.003494243 valid loss= 0.004472232\n",
      "train reg_fs: 0.0009357493836432695\n",
      "Epoch: 3500 train loss=0.003601147 valid loss= 0.004382988\n",
      "train reg_fs: 0.0009231362491846085\n",
      "Epoch: 4000 train loss=0.005154479 valid loss= 0.004506035\n",
      "train reg_fs: 0.0009117271401919425\n",
      "Epoch: 4500 train loss=0.006912685 valid loss= 0.004544257\n",
      "train reg_fs: 0.0009035654366016388\n",
      "Epoch: 5000 train loss=0.003185112 valid loss= 0.004385329\n",
      "train reg_fs: 0.0008945034933276474\n",
      "Epoch: 5500 train loss=0.001679143 valid loss= 0.004419068\n",
      "train reg_fs: 0.0008891961188055575\n",
      "Epoch: 6000 train loss=0.002588800 valid loss= 0.004427264\n",
      "train reg_fs: 0.0008831178420223296\n",
      "Epoch: 6500 train loss=0.002488720 valid loss= 0.004479744\n",
      "train reg_fs: 0.0008767570252530277\n",
      "Epoch: 7000 train loss=0.003546470 valid loss= 0.004549049\n",
      "train reg_fs: 0.000871198542881757\n",
      "Epoch: 7500 train loss=0.002084474 valid loss= 0.004598215\n",
      "train reg_fs: 0.0008643193868920207\n",
      "Epoch: 8000 train loss=0.002736622 valid loss= 0.004515785\n",
      "train reg_fs: 0.0008605435723438859\n",
      "Epoch: 8500 train loss=0.001900681 valid loss= 0.004632511\n",
      "train reg_fs: 0.0008542152354493737\n",
      "Epoch: 9000 train loss=0.001363931 valid loss= 0.004512352\n",
      "train reg_fs: 0.0008519711554981768\n",
      "Epoch: 9500 train loss=0.001685195 valid loss= 0.004450172\n",
      "train reg_fs: 0.0008477994124405086\n",
      "Epoch: 10000 train loss=0.001454629 valid loss= 0.004682255\n",
      "train reg_fs: 0.0008432638715021312\n",
      "Epoch: 10500 train loss=0.002396949 valid loss= 0.004696595\n",
      "train reg_fs: 0.0008382416563108563\n",
      "Epoch: 11000 train loss=0.001432448 valid loss= 0.004868546\n",
      "train reg_fs: 0.0008353441371582448\n",
      "Epoch: 11500 train loss=0.002448932 valid loss= 0.004937938\n",
      "train reg_fs: 0.0008319337503053248\n",
      "Epoch: 12000 train loss=0.001243199 valid loss= 0.004836109\n",
      "train reg_fs: 0.0008290344849228859\n",
      "Epoch: 12500 train loss=0.006526557 valid loss= 0.004837792\n",
      "train reg_fs: 0.0008245623321272433\n",
      "Epoch: 13000 train loss=0.003051909 valid loss= 0.005100121\n",
      "train reg_fs: 0.0008232408436015248\n",
      "Epoch: 13500 train loss=0.002031975 valid loss= 0.005015731\n",
      "train reg_fs: 0.000819315027911216\n",
      "Epoch: 14000 train loss=0.002707935 valid loss= 0.004981832\n",
      "train reg_fs: 0.0008156750118359923\n",
      "Epoch: 14500 train loss=0.003324508 valid loss= 0.005085791\n",
      "train reg_fs: 0.0008120015845634043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:29:55,893]\u001b[0m Trial 53 finished with value: 0.004052427421152404 and parameters: {'lam': 0.0012571913841931295, 'learning_rate': 0.148579284233222, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002870364 valid loss= 0.004898880\n",
      "train reg_fs: 0.0008116501267068088\n",
      "In trial:---------------------\n",
      "validation mse: 0.004052427421152404\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014598181 valid loss= 0.006445351\n",
      "train reg_fs: 0.0026299788150936365\n",
      "Epoch: 1000 train loss=0.007667793 valid loss= 0.005427260\n",
      "train reg_fs: 0.0024565753992646933\n",
      "Epoch: 1500 train loss=0.002550491 valid loss= 0.005521519\n",
      "train reg_fs: 0.0023719724267721176\n",
      "Epoch: 2000 train loss=0.004872562 valid loss= 0.004583466\n",
      "train reg_fs: 0.0023209936916828156\n",
      "Epoch: 2500 train loss=0.004823961 valid loss= 0.005222524\n",
      "train reg_fs: 0.0022822802420705557\n",
      "Epoch: 3000 train loss=0.004228760 valid loss= 0.004558093\n",
      "train reg_fs: 0.00226051383651793\n",
      "Epoch: 3500 train loss=0.006154554 valid loss= 0.004276718\n",
      "train reg_fs: 0.0022453300189226866\n",
      "Epoch: 4000 train loss=0.003123625 valid loss= 0.004167875\n",
      "train reg_fs: 0.002219902817159891\n",
      "Epoch: 4500 train loss=0.003933806 valid loss= 0.003987181\n",
      "train reg_fs: 0.002194034168496728\n",
      "Epoch: 5000 train loss=0.003212479 valid loss= 0.004258328\n",
      "train reg_fs: 0.002162626013159752\n",
      "Epoch: 5500 train loss=0.006366825 valid loss= 0.004510744\n",
      "train reg_fs: 0.0021060302387923002\n",
      "Epoch: 6000 train loss=0.002578773 valid loss= 0.004470134\n",
      "train reg_fs: 0.002050714800134301\n",
      "Epoch: 6500 train loss=0.002979482 valid loss= 0.004316916\n",
      "train reg_fs: 0.0020117005333304405\n",
      "Epoch: 7000 train loss=0.004243631 valid loss= 0.004420439\n",
      "train reg_fs: 0.0019824118353426456\n",
      "Epoch: 7500 train loss=0.004025792 valid loss= 0.004116749\n",
      "train reg_fs: 0.0019648822490125895\n",
      "Epoch: 8000 train loss=0.002467340 valid loss= 0.004280614\n",
      "train reg_fs: 0.0019531904254108667\n",
      "Epoch: 8500 train loss=0.003896593 valid loss= 0.004169468\n",
      "train reg_fs: 0.00194590596947819\n",
      "Epoch: 9000 train loss=0.005445299 valid loss= 0.004634399\n",
      "train reg_fs: 0.0019396075513213873\n",
      "Epoch: 9500 train loss=0.002849069 valid loss= 0.004447421\n",
      "train reg_fs: 0.0019350523361936212\n",
      "Epoch: 10000 train loss=0.003282413 valid loss= 0.004166253\n",
      "train reg_fs: 0.0019311823416501284\n",
      "Epoch: 10500 train loss=0.003353218 valid loss= 0.004434915\n",
      "train reg_fs: 0.0019277152605354786\n",
      "Epoch: 11000 train loss=0.004889563 valid loss= 0.003972773\n",
      "train reg_fs: 0.0019250429468229413\n",
      "Epoch: 11500 train loss=0.002603679 valid loss= 0.004389822\n",
      "train reg_fs: 0.0019228518940508366\n",
      "Epoch: 12000 train loss=0.002577904 valid loss= 0.004492383\n",
      "train reg_fs: 0.0019209436140954494\n",
      "Epoch: 12500 train loss=0.004917394 valid loss= 0.004238629\n",
      "train reg_fs: 0.00191947678104043\n",
      "Epoch: 13000 train loss=0.003398180 valid loss= 0.003965362\n",
      "train reg_fs: 0.0019180128583684564\n",
      "Epoch: 13500 train loss=0.002992708 valid loss= 0.004023185\n",
      "train reg_fs: 0.0019167165737599134\n",
      "Epoch: 14000 train loss=0.002255411 valid loss= 0.003893533\n",
      "train reg_fs: 0.001915452186949551\n",
      "Epoch: 14500 train loss=0.004168640 valid loss= 0.004216707\n",
      "train reg_fs: 0.0019144534599035978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:31:30,740]\u001b[0m Trial 54 finished with value: 0.0021082446265529207 and parameters: {'lam': 0.0031828768874612003, 'learning_rate': 0.16851452666498185, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002545447 valid loss= 0.003970179\n",
      "train reg_fs: 0.0019134385511279106\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021082446265529207\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017847493 valid loss= 0.009151521\n",
      "train reg_fs: 0.001201093546114862\n",
      "Epoch: 1000 train loss=0.005580411 valid loss= 0.007547425\n",
      "train reg_fs: 0.001148149953223765\n",
      "Epoch: 1500 train loss=0.003428110 valid loss= 0.006780877\n",
      "train reg_fs: 0.0011146372416988015\n",
      "Epoch: 2000 train loss=0.006287749 valid loss= 0.005679726\n",
      "train reg_fs: 0.0011033089831471443\n",
      "Epoch: 2500 train loss=0.002856551 valid loss= 0.005259663\n",
      "train reg_fs: 0.0010859754402190447\n",
      "Epoch: 3000 train loss=0.003107882 valid loss= 0.004118113\n",
      "train reg_fs: 0.0010639714309945703\n",
      "Epoch: 3500 train loss=0.003029233 valid loss= 0.004412265\n",
      "train reg_fs: 0.0010350680677220225\n",
      "Epoch: 4000 train loss=0.005592790 valid loss= 0.004176992\n",
      "train reg_fs: 0.0010117660276591778\n",
      "Epoch: 4500 train loss=0.001695701 valid loss= 0.004026045\n",
      "train reg_fs: 0.0009981895564123988\n",
      "Epoch: 5000 train loss=0.001873962 valid loss= 0.003924991\n",
      "train reg_fs: 0.00099021359346807\n",
      "Epoch: 5500 train loss=0.002715283 valid loss= 0.004362968\n",
      "train reg_fs: 0.0009823022410273552\n",
      "Epoch: 6000 train loss=0.001628220 valid loss= 0.004024226\n",
      "train reg_fs: 0.0009780197869986296\n",
      "Epoch: 6500 train loss=0.001818138 valid loss= 0.003813810\n",
      "train reg_fs: 0.0009711197344586253\n",
      "Epoch: 7000 train loss=0.001449951 valid loss= 0.003753440\n",
      "train reg_fs: 0.0009669953724369407\n",
      "Epoch: 7500 train loss=0.001610081 valid loss= 0.004177646\n",
      "train reg_fs: 0.0009630011045373976\n",
      "Epoch: 8000 train loss=0.007876066 valid loss= 0.004304188\n",
      "train reg_fs: 0.0009614981827326119\n",
      "Epoch: 8500 train loss=0.004223713 valid loss= 0.003827974\n",
      "train reg_fs: 0.0009578265598975122\n",
      "Epoch: 9000 train loss=0.001530696 valid loss= 0.003932835\n",
      "train reg_fs: 0.0009537506848573685\n",
      "Epoch: 9500 train loss=0.002814940 valid loss= 0.003839626\n",
      "train reg_fs: 0.0009501446620561182\n",
      "Epoch: 10000 train loss=0.003441963 valid loss= 0.003955699\n",
      "train reg_fs: 0.0009481018641963601\n",
      "Epoch: 10500 train loss=0.002714626 valid loss= 0.004113626\n",
      "train reg_fs: 0.000944090832490474\n",
      "Epoch: 11000 train loss=0.001577261 valid loss= 0.003882627\n",
      "train reg_fs: 0.000941414968110621\n",
      "Epoch: 11500 train loss=0.003506276 valid loss= 0.004070313\n",
      "train reg_fs: 0.000941832026001066\n",
      "Epoch: 12000 train loss=0.003752478 valid loss= 0.003835110\n",
      "train reg_fs: 0.0009379216353408992\n",
      "Epoch: 12500 train loss=0.004107377 valid loss= 0.004106039\n",
      "train reg_fs: 0.0009325598366558552\n",
      "Epoch: 13000 train loss=0.003516205 valid loss= 0.004129956\n",
      "train reg_fs: 0.0009333181660622358\n",
      "Epoch: 13500 train loss=0.001700204 valid loss= 0.004337454\n",
      "train reg_fs: 0.0009304555132985115\n",
      "Epoch: 14000 train loss=0.001326887 valid loss= 0.004005627\n",
      "train reg_fs: 0.0009245034889318049\n",
      "Epoch: 14500 train loss=0.001421547 valid loss= 0.003856465\n",
      "train reg_fs: 0.0009211921715177596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:33:07,461]\u001b[0m Trial 55 finished with value: 0.003042795898380956 and parameters: {'lam': 0.0013650121224895889, 'learning_rate': 0.1717577824306553, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001597900 valid loss= 0.003945473\n",
      "train reg_fs: 0.0009198372717946768\n",
      "In trial:---------------------\n",
      "validation mse: 0.003042795898380956\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022862017 valid loss= 0.008832574\n",
      "train reg_fs: 0.0011439351364970207\n",
      "Epoch: 1000 train loss=0.004633224 valid loss= 0.008376240\n",
      "train reg_fs: 0.0011540326522663236\n",
      "Epoch: 1500 train loss=0.013029359 valid loss= 0.006753944\n",
      "train reg_fs: 0.0011357292532920837\n",
      "Epoch: 2000 train loss=0.008102205 valid loss= 0.005720501\n",
      "train reg_fs: 0.0010964790126308799\n",
      "Epoch: 2500 train loss=0.003355396 valid loss= 0.004935850\n",
      "train reg_fs: 0.0010539194336161017\n",
      "Epoch: 3000 train loss=0.004377290 valid loss= 0.003656029\n",
      "train reg_fs: 0.0010176505893468857\n",
      "Epoch: 3500 train loss=0.003862029 valid loss= 0.003785043\n",
      "train reg_fs: 0.0009910068474709988\n",
      "Epoch: 4000 train loss=0.003977851 valid loss= 0.003823437\n",
      "train reg_fs: 0.0009737653890624642\n",
      "Epoch: 4500 train loss=0.002580680 valid loss= 0.003868913\n",
      "train reg_fs: 0.000958738150075078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:33:41,361]\u001b[0m Trial 56 finished with value: 0.0032675370828452806 and parameters: {'lam': 0.0012877587546825788, 'learning_rate': 0.10438176792834952, 'num_epoch': 5000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003866276 valid loss= 0.004202264\n",
      "train reg_fs: 0.0009490041411481798\n",
      "In trial:---------------------\n",
      "validation mse: 0.0032675370828452806\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014255867 valid loss= 0.007327354\n",
      "train reg_fs: 0.0015947811771184206\n",
      "Epoch: 1000 train loss=0.006470286 valid loss= 0.006681393\n",
      "train reg_fs: 0.001549446489661932\n",
      "Epoch: 1500 train loss=0.003404870 valid loss= 0.004459262\n",
      "train reg_fs: 0.0015045716427266598\n",
      "Epoch: 2000 train loss=0.004436884 valid loss= 0.004612260\n",
      "train reg_fs: 0.0014552850043401122\n",
      "Epoch: 2500 train loss=0.004239349 valid loss= 0.004056696\n",
      "train reg_fs: 0.0014343808870762587\n",
      "Epoch: 3000 train loss=0.002753151 valid loss= 0.004705151\n",
      "train reg_fs: 0.0014237924478948116\n",
      "Epoch: 3500 train loss=0.004896834 valid loss= 0.004441453\n",
      "train reg_fs: 0.001409347401931882\n",
      "Epoch: 4000 train loss=0.002759396 valid loss= 0.004260948\n",
      "train reg_fs: 0.0013910738052800298\n",
      "Epoch: 4500 train loss=0.009915503 valid loss= 0.003821074\n",
      "train reg_fs: 0.0013736148830503225\n",
      "Epoch: 5000 train loss=0.002529133 valid loss= 0.004045455\n",
      "train reg_fs: 0.0013611195608973503\n",
      "Epoch: 5500 train loss=0.003738246 valid loss= 0.003807976\n",
      "train reg_fs: 0.0013456050073727965\n",
      "Epoch: 6000 train loss=0.004308764 valid loss= 0.003584332\n",
      "train reg_fs: 0.0013332677772268653\n",
      "Epoch: 6500 train loss=0.003202690 valid loss= 0.003890223\n",
      "train reg_fs: 0.0013222789857536554\n",
      "Epoch: 7000 train loss=0.002878637 valid loss= 0.004013531\n",
      "train reg_fs: 0.00131379091180861\n",
      "Epoch: 7500 train loss=0.001917202 valid loss= 0.003947114\n",
      "train reg_fs: 0.0013039158657193184\n",
      "Epoch: 8000 train loss=0.004694026 valid loss= 0.003541100\n",
      "train reg_fs: 0.0012971577234566212\n",
      "Epoch: 8500 train loss=0.002316168 valid loss= 0.003572043\n",
      "train reg_fs: 0.0012922873720526695\n",
      "Epoch: 9000 train loss=0.002235082 valid loss= 0.004019586\n",
      "train reg_fs: 0.0012860862771049142\n",
      "Epoch: 9500 train loss=0.003287206 valid loss= 0.003786820\n",
      "train reg_fs: 0.0012835696106776595\n",
      "Epoch: 10000 train loss=0.001628520 valid loss= 0.003280128\n",
      "train reg_fs: 0.0012772234622389078\n",
      "Epoch: 10500 train loss=0.001870010 valid loss= 0.003538895\n",
      "train reg_fs: 0.001271735643967986\n",
      "Epoch: 11000 train loss=0.004706439 valid loss= 0.003743853\n",
      "train reg_fs: 0.0012672233860939741\n",
      "Epoch: 11500 train loss=0.001568759 valid loss= 0.003554411\n",
      "train reg_fs: 0.0012646738905459642\n",
      "Epoch: 12000 train loss=0.002271603 valid loss= 0.003627506\n",
      "train reg_fs: 0.0012591659324243665\n",
      "Epoch: 12500 train loss=0.001675512 valid loss= 0.003297504\n",
      "train reg_fs: 0.0012568329693749547\n",
      "Epoch: 13000 train loss=0.001759453 valid loss= 0.003626655\n",
      "train reg_fs: 0.0012524250196292996\n",
      "Epoch: 13500 train loss=0.001912813 valid loss= 0.003550394\n",
      "train reg_fs: 0.0012521061580628157\n",
      "Epoch: 14000 train loss=0.001700758 valid loss= 0.003658638\n",
      "train reg_fs: 0.0012480829609557986\n",
      "Epoch: 14500 train loss=0.006281056 valid loss= 0.004073163\n",
      "train reg_fs: 0.0012451643124222755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:35:21,460]\u001b[0m Trial 57 finished with value: 0.0024202102002830756 and parameters: {'lam': 0.0018311310403934405, 'learning_rate': 0.13834511663541105, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002352571 valid loss= 0.003622690\n",
      "train reg_fs: 0.0012428973568603396\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024202102002830756\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022602819 valid loss= 0.010846630\n",
      "train reg_fs: 0.0033495170064270496\n",
      "Epoch: 1000 train loss=0.009310639 valid loss= 0.011635570\n",
      "train reg_fs: 0.0033959802240133286\n",
      "Epoch: 1500 train loss=0.010268489 valid loss= 0.012219052\n",
      "train reg_fs: 0.0033883070573210716\n",
      "Epoch: 2000 train loss=0.007784364 valid loss= 0.011618878\n",
      "train reg_fs: 0.0033189598470926285\n",
      "Epoch: 2500 train loss=0.005872739 valid loss= 0.010150148\n",
      "train reg_fs: 0.00324205681681633\n",
      "Epoch: 3000 train loss=0.008445860 valid loss= 0.009287674\n",
      "train reg_fs: 0.003187251277267933\n",
      "Epoch: 3500 train loss=0.007762290 valid loss= 0.009197694\n",
      "train reg_fs: 0.003151204902678728\n",
      "Epoch: 4000 train loss=0.008341774 valid loss= 0.008691704\n",
      "train reg_fs: 0.0031255336944013834\n",
      "Epoch: 4500 train loss=0.004387011 valid loss= 0.008595386\n",
      "train reg_fs: 0.003105700481683016\n",
      "Epoch: 5000 train loss=0.003973535 valid loss= 0.007657889\n",
      "train reg_fs: 0.0030998524744063616\n",
      "Epoch: 5500 train loss=0.006605332 valid loss= 0.007796758\n",
      "train reg_fs: 0.003087275428697467\n",
      "Epoch: 6000 train loss=0.007150283 valid loss= 0.007287185\n",
      "train reg_fs: 0.00306690507568419\n",
      "Epoch: 6500 train loss=0.005477837 valid loss= 0.006843502\n",
      "train reg_fs: 0.0030570069793611765\n",
      "Epoch: 7000 train loss=0.004422537 valid loss= 0.006960300\n",
      "train reg_fs: 0.003034070134162903\n",
      "Epoch: 7500 train loss=0.005470717 valid loss= 0.007395324\n",
      "train reg_fs: 0.003011561231687665\n",
      "Epoch: 8000 train loss=0.003431888 valid loss= 0.007126835\n",
      "train reg_fs: 0.0029937380459159613\n",
      "Epoch: 8500 train loss=0.005855050 valid loss= 0.007289555\n",
      "train reg_fs: 0.0029696812853217125\n",
      "Epoch: 9000 train loss=0.005422793 valid loss= 0.007167725\n",
      "train reg_fs: 0.0029500052332878113\n",
      "Epoch: 9500 train loss=0.004606866 valid loss= 0.007423816\n",
      "train reg_fs: 0.002931910799816251\n",
      "Epoch: 10000 train loss=0.003818220 valid loss= 0.007450169\n",
      "train reg_fs: 0.0029113139025866985\n",
      "Epoch: 10500 train loss=0.006715484 valid loss= 0.007257686\n",
      "train reg_fs: 0.002889455994591117\n",
      "Epoch: 11000 train loss=0.004132911 valid loss= 0.007328315\n",
      "train reg_fs: 0.0028710111510008574\n",
      "Epoch: 11500 train loss=0.004389266 valid loss= 0.007548170\n",
      "train reg_fs: 0.002850982826203108\n",
      "Epoch: 12000 train loss=0.004024474 valid loss= 0.007833710\n",
      "train reg_fs: 0.002832690952345729\n",
      "Epoch: 12500 train loss=0.004059127 valid loss= 0.007560777\n",
      "train reg_fs: 0.0028191697783768177\n",
      "Epoch: 13000 train loss=0.005236511 valid loss= 0.007466018\n",
      "train reg_fs: 0.002801173599436879\n",
      "Epoch: 13500 train loss=0.003980256 valid loss= 0.007725926\n",
      "train reg_fs: 0.002782221417874098\n",
      "Epoch: 14000 train loss=0.003672233 valid loss= 0.007828869\n",
      "train reg_fs: 0.002766332821920514\n",
      "Epoch: 14500 train loss=0.004088371 valid loss= 0.007706073\n",
      "train reg_fs: 0.00274514127522707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:37:00,734]\u001b[0m Trial 58 finished with value: 0.00505657011582325 and parameters: {'lam': 0.0038363930263235185, 'learning_rate': 0.08958440985888318, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006239026 valid loss= 0.007805386\n",
      "train reg_fs: 0.0027316282503306866\n",
      "In trial:---------------------\n",
      "validation mse: 0.00505657011582325\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011818959 valid loss= 0.007708380\n",
      "train reg_fs: 0.0012558993184939027\n",
      "Epoch: 1000 train loss=0.010758054 valid loss= 0.008214249\n",
      "train reg_fs: 0.0012535612331703305\n",
      "Epoch: 1500 train loss=0.004982856 valid loss= 0.007719641\n",
      "train reg_fs: 0.0012235502945259213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:37:15,398]\u001b[0m Trial 59 finished with value: 0.005592057807751365 and parameters: {'lam': 0.0014346642309730983, 'learning_rate': 0.10686279610366928, 'num_epoch': 2000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.005906273 valid loss= 0.006837156\n",
      "train reg_fs: 0.0012120036408305168\n",
      "In trial:---------------------\n",
      "validation mse: 0.005592057807751365\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008579886 valid loss= 0.005929688\n",
      "train reg_fs: 0.0009599208133295178\n",
      "Epoch: 1000 train loss=0.010039265 valid loss= 0.004085103\n",
      "train reg_fs: 0.0008908321615308523\n",
      "Epoch: 1500 train loss=0.006633197 valid loss= 0.003534896\n",
      "train reg_fs: 0.0008624815382063389\n",
      "Epoch: 2000 train loss=0.001487081 valid loss= 0.003483048\n",
      "train reg_fs: 0.0008472643094137311\n",
      "Epoch: 2500 train loss=0.001968050 valid loss= 0.003360557\n",
      "train reg_fs: 0.0008313077269122005\n",
      "Epoch: 3000 train loss=0.003953223 valid loss= 0.003247639\n",
      "train reg_fs: 0.0008190685184672475\n",
      "Epoch: 3500 train loss=0.001877960 valid loss= 0.003087383\n",
      "train reg_fs: 0.0008086998132057488\n",
      "Epoch: 4000 train loss=0.004756636 valid loss= 0.003207600\n",
      "train reg_fs: 0.0007985351257957518\n",
      "Epoch: 4500 train loss=0.001396024 valid loss= 0.003121422\n",
      "train reg_fs: 0.0007871649577282369\n",
      "Epoch: 5000 train loss=0.001094213 valid loss= 0.002818973\n",
      "train reg_fs: 0.0007772783865220845\n",
      "Epoch: 5500 train loss=0.001506452 valid loss= 0.003231036\n",
      "train reg_fs: 0.0007654433720745146\n",
      "Epoch: 6000 train loss=0.007997897 valid loss= 0.003049716\n",
      "train reg_fs: 0.0007526838453486562\n",
      "Epoch: 6500 train loss=0.007841651 valid loss= 0.003569952\n",
      "train reg_fs: 0.000739867624361068\n",
      "Epoch: 7000 train loss=0.006769245 valid loss= 0.002695754\n",
      "train reg_fs: 0.0007280006539076567\n",
      "Epoch: 7500 train loss=0.013156821 valid loss= 0.003252633\n",
      "train reg_fs: 0.0007200445979833603\n",
      "Epoch: 8000 train loss=0.001871623 valid loss= 0.003116965\n",
      "train reg_fs: 0.0007131820311769843\n",
      "Epoch: 8500 train loss=0.001134654 valid loss= 0.003056636\n",
      "train reg_fs: 0.0007074130116961896\n",
      "Epoch: 9000 train loss=0.001251043 valid loss= 0.003149793\n",
      "train reg_fs: 0.0007023398648016155\n",
      "Epoch: 9500 train loss=0.001188320 valid loss= 0.002673390\n",
      "train reg_fs: 0.0006990820402279496\n",
      "Epoch: 10000 train loss=0.006458797 valid loss= 0.003035815\n",
      "train reg_fs: 0.0006958160665817559\n",
      "Epoch: 10500 train loss=0.001989072 valid loss= 0.003174234\n",
      "train reg_fs: 0.0006930319941602647\n",
      "Epoch: 11000 train loss=0.004600680 valid loss= 0.002783398\n",
      "train reg_fs: 0.0006907803472131491\n",
      "Epoch: 11500 train loss=0.001840806 valid loss= 0.003077332\n",
      "train reg_fs: 0.0006886461633257568\n",
      "Epoch: 12000 train loss=0.004104441 valid loss= 0.002793547\n",
      "train reg_fs: 0.0006868908531032503\n",
      "Epoch: 12500 train loss=0.001802105 valid loss= 0.002943626\n",
      "train reg_fs: 0.0006851482321508229\n",
      "Epoch: 13000 train loss=0.001591299 valid loss= 0.002638291\n",
      "train reg_fs: 0.000683712656609714\n",
      "Epoch: 13500 train loss=0.001969969 valid loss= 0.002741128\n",
      "train reg_fs: 0.0006823488511145115\n",
      "Epoch: 14000 train loss=0.001123822 valid loss= 0.003156610\n",
      "train reg_fs: 0.0006812160718254745\n",
      "Epoch: 14500 train loss=0.004664767 valid loss= 0.002900354\n",
      "train reg_fs: 0.000680239056237042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:38:56,632]\u001b[0m Trial 60 finished with value: 0.0024506438564275927 and parameters: {'lam': 0.0011120085742816392, 'learning_rate': 0.12975479111046914, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004982404 valid loss= 0.003116084\n",
      "train reg_fs: 0.0006793694337829947\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024506438564275927\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.004204234 valid loss= 0.007408222\n",
      "train reg_fs: 0.0008606216288171709\n",
      "Epoch: 1000 train loss=0.005879309 valid loss= 0.004037298\n",
      "train reg_fs: 0.0008265014039352536\n",
      "Epoch: 1500 train loss=0.005438773 valid loss= 0.003052586\n",
      "train reg_fs: 0.000798392400611192\n",
      "Epoch: 2000 train loss=0.003886301 valid loss= 0.003651814\n",
      "train reg_fs: 0.0007804037886671722\n",
      "Epoch: 2500 train loss=0.002676220 valid loss= 0.003481374\n",
      "train reg_fs: 0.00076646963134408\n",
      "Epoch: 3000 train loss=0.001949562 valid loss= 0.003886625\n",
      "train reg_fs: 0.000755575078073889\n",
      "Epoch: 3500 train loss=0.001252564 valid loss= 0.003527611\n",
      "train reg_fs: 0.0007481517386622727\n",
      "Epoch: 4000 train loss=0.002510862 valid loss= 0.003127816\n",
      "train reg_fs: 0.0007419664761982858\n",
      "Epoch: 4500 train loss=0.001635852 valid loss= 0.003357311\n",
      "train reg_fs: 0.0007380993338301778\n",
      "Epoch: 5000 train loss=0.001323611 valid loss= 0.003467906\n",
      "train reg_fs: 0.0007345139165408909\n",
      "Epoch: 5500 train loss=0.004002360 valid loss= 0.003483847\n",
      "train reg_fs: 0.0007329393411055207\n",
      "Epoch: 6000 train loss=0.001181182 valid loss= 0.002869385\n",
      "train reg_fs: 0.000730217550881207\n",
      "Epoch: 6500 train loss=0.001330612 valid loss= 0.003473181\n",
      "train reg_fs: 0.0007282624137587845\n",
      "Epoch: 7000 train loss=0.002635394 valid loss= 0.002831711\n",
      "train reg_fs: 0.0007263222942128778\n",
      "Epoch: 7500 train loss=0.003862910 valid loss= 0.002747600\n",
      "train reg_fs: 0.0007251915521919727\n",
      "Epoch: 8000 train loss=0.004596243 valid loss= 0.002978511\n",
      "train reg_fs: 0.0007243139552883804\n",
      "Epoch: 8500 train loss=0.001900540 valid loss= 0.002727951\n",
      "train reg_fs: 0.0007229822222143412\n",
      "Epoch: 9000 train loss=0.002409998 valid loss= 0.003080955\n",
      "train reg_fs: 0.0007217684178613126\n",
      "Epoch: 9500 train loss=0.004479660 valid loss= 0.003155999\n",
      "train reg_fs: 0.0007201764383353293\n",
      "Epoch: 10000 train loss=0.001248997 valid loss= 0.002569057\n",
      "train reg_fs: 0.0007187970913946629\n",
      "Epoch: 10500 train loss=0.000979093 valid loss= 0.002642090\n",
      "train reg_fs: 0.0007182308472692966\n",
      "Epoch: 11000 train loss=0.002207831 valid loss= 0.002436660\n",
      "train reg_fs: 0.0007173335761763155\n",
      "Epoch: 11500 train loss=0.000912925 valid loss= 0.002820084\n",
      "train reg_fs: 0.0007169321179389954\n",
      "Epoch: 12000 train loss=0.004306125 valid loss= 0.002805467\n",
      "train reg_fs: 0.0007164904964156449\n",
      "Epoch: 12500 train loss=0.001675481 valid loss= 0.002690597\n",
      "train reg_fs: 0.0007161087123677135\n",
      "Epoch: 13000 train loss=0.000975121 valid loss= 0.002949016\n",
      "train reg_fs: 0.0007152264006435871\n",
      "Epoch: 13500 train loss=0.001524684 valid loss= 0.002621982\n",
      "train reg_fs: 0.0007143200491555035\n",
      "Epoch: 14000 train loss=0.002414175 valid loss= 0.002585785\n",
      "train reg_fs: 0.0007131837191991508\n",
      "Epoch: 14500 train loss=0.001045043 valid loss= 0.002571536\n",
      "train reg_fs: 0.0007126420387066901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:40:34,689]\u001b[0m Trial 61 finished with value: 0.0018862940674741258 and parameters: {'lam': 0.0010131150928934516, 'learning_rate': 0.1183571940280598, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003515311 valid loss= 0.002568660\n",
      "train reg_fs: 0.0007117302156984806\n",
      "In trial:---------------------\n",
      "validation mse: 0.0018862940674741258\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011451950 valid loss= 0.006519410\n",
      "train reg_fs: 0.0008845514385029674\n",
      "Epoch: 1000 train loss=0.009236456 valid loss= 0.004859136\n",
      "train reg_fs: 0.0008473971392959356\n",
      "Epoch: 1500 train loss=0.007382000 valid loss= 0.002978417\n",
      "train reg_fs: 0.0008059387328103185\n",
      "Epoch: 2000 train loss=0.005855658 valid loss= 0.002662785\n",
      "train reg_fs: 0.0007868887041695416\n",
      "Epoch: 2500 train loss=0.005960721 valid loss= 0.002610391\n",
      "train reg_fs: 0.0007743475143797696\n",
      "Epoch: 3000 train loss=0.005477043 valid loss= 0.003812082\n",
      "train reg_fs: 0.0007647883612662554\n",
      "Epoch: 3500 train loss=0.001273798 valid loss= 0.003081280\n",
      "train reg_fs: 0.0007557364297099411\n",
      "Epoch: 4000 train loss=0.002669717 valid loss= 0.003232247\n",
      "train reg_fs: 0.0007469532429240644\n",
      "Epoch: 4500 train loss=0.001428190 valid loss= 0.002920938\n",
      "train reg_fs: 0.0007390978280454874\n",
      "Epoch: 5000 train loss=0.001507778 valid loss= 0.002900412\n",
      "train reg_fs: 0.0007321907905861735\n",
      "Epoch: 5500 train loss=0.001867325 valid loss= 0.003278122\n",
      "train reg_fs: 0.0007264016312547028\n",
      "Epoch: 6000 train loss=0.002267859 valid loss= 0.002928233\n",
      "train reg_fs: 0.0007208730676211417\n",
      "Epoch: 6500 train loss=0.008187460 valid loss= 0.002867337\n",
      "train reg_fs: 0.0007156954961828887\n",
      "Epoch: 7000 train loss=0.001303815 valid loss= 0.003047786\n",
      "train reg_fs: 0.0007099821814335883\n",
      "Epoch: 7500 train loss=0.004968132 valid loss= 0.002969887\n",
      "train reg_fs: 0.0007029162370599806\n",
      "Epoch: 8000 train loss=0.004013813 valid loss= 0.002806766\n",
      "train reg_fs: 0.0006980936741456389\n",
      "Epoch: 8500 train loss=0.000993453 valid loss= 0.002778357\n",
      "train reg_fs: 0.0006915831472724676\n",
      "Epoch: 9000 train loss=0.002385558 valid loss= 0.003013548\n",
      "train reg_fs: 0.0006858292035758495\n",
      "Epoch: 9500 train loss=0.001461549 valid loss= 0.002881683\n",
      "train reg_fs: 0.000680687720887363\n",
      "Epoch: 10000 train loss=0.008434528 valid loss= 0.003027811\n",
      "train reg_fs: 0.0006758763920515776\n",
      "Epoch: 10500 train loss=0.001288469 valid loss= 0.003038622\n",
      "train reg_fs: 0.000671058485750109\n",
      "Epoch: 11000 train loss=0.010423579 valid loss= 0.003100204\n",
      "train reg_fs: 0.0006673589814454317\n",
      "Epoch: 11500 train loss=0.001071612 valid loss= 0.003005537\n",
      "train reg_fs: 0.0006637283368036151\n",
      "Epoch: 12000 train loss=0.003901110 valid loss= 0.002862977\n",
      "train reg_fs: 0.0006601214990951121\n",
      "Epoch: 12500 train loss=0.001031178 valid loss= 0.002911785\n",
      "train reg_fs: 0.0006572091951966286\n",
      "Epoch: 13000 train loss=0.005380410 valid loss= 0.003121008\n",
      "train reg_fs: 0.0006541554466821253\n",
      "Epoch: 13500 train loss=0.000923154 valid loss= 0.003106663\n",
      "train reg_fs: 0.0006511131068691611\n",
      "Epoch: 14000 train loss=0.001597900 valid loss= 0.002795847\n",
      "train reg_fs: 0.0006484519108198583\n",
      "Epoch: 14500 train loss=0.001998174 valid loss= 0.003109323\n",
      "train reg_fs: 0.0006456254632212222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:42:14,018]\u001b[0m Trial 62 finished with value: 0.0027673033678123904 and parameters: {'lam': 0.0010191513303361185, 'learning_rate': 0.11292153903128034, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005317113 valid loss= 0.003403509\n",
      "train reg_fs: 0.0006429373752325773\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027673033678123904\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.002963026 valid loss= 0.006617148\n",
      "train reg_fs: 0.0010095465695485473\n",
      "Epoch: 1000 train loss=0.007867098 valid loss= 0.005514849\n",
      "train reg_fs: 0.0009516977006569505\n",
      "Epoch: 1500 train loss=0.002384124 valid loss= 0.003966843\n",
      "train reg_fs: 0.0008842407260090113\n",
      "Epoch: 2000 train loss=0.002356196 valid loss= 0.003584986\n",
      "train reg_fs: 0.0008577736443839967\n",
      "Epoch: 2500 train loss=0.001978703 valid loss= 0.003193694\n",
      "train reg_fs: 0.0008456406649202108\n",
      "Epoch: 3000 train loss=0.003834464 valid loss= 0.003185356\n",
      "train reg_fs: 0.0008409271249547601\n",
      "Epoch: 3500 train loss=0.002083371 valid loss= 0.003020062\n",
      "train reg_fs: 0.0008341495413333178\n",
      "Epoch: 4000 train loss=0.003703319 valid loss= 0.003027652\n",
      "train reg_fs: 0.0008270346443168819\n",
      "Epoch: 4500 train loss=0.003356114 valid loss= 0.003394236\n",
      "train reg_fs: 0.0008248730446211994\n",
      "Epoch: 5000 train loss=0.003367470 valid loss= 0.002797010\n",
      "train reg_fs: 0.0008203735924325883\n",
      "Epoch: 5500 train loss=0.005481413 valid loss= 0.002895529\n",
      "train reg_fs: 0.0008171202498488128\n",
      "Epoch: 6000 train loss=0.002030246 valid loss= 0.003179902\n",
      "train reg_fs: 0.0008119515841826797\n",
      "Epoch: 6500 train loss=0.001578170 valid loss= 0.003241929\n",
      "train reg_fs: 0.0008075230289250612\n",
      "Epoch: 7000 train loss=0.001957457 valid loss= 0.003316612\n",
      "train reg_fs: 0.0008084861910901964\n",
      "Epoch: 7500 train loss=0.002118017 valid loss= 0.003096537\n",
      "train reg_fs: 0.0008044381393119693\n",
      "Epoch: 8000 train loss=0.001572555 valid loss= 0.002970936\n",
      "train reg_fs: 0.0008035973296500742\n",
      "Epoch: 8500 train loss=0.001372988 valid loss= 0.003071259\n",
      "train reg_fs: 0.0008015909697860479\n",
      "Epoch: 9000 train loss=0.003949123 valid loss= 0.003090532\n",
      "train reg_fs: 0.0007999784429557621\n",
      "Epoch: 9500 train loss=0.001242134 valid loss= 0.003104579\n",
      "train reg_fs: 0.0007986362325027585\n",
      "Epoch: 10000 train loss=0.001400765 valid loss= 0.003100567\n",
      "train reg_fs: 0.0007985823904164135\n",
      "Epoch: 10500 train loss=0.005726274 valid loss= 0.003371463\n",
      "train reg_fs: 0.0007956488407216966\n",
      "Epoch: 11000 train loss=0.003145274 valid loss= 0.003335443\n",
      "train reg_fs: 0.0007922393851913512\n",
      "Epoch: 11500 train loss=0.002093493 valid loss= 0.003129568\n",
      "train reg_fs: 0.0007893033907748759\n",
      "Epoch: 12000 train loss=0.001881468 valid loss= 0.003178191\n",
      "train reg_fs: 0.0007891966961324215\n",
      "Epoch: 12500 train loss=0.001361253 valid loss= 0.003242971\n",
      "train reg_fs: 0.0007863312494009733\n",
      "Epoch: 13500 train loss=0.001192196 valid loss= 0.003517751\n",
      "train reg_fs: 0.0007830484537407756\n",
      "Epoch: 14000 train loss=0.001242495 valid loss= 0.003082506\n",
      "train reg_fs: 0.0007788165239617229\n",
      "Epoch: 14500 train loss=0.001832888 valid loss= 0.003482050\n",
      "train reg_fs: 0.0007789225201122463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:43:53,355]\u001b[0m Trial 63 finished with value: 0.002525780479196181 and parameters: {'lam': 0.0011413536362712441, 'learning_rate': 0.1731099420181286, 'num_epoch': 15000}. Best is trial 52 with value: 0.0004479713151502902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002058736 valid loss= 0.003280496\n",
      "train reg_fs: 0.0007802906329743564\n",
      "In trial:---------------------\n",
      "validation mse: 0.002525780479196181\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019906815 valid loss= 0.008576143\n",
      "train reg_fs: 0.0011088547762483358\n",
      "Epoch: 1000 train loss=0.011126397 valid loss= 0.004030507\n",
      "train reg_fs: 0.0010395388817414641\n",
      "Epoch: 1500 train loss=0.001709298 valid loss= 0.003423055\n",
      "train reg_fs: 0.0010024202056229115\n",
      "Epoch: 2000 train loss=0.008391248 valid loss= 0.003649752\n",
      "train reg_fs: 0.000991939683444798\n",
      "Epoch: 2500 train loss=0.002314624 valid loss= 0.003737454\n",
      "train reg_fs: 0.0009747036965563893\n",
      "Epoch: 3000 train loss=0.006264686 valid loss= 0.003470282\n",
      "train reg_fs: 0.0009573590941727161\n",
      "Epoch: 3500 train loss=0.001432991 valid loss= 0.002752147\n",
      "train reg_fs: 0.0009431621292605996\n",
      "Epoch: 4000 train loss=0.002825170 valid loss= 0.003052860\n",
      "train reg_fs: 0.0009336278890259564\n",
      "Epoch: 4500 train loss=0.002348654 valid loss= 0.002660458\n",
      "train reg_fs: 0.0009233041782863438\n",
      "Epoch: 5000 train loss=0.004389741 valid loss= 0.002266860\n",
      "train reg_fs: 0.0009131215629167855\n",
      "Epoch: 5500 train loss=0.001295592 valid loss= 0.002476508\n",
      "train reg_fs: 0.0009025745093822479\n",
      "Epoch: 6000 train loss=0.011093310 valid loss= 0.001890022\n",
      "train reg_fs: 0.0008917682571336627\n",
      "Epoch: 6500 train loss=0.003212482 valid loss= 0.001657671\n",
      "train reg_fs: 0.000884257024154067\n",
      "Epoch: 7000 train loss=0.003910375 valid loss= 0.001836432\n",
      "train reg_fs: 0.0008778885821811855\n",
      "Epoch: 7500 train loss=0.001252896 valid loss= 0.002110204\n",
      "train reg_fs: 0.0008719480247236788\n",
      "Epoch: 8000 train loss=0.003551547 valid loss= 0.001980113\n",
      "train reg_fs: 0.0008677860023453832\n",
      "Epoch: 8500 train loss=0.001763021 valid loss= 0.001626543\n",
      "train reg_fs: 0.0008643244509585202\n",
      "Epoch: 9000 train loss=0.001284133 valid loss= 0.001260339\n",
      "train reg_fs: 0.0008613772806711495\n",
      "Epoch: 9500 train loss=0.001753049 valid loss= 0.001768558\n",
      "train reg_fs: 0.0008594518876634538\n",
      "Epoch: 5000 train loss=0.002849887 valid loss= 0.004033303\n",
      "train reg_fs: 0.0009455967810936272\n",
      "Epoch: 5500 train loss=0.004765759 valid loss= 0.004257046\n",
      "train reg_fs: 0.0009370198240503669\n",
      "Epoch: 6000 train loss=0.002874646 valid loss= 0.004043872\n",
      "train reg_fs: 0.0009322771802544594\n",
      "Epoch: 6500 train loss=0.001523531 valid loss= 0.003834687\n",
      "train reg_fs: 0.0009259513462893665\n",
      "Epoch: 7000 train loss=0.004231181 valid loss= 0.004080897\n",
      "train reg_fs: 0.0009202177170664072\n",
      "Epoch: 7500 train loss=0.002388357 valid loss= 0.004017759\n",
      "train reg_fs: 0.0009175883023999631\n",
      "Epoch: 8000 train loss=0.003003440 valid loss= 0.004347043\n",
      "train reg_fs: 0.0009121997281908989\n",
      "Epoch: 8500 train loss=0.001858034 valid loss= 0.004392657\n",
      "train reg_fs: 0.0009065280319191515\n",
      "Epoch: 9000 train loss=0.003778308 valid loss= 0.003805269\n",
      "train reg_fs: 0.0009052129462361336\n",
      "Epoch: 9500 train loss=0.001801441 valid loss= 0.003980480\n",
      "train reg_fs: 0.0009051616070792079\n",
      "Epoch: 10000 train loss=0.001548989 valid loss= 0.003821987\n",
      "train reg_fs: 0.0009030532673932612\n",
      "Epoch: 10500 train loss=0.001271371 valid loss= 0.004131625\n",
      "train reg_fs: 0.0008973345393314958\n",
      "Epoch: 11000 train loss=0.003431662 valid loss= 0.004027885\n",
      "train reg_fs: 0.0008951025665737689\n",
      "Epoch: 11500 train loss=0.001776302 valid loss= 0.003896963\n",
      "train reg_fs: 0.0008891806355677545\n",
      "Epoch: 12000 train loss=0.002737322 valid loss= 0.004449104\n",
      "train reg_fs: 0.0008848899160511792\n",
      "Epoch: 12500 train loss=0.001253754 valid loss= 0.004160942\n",
      "train reg_fs: 0.000882460328284651\n",
      "Epoch: 13000 train loss=0.001200392 valid loss= 0.004529394\n",
      "train reg_fs: 0.0008788834675215185\n",
      "Epoch: 13500 train loss=0.002237041 valid loss= 0.004389205\n",
      "train reg_fs: 0.0008752470603212714\n",
      "Epoch: 14000 train loss=0.002328218 valid loss= 0.004329295\n",
      "train reg_fs: 0.0008715337608009577\n",
      "Epoch: 14500 train loss=0.001907774 valid loss= 0.004438210\n",
      "train reg_fs: 0.0008732092683203518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:47:11,723]\u001b[0m Trial 65 finished with value: 0.00363022595376763 and parameters: {'lam': 0.0012860723128362073, 'learning_rate': 0.14657025826153203, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002227885 valid loss= 0.004483553\n",
      "train reg_fs: 0.0008682641782797873\n",
      "In trial:---------------------\n",
      "validation mse: 0.00363022595376763\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011951288 valid loss= 0.007333731\n",
      "train reg_fs: 0.0013567073037847877\n",
      "Epoch: 1000 train loss=0.006423251 valid loss= 0.004743527\n",
      "train reg_fs: 0.0012930630473420024\n",
      "Epoch: 1500 train loss=0.007722928 valid loss= 0.003114732\n",
      "train reg_fs: 0.0012434697709977627\n",
      "Epoch: 2000 train loss=0.005921777 valid loss= 0.003124153\n",
      "train reg_fs: 0.0012267770944163203\n",
      "Epoch: 2500 train loss=0.003038538 valid loss= 0.002576539\n",
      "train reg_fs: 0.0012163029750809073\n",
      "Epoch: 3000 train loss=0.004957424 valid loss= 0.003224823\n",
      "train reg_fs: 0.0011962243588641286\n",
      "Epoch: 3500 train loss=0.002118292 valid loss= 0.002571135\n",
      "train reg_fs: 0.0011722033377736807\n",
      "Epoch: 4000 train loss=0.002823032 valid loss= 0.002717944\n",
      "train reg_fs: 0.0011516365921124816\n",
      "Epoch: 4500 train loss=0.002306195 valid loss= 0.002525700\n",
      "train reg_fs: 0.0011341806966811419\n",
      "Epoch: 5000 train loss=0.002710239 valid loss= 0.002681858\n",
      "train reg_fs: 0.0011205964256078005\n",
      "Epoch: 5500 train loss=0.002304413 valid loss= 0.002220652\n",
      "train reg_fs: 0.0011094390647485852\n",
      "Epoch: 6000 train loss=0.004029569 valid loss= 0.002206827\n",
      "train reg_fs: 0.0010991395683959126\n",
      "Epoch: 6500 train loss=0.002669734 valid loss= 0.002507657\n",
      "train reg_fs: 0.0010916540632024407\n",
      "Epoch: 7000 train loss=0.007571777 valid loss= 0.001763925\n",
      "train reg_fs: 0.0010849464451894164\n",
      "Epoch: 7500 train loss=0.004252892 valid loss= 0.001681701\n",
      "train reg_fs: 0.0010789412772282958\n",
      "Epoch: 8000 train loss=0.002113559 valid loss= 0.001779450\n",
      "train reg_fs: 0.0010745229665189981\n",
      "Epoch: 8500 train loss=0.002258502 valid loss= 0.001609342\n",
      "train reg_fs: 0.0010706526227295399\n",
      "Epoch: 9000 train loss=0.001144605 valid loss= 0.001723781\n",
      "train reg_fs: 0.0010674920631572604\n",
      "Epoch: 9500 train loss=0.001427319 valid loss= 0.002096428\n",
      "train reg_fs: 0.0010648549068719149\n",
      "Epoch: 10000 train loss=0.003065157 valid loss= 0.001414645\n",
      "train reg_fs: 0.0010627119336277246\n",
      "Epoch: 10500 train loss=0.002202454 valid loss= 0.001705040\n",
      "train reg_fs: 0.0010606484720483422\n",
      "Epoch: 11000 train loss=0.005160184 valid loss= 0.002241591\n",
      "train reg_fs: 0.001058862661011517\n",
      "Epoch: 11500 train loss=0.003127223 valid loss= 0.001805653\n",
      "train reg_fs: 0.0010573908220976591\n",
      "Epoch: 12000 train loss=0.002922511 valid loss= 0.001719593\n",
      "train reg_fs: 0.001056051580235362\n",
      "Epoch: 12500 train loss=0.003482676 valid loss= 0.001457288\n",
      "train reg_fs: 0.0010548796271905303\n",
      "Epoch: 13000 train loss=0.003651617 valid loss= 0.001547991\n",
      "train reg_fs: 0.0010537744965404272\n",
      "Epoch: 13500 train loss=0.003949125 valid loss= 0.001513746\n",
      "train reg_fs: 0.001052731298841536\n",
      "Epoch: 14000 train loss=0.003773900 valid loss= 0.001478025\n",
      "train reg_fs: 0.0010517932241782546\n",
      "Epoch: 14500 train loss=0.002227395 valid loss= 0.001711376\n",
      "train reg_fs: 0.0010509327985346317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:48:56,704]\u001b[0m Trial 66 finished with value: 0.000677666919178786 and parameters: {'lam': 0.001565982142661083, 'learning_rate': 0.12822692475957048, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002199200 valid loss= 0.001731696\n",
      "train reg_fs: 0.0010501873912289739\n",
      "In trial:---------------------\n",
      "validation mse: 0.000677666919178786\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006191702 valid loss= 0.007078239\n",
      "train reg_fs: 0.0014307175297290087\n",
      "Epoch: 1000 train loss=0.007908619 valid loss= 0.005588775\n",
      "train reg_fs: 0.0013802767498418689\n",
      "Epoch: 1500 train loss=0.007180015 valid loss= 0.004621270\n",
      "train reg_fs: 0.0013293145457282662\n",
      "Epoch: 2000 train loss=0.004080215 valid loss= 0.003571116\n",
      "train reg_fs: 0.001280690194107592\n",
      "Epoch: 2500 train loss=0.007484103 valid loss= 0.003017842\n",
      "train reg_fs: 0.0012536774156615138\n",
      "Epoch: 3000 train loss=0.001902619 valid loss= 0.003313911\n",
      "train reg_fs: 0.0012332338374108076\n",
      "Epoch: 3500 train loss=0.001813271 valid loss= 0.003383803\n",
      "train reg_fs: 0.0012196734314784408\n",
      "Epoch: 4000 train loss=0.002040267 valid loss= 0.003168148\n",
      "train reg_fs: 0.0012073653051629663\n",
      "Epoch: 4500 train loss=0.002614977 valid loss= 0.003451603\n",
      "train reg_fs: 0.0011967356549575925\n",
      "Epoch: 5000 train loss=0.006041535 valid loss= 0.003046388\n",
      "train reg_fs: 0.0011860798113048077\n",
      "Epoch: 5500 train loss=0.001911878 valid loss= 0.003544339\n",
      "train reg_fs: 0.001177444588392973\n",
      "Epoch: 6000 train loss=0.001578093 valid loss= 0.003505799\n",
      "train reg_fs: 0.0011694899294525385\n",
      "Epoch: 6500 train loss=0.002147042 valid loss= 0.003374896\n",
      "train reg_fs: 0.001160831074230373\n",
      "Epoch: 7000 train loss=0.002538052 valid loss= 0.003371408\n",
      "train reg_fs: 0.0011518256505951285\n",
      "Epoch: 7500 train loss=0.001250288 valid loss= 0.003744247\n",
      "train reg_fs: 0.001144025824032724\n",
      "Epoch: 8000 train loss=0.001408844 valid loss= 0.003592050\n",
      "train reg_fs: 0.0011349632404744625\n",
      "Epoch: 8500 train loss=0.001797441 valid loss= 0.003678799\n",
      "train reg_fs: 0.0011256685247644782\n",
      "Epoch: 9000 train loss=0.004220008 valid loss= 0.003557769\n",
      "train reg_fs: 0.0011166674084961414\n",
      "Epoch: 9500 train loss=0.004273600 valid loss= 0.003411583\n",
      "train reg_fs: 0.0011073458008468151\n",
      "Epoch: 10000 train loss=0.002560006 valid loss= 0.004178398\n",
      "train reg_fs: 0.0010997848585247993\n",
      "Epoch: 10500 train loss=0.001600357 valid loss= 0.004104597\n",
      "train reg_fs: 0.0010925965616479516\n",
      "Epoch: 11000 train loss=0.003601842 valid loss= 0.004917830\n",
      "train reg_fs: 0.0010859225876629353\n",
      "Epoch: 11500 train loss=0.001658403 valid loss= 0.004562744\n",
      "train reg_fs: 0.0010788135696202517\n",
      "Epoch: 12000 train loss=0.001548575 valid loss= 0.004991190\n",
      "train reg_fs: 0.0010727824410423636\n",
      "Epoch: 12500 train loss=0.001836407 valid loss= 0.004662439\n",
      "train reg_fs: 0.0010677474783733487\n",
      "Epoch: 13000 train loss=0.002488492 valid loss= 0.005335687\n",
      "train reg_fs: 0.0010628257878124714\n",
      "Epoch: 13500 train loss=0.002176855 valid loss= 0.005301690\n",
      "train reg_fs: 0.0010575999040156603\n",
      "Epoch: 14000 train loss=0.002656494 valid loss= 0.004694589\n",
      "train reg_fs: 0.001054435153491795\n",
      "Epoch: 14500 train loss=0.001552625 valid loss= 0.006690674\n",
      "train reg_fs: 0.0010499847121536732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:50:37,044]\u001b[0m Trial 67 finished with value: 0.005120474474524162 and parameters: {'lam': 0.0016195814010700343, 'learning_rate': 0.17815681786940457, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001483928 valid loss= 0.006170821\n",
      "train reg_fs: 0.0010457905009388924\n",
      "In trial:---------------------\n",
      "validation mse: 0.005120474474524162\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010106981 valid loss= 0.007003362\n",
      "train reg_fs: 0.0021122454199939966\n",
      "Epoch: 1000 train loss=0.004967303 valid loss= 0.006881546\n",
      "train reg_fs: 0.0020993321668356657\n",
      "Epoch: 1500 train loss=0.007255184 valid loss= 0.004986495\n",
      "train reg_fs: 0.0020023302640765905\n",
      "Epoch: 2000 train loss=0.005968578 valid loss= 0.004875683\n",
      "train reg_fs: 0.0019107055850327015\n",
      "Epoch: 2500 train loss=0.009206044 valid loss= 0.004544846\n",
      "train reg_fs: 0.0018805222352966666\n",
      "Epoch: 3000 train loss=0.002735868 valid loss= 0.004587317\n",
      "train reg_fs: 0.0018586947117000818\n",
      "Epoch: 3500 train loss=0.005086687 valid loss= 0.004466819\n",
      "train reg_fs: 0.0018333885818719864\n",
      "Epoch: 4000 train loss=0.005130816 valid loss= 0.004846400\n",
      "train reg_fs: 0.0018030331702902913\n",
      "Epoch: 4500 train loss=0.004243629 valid loss= 0.005063324\n",
      "train reg_fs: 0.001781823462806642\n",
      "Epoch: 5000 train loss=0.004275267 valid loss= 0.004550815\n",
      "train reg_fs: 0.001758167869411409\n",
      "Epoch: 5500 train loss=0.004579583 valid loss= 0.004376147\n",
      "train reg_fs: 0.0017352792201563716\n",
      "Epoch: 6000 train loss=0.003049511 valid loss= 0.004251720\n",
      "train reg_fs: 0.0017092326888814569\n",
      "Epoch: 6500 train loss=0.002909802 valid loss= 0.004385267\n",
      "train reg_fs: 0.0016921346541494131\n",
      "Epoch: 7000 train loss=0.001966874 valid loss= 0.004409494\n",
      "train reg_fs: 0.001675648964010179\n",
      "Epoch: 7500 train loss=0.002673018 valid loss= 0.004501399\n",
      "train reg_fs: 0.0016665988368913531\n",
      "Epoch: 8000 train loss=0.003868541 valid loss= 0.004144988\n",
      "train reg_fs: 0.0016588438302278519\n",
      "Epoch: 8500 train loss=0.002262677 valid loss= 0.004288981\n",
      "train reg_fs: 0.001650479738600552\n",
      "Epoch: 9000 train loss=0.003502541 valid loss= 0.004466273\n",
      "train reg_fs: 0.0016393972327932715\n",
      "Epoch: 9500 train loss=0.002078230 valid loss= 0.004096340\n",
      "train reg_fs: 0.0016322963638231158\n",
      "Epoch: 10000 train loss=0.002396148 valid loss= 0.004114307\n",
      "train reg_fs: 0.0016290259081870317\n",
      "Epoch: 10500 train loss=0.002065192 valid loss= 0.004095377\n",
      "train reg_fs: 0.0016294891247525811\n",
      "Epoch: 11000 train loss=0.002634301 valid loss= 0.004193490\n",
      "train reg_fs: 0.001620185561478138\n",
      "Epoch: 11500 train loss=0.004466383 valid loss= 0.004014329\n",
      "train reg_fs: 0.0016139316139742732\n",
      "Epoch: 12000 train loss=0.015487543 valid loss= 0.003963457\n",
      "train reg_fs: 0.0016097361221909523\n",
      "Epoch: 12500 train loss=0.003770926 valid loss= 0.003971245\n",
      "train reg_fs: 0.001608054619282484\n",
      "Epoch: 13000 train loss=0.002213759 valid loss= 0.004052203\n",
      "train reg_fs: 0.00160378182772547\n",
      "Epoch: 13500 train loss=0.002071410 valid loss= 0.004172603\n",
      "train reg_fs: 0.0016002703923732042\n",
      "Epoch: 14000 train loss=0.005554940 valid loss= 0.004281249\n",
      "train reg_fs: 0.0015981420874595642\n",
      "Epoch: 14500 train loss=0.002118674 valid loss= 0.004027911\n",
      "train reg_fs: 0.0015944511396810412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:52:13,428]\u001b[0m Trial 68 finished with value: 0.0025620167318279943 and parameters: {'lam': 0.002391123306511879, 'learning_rate': 0.1282164114485713, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002200562 valid loss= 0.004112215\n",
      "train reg_fs: 0.001590864616446197\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025620167318279943\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013553458 valid loss= 0.007002574\n",
      "train reg_fs: 0.0012162607163190842\n",
      "Epoch: 1000 train loss=0.007116348 valid loss= 0.006496721\n",
      "train reg_fs: 0.001215773751027882\n",
      "Epoch: 1500 train loss=0.002399911 valid loss= 0.005832484\n",
      "train reg_fs: 0.0011768274707719684\n",
      "Epoch: 2000 train loss=0.004977170 valid loss= 0.003868908\n",
      "train reg_fs: 0.0011456735664978623\n",
      "Epoch: 2500 train loss=0.004963449 valid loss= 0.003635798\n",
      "train reg_fs: 0.0011209211079403758\n",
      "Epoch: 3000 train loss=0.003238059 valid loss= 0.003893896\n",
      "train reg_fs: 0.001098768669180572\n",
      "Epoch: 3500 train loss=0.002031959 valid loss= 0.003934603\n",
      "train reg_fs: 0.0010811543324962258\n",
      "Epoch: 4000 train loss=0.004191559 valid loss= 0.003585836\n",
      "train reg_fs: 0.0010633057681843638\n",
      "Epoch: 4500 train loss=0.003507472 valid loss= 0.003424806\n",
      "train reg_fs: 0.001050946768373251\n",
      "Epoch: 5000 train loss=0.002688372 valid loss= 0.003892119\n",
      "train reg_fs: 0.0010360508458688855\n",
      "Epoch: 5500 train loss=0.002087922 valid loss= 0.003988542\n",
      "train reg_fs: 0.0010216098744422197\n",
      "Epoch: 6000 train loss=0.002535995 valid loss= 0.003789202\n",
      "train reg_fs: 0.0010110231814906001\n",
      "Epoch: 6500 train loss=0.002276347 valid loss= 0.004024183\n",
      "train reg_fs: 0.001001677825115621\n",
      "Epoch: 7000 train loss=0.002169101 valid loss= 0.004222129\n",
      "train reg_fs: 0.000991161330603063\n",
      "Epoch: 7500 train loss=0.002476795 valid loss= 0.003721951\n",
      "train reg_fs: 0.0009853736264631152\n",
      "Epoch: 8000 train loss=0.002064415 valid loss= 0.004013200\n",
      "train reg_fs: 0.0009764618007466197\n",
      "Epoch: 8500 train loss=0.001328088 valid loss= 0.004129913\n",
      "train reg_fs: 0.0009713023318909109\n",
      "Epoch: 9000 train loss=0.004398526 valid loss= 0.003898327\n",
      "train reg_fs: 0.0009663598029874265\n",
      "Epoch: 9500 train loss=0.001656149 valid loss= 0.004026221\n",
      "train reg_fs: 0.0009606577223166823\n",
      "Epoch: 10000 train loss=0.002465054 valid loss= 0.003589058\n",
      "train reg_fs: 0.0009560856269672513\n",
      "Epoch: 10500 train loss=0.001869436 valid loss= 0.003861546\n",
      "train reg_fs: 0.0009504478657618165\n",
      "Epoch: 11000 train loss=0.001986710 valid loss= 0.003955700\n",
      "train reg_fs: 0.000949389417655766\n",
      "Epoch: 11500 train loss=0.002432643 valid loss= 0.003742242\n",
      "train reg_fs: 0.0009429124766029418\n",
      "Epoch: 12000 train loss=0.002768718 valid loss= 0.003904461\n",
      "train reg_fs: 0.0009407741599716246\n",
      "Epoch: 12500 train loss=0.003758085 valid loss= 0.004261904\n",
      "train reg_fs: 0.0009345273720100522\n",
      "Epoch: 13000 train loss=0.001261554 valid loss= 0.004411741\n",
      "train reg_fs: 0.000929926463868469\n",
      "Epoch: 13500 train loss=0.001892530 valid loss= 0.003655003\n",
      "train reg_fs: 0.0009274001349695027\n",
      "Epoch: 14000 train loss=0.001488201 valid loss= 0.004239168\n",
      "train reg_fs: 0.0009228206472471356\n",
      "Epoch: 14500 train loss=0.004445399 valid loss= 0.004485164\n",
      "train reg_fs: 0.0009230200084857643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:53:49,040]\u001b[0m Trial 69 finished with value: 0.003402046201485388 and parameters: {'lam': 0.0013616714994033664, 'learning_rate': 0.14117462402623332, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001717909 valid loss= 0.004298399\n",
      "train reg_fs: 0.0009180426714010537\n",
      "In trial:---------------------\n",
      "validation mse: 0.003402046201485388\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011833888 valid loss= 0.008734843\n",
      "train reg_fs: 0.0013331357622519135\n",
      "Epoch: 1000 train loss=0.005324717 valid loss= 0.007802453\n",
      "train reg_fs: 0.001294889603741467\n",
      "Epoch: 1500 train loss=0.003929193 valid loss= 0.005787310\n",
      "train reg_fs: 0.0012753579067066312\n",
      "Epoch: 2000 train loss=0.006044831 valid loss= 0.004106387\n",
      "train reg_fs: 0.0012511051027104259\n",
      "Epoch: 2500 train loss=0.004227426 valid loss= 0.003273323\n",
      "train reg_fs: 0.0012040057918056846\n",
      "Epoch: 3000 train loss=0.003090449 valid loss= 0.004047512\n",
      "train reg_fs: 0.001171695999801159\n",
      "Epoch: 3500 train loss=0.002328819 valid loss= 0.003726250\n",
      "train reg_fs: 0.001156618702225387\n",
      "Epoch: 4000 train loss=0.004301644 valid loss= 0.003797672\n",
      "train reg_fs: 0.0011465225834399462\n",
      "Epoch: 4500 train loss=0.001487659 valid loss= 0.003066977\n",
      "train reg_fs: 0.0011391673469915986\n",
      "Epoch: 5000 train loss=0.001480247 valid loss= 0.003485974\n",
      "train reg_fs: 0.001132916659116745\n",
      "Epoch: 5500 train loss=0.001930194 valid loss= 0.003464830\n",
      "train reg_fs: 0.0011270277900621295\n",
      "Epoch: 6000 train loss=0.002846494 valid loss= 0.003164845\n",
      "train reg_fs: 0.001121833804063499\n",
      "Epoch: 6500 train loss=0.001827588 valid loss= 0.003220995\n",
      "train reg_fs: 0.0011176472762599587\n",
      "Epoch: 7000 train loss=0.004486518 valid loss= 0.003364328\n",
      "train reg_fs: 0.001111754565499723\n",
      "Epoch: 7500 train loss=0.001475465 valid loss= 0.003453007\n",
      "train reg_fs: 0.0011074692010879517\n",
      "Epoch: 8000 train loss=0.001585805 valid loss= 0.003779780\n",
      "train reg_fs: 0.0011024796403944492\n",
      "Epoch: 8500 train loss=0.003041113 valid loss= 0.003549578\n",
      "train reg_fs: 0.0010973659809678793\n",
      "Epoch: 9000 train loss=0.001640136 valid loss= 0.003811708\n",
      "train reg_fs: 0.001092876773327589\n",
      "Epoch: 9500 train loss=0.002809681 valid loss= 0.003419754\n",
      "train reg_fs: 0.0010889957193285227\n",
      "Epoch: 10000 train loss=0.001729027 valid loss= 0.003617499\n",
      "train reg_fs: 0.0010846368968486786\n",
      "Epoch: 10500 train loss=0.001835620 valid loss= 0.003261426\n",
      "train reg_fs: 0.0010803287150338292\n",
      "Epoch: 11000 train loss=0.001795823 valid loss= 0.003228052\n",
      "train reg_fs: 0.001078402972780168\n",
      "Epoch: 11500 train loss=0.004081434 valid loss= 0.003029143\n",
      "train reg_fs: 0.0010738049168139696\n",
      "Epoch: 12000 train loss=0.005031646 valid loss= 0.003344640\n",
      "train reg_fs: 0.0010700796265155077\n",
      "Epoch: 12500 train loss=0.004392343 valid loss= 0.003151078\n",
      "train reg_fs: 0.0010675019584596157\n",
      "Epoch: 13000 train loss=0.006815115 valid loss= 0.003332443\n",
      "train reg_fs: 0.0010629299795255065\n",
      "Epoch: 13500 train loss=0.001293426 valid loss= 0.003327242\n",
      "train reg_fs: 0.0010613903868943453\n",
      "Epoch: 14000 train loss=0.005050604 valid loss= 0.003622587\n",
      "train reg_fs: 0.0010584163246676326\n",
      "Epoch: 14500 train loss=0.001657012 valid loss= 0.003580742\n",
      "train reg_fs: 0.001056250068359077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:55:25,130]\u001b[0m Trial 70 finished with value: 0.0023403424606676026 and parameters: {'lam': 0.0015251288156077076, 'learning_rate': 0.15593738162292556, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003606559 valid loss= 0.003356291\n",
      "train reg_fs: 0.0010534365428611636\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023403424606676026\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012371335 valid loss= 0.006055553\n",
      "train reg_fs: 0.0008727285312488675\n",
      "Epoch: 1000 train loss=0.006341369 valid loss= 0.004469902\n",
      "train reg_fs: 0.0008339787600561976\n",
      "Epoch: 1500 train loss=0.004597072 valid loss= 0.003307708\n",
      "train reg_fs: 0.0007906981045380235\n",
      "Epoch: 2000 train loss=0.001945972 valid loss= 0.003400135\n",
      "train reg_fs: 0.0007696057436987758\n",
      "Epoch: 2500 train loss=0.001577492 valid loss= 0.003175243\n",
      "train reg_fs: 0.0007587674190290272\n",
      "Epoch: 3000 train loss=0.003468611 valid loss= 0.003153044\n",
      "train reg_fs: 0.0007517741178162396\n",
      "Epoch: 3500 train loss=0.001105781 valid loss= 0.003139844\n",
      "train reg_fs: 0.0007476276368834078\n",
      "Epoch: 4000 train loss=0.002688388 valid loss= 0.002935947\n",
      "train reg_fs: 0.0007440950721502304\n",
      "Epoch: 4500 train loss=0.002010251 valid loss= 0.003234969\n",
      "train reg_fs: 0.0007413678686134517\n",
      "Epoch: 5000 train loss=0.001547355 valid loss= 0.003289003\n",
      "train reg_fs: 0.0007389284437522292\n",
      "Epoch: 5500 train loss=0.001909270 valid loss= 0.003255222\n",
      "train reg_fs: 0.0007365030469372869\n",
      "Epoch: 6000 train loss=0.002203251 valid loss= 0.002631166\n",
      "train reg_fs: 0.0007347898790612817\n",
      "Epoch: 6500 train loss=0.001322864 valid loss= 0.002996434\n",
      "train reg_fs: 0.0007331131491810083\n",
      "Epoch: 7000 train loss=0.002061313 valid loss= 0.002835303\n",
      "train reg_fs: 0.0007317049894481897\n",
      "Epoch: 7500 train loss=0.002567815 valid loss= 0.002869341\n",
      "train reg_fs: 0.0007298937998712063\n",
      "Epoch: 8000 train loss=0.002735266 valid loss= 0.002988205\n",
      "train reg_fs: 0.000728628016076982\n",
      "Epoch: 8500 train loss=0.002809119 valid loss= 0.003222347\n",
      "train reg_fs: 0.0007277124095708132\n",
      "Epoch: 9000 train loss=0.004267428 valid loss= 0.002884421\n",
      "train reg_fs: 0.0007265689200721681\n",
      "Epoch: 9500 train loss=0.000977616 valid loss= 0.002856184\n",
      "train reg_fs: 0.0007253604708239436\n",
      "Epoch: 10000 train loss=0.001785154 valid loss= 0.002707094\n",
      "train reg_fs: 0.0007243085419759154\n",
      "Epoch: 10500 train loss=0.001247332 valid loss= 0.002771368\n",
      "train reg_fs: 0.000722928496543318\n",
      "Epoch: 11000 train loss=0.001946843 valid loss= 0.002896751\n",
      "train reg_fs: 0.000721711025107652\n",
      "Epoch: 11500 train loss=0.001223916 valid loss= 0.002746785\n",
      "train reg_fs: 0.0007207469898276031\n",
      "Epoch: 12000 train loss=0.001566007 valid loss= 0.003126676\n",
      "train reg_fs: 0.0007197022787295282\n",
      "Epoch: 12500 train loss=0.003243250 valid loss= 0.003055110\n",
      "train reg_fs: 0.0007188260206021369\n",
      "Epoch: 13000 train loss=0.001877510 valid loss= 0.002483629\n",
      "train reg_fs: 0.0007178926607593894\n",
      "Epoch: 13500 train loss=0.001555383 valid loss= 0.002974448\n",
      "train reg_fs: 0.0007170652970671654\n",
      "Epoch: 14000 train loss=0.002030187 valid loss= 0.002666367\n",
      "train reg_fs: 0.0007164778653532267\n",
      "Epoch: 14500 train loss=0.001472865 valid loss= 0.002639121\n",
      "train reg_fs: 0.0007158606313169003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:57:00,377]\u001b[0m Trial 71 finished with value: 0.001926183259613295 and parameters: {'lam': 0.001004112905193822, 'learning_rate': 0.09745751131582223, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002705216 valid loss= 0.002612957\n",
      "train reg_fs: 0.0007150577148422599\n",
      "In trial:---------------------\n",
      "validation mse: 0.001926183259613295\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009532616 valid loss= 0.007504812\n",
      "train reg_fs: 0.0009473242680542171\n",
      "Epoch: 1000 train loss=0.012636364 valid loss= 0.007473216\n",
      "train reg_fs: 0.000958807475399226\n",
      "Epoch: 1500 train loss=0.013179567 valid loss= 0.007248002\n",
      "train reg_fs: 0.0009462059824727476\n",
      "Epoch: 2000 train loss=0.007436553 valid loss= 0.005406774\n",
      "train reg_fs: 0.0009181617642752826\n",
      "Epoch: 2500 train loss=0.004416754 valid loss= 0.003288555\n",
      "train reg_fs: 0.0008866696734912694\n",
      "Epoch: 3000 train loss=0.006467890 valid loss= 0.003524378\n",
      "train reg_fs: 0.0008557914406992495\n",
      "Epoch: 3500 train loss=0.004117295 valid loss= 0.002985473\n",
      "train reg_fs: 0.0008385648252442479\n",
      "Epoch: 4000 train loss=0.002943849 valid loss= 0.003406745\n",
      "train reg_fs: 0.0008280436741188169\n",
      "Epoch: 4500 train loss=0.002190052 valid loss= 0.003153573\n",
      "train reg_fs: 0.0008209978695958853\n",
      "Epoch: 5000 train loss=0.002868615 valid loss= 0.003313647\n",
      "train reg_fs: 0.000815651030279696\n",
      "Epoch: 5500 train loss=0.004711680 valid loss= 0.003310692\n",
      "train reg_fs: 0.0008119183476082981\n",
      "Epoch: 6000 train loss=0.001655976 valid loss= 0.003054553\n",
      "train reg_fs: 0.000809162447694689\n",
      "Epoch: 6500 train loss=0.002010811 valid loss= 0.003385685\n",
      "train reg_fs: 0.0008065230213105679\n",
      "Epoch: 7000 train loss=0.003402872 valid loss= 0.002799603\n",
      "train reg_fs: 0.0008045276044867933\n",
      "Epoch: 7500 train loss=0.001440557 valid loss= 0.003039612\n",
      "train reg_fs: 0.0008024396956898272\n",
      "Epoch: 8000 train loss=0.003051199 valid loss= 0.002790082\n",
      "train reg_fs: 0.0008008923032321036\n",
      "Epoch: 8500 train loss=0.001655420 valid loss= 0.003099228\n",
      "train reg_fs: 0.0007991192396730185\n",
      "Epoch: 9000 train loss=0.004448880 valid loss= 0.002998938\n",
      "train reg_fs: 0.0007974521722644567\n",
      "Epoch: 9500 train loss=0.002266277 valid loss= 0.003002075\n",
      "train reg_fs: 0.0007959917420521379\n",
      "Epoch: 10000 train loss=0.004019649 valid loss= 0.002837440\n",
      "train reg_fs: 0.0007944751414470375\n",
      "Epoch: 10500 train loss=0.002662192 valid loss= 0.003042713\n",
      "train reg_fs: 0.0007930125575512648\n",
      "Epoch: 11000 train loss=0.002183366 valid loss= 0.002741377\n",
      "train reg_fs: 0.0007918246556073427\n",
      "Epoch: 11500 train loss=0.003715205 valid loss= 0.003035154\n",
      "train reg_fs: 0.0007903490331955254\n",
      "Epoch: 12000 train loss=0.001878191 valid loss= 0.002909779\n",
      "train reg_fs: 0.0007886496605351567\n",
      "Epoch: 12500 train loss=0.002133071 valid loss= 0.003217282\n",
      "train reg_fs: 0.0007869619876146317\n",
      "Epoch: 13000 train loss=0.003022393 valid loss= 0.003290840\n",
      "train reg_fs: 0.0007853283896110952\n",
      "Epoch: 13500 train loss=0.001460658 valid loss= 0.003076160\n",
      "train reg_fs: 0.0007840978796593845\n",
      "Epoch: 14000 train loss=0.001403565 valid loss= 0.003027349\n",
      "train reg_fs: 0.0007827856461517513\n",
      "Epoch: 14500 train loss=0.001430035 valid loss= 0.002969361\n",
      "train reg_fs: 0.0007816001889295876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 17:58:43,681]\u001b[0m Trial 72 finished with value: 0.002337706493200308 and parameters: {'lam': 0.0010689857960532023, 'learning_rate': 0.09787939474414149, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001603390 valid loss= 0.003091404\n",
      "train reg_fs: 0.0007800035527907312\n",
      "In trial:---------------------\n",
      "validation mse: 0.002337706493200308\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014836356 valid loss= 0.004722114\n",
      "train reg_fs: 0.0008654177654534578\n",
      "Epoch: 1000 train loss=0.002989549 valid loss= 0.003185537\n",
      "train reg_fs: 0.0008094831719063222\n",
      "Epoch: 1500 train loss=0.005204507 valid loss= 0.003119403\n",
      "train reg_fs: 0.0007913876906968653\n",
      "Epoch: 2000 train loss=0.003982632 valid loss= 0.003098767\n",
      "train reg_fs: 0.0007920346106402576\n",
      "Epoch: 2500 train loss=0.006288542 valid loss= 0.002343001\n",
      "train reg_fs: 0.0007915952010080218\n",
      "Epoch: 3000 train loss=0.001839852 valid loss= 0.002867833\n",
      "train reg_fs: 0.0007859317702241242\n",
      "Epoch: 3500 train loss=0.006087464 valid loss= 0.003071156\n",
      "train reg_fs: 0.0007783483015373349\n",
      "Epoch: 4000 train loss=0.004680713 valid loss= 0.003232072\n",
      "train reg_fs: 0.0007709122728556395\n",
      "Epoch: 4500 train loss=0.001416860 valid loss= 0.002850318\n",
      "train reg_fs: 0.0007657057722099125\n",
      "Epoch: 5000 train loss=0.002766044 valid loss= 0.002607546\n",
      "train reg_fs: 0.0007625839207321405\n",
      "Epoch: 5500 train loss=0.009604584 valid loss= 0.002497441\n",
      "train reg_fs: 0.0007593240588903427\n",
      "Epoch: 6000 train loss=0.002354484 valid loss= 0.002834889\n",
      "train reg_fs: 0.000757033412810415\n",
      "Epoch: 6500 train loss=0.005014801 valid loss= 0.002622353\n",
      "train reg_fs: 0.0007545165717601776\n",
      "Epoch: 7000 train loss=0.003302381 valid loss= 0.003068744\n",
      "train reg_fs: 0.000752418243791908\n",
      "Epoch: 7500 train loss=0.001539593 valid loss= 0.002555884\n",
      "train reg_fs: 0.0007502593216486275\n",
      "Epoch: 8000 train loss=0.002727056 valid loss= 0.002504349\n",
      "train reg_fs: 0.00074777752161026\n",
      "Epoch: 8500 train loss=0.001104034 valid loss= 0.002524016\n",
      "train reg_fs: 0.0007453308207914233\n",
      "Epoch: 9000 train loss=0.001149130 valid loss= 0.002239968\n",
      "train reg_fs: 0.0007429626421071589\n",
      "Epoch: 9500 train loss=0.001527087 valid loss= 0.002332965\n",
      "train reg_fs: 0.0007403336931020021\n",
      "Epoch: 10000 train loss=0.001340885 valid loss= 0.002493984\n",
      "train reg_fs: 0.0007369345403276384\n",
      "Epoch: 10500 train loss=0.001002928 valid loss= 0.002288854\n",
      "train reg_fs: 0.0007332403329201043\n",
      "Epoch: 11000 train loss=0.001039925 valid loss= 0.001806402\n",
      "train reg_fs: 0.0007287963526323438\n",
      "Epoch: 11500 train loss=0.004432444 valid loss= 0.002093502\n",
      "train reg_fs: 0.0007243876461870968\n",
      "Epoch: 12000 train loss=0.001828712 valid loss= 0.001610464\n",
      "train reg_fs: 0.0007200943073257804\n",
      "Epoch: 12500 train loss=0.001495426 valid loss= 0.001786356\n",
      "train reg_fs: 0.0007150346646085382\n",
      "Epoch: 13000 train loss=0.001201860 valid loss= 0.001509396\n",
      "train reg_fs: 0.0007094708853401244\n",
      "Epoch: 13500 train loss=0.004011223 valid loss= 0.002656441\n",
      "train reg_fs: 0.0007057329639792442\n",
      "Epoch: 14000 train loss=0.000920730 valid loss= 0.001738632\n",
      "train reg_fs: 0.0007011240813881159\n",
      "Epoch: 14500 train loss=0.001816208 valid loss= 0.001849871\n",
      "train reg_fs: 0.0006962668849155307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:00:28,677]\u001b[0m Trial 73 finished with value: 0.0005242687413980171 and parameters: {'lam': 0.001003405957760672, 'learning_rate': 0.1275498649890309, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001498470 valid loss= 0.001216821\n",
      "train reg_fs: 0.0006922413595020771\n",
      "In trial:---------------------\n",
      "validation mse: 0.0005242687413980171\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008341157 valid loss= 0.009182368\n",
      "train reg_fs: 0.002715693088248372\n",
      "Epoch: 1000 train loss=0.008694698 valid loss= 0.007429278\n",
      "train reg_fs: 0.00261549255810678\n",
      "Epoch: 1500 train loss=0.007671724 valid loss= 0.006274087\n",
      "train reg_fs: 0.0025530955754220486\n",
      "Epoch: 2000 train loss=0.004059863 valid loss= 0.005523179\n",
      "train reg_fs: 0.0024764174595475197\n",
      "Epoch: 2500 train loss=0.003489539 valid loss= 0.005497403\n",
      "train reg_fs: 0.002398582175374031\n",
      "Epoch: 3000 train loss=0.005157575 valid loss= 0.005109363\n",
      "train reg_fs: 0.00232716859318316\n",
      "Epoch: 3500 train loss=0.002858762 valid loss= 0.005520456\n",
      "train reg_fs: 0.0022752638906240463\n",
      "Epoch: 4000 train loss=0.003042959 valid loss= 0.005526308\n",
      "train reg_fs: 0.0022477139718830585\n",
      "Epoch: 4500 train loss=0.006671784 valid loss= 0.005629104\n",
      "train reg_fs: 0.002211035927757621\n",
      "Epoch: 5000 train loss=0.002964231 valid loss= 0.005294497\n",
      "train reg_fs: 0.0021840042900294065\n",
      "Epoch: 5500 train loss=0.004205475 valid loss= 0.005301713\n",
      "train reg_fs: 0.0021678816992789507\n",
      "Epoch: 6000 train loss=0.002642227 valid loss= 0.005429524\n",
      "train reg_fs: 0.0021527791395783424\n",
      "Epoch: 6500 train loss=0.003246363 valid loss= 0.005391855\n",
      "train reg_fs: 0.002135489135980606\n",
      "Epoch: 7000 train loss=0.003918785 valid loss= 0.005576095\n",
      "train reg_fs: 0.002124528167769313\n",
      "Epoch: 7500 train loss=0.005577380 valid loss= 0.005265388\n",
      "train reg_fs: 0.0021134866401553154\n",
      "Epoch: 8000 train loss=0.003458010 valid loss= 0.005415319\n",
      "train reg_fs: 0.002100680023431778\n",
      "Epoch: 8500 train loss=0.002351404 valid loss= 0.005413524\n",
      "train reg_fs: 0.0020947158336639404\n",
      "Epoch: 9000 train loss=0.003149206 valid loss= 0.005294346\n",
      "train reg_fs: 0.0020857600029557943\n",
      "Epoch: 9500 train loss=0.004481640 valid loss= 0.005408926\n",
      "train reg_fs: 0.0020731454715132713\n",
      "Epoch: 10000 train loss=0.003741479 valid loss= 0.005583198\n",
      "train reg_fs: 0.0020661535672843456\n",
      "Epoch: 10500 train loss=0.003609803 valid loss= 0.005487001\n",
      "train reg_fs: 0.002055587712675333\n",
      "Epoch: 11000 train loss=0.005766283 valid loss= 0.005707706\n",
      "train reg_fs: 0.0020434437319636345\n",
      "Epoch: 11500 train loss=0.002258811 valid loss= 0.006052872\n",
      "train reg_fs: 0.002040682127699256\n",
      "Epoch: 12000 train loss=0.003616577 valid loss= 0.005973333\n",
      "train reg_fs: 0.0020287218503654003\n",
      "Epoch: 12500 train loss=0.003178068 valid loss= 0.005821638\n",
      "train reg_fs: 0.0020242328755557537\n",
      "Epoch: 13000 train loss=0.004313570 valid loss= 0.006069171\n",
      "train reg_fs: 0.0020184654276818037\n",
      "Epoch: 13500 train loss=0.003210411 valid loss= 0.005954441\n",
      "train reg_fs: 0.002010325901210308\n",
      "Epoch: 14000 train loss=0.004292727 valid loss= 0.005771442\n",
      "train reg_fs: 0.002003233414143324\n",
      "Epoch: 14500 train loss=0.003359148 valid loss= 0.005554000\n",
      "train reg_fs: 0.001999429427087307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:02:13,629]\u001b[0m Trial 74 finished with value: 0.004123874103860748 and parameters: {'lam': 0.003148899805635839, 'learning_rate': 0.19963906272534332, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002450652 valid loss= 0.006042938\n",
      "train reg_fs: 0.0019993551541119814\n",
      "In trial:---------------------\n",
      "validation mse: 0.004123874103860748\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.004429730 valid loss= 0.007222719\n",
      "train reg_fs: 0.0008791922591626644\n",
      "Epoch: 1000 train loss=0.017032122 valid loss= 0.005594528\n",
      "train reg_fs: 0.0008685135398991406\n",
      "Epoch: 1500 train loss=0.005467793 valid loss= 0.003484933\n",
      "train reg_fs: 0.0008296756423078477\n",
      "Epoch: 2000 train loss=0.005357519 valid loss= 0.003669492\n",
      "train reg_fs: 0.0008070555049926043\n",
      "Epoch: 2500 train loss=0.003531414 valid loss= 0.003303712\n",
      "train reg_fs: 0.0007948322454467416\n",
      "Epoch: 3000 train loss=0.003705233 valid loss= 0.003173972\n",
      "train reg_fs: 0.0007851827540434897\n",
      "Epoch: 3500 train loss=0.002303358 valid loss= 0.003379621\n",
      "train reg_fs: 0.0007767077768221498\n",
      "Epoch: 4000 train loss=0.003022033 valid loss= 0.002818240\n",
      "train reg_fs: 0.0007706689648330212\n",
      "Epoch: 4500 train loss=0.002534631 valid loss= 0.003118154\n",
      "train reg_fs: 0.0007659755647182465\n",
      "Epoch: 5000 train loss=0.001056098 valid loss= 0.002969157\n",
      "train reg_fs: 0.0007617626688443124\n",
      "Epoch: 5500 train loss=0.001327773 valid loss= 0.003142099\n",
      "train reg_fs: 0.0007588331354781985\n",
      "Epoch: 6000 train loss=0.002314602 valid loss= 0.003002670\n",
      "train reg_fs: 0.0007565633859485388\n",
      "Epoch: 6500 train loss=0.009572620 valid loss= 0.003104755\n",
      "train reg_fs: 0.0007546361885033548\n",
      "Epoch: 7000 train loss=0.002898622 valid loss= 0.002720749\n",
      "train reg_fs: 0.0007528347196057439\n",
      "Epoch: 7500 train loss=0.001901955 valid loss= 0.002991909\n",
      "train reg_fs: 0.0007511992589570582\n",
      "Epoch: 8000 train loss=0.001474437 valid loss= 0.002939643\n",
      "train reg_fs: 0.0007498027989640832\n",
      "Epoch: 8500 train loss=0.000825119 valid loss= 0.002983935\n",
      "train reg_fs: 0.0007487993570975959\n",
      "Epoch: 9000 train loss=0.003044722 valid loss= 0.003564267\n",
      "train reg_fs: 0.0007472066790796816\n",
      "Epoch: 9500 train loss=0.002246976 valid loss= 0.003564434\n",
      "train reg_fs: 0.0007461448549292982\n",
      "Epoch: 10000 train loss=0.001811617 valid loss= 0.002905654\n",
      "train reg_fs: 0.0007451270357705653\n",
      "Epoch: 10500 train loss=0.004033171 valid loss= 0.003224474\n",
      "train reg_fs: 0.0007440054905600846\n",
      "Epoch: 11000 train loss=0.003978799 valid loss= 0.002846793\n",
      "train reg_fs: 0.0007424071663990617\n",
      "Epoch: 11500 train loss=0.001224961 valid loss= 0.003020756\n",
      "train reg_fs: 0.0007410182734020054\n",
      "Epoch: 12000 train loss=0.000983922 valid loss= 0.003322205\n",
      "train reg_fs: 0.0007396589498966932\n",
      "Epoch: 12500 train loss=0.001750974 valid loss= 0.003067793\n",
      "train reg_fs: 0.000738269358407706\n",
      "Epoch: 13000 train loss=0.001188027 valid loss= 0.002867124\n",
      "train reg_fs: 0.0007368830847553909\n",
      "Epoch: 13500 train loss=0.002733702 valid loss= 0.002597500\n",
      "train reg_fs: 0.0007353998953476548\n",
      "Epoch: 14000 train loss=0.001325696 valid loss= 0.002780862\n",
      "train reg_fs: 0.0007341762538999319\n",
      "Epoch: 14500 train loss=0.001878574 valid loss= 0.002944403\n",
      "train reg_fs: 0.0007325670449063182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:03:58,515]\u001b[0m Trial 75 finished with value: 0.002466424842067526 and parameters: {'lam': 0.00100063003608698, 'learning_rate': 0.12456205629708567, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004019631 valid loss= 0.003173139\n",
      "train reg_fs: 0.0007310621440410614\n",
      "In trial:---------------------\n",
      "validation mse: 0.002466424842067526\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009940688 valid loss= 0.007203645\n",
      "train reg_fs: 0.0010784355690702796\n",
      "Epoch: 1000 train loss=0.007426270 valid loss= 0.006594406\n",
      "train reg_fs: 0.0010638009989634156\n",
      "Epoch: 1500 train loss=0.004027882 valid loss= 0.005089030\n",
      "train reg_fs: 0.0010379920713603497\n",
      "Epoch: 2000 train loss=0.003545596 valid loss= 0.004288522\n",
      "train reg_fs: 0.0010081618092954159\n",
      "Epoch: 2500 train loss=0.004388668 valid loss= 0.003930349\n",
      "train reg_fs: 0.0009802982676774263\n",
      "Epoch: 3000 train loss=0.002492821 valid loss= 0.003798790\n",
      "train reg_fs: 0.0009618023177608848\n",
      "Epoch: 3500 train loss=0.003069203 valid loss= 0.003888662\n",
      "train reg_fs: 0.0009448092896491289\n",
      "Epoch: 4000 train loss=0.003423897 valid loss= 0.004213900\n",
      "train reg_fs: 0.0009337395895272493\n",
      "Epoch: 4500 train loss=0.004382676 valid loss= 0.003774825\n",
      "train reg_fs: 0.0009247905691154301\n",
      "Epoch: 5000 train loss=0.001582656 valid loss= 0.004219555\n",
      "train reg_fs: 0.0009133988060057163\n",
      "Epoch: 5500 train loss=0.002824706 valid loss= 0.004270683\n",
      "train reg_fs: 0.0009038815624080598\n",
      "Epoch: 6000 train loss=0.003913225 valid loss= 0.004281972\n",
      "train reg_fs: 0.0008967439061962068\n",
      "Epoch: 6500 train loss=0.003517710 valid loss= 0.004212064\n",
      "train reg_fs: 0.0008885830757208169\n",
      "Epoch: 7000 train loss=0.002076112 valid loss= 0.004325745\n",
      "train reg_fs: 0.0008816541521809995\n",
      "Epoch: 7500 train loss=0.001513258 valid loss= 0.004713474\n",
      "train reg_fs: 0.0008747673709876835\n",
      "Epoch: 8000 train loss=0.002274260 valid loss= 0.004626855\n",
      "train reg_fs: 0.000867007183842361\n",
      "Epoch: 8500 train loss=0.001378211 valid loss= 0.004467103\n",
      "train reg_fs: 0.0008599463617429137\n",
      "Epoch: 9000 train loss=0.001975278 valid loss= 0.004747584\n",
      "train reg_fs: 0.0008524313452653587\n",
      "Epoch: 9500 train loss=0.001920576 valid loss= 0.004546453\n",
      "train reg_fs: 0.0008458239026367664\n",
      "Epoch: 10000 train loss=0.002549350 valid loss= 0.004915528\n",
      "train reg_fs: 0.0008374876342713833\n",
      "Epoch: 10500 train loss=0.002672856 valid loss= 0.004702103\n",
      "train reg_fs: 0.0008306301315315068\n",
      "Epoch: 11000 train loss=0.001664915 valid loss= 0.004729379\n",
      "train reg_fs: 0.0008257204317487776\n",
      "Epoch: 11500 train loss=0.001560565 valid loss= 0.005017779\n",
      "train reg_fs: 0.0008209266816265881\n",
      "Epoch: 12000 train loss=0.003455355 valid loss= 0.005169237\n",
      "train reg_fs: 0.0008170395740307868\n",
      "Epoch: 12500 train loss=0.002965272 valid loss= 0.005213566\n",
      "train reg_fs: 0.0008129706257022917\n",
      "Epoch: 13000 train loss=0.001611121 valid loss= 0.005257877\n",
      "train reg_fs: 0.0008079491090029478\n",
      "Epoch: 13500 train loss=0.001529739 valid loss= 0.005039342\n",
      "train reg_fs: 0.0008042227709665895\n",
      "Epoch: 14000 train loss=0.001285024 valid loss= 0.005293499\n",
      "train reg_fs: 0.0007994489278644323\n",
      "Epoch: 14500 train loss=0.001958632 valid loss= 0.005370146\n",
      "train reg_fs: 0.0007945039542391896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:05:43,013]\u001b[0m Trial 76 finished with value: 0.0043679908092801685 and parameters: {'lam': 0.0012317433919804253, 'learning_rate': 0.10929960890883611, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001336448 valid loss= 0.005184449\n",
      "train reg_fs: 0.0007924222154542804\n",
      "In trial:---------------------\n",
      "validation mse: 0.0043679908092801685\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012907830 valid loss= 0.013325989\n",
      "train reg_fs: 0.007868079468607903\n",
      "Epoch: 1000 train loss=0.009869832 valid loss= 0.010698719\n",
      "train reg_fs: 0.007114145439118147\n",
      "Epoch: 1500 train loss=0.010206607 valid loss= 0.009991306\n",
      "train reg_fs: 0.006529625505208969\n",
      "Epoch: 2000 train loss=0.007440793 valid loss= 0.008688921\n",
      "train reg_fs: 0.006167668383568525\n",
      "Epoch: 2500 train loss=0.007593448 valid loss= 0.008508379\n",
      "train reg_fs: 0.005994396284222603\n",
      "Epoch: 3000 train loss=0.016284905 valid loss= 0.008441481\n",
      "train reg_fs: 0.005901006516069174\n",
      "Epoch: 3500 train loss=0.011521932 valid loss= 0.007913014\n",
      "train reg_fs: 0.005842060316354036\n",
      "Epoch: 4000 train loss=0.006688005 valid loss= 0.007856047\n",
      "train reg_fs: 0.005803038831800222\n",
      "Epoch: 4500 train loss=0.008033585 valid loss= 0.007716986\n",
      "train reg_fs: 0.0057746125385165215\n",
      "Epoch: 5000 train loss=0.006584720 valid loss= 0.007844205\n",
      "train reg_fs: 0.005753735546022654\n",
      "Epoch: 5500 train loss=0.006444404 valid loss= 0.008151528\n",
      "train reg_fs: 0.005737164057791233\n",
      "Epoch: 6000 train loss=0.005927269 valid loss= 0.007960361\n",
      "train reg_fs: 0.005724097602069378\n",
      "Epoch: 6500 train loss=0.008947348 valid loss= 0.008280147\n",
      "train reg_fs: 0.005713940132409334\n",
      "Epoch: 7000 train loss=0.008280030 valid loss= 0.007764107\n",
      "train reg_fs: 0.005705677438527346\n",
      "Epoch: 7500 train loss=0.006463252 valid loss= 0.008113964\n",
      "train reg_fs: 0.005698256194591522\n",
      "Epoch: 8000 train loss=0.007320656 valid loss= 0.007772322\n",
      "train reg_fs: 0.005691875703632832\n",
      "Epoch: 8500 train loss=0.006026693 valid loss= 0.007786945\n",
      "train reg_fs: 0.005686384625732899\n",
      "Epoch: 9000 train loss=0.006590699 valid loss= 0.007913454\n",
      "train reg_fs: 0.00568178528919816\n",
      "Epoch: 9500 train loss=0.007337577 valid loss= 0.007795750\n",
      "train reg_fs: 0.005677767097949982\n",
      "Epoch: 10000 train loss=0.006349935 valid loss= 0.007922951\n",
      "train reg_fs: 0.005674063228070736\n",
      "Epoch: 10500 train loss=0.006006951 valid loss= 0.007797148\n",
      "train reg_fs: 0.005670702084898949\n",
      "Epoch: 11000 train loss=0.007182530 valid loss= 0.007670810\n",
      "train reg_fs: 0.005667783319950104\n",
      "Epoch: 11500 train loss=0.010366959 valid loss= 0.007606314\n",
      "train reg_fs: 0.005665072239935398\n",
      "Epoch: 12000 train loss=0.007459020 valid loss= 0.008110339\n",
      "train reg_fs: 0.005662727169692516\n",
      "Epoch: 12500 train loss=0.005875543 valid loss= 0.007691269\n",
      "train reg_fs: 0.005660528317093849\n",
      "Epoch: 13000 train loss=0.008213345 valid loss= 0.007676771\n",
      "train reg_fs: 0.0056585767306387424\n",
      "Epoch: 13500 train loss=0.007005731 valid loss= 0.007663911\n",
      "train reg_fs: 0.005656654946506023\n",
      "Epoch: 14000 train loss=0.008150979 valid loss= 0.007748071\n",
      "train reg_fs: 0.005654993001371622\n",
      "Epoch: 14500 train loss=0.006010590 valid loss= 0.007876188\n",
      "train reg_fs: 0.005653531290590763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:07:23,764]\u001b[0m Trial 77 finished with value: 0.002438023767916306 and parameters: {'lam': 0.009439404611410596, 'learning_rate': 0.1373793033546193, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006088126 valid loss= 0.007922548\n",
      "train reg_fs: 0.005652156658470631\n",
      "In trial:---------------------\n",
      "validation mse: 0.002438023767916306\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010239542 valid loss= 0.009104377\n",
      "train reg_fs: 0.0014703311026096344\n",
      "Epoch: 1000 train loss=0.012452939 valid loss= 0.009151312\n",
      "train reg_fs: 0.0014865909470245242\n",
      "Epoch: 1500 train loss=0.014042475 valid loss= 0.008611904\n",
      "train reg_fs: 0.0014991157222539186\n",
      "Epoch: 2000 train loss=0.006864374 valid loss= 0.008796236\n",
      "train reg_fs: 0.001507108099758625\n",
      "Epoch: 2500 train loss=0.005643255 valid loss= 0.008204398\n",
      "train reg_fs: 0.001511505339294672\n",
      "Epoch: 3000 train loss=0.008073916 valid loss= 0.007876628\n",
      "train reg_fs: 0.0015134696150198579\n",
      "Epoch: 3500 train loss=0.007472284 valid loss= 0.007842957\n",
      "train reg_fs: 0.0015125711215659976\n",
      "Epoch: 4000 train loss=0.008319668 valid loss= 0.007588761\n",
      "train reg_fs: 0.0015075670089572668\n",
      "Epoch: 4500 train loss=0.005190949 valid loss= 0.007033922\n",
      "train reg_fs: 0.001501675695180893\n",
      "Epoch: 5000 train loss=0.006401555 valid loss= 0.007012785\n",
      "train reg_fs: 0.001492757466621697\n",
      "Epoch: 5500 train loss=0.008581649 valid loss= 0.007036792\n",
      "train reg_fs: 0.0014833040768280625\n",
      "Epoch: 6000 train loss=0.005107606 valid loss= 0.006888448\n",
      "train reg_fs: 0.0014746086671948433\n",
      "Epoch: 6500 train loss=0.011283585 valid loss= 0.006619907\n",
      "train reg_fs: 0.001463884487748146\n",
      "Epoch: 7000 train loss=0.005962137 valid loss= 0.006166298\n",
      "train reg_fs: 0.0014554105000570416\n",
      "Epoch: 7500 train loss=0.004042660 valid loss= 0.006019700\n",
      "train reg_fs: 0.0014483352424576879\n",
      "Epoch: 8000 train loss=0.004697940 valid loss= 0.005914486\n",
      "train reg_fs: 0.0014415200566872954\n",
      "Epoch: 8500 train loss=0.003731895 valid loss= 0.005664184\n",
      "train reg_fs: 0.001434591831639409\n",
      "Epoch: 9000 train loss=0.002849844 valid loss= 0.005403362\n",
      "train reg_fs: 0.0014276251895353198\n",
      "Epoch: 9500 train loss=0.006919853 valid loss= 0.005095754\n",
      "train reg_fs: 0.0014201283920556307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:08:27,884]\u001b[0m Trial 78 finished with value: 0.0035492899511655337 and parameters: {'lam': 0.001727491758332028, 'learning_rate': 0.019969244304014467, 'num_epoch': 10000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003120044 valid loss= 0.004998368\n",
      "train reg_fs: 0.0014131584903225303\n",
      "In trial:---------------------\n",
      "validation mse: 0.0035492899511655337\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010177176 valid loss= 0.005304446\n",
      "train reg_fs: 0.001261295867152512\n",
      "Epoch: 1000 train loss=0.005746877 valid loss= 0.004577745\n",
      "train reg_fs: 0.0012327706208452582\n",
      "Epoch: 1500 train loss=0.007056300 valid loss= 0.004256331\n",
      "train reg_fs: 0.0011772012803703547\n",
      "Epoch: 2000 train loss=0.006243448 valid loss= 0.003487719\n",
      "train reg_fs: 0.001150833209976554\n",
      "Epoch: 2500 train loss=0.004446644 valid loss= 0.003584428\n",
      "train reg_fs: 0.0011401475640013814\n",
      "Epoch: 3000 train loss=0.002489963 valid loss= 0.003898499\n",
      "train reg_fs: 0.0011294764699414372\n",
      "Epoch: 3500 train loss=0.002916132 valid loss= 0.003924139\n",
      "train reg_fs: 0.0011181056033819914\n",
      "Epoch: 4000 train loss=0.002194514 valid loss= 0.003345831\n",
      "train reg_fs: 0.0011082168202847242\n",
      "Epoch: 4500 train loss=0.005235820 valid loss= 0.003506548\n",
      "train reg_fs: 0.0011010960442945361\n",
      "Epoch: 5000 train loss=0.002948741 valid loss= 0.002986616\n",
      "train reg_fs: 0.0010959545616060495\n",
      "Epoch: 5500 train loss=0.001547210 valid loss= 0.002871774\n",
      "train reg_fs: 0.0010914792073890567\n",
      "Epoch: 6000 train loss=0.002727779 valid loss= 0.003239688\n",
      "train reg_fs: 0.0010885605588555336\n",
      "Epoch: 6500 train loss=0.001960092 valid loss= 0.002972155\n",
      "train reg_fs: 0.0010861627524718642\n",
      "Epoch: 7000 train loss=0.020946134 valid loss= 0.003296364\n",
      "train reg_fs: 0.0010831532999873161\n",
      "Epoch: 7500 train loss=0.001762560 valid loss= 0.003124948\n",
      "train reg_fs: 0.0010801033349707723\n",
      "Epoch: 8000 train loss=0.001852848 valid loss= 0.002468101\n",
      "train reg_fs: 0.001077441731467843\n",
      "Epoch: 8500 train loss=0.002565816 valid loss= 0.003041667\n",
      "train reg_fs: 0.0010751306544989347\n",
      "Epoch: 9000 train loss=0.001701352 valid loss= 0.002532984\n",
      "train reg_fs: 0.0010713548399508\n",
      "Epoch: 9500 train loss=0.007265095 valid loss= 0.002352709\n",
      "train reg_fs: 0.0010683396831154823\n",
      "Epoch: 10000 train loss=0.001738053 valid loss= 0.002608072\n",
      "train reg_fs: 0.0010643498972058296\n",
      "Epoch: 10500 train loss=0.002925564 valid loss= 0.002624690\n",
      "train reg_fs: 0.0010607795557007194\n",
      "Epoch: 11000 train loss=0.001672159 valid loss= 0.001984546\n",
      "train reg_fs: 0.0010571627644822001\n",
      "Epoch: 11500 train loss=0.001465520 valid loss= 0.002403702\n",
      "train reg_fs: 0.0010516262846067548\n",
      "Epoch: 12000 train loss=0.002210746 valid loss= 0.002009426\n",
      "train reg_fs: 0.00104648491833359\n",
      "Epoch: 12500 train loss=0.002637250 valid loss= 0.002118164\n",
      "train reg_fs: 0.0010405384236946702\n",
      "Epoch: 13000 train loss=0.003318643 valid loss= 0.002570518\n",
      "train reg_fs: 0.0010344303445890546\n",
      "Epoch: 13500 train loss=0.003840622 valid loss= 0.001827744\n",
      "train reg_fs: 0.0010287888580933213\n",
      "Epoch: 14000 train loss=0.001379424 valid loss= 0.001915309\n",
      "train reg_fs: 0.0010228169849142432\n",
      "Epoch: 14500 train loss=0.001347914 valid loss= 0.002033527\n",
      "train reg_fs: 0.0010178948286920786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:10:02,983]\u001b[0m Trial 79 finished with value: 0.0006804822708091409 and parameters: {'lam': 0.001461176782002776, 'learning_rate': 0.09003483686735618, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001947197 valid loss= 0.001690192\n",
      "train reg_fs: 0.0010120758088305593\n",
      "In trial:---------------------\n",
      "validation mse: 0.0006804822708091409\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015032898 valid loss= 0.007861162\n",
      "train reg_fs: 0.0012041785521432757\n",
      "Epoch: 1000 train loss=0.005038845 valid loss= 0.007165932\n",
      "train reg_fs: 0.0012023175368085504\n",
      "Epoch: 1500 train loss=0.006489516 valid loss= 0.005777876\n",
      "train reg_fs: 0.0011718226596713066\n",
      "Epoch: 2000 train loss=0.005307577 valid loss= 0.004146351\n",
      "train reg_fs: 0.001152068143710494\n",
      "Epoch: 2500 train loss=0.007902049 valid loss= 0.003926801\n",
      "train reg_fs: 0.0011281961342319846\n",
      "Epoch: 3000 train loss=0.005477277 valid loss= 0.002964237\n",
      "train reg_fs: 0.0011027260916307569\n",
      "Epoch: 3500 train loss=0.007117352 valid loss= 0.002880672\n",
      "train reg_fs: 0.001086286036297679\n",
      "Epoch: 4000 train loss=0.004164483 valid loss= 0.003618700\n",
      "train reg_fs: 0.0010744765168055892\n",
      "Epoch: 4500 train loss=0.001942193 valid loss= 0.003526599\n",
      "train reg_fs: 0.0010634154314175248\n",
      "Epoch: 5000 train loss=0.001814397 valid loss= 0.003387204\n",
      "train reg_fs: 0.001054085441865027\n",
      "Epoch: 5500 train loss=0.004372729 valid loss= 0.003575555\n",
      "train reg_fs: 0.0010452800197526813\n",
      "Epoch: 6000 train loss=0.005605513 valid loss= 0.003658945\n",
      "train reg_fs: 0.0010374672710895538\n",
      "Epoch: 6500 train loss=0.002580570 valid loss= 0.003469727\n",
      "train reg_fs: 0.0010339220752939582\n",
      "Epoch: 7000 train loss=0.003581432 valid loss= 0.003509875\n",
      "train reg_fs: 0.0010286286706104875\n",
      "Epoch: 7500 train loss=0.002053414 valid loss= 0.003726115\n",
      "train reg_fs: 0.0010217909002676606\n",
      "Epoch: 8000 train loss=0.001793570 valid loss= 0.003402307\n",
      "train reg_fs: 0.0010174782946705818\n",
      "Epoch: 8500 train loss=0.007986645 valid loss= 0.003364974\n",
      "train reg_fs: 0.0010101549560204148\n",
      "Epoch: 9000 train loss=0.002069597 valid loss= 0.003368021\n",
      "train reg_fs: 0.0010057148756459355\n",
      "Epoch: 9500 train loss=0.002824737 valid loss= 0.003580607\n",
      "train reg_fs: 0.0010025575757026672\n",
      "Epoch: 10000 train loss=0.004607811 valid loss= 0.003602200\n",
      "train reg_fs: 0.0009989677928388119\n",
      "Epoch: 10500 train loss=0.002291966 valid loss= 0.003462756\n",
      "train reg_fs: 0.0009955845307558775\n",
      "Epoch: 11000 train loss=0.002720846 valid loss= 0.003774561\n",
      "train reg_fs: 0.0009918062714859843\n",
      "Epoch: 11500 train loss=0.002092372 valid loss= 0.003567710\n",
      "train reg_fs: 0.0009888062486425042\n",
      "Epoch: 12000 train loss=0.002946194 valid loss= 0.003639634\n",
      "train reg_fs: 0.0009860150748863816\n",
      "Epoch: 12500 train loss=0.001389777 valid loss= 0.003399606\n",
      "train reg_fs: 0.0009842893341556191\n",
      "Epoch: 13000 train loss=0.003951927 valid loss= 0.003742449\n",
      "train reg_fs: 0.000980143086053431\n",
      "Epoch: 13500 train loss=0.004635376 valid loss= 0.003895967\n",
      "train reg_fs: 0.0009760672692209482\n",
      "Epoch: 14000 train loss=0.001503257 valid loss= 0.003770619\n",
      "train reg_fs: 0.0009721532114781439\n",
      "Epoch: 14500 train loss=0.001301952 valid loss= 0.003667658\n",
      "train reg_fs: 0.0009684431715868413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:11:38,808]\u001b[0m Trial 80 finished with value: 0.002346405185246837 and parameters: {'lam': 0.001375853017015663, 'learning_rate': 0.08758679353703823, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003070788 valid loss= 0.003297376\n",
      "train reg_fs: 0.0009659765055403113\n",
      "In trial:---------------------\n",
      "validation mse: 0.002346405185246837\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.024511332 valid loss= 0.008448781\n",
      "train reg_fs: 0.0012669835705310106\n",
      "Epoch: 1000 train loss=0.010552574 valid loss= 0.008151568\n",
      "train reg_fs: 0.0012702554231509566\n",
      "Epoch: 1500 train loss=0.008182867 valid loss= 0.006975740\n",
      "train reg_fs: 0.0012447258923202753\n",
      "Epoch: 2000 train loss=0.005401057 valid loss= 0.006764315\n",
      "train reg_fs: 0.001222950522787869\n",
      "Epoch: 2500 train loss=0.003074828 valid loss= 0.006471613\n",
      "train reg_fs: 0.0012076912680640817\n",
      "Epoch: 3000 train loss=0.004360866 valid loss= 0.006272684\n",
      "train reg_fs: 0.0011975571978837252\n",
      "Epoch: 3500 train loss=0.004039671 valid loss= 0.005619269\n",
      "train reg_fs: 0.0011900556273758411\n",
      "Epoch: 4000 train loss=0.004516761 valid loss= 0.005120386\n",
      "train reg_fs: 0.0011852626921609044\n",
      "Epoch: 4500 train loss=0.003737640 valid loss= 0.005451269\n",
      "train reg_fs: 0.001183562446385622\n",
      "Epoch: 5000 train loss=0.001619939 valid loss= 0.004900978\n",
      "train reg_fs: 0.0011840944644063711\n",
      "Epoch: 5500 train loss=0.002652988 valid loss= 0.004434788\n",
      "train reg_fs: 0.0011814048048108816\n",
      "Epoch: 6000 train loss=0.002493845 valid loss= 0.004638188\n",
      "train reg_fs: 0.0011795666068792343\n",
      "Epoch: 6500 train loss=0.002042817 valid loss= 0.004765647\n",
      "train reg_fs: 0.0011740842601284385\n",
      "Epoch: 7000 train loss=0.004029216 valid loss= 0.004452855\n",
      "train reg_fs: 0.0011691988911479712\n",
      "Epoch: 7500 train loss=0.002387801 valid loss= 0.004802634\n",
      "train reg_fs: 0.0011658428702503443\n",
      "Epoch: 8000 train loss=0.002540995 valid loss= 0.004829914\n",
      "train reg_fs: 0.0011625520419329405\n",
      "Epoch: 8500 train loss=0.001931228 valid loss= 0.004539036\n",
      "train reg_fs: 0.0011583210434764624\n",
      "Epoch: 9000 train loss=0.002557173 valid loss= 0.004871979\n",
      "train reg_fs: 0.001154732541181147\n",
      "Epoch: 9500 train loss=0.002414787 valid loss= 0.004822762\n",
      "train reg_fs: 0.0011505645234137774\n",
      "Epoch: 10000 train loss=0.004757726 valid loss= 0.004597601\n",
      "train reg_fs: 0.00114681595005095\n",
      "Epoch: 10500 train loss=0.002460673 valid loss= 0.004993825\n",
      "train reg_fs: 0.001143077271990478\n",
      "Epoch: 11000 train loss=0.002719310 valid loss= 0.005288379\n",
      "train reg_fs: 0.0011378099443390965\n",
      "Epoch: 11500 train loss=0.002342202 valid loss= 0.005147632\n",
      "train reg_fs: 0.0011339079355821013\n",
      "Epoch: 12000 train loss=0.001737472 valid loss= 0.005077645\n",
      "train reg_fs: 0.0011311400448903441\n",
      "Epoch: 12500 train loss=0.003888405 valid loss= 0.005231577\n",
      "train reg_fs: 0.0011271354742348194\n",
      "Epoch: 13000 train loss=0.003627768 valid loss= 0.005253289\n",
      "train reg_fs: 0.001123473746702075\n",
      "Epoch: 13500 train loss=0.004192517 valid loss= 0.005272313\n",
      "train reg_fs: 0.0011196258710697293\n",
      "Epoch: 14000 train loss=0.004523411 valid loss= 0.004838509\n",
      "train reg_fs: 0.0011169339995831251\n",
      "Epoch: 14500 train loss=0.001264747 valid loss= 0.005490271\n",
      "train reg_fs: 0.0011112052015960217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:13:15,437]\u001b[0m Trial 81 finished with value: 0.004506437515908388 and parameters: {'lam': 0.0014319955761667507, 'learning_rate': 0.11251082399365679, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001842520 valid loss= 0.005629709\n",
      "train reg_fs: 0.0011088637402281165\n",
      "In trial:---------------------\n",
      "validation mse: 0.004506437515908388\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011883472 valid loss= 0.007105852\n",
      "train reg_fs: 0.0011391163570806384\n",
      "Epoch: 1000 train loss=0.008590152 valid loss= 0.007035971\n",
      "train reg_fs: 0.0011601918376982212\n",
      "Epoch: 1500 train loss=0.003476194 valid loss= 0.006992670\n",
      "train reg_fs: 0.0011592564405873418\n",
      "Epoch: 2000 train loss=0.003977414 valid loss= 0.005232709\n",
      "train reg_fs: 0.00114178447984159\n",
      "Epoch: 2500 train loss=0.004847049 valid loss= 0.005447699\n",
      "train reg_fs: 0.0011195079423487186\n",
      "Epoch: 3000 train loss=0.011705066 valid loss= 0.004974269\n",
      "train reg_fs: 0.001104955212213099\n",
      "Epoch: 3500 train loss=0.005529823 valid loss= 0.004298452\n",
      "train reg_fs: 0.0010898703476414084\n",
      "Epoch: 4000 train loss=0.004087251 valid loss= 0.003957419\n",
      "train reg_fs: 0.0010783526813611388\n",
      "Epoch: 4500 train loss=0.002909076 valid loss= 0.003832151\n",
      "train reg_fs: 0.001067600678652525\n",
      "Epoch: 5000 train loss=0.001759675 valid loss= 0.003652919\n",
      "train reg_fs: 0.001053689164109528\n",
      "Epoch: 5500 train loss=0.005847238 valid loss= 0.003987213\n",
      "train reg_fs: 0.0010432819835841656\n",
      "Epoch: 6000 train loss=0.004138384 valid loss= 0.004075769\n",
      "train reg_fs: 0.0010354110272601247\n",
      "Epoch: 6500 train loss=0.002683425 valid loss= 0.004282949\n",
      "train reg_fs: 0.0010250047780573368\n",
      "Epoch: 7000 train loss=0.003381474 valid loss= 0.003889915\n",
      "train reg_fs: 0.0010138421785086393\n",
      "Epoch: 7500 train loss=0.002100022 valid loss= 0.004151458\n",
      "train reg_fs: 0.0010034216102212667\n",
      "Epoch: 8000 train loss=0.002720050 valid loss= 0.003967077\n",
      "train reg_fs: 0.0009902322199195623\n",
      "Epoch: 8500 train loss=0.002429543 valid loss= 0.004026403\n",
      "train reg_fs: 0.0009794641518965364\n",
      "Epoch: 9000 train loss=0.003479920 valid loss= 0.003563888\n",
      "train reg_fs: 0.0009707040153443813\n",
      "Epoch: 9500 train loss=0.003511088 valid loss= 0.004111366\n",
      "train reg_fs: 0.0009605441009625793\n",
      "Epoch: 10000 train loss=0.001368545 valid loss= 0.003698161\n",
      "train reg_fs: 0.000950857880525291\n",
      "Epoch: 10500 train loss=0.002688482 valid loss= 0.003862551\n",
      "train reg_fs: 0.0009438877459615469\n",
      "Epoch: 11000 train loss=0.001647075 valid loss= 0.003807395\n",
      "train reg_fs: 0.0009341484983451664\n",
      "Epoch: 11500 train loss=0.001347524 valid loss= 0.003713142\n",
      "train reg_fs: 0.00092921411851421\n",
      "Epoch: 12000 train loss=0.002925683 valid loss= 0.004197257\n",
      "train reg_fs: 0.0009216303587891161\n",
      "Epoch: 12500 train loss=0.002915101 valid loss= 0.003921572\n",
      "train reg_fs: 0.0009156871819868684\n",
      "Epoch: 13000 train loss=0.001885034 valid loss= 0.004107278\n",
      "train reg_fs: 0.0009097506990656257\n",
      "Epoch: 13500 train loss=0.003133837 valid loss= 0.004022951\n",
      "train reg_fs: 0.0009047971107065678\n",
      "Epoch: 14000 train loss=0.002315553 valid loss= 0.004144581\n",
      "train reg_fs: 0.0009005642496049404\n",
      "Epoch: 14500 train loss=0.004652323 valid loss= 0.004383361\n",
      "train reg_fs: 0.000897224759683013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:14:53,713]\u001b[0m Trial 82 finished with value: 0.0028257798660290324 and parameters: {'lam': 0.0012853470163113423, 'learning_rate': 0.0986150308423417, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002576911 valid loss= 0.003705890\n",
      "train reg_fs: 0.0008962437859736383\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028257798660290324\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007420167 valid loss= 0.005972238\n",
      "train reg_fs: 0.0009250797447748482\n",
      "Epoch: 1000 train loss=0.004546567 valid loss= 0.003414853\n",
      "train reg_fs: 0.0008649390656501055\n",
      "Epoch: 1500 train loss=0.007696926 valid loss= 0.003202930\n",
      "train reg_fs: 0.000848200754262507\n",
      "Epoch: 2000 train loss=0.002968269 valid loss= 0.003541176\n",
      "train reg_fs: 0.0008338501793332398\n",
      "Epoch: 2500 train loss=0.002724824 valid loss= 0.003469957\n",
      "train reg_fs: 0.000823731126729399\n",
      "Epoch: 3000 train loss=0.001493875 valid loss= 0.002762631\n",
      "train reg_fs: 0.0008181227603927255\n",
      "Epoch: 3500 train loss=0.002303714 valid loss= 0.002956722\n",
      "train reg_fs: 0.0008158159907907248\n",
      "Epoch: 4000 train loss=0.004639022 valid loss= 0.002632074\n",
      "train reg_fs: 0.0008140949066728354\n",
      "Epoch: 4500 train loss=0.001000113 valid loss= 0.003078976\n",
      "train reg_fs: 0.0008127728942781687\n",
      "Epoch: 5000 train loss=0.001949719 valid loss= 0.002926352\n",
      "train reg_fs: 0.000811894831713289\n",
      "Epoch: 5500 train loss=0.002216131 valid loss= 0.002655554\n",
      "train reg_fs: 0.0008110794005915523\n",
      "Epoch: 6000 train loss=0.002907433 valid loss= 0.002773487\n",
      "train reg_fs: 0.0008098720572888851\n",
      "Epoch: 6500 train loss=0.002152202 valid loss= 0.003350817\n",
      "train reg_fs: 0.0008085614535957575\n",
      "Epoch: 7000 train loss=0.004081324 valid loss= 0.002723300\n",
      "train reg_fs: 0.0008075729128904641\n",
      "Epoch: 7500 train loss=0.001861928 valid loss= 0.002982558\n",
      "train reg_fs: 0.000806089024990797\n",
      "Epoch: 8000 train loss=0.003508906 valid loss= 0.003439587\n",
      "train reg_fs: 0.0008042095578275621\n",
      "Epoch: 8500 train loss=0.001827837 valid loss= 0.002924766\n",
      "train reg_fs: 0.0008025423740036786\n",
      "Epoch: 9000 train loss=0.001729685 valid loss= 0.003072908\n",
      "train reg_fs: 0.0008007505675777793\n",
      "Epoch: 9500 train loss=0.002000255 valid loss= 0.002557703\n",
      "train reg_fs: 0.0007987561402842402\n",
      "Epoch: 10000 train loss=0.002257215 valid loss= 0.003211871\n",
      "train reg_fs: 0.0007968632271513343\n",
      "Epoch: 10500 train loss=0.001267025 valid loss= 0.002708978\n",
      "train reg_fs: 0.0007952768355607986\n",
      "Epoch: 11000 train loss=0.001550240 valid loss= 0.002934799\n",
      "train reg_fs: 0.0007929473649710417\n",
      "Epoch: 11500 train loss=0.001052572 valid loss= 0.002609730\n",
      "train reg_fs: 0.0007911052089184523\n",
      "Epoch: 12000 train loss=0.001027541 valid loss= 0.002760123\n",
      "train reg_fs: 0.0007891064160503447\n",
      "Epoch: 12500 train loss=0.001117148 valid loss= 0.002929456\n",
      "train reg_fs: 0.0007873745635151863\n",
      "Epoch: 13000 train loss=0.001719568 valid loss= 0.003068028\n",
      "train reg_fs: 0.0007857134914956987\n",
      "Epoch: 13500 train loss=0.005912946 valid loss= 0.003213697\n",
      "train reg_fs: 0.0007839705795049667\n",
      "Epoch: 14000 train loss=0.001466906 valid loss= 0.002959838\n",
      "train reg_fs: 0.0007821696344763041\n",
      "Epoch: 14500 train loss=0.001201779 valid loss= 0.003279571\n",
      "train reg_fs: 0.0007806877256371081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:16:29,900]\u001b[0m Trial 83 finished with value: 0.0020302693022271707 and parameters: {'lam': 0.001091307435312138, 'learning_rate': 0.15881081460225327, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004928666 valid loss= 0.002777411\n",
      "train reg_fs: 0.0007793524418957531\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020302693022271707\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015723474 valid loss= 0.009317620\n",
      "train reg_fs: 0.00086682551773265\n",
      "Epoch: 1000 train loss=0.011383340 valid loss= 0.008940028\n",
      "train reg_fs: 0.0008739352342672646\n",
      "Epoch: 1500 train loss=0.004532153 valid loss= 0.007946665\n",
      "train reg_fs: 0.000860473548527807\n",
      "Epoch: 2000 train loss=0.011427170 valid loss= 0.006720189\n",
      "train reg_fs: 0.0008421657839789987\n",
      "Epoch: 2500 train loss=0.003089452 valid loss= 0.005646833\n",
      "train reg_fs: 0.0008314137230627239\n",
      "Epoch: 3000 train loss=0.005562146 valid loss= 0.004825108\n",
      "train reg_fs: 0.0008248009835369885\n",
      "Epoch: 3500 train loss=0.006160483 valid loss= 0.004428841\n",
      "train reg_fs: 0.0008171764784492552\n",
      "Epoch: 4000 train loss=0.004917155 valid loss= 0.003558432\n",
      "train reg_fs: 0.000807796255685389\n",
      "Epoch: 4500 train loss=0.004958245 valid loss= 0.003590152\n",
      "train reg_fs: 0.0007979309884831309\n",
      "Epoch: 5000 train loss=0.004116037 valid loss= 0.003578039\n",
      "train reg_fs: 0.0007922279182821512\n",
      "Epoch: 5500 train loss=0.002426379 valid loss= 0.003389621\n",
      "train reg_fs: 0.0007899622432887554\n",
      "Epoch: 6000 train loss=0.005964571 valid loss= 0.003448656\n",
      "train reg_fs: 0.0007883081561885774\n",
      "Epoch: 6500 train loss=0.007024984 valid loss= 0.003414783\n",
      "train reg_fs: 0.0007860183832235634\n",
      "Epoch: 7000 train loss=0.004750116 valid loss= 0.003367815\n",
      "train reg_fs: 0.0007814636919647455\n",
      "Epoch: 7500 train loss=0.002141106 valid loss= 0.003509509\n",
      "train reg_fs: 0.0007770008523948491\n",
      "Epoch: 8000 train loss=0.002039310 valid loss= 0.003462930\n",
      "train reg_fs: 0.0007739446009509265\n",
      "Epoch: 8500 train loss=0.005124761 valid loss= 0.003714450\n",
      "train reg_fs: 0.0007694714004173875\n",
      "Epoch: 9000 train loss=0.002378179 valid loss= 0.003477611\n",
      "train reg_fs: 0.0007640196708962321\n",
      "Epoch: 9500 train loss=0.001371829 valid loss= 0.003493723\n",
      "train reg_fs: 0.0007595807546749711\n",
      "Epoch: 10000 train loss=0.002127647 valid loss= 0.003217337\n",
      "train reg_fs: 0.0007563127437606454\n",
      "Epoch: 10500 train loss=0.000964985 valid loss= 0.003094786\n",
      "train reg_fs: 0.0007536453194916248\n",
      "Epoch: 11000 train loss=0.001997710 valid loss= 0.003411457\n",
      "train reg_fs: 0.0007505782996304333\n",
      "Epoch: 11500 train loss=0.001305639 valid loss= 0.003582921\n",
      "train reg_fs: 0.0007477313629351556\n",
      "Epoch: 12000 train loss=0.003063506 valid loss= 0.003233566\n",
      "train reg_fs: 0.0007450844277627766\n",
      "Epoch: 12500 train loss=0.004124525 valid loss= 0.003053869\n",
      "train reg_fs: 0.0007428170065395534\n",
      "Epoch: 13000 train loss=0.012044330 valid loss= 0.003146968\n",
      "train reg_fs: 0.0007406816584989429\n",
      "Epoch: 13500 train loss=0.002164579 valid loss= 0.003194604\n",
      "train reg_fs: 0.0007380407769232988\n",
      "Epoch: 14000 train loss=0.001026511 valid loss= 0.003342693\n",
      "train reg_fs: 0.0007361749885603786\n",
      "Epoch: 14500 train loss=0.001318225 valid loss= 0.003413803\n",
      "train reg_fs: 0.0007340687443502247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:18:10,529]\u001b[0m Trial 84 finished with value: 0.0025128895339924045 and parameters: {'lam': 0.0010032083666825095, 'learning_rate': 0.07726230794091583, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004067254 valid loss= 0.003236564\n",
      "train reg_fs: 0.0007328114006668329\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025128895339924045\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007061153 valid loss= 0.006566068\n",
      "train reg_fs: 0.0010516266338527203\n",
      "Epoch: 1000 train loss=0.007585353 valid loss= 0.005886904\n",
      "train reg_fs: 0.0010243685683235526\n",
      "Epoch: 1500 train loss=0.006825306 valid loss= 0.004029695\n",
      "train reg_fs: 0.000989057240076363\n",
      "Epoch: 2000 train loss=0.004848271 valid loss= 0.002802974\n",
      "train reg_fs: 0.0009505694615654647\n",
      "Epoch: 2500 train loss=0.005627974 valid loss= 0.002956351\n",
      "train reg_fs: 0.0009267909335903823\n",
      "Epoch: 3000 train loss=0.003351543 valid loss= 0.003426099\n",
      "train reg_fs: 0.0009150510304607451\n",
      "Epoch: 3500 train loss=0.001546033 valid loss= 0.002914811\n",
      "train reg_fs: 0.0009069273946806788\n",
      "Epoch: 4000 train loss=0.003515698 valid loss= 0.002989151\n",
      "train reg_fs: 0.0009024075698107481\n",
      "Epoch: 4500 train loss=0.002736984 valid loss= 0.002581517\n",
      "train reg_fs: 0.0008998090634122491\n",
      "Epoch: 5000 train loss=0.002343931 valid loss= 0.003113764\n",
      "train reg_fs: 0.000896383891813457\n",
      "In trial:---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:19:13,678]\u001b[0m Trial 85 finished with value: 0.0022340949918178954 and parameters: {'lam': 0.0012043345112359453, 'learning_rate': 0.12375109222487471, 'num_epoch': 5000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mse: 0.0022340949918178954\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.024704596 valid loss= 0.007956521\n",
      "train reg_fs: 0.0019126713741570711\n",
      "Epoch: 1000 train loss=0.005146876 valid loss= 0.007704056\n",
      "train reg_fs: 0.0019152623135596514\n",
      "Epoch: 1500 train loss=0.006007733 valid loss= 0.007188096\n",
      "train reg_fs: 0.0018832663772627711\n",
      "Epoch: 2000 train loss=0.007043129 valid loss= 0.005735738\n",
      "train reg_fs: 0.0018437022808939219\n",
      "Epoch: 2500 train loss=0.002934519 valid loss= 0.005255266\n",
      "train reg_fs: 0.0017969663022086024\n",
      "Epoch: 3000 train loss=0.007929538 valid loss= 0.004304383\n",
      "train reg_fs: 0.0017478944500908256\n",
      "Epoch: 3500 train loss=0.005450982 valid loss= 0.003978021\n",
      "train reg_fs: 0.0017121731070801616\n",
      "Epoch: 4000 train loss=0.005161102 valid loss= 0.003984666\n",
      "train reg_fs: 0.0016872708220034838\n",
      "Epoch: 4500 train loss=0.001859100 valid loss= 0.003546222\n",
      "train reg_fs: 0.0016690478660166264\n",
      "Epoch: 5000 train loss=0.009464378 valid loss= 0.004342743\n",
      "train reg_fs: 0.001657324843108654\n",
      "Epoch: 5500 train loss=0.008412610 valid loss= 0.003583729\n",
      "train reg_fs: 0.0016481679631397128\n",
      "Epoch: 6000 train loss=0.004077609 valid loss= 0.003891993\n",
      "train reg_fs: 0.0016417262377217412\n",
      "Epoch: 6500 train loss=0.003755417 valid loss= 0.003569197\n",
      "train reg_fs: 0.0016349070938304067\n",
      "Epoch: 7000 train loss=0.003501826 valid loss= 0.003577976\n",
      "train reg_fs: 0.0016302221920341253\n",
      "Epoch: 7500 train loss=0.003154136 valid loss= 0.003458609\n",
      "train reg_fs: 0.0016263076104223728\n",
      "Epoch: 8000 train loss=0.003085694 valid loss= 0.003428949\n",
      "train reg_fs: 0.0016217236407101154\n",
      "Epoch: 8500 train loss=0.001947801 valid loss= 0.003170802\n",
      "train reg_fs: 0.0016177878715097904\n",
      "Epoch: 9000 train loss=0.003395100 valid loss= 0.003215245\n",
      "train reg_fs: 0.0016135865589603782\n",
      "Epoch: 9500 train loss=0.004584518 valid loss= 0.003015452\n",
      "train reg_fs: 0.0016094716265797615\n",
      "Epoch: 10000 train loss=0.003783260 valid loss= 0.003445180\n",
      "train reg_fs: 0.0016039581969380379\n",
      "Epoch: 10500 train loss=0.003316848 valid loss= 0.003009682\n",
      "train reg_fs: 0.0015969413798302412\n",
      "Epoch: 11000 train loss=0.002394454 valid loss= 0.003033332\n",
      "train reg_fs: 0.0015908501809462905\n",
      "Epoch: 11500 train loss=0.003182156 valid loss= 0.002854337\n",
      "train reg_fs: 0.001584026962518692\n",
      "Epoch: 12000 train loss=0.006725571 valid loss= 0.002648647\n",
      "train reg_fs: 0.001577781280502677\n",
      "Epoch: 12500 train loss=0.001732189 valid loss= 0.002618974\n",
      "train reg_fs: 0.0015702672535553575\n",
      "Epoch: 13000 train loss=0.001775897 valid loss= 0.002926257\n",
      "train reg_fs: 0.001562799559906125\n",
      "Epoch: 13500 train loss=0.001883472 valid loss= 0.002724578\n",
      "train reg_fs: 0.001555339782498777\n",
      "Epoch: 14000 train loss=0.003419577 valid loss= 0.002570856\n",
      "train reg_fs: 0.0015494731487706304\n",
      "Epoch: 14500 train loss=0.002841359 valid loss= 0.003199729\n",
      "train reg_fs: 0.0015417613321915269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:22:10,383]\u001b[0m Trial 86 finished with value: 0.001096521407566575 and parameters: {'lam': 0.0022046879625377143, 'learning_rate': 0.06439738582186634, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006775028 valid loss= 0.002629458\n",
      "train reg_fs: 0.001535402494482696\n",
      "In trial:---------------------\n",
      "validation mse: 0.001096521407566575\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009276664 valid loss= 0.008231747\n",
      "train reg_fs: 0.0018370317993685603\n",
      "Epoch: 1000 train loss=0.013324753 valid loss= 0.007655943\n",
      "train reg_fs: 0.0018351742764934897\n",
      "Epoch: 1500 train loss=0.003504034 valid loss= 0.006542041\n",
      "train reg_fs: 0.0017992722569033504\n",
      "Epoch: 2000 train loss=0.011528111 valid loss= 0.006196542\n",
      "train reg_fs: 0.0017429060535505414\n",
      "Epoch: 2500 train loss=0.004200541 valid loss= 0.004606038\n",
      "train reg_fs: 0.0016888740938156843\n",
      "Epoch: 3000 train loss=0.012262836 valid loss= 0.003924193\n",
      "train reg_fs: 0.0016383032780140638\n",
      "Epoch: 3500 train loss=0.006117884 valid loss= 0.004174484\n",
      "train reg_fs: 0.0016043398063629866\n",
      "Epoch: 4000 train loss=0.008449393 valid loss= 0.004491342\n",
      "train reg_fs: 0.001576868467964232\n",
      "Epoch: 4500 train loss=0.006476355 valid loss= 0.004164921\n",
      "train reg_fs: 0.0015555942663922906\n",
      "Epoch: 5000 train loss=0.011143156 valid loss= 0.004177075\n",
      "train reg_fs: 0.0015369130996987224\n",
      "Epoch: 5500 train loss=0.002729192 valid loss= 0.004380745\n",
      "train reg_fs: 0.001519685611128807\n",
      "Epoch: 6000 train loss=0.007304221 valid loss= 0.003893650\n",
      "train reg_fs: 0.0015037626726552844\n",
      "Epoch: 6500 train loss=0.005908859 valid loss= 0.003863845\n",
      "train reg_fs: 0.0014896170469000936\n",
      "Epoch: 7000 train loss=0.004506966 valid loss= 0.004043597\n",
      "train reg_fs: 0.001473501673899591\n",
      "Epoch: 7500 train loss=0.003323538 valid loss= 0.003797841\n",
      "train reg_fs: 0.0014557306421920657\n",
      "Epoch: 8000 train loss=0.002600690 valid loss= 0.003980251\n",
      "train reg_fs: 0.0014388792915269732\n",
      "Epoch: 8500 train loss=0.004441485 valid loss= 0.004064691\n",
      "train reg_fs: 0.0014238905860111117\n",
      "Epoch: 9000 train loss=0.001880191 valid loss= 0.003745479\n",
      "train reg_fs: 0.0014088554307818413\n",
      "Epoch: 9500 train loss=0.002500443 valid loss= 0.003659301\n",
      "train reg_fs: 0.0013939854688942432\n",
      "Epoch: 10000 train loss=0.002872773 valid loss= 0.003869225\n",
      "train reg_fs: 0.0013805984053760767\n",
      "Epoch: 10500 train loss=0.001937923 valid loss= 0.003565329\n",
      "train reg_fs: 0.001369973411783576\n",
      "Epoch: 11000 train loss=0.001966475 valid loss= 0.003559061\n",
      "train reg_fs: 0.0013597572688013315\n",
      "Epoch: 11500 train loss=0.008614124 valid loss= 0.003770996\n",
      "train reg_fs: 0.0013508880510926247\n",
      "Epoch: 12000 train loss=0.003609414 valid loss= 0.003473629\n",
      "train reg_fs: 0.0013438065070658922\n",
      "Epoch: 12500 train loss=0.001809226 valid loss= 0.003623772\n",
      "train reg_fs: 0.0013378895819187164\n",
      "Epoch: 13000 train loss=0.002564648 valid loss= 0.003535269\n",
      "train reg_fs: 0.0013324104947969317\n",
      "Epoch: 13500 train loss=0.002645113 valid loss= 0.004034235\n",
      "train reg_fs: 0.0013277959078550339\n",
      "Epoch: 14000 train loss=0.004613220 valid loss= 0.003668589\n",
      "train reg_fs: 0.001323699252679944\n",
      "Epoch: 14500 train loss=0.001727899 valid loss= 0.003677694\n",
      "train reg_fs: 0.0013198027154430747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:23:51,920]\u001b[0m Trial 87 finished with value: 0.0020511547755111543 and parameters: {'lam': 0.00211755970261505, 'learning_rate': 0.059449822038836704, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002236890 valid loss= 0.003342905\n",
      "train reg_fs: 0.0013163965195417404\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020511547755111543\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008157247 valid loss= 0.007706000\n",
      "train reg_fs: 0.0013156681088730693\n",
      "Epoch: 1000 train loss=0.013990852 valid loss= 0.007623780\n",
      "train reg_fs: 0.0013134728651493788\n",
      "Epoch: 1500 train loss=0.008614870 valid loss= 0.006695957\n",
      "train reg_fs: 0.001296658650971949\n",
      "Epoch: 2000 train loss=0.009676555 valid loss= 0.006238726\n",
      "train reg_fs: 0.0012789256870746613\n",
      "Epoch: 2500 train loss=0.005115103 valid loss= 0.006170733\n",
      "train reg_fs: 0.001264981459826231\n",
      "Epoch: 3000 train loss=0.007736691 valid loss= 0.006160524\n",
      "train reg_fs: 0.0012574986321851611\n",
      "Epoch: 3500 train loss=0.003593564 valid loss= 0.005555618\n",
      "train reg_fs: 0.0012524237390607595\n",
      "Epoch: 4000 train loss=0.005645910 valid loss= 0.004971039\n",
      "train reg_fs: 0.0012491451343521476\n",
      "Epoch: 4500 train loss=0.003667323 valid loss= 0.004835416\n",
      "train reg_fs: 0.0012462445301935077\n",
      "Epoch: 5000 train loss=0.005507104 valid loss= 0.004559021\n",
      "train reg_fs: 0.0012443531304597855\n",
      "Epoch: 5500 train loss=0.004587141 valid loss= 0.004500741\n",
      "train reg_fs: 0.0012407165486365557\n",
      "Epoch: 6000 train loss=0.002625450 valid loss= 0.004254139\n",
      "train reg_fs: 0.0012396759120747447\n",
      "Epoch: 6500 train loss=0.004656124 valid loss= 0.003926918\n",
      "train reg_fs: 0.0012356698280200362\n",
      "Epoch: 7000 train loss=0.003881822 valid loss= 0.004014605\n",
      "train reg_fs: 0.0012320124078541994\n",
      "Epoch: 7500 train loss=0.002859671 valid loss= 0.004109712\n",
      "train reg_fs: 0.0012245284160599113\n",
      "Epoch: 8000 train loss=0.003375023 valid loss= 0.004015706\n",
      "train reg_fs: 0.0012185898376628757\n",
      "Epoch: 8500 train loss=0.006308657 valid loss= 0.003890320\n",
      "train reg_fs: 0.0012129541719332337\n",
      "Epoch: 9000 train loss=0.004055450 valid loss= 0.003927246\n",
      "train reg_fs: 0.001205338747240603\n",
      "Epoch: 9500 train loss=0.005539721 valid loss= 0.003811169\n",
      "train reg_fs: 0.0011978491675108671\n",
      "Epoch: 10000 train loss=0.003482816 valid loss= 0.004124502\n",
      "train reg_fs: 0.001189862028695643\n",
      "Epoch: 10500 train loss=0.001971106 valid loss= 0.003969194\n",
      "train reg_fs: 0.0011837268248200417\n",
      "Epoch: 11000 train loss=0.002191396 valid loss= 0.003969906\n",
      "train reg_fs: 0.0011779011692851782\n",
      "Epoch: 11500 train loss=0.002779840 valid loss= 0.003926710\n",
      "train reg_fs: 0.0011699222959578037\n",
      "Epoch: 12000 train loss=0.001675279 valid loss= 0.003858441\n",
      "train reg_fs: 0.0011624187463894486\n",
      "Epoch: 12500 train loss=0.003097203 valid loss= 0.003924999\n",
      "train reg_fs: 0.0011571189388632774\n",
      "Epoch: 13000 train loss=0.002012507 valid loss= 0.004024785\n",
      "train reg_fs: 0.0011499046813696623\n",
      "Epoch: 13500 train loss=0.003639793 valid loss= 0.003923467\n",
      "train reg_fs: 0.0011443268740549684\n",
      "Epoch: 14000 train loss=0.005570880 valid loss= 0.004042412\n",
      "train reg_fs: 0.001138627645559609\n",
      "Epoch: 14500 train loss=0.002505350 valid loss= 0.004022674\n",
      "train reg_fs: 0.0011331051355227828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:25:33,079]\u001b[0m Trial 88 finished with value: 0.0026840584858194654 and parameters: {'lam': 0.001534185366988185, 'learning_rate': 0.06703510921088929, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001799349 valid loss= 0.003814474\n",
      "train reg_fs: 0.0011264508357271552\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026840584858194654\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011229913 valid loss= 0.008469895\n",
      "train reg_fs: 0.0016643479466438293\n",
      "Epoch: 1000 train loss=0.010915063 valid loss= 0.007338491\n",
      "train reg_fs: 0.0016776007832959294\n",
      "Epoch: 1500 train loss=0.012200745 valid loss= 0.007221521\n",
      "train reg_fs: 0.0016768876230344176\n",
      "Epoch: 2000 train loss=0.006835725 valid loss= 0.006817506\n",
      "train reg_fs: 0.0016611337196081877\n",
      "Epoch: 2500 train loss=0.009924344 valid loss= 0.007009194\n",
      "train reg_fs: 0.00164012738969177\n",
      "Epoch: 3000 train loss=0.007408567 valid loss= 0.006270991\n",
      "train reg_fs: 0.0016116551123559475\n",
      "Epoch: 3500 train loss=0.006806100 valid loss= 0.006124819\n",
      "train reg_fs: 0.001585023826919496\n",
      "Epoch: 4000 train loss=0.009546773 valid loss= 0.004536009\n",
      "train reg_fs: 0.001558097661472857\n",
      "Epoch: 4500 train loss=0.006076220 valid loss= 0.004090176\n",
      "train reg_fs: 0.0015306613640859723\n",
      "Epoch: 5000 train loss=0.004453519 valid loss= 0.004243479\n",
      "train reg_fs: 0.0015062877209857106\n",
      "Epoch: 5500 train loss=0.008595355 valid loss= 0.004138467\n",
      "train reg_fs: 0.001483733532950282\n",
      "Epoch: 6000 train loss=0.009442865 valid loss= 0.004121837\n",
      "train reg_fs: 0.0014645634219050407\n",
      "Epoch: 6500 train loss=0.004864283 valid loss= 0.004032765\n",
      "train reg_fs: 0.0014458742225542665\n",
      "Epoch: 7000 train loss=0.004320485 valid loss= 0.004391945\n",
      "train reg_fs: 0.0014292261330410838\n",
      "Epoch: 7500 train loss=0.005369700 valid loss= 0.004051640\n",
      "train reg_fs: 0.001413936261087656\n",
      "Epoch: 8000 train loss=0.004961625 valid loss= 0.004448734\n",
      "train reg_fs: 0.0014001118252053857\n",
      "Epoch: 8500 train loss=0.005962235 valid loss= 0.004246415\n",
      "train reg_fs: 0.0013878237223252654\n",
      "Epoch: 9000 train loss=0.006096036 valid loss= 0.004194960\n",
      "train reg_fs: 0.0013752205995842814\n",
      "Epoch: 9500 train loss=0.001939806 valid loss= 0.004226632\n",
      "train reg_fs: 0.0013638834934681654\n",
      "Epoch: 10000 train loss=0.001855488 valid loss= 0.003855751\n",
      "train reg_fs: 0.0013540792278945446\n",
      "Epoch: 10500 train loss=0.008465719 valid loss= 0.003899996\n",
      "train reg_fs: 0.0013453847495839\n",
      "Epoch: 11000 train loss=0.002769798 valid loss= 0.003925167\n",
      "train reg_fs: 0.001336284913122654\n",
      "Epoch: 11500 train loss=0.002639333 valid loss= 0.003532824\n",
      "train reg_fs: 0.0013285012682899833\n",
      "Epoch: 12000 train loss=0.003398118 valid loss= 0.003749143\n",
      "train reg_fs: 0.0013210466131567955\n",
      "Epoch: 12500 train loss=0.003298351 valid loss= 0.003895528\n",
      "train reg_fs: 0.0013143918476998806\n",
      "Epoch: 13000 train loss=0.003442402 valid loss= 0.003667112\n",
      "train reg_fs: 0.0013087582774460316\n",
      "Epoch: 13500 train loss=0.002720488 valid loss= 0.003515273\n",
      "train reg_fs: 0.0013036902528256178\n",
      "Epoch: 14000 train loss=0.002415104 valid loss= 0.003714981\n",
      "train reg_fs: 0.0012988051166757941\n",
      "Epoch: 14500 train loss=0.005247735 valid loss= 0.003731322\n",
      "train reg_fs: 0.0012942521134391427\n",
      "Epoch: 15000 train loss=0.002171068 valid loss= 0.003701486\n",
      "train reg_fs: 0.0012898579007014632\n",
      "In trial:---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:27:18,023]\u001b[0m Trial 89 finished with value: 0.002402630503974936 and parameters: {'lam': 0.0019479302598058037, 'learning_rate': 0.038929841757173594, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mse: 0.002402630503974936\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010820958 valid loss= 0.008103735\n",
      "train reg_fs: 0.001540329889394343\n",
      "Epoch: 1000 train loss=0.007230764 valid loss= 0.009085628\n",
      "train reg_fs: 0.0015715783229097724\n",
      "Epoch: 1500 train loss=0.012044249 valid loss= 0.009417007\n",
      "train reg_fs: 0.0015785645227879286\n",
      "Epoch: 2000 train loss=0.011046049 valid loss= 0.008386583\n",
      "train reg_fs: 0.0015620131744071841\n",
      "Epoch: 2500 train loss=0.004393145 valid loss= 0.006419736\n",
      "train reg_fs: 0.0015075349947437644\n",
      "Epoch: 3000 train loss=0.006569281 valid loss= 0.004301345\n",
      "train reg_fs: 0.001448056660592556\n",
      "Epoch: 3500 train loss=0.004921533 valid loss= 0.003617156\n",
      "train reg_fs: 0.0013954320456832647\n",
      "Epoch: 4000 train loss=0.003102857 valid loss= 0.003946954\n",
      "train reg_fs: 0.0013642468256875873\n",
      "Epoch: 4500 train loss=0.010854132 valid loss= 0.003979080\n",
      "train reg_fs: 0.0013453190913423896\n",
      "Epoch: 5000 train loss=0.009131642 valid loss= 0.004042825\n",
      "train reg_fs: 0.0013312596129253507\n",
      "Epoch: 5500 train loss=0.004023481 valid loss= 0.003719160\n",
      "train reg_fs: 0.0013213369529694319\n",
      "Epoch: 6000 train loss=0.001755323 valid loss= 0.003432477\n",
      "train reg_fs: 0.0013131228042766452\n",
      "Epoch: 6500 train loss=0.003610821 valid loss= 0.003409181\n",
      "train reg_fs: 0.0013061721110716462\n",
      "Epoch: 7000 train loss=0.001922080 valid loss= 0.003468003\n",
      "train reg_fs: 0.0012994292192161083\n",
      "Epoch: 7500 train loss=0.001697742 valid loss= 0.003434978\n",
      "train reg_fs: 0.0012947035720571876\n",
      "Epoch: 8000 train loss=0.003102176 valid loss= 0.003886208\n",
      "train reg_fs: 0.0012910731602460146\n",
      "Epoch: 8500 train loss=0.004514038 valid loss= 0.003308148\n",
      "train reg_fs: 0.0012861057184636593\n",
      "Epoch: 9000 train loss=0.001468709 valid loss= 0.003647860\n",
      "train reg_fs: 0.0012820690171793103\n",
      "Epoch: 9500 train loss=0.004309924 valid loss= 0.003606206\n",
      "train reg_fs: 0.0012781218392774463\n",
      "Epoch: 10000 train loss=0.002969602 valid loss= 0.003558252\n",
      "train reg_fs: 0.0012746243737637997\n",
      "Epoch: 10500 train loss=0.001767756 valid loss= 0.003654597\n",
      "train reg_fs: 0.001270892797037959\n",
      "Epoch: 11000 train loss=0.001923347 valid loss= 0.003377604\n",
      "train reg_fs: 0.001268051448278129\n",
      "Epoch: 11500 train loss=0.002136959 valid loss= 0.003798451\n",
      "train reg_fs: 0.0012651203433051705\n",
      "Epoch: 12000 train loss=0.007705220 valid loss= 0.003494050\n",
      "train reg_fs: 0.0012621431378647685\n",
      "Epoch: 12500 train loss=0.002150492 valid loss= 0.003124030\n",
      "train reg_fs: 0.0012590026017278433\n",
      "Epoch: 13000 train loss=0.001807708 valid loss= 0.003357078\n",
      "train reg_fs: 0.0012565782526507974\n",
      "Epoch: 13500 train loss=0.004955918 valid loss= 0.003366294\n",
      "train reg_fs: 0.0012541296891868114\n",
      "Epoch: 14000 train loss=0.003124761 valid loss= 0.003178500\n",
      "train reg_fs: 0.0012520179152488708\n",
      "Epoch: 14500 train loss=0.003115189 valid loss= 0.003281363\n",
      "train reg_fs: 0.0012502588797360659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:29:09,296]\u001b[0m Trial 90 finished with value: 0.002361578762268217 and parameters: {'lam': 0.001749249171153748, 'learning_rate': 0.08876124323474481, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001561318 valid loss= 0.003564918\n",
      "train reg_fs: 0.0012488176580518484\n",
      "In trial:---------------------\n",
      "validation mse: 0.002361578762268217\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009832487 valid loss= 0.009225358\n",
      "train reg_fs: 0.0024378765374422073\n",
      "Epoch: 1000 train loss=0.008946975 valid loss= 0.008551716\n",
      "train reg_fs: 0.0023558735847473145\n",
      "Epoch: 1500 train loss=0.009523649 valid loss= 0.008337766\n",
      "train reg_fs: 0.002303407061845064\n",
      "Epoch: 2000 train loss=0.010650449 valid loss= 0.008283386\n",
      "train reg_fs: 0.002253210637718439\n",
      "Epoch: 2500 train loss=0.006213224 valid loss= 0.007639529\n",
      "train reg_fs: 0.002214518142864108\n",
      "Epoch: 3000 train loss=0.008555797 valid loss= 0.007228822\n",
      "train reg_fs: 0.002165872370824218\n",
      "Epoch: 3500 train loss=0.006109131 valid loss= 0.005636670\n",
      "train reg_fs: 0.00210755318403244\n",
      "Epoch: 4000 train loss=0.003895362 valid loss= 0.005678682\n",
      "train reg_fs: 0.0020543024875223637\n",
      "Epoch: 4500 train loss=0.005628450 valid loss= 0.005609264\n",
      "train reg_fs: 0.002026936039328575\n",
      "Epoch: 5000 train loss=0.004725383 valid loss= 0.005878239\n",
      "train reg_fs: 0.00200539524666965\n",
      "Epoch: 5500 train loss=0.009937601 valid loss= 0.006307588\n",
      "train reg_fs: 0.0019903124775737524\n",
      "Epoch: 6000 train loss=0.006472799 valid loss= 0.005799309\n",
      "train reg_fs: 0.0019740816205739975\n",
      "Epoch: 6500 train loss=0.004716696 valid loss= 0.006043300\n",
      "train reg_fs: 0.001972578465938568\n",
      "Epoch: 7000 train loss=0.009807714 valid loss= 0.005817760\n",
      "train reg_fs: 0.0019682319834828377\n",
      "Epoch: 7500 train loss=0.005037571 valid loss= 0.006272457\n",
      "train reg_fs: 0.0019744045566767454\n",
      "Epoch: 8000 train loss=0.007450407 valid loss= 0.005766944\n",
      "train reg_fs: 0.0019815503619611263\n",
      "Epoch: 8500 train loss=0.003603156 valid loss= 0.005458828\n",
      "train reg_fs: 0.0019860321190208197\n",
      "Epoch: 9000 train loss=0.005714693 valid loss= 0.005714298\n",
      "train reg_fs: 0.0019743856973946095\n",
      "Epoch: 9500 train loss=0.005770614 valid loss= 0.005669548\n",
      "train reg_fs: 0.0019705560989677906\n",
      "Epoch: 10000 train loss=0.003129206 valid loss= 0.005762553\n",
      "train reg_fs: 0.001958297798410058\n",
      "Epoch: 10500 train loss=0.003795424 valid loss= 0.005661179\n",
      "train reg_fs: 0.0019504507072269917\n",
      "Epoch: 11000 train loss=0.005430385 valid loss= 0.005502011\n",
      "train reg_fs: 0.0019389535300433636\n",
      "Epoch: 11500 train loss=0.002520258 valid loss= 0.005681170\n",
      "train reg_fs: 0.0019297668477520347\n",
      "Epoch: 12000 train loss=0.003710207 valid loss= 0.005440573\n",
      "train reg_fs: 0.0019230114994570613\n",
      "Epoch: 12500 train loss=0.002366034 valid loss= 0.005351255\n",
      "train reg_fs: 0.0019127367995679379\n",
      "Epoch: 13000 train loss=0.003894988 valid loss= 0.005326987\n",
      "train reg_fs: 0.0019096980104222894\n",
      "Epoch: 13500 train loss=0.002294812 valid loss= 0.005331785\n",
      "train reg_fs: 0.0019002911867573857\n",
      "Epoch: 14000 train loss=0.003221029 valid loss= 0.005373561\n",
      "train reg_fs: 0.0018911767983809114\n",
      "Epoch: 14500 train loss=0.002928763 valid loss= 0.005464581\n",
      "train reg_fs: 0.0018806528532877564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:30:57,016]\u001b[0m Trial 91 finished with value: 0.0034164828308326026 and parameters: {'lam': 0.0028618519510441617, 'learning_rate': 0.10112985012452004, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003064393 valid loss= 0.005374095\n",
      "train reg_fs: 0.0018793499330058694\n",
      "In trial:---------------------\n",
      "validation mse: 0.0034164828308326026\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012673903 valid loss= 0.007112233\n",
      "train reg_fs: 0.001970512792468071\n",
      "Epoch: 1000 train loss=0.007420980 valid loss= 0.006867778\n",
      "train reg_fs: 0.0019542775116860867\n",
      "Epoch: 1500 train loss=0.018059948 valid loss= 0.005662285\n",
      "train reg_fs: 0.0018859902629628778\n",
      "Epoch: 2000 train loss=0.004107024 valid loss= 0.004334448\n",
      "train reg_fs: 0.0018147705122828484\n",
      "Epoch: 2500 train loss=0.008473714 valid loss= 0.004351253\n",
      "train reg_fs: 0.0017654893454164267\n",
      "Epoch: 3000 train loss=0.005339835 valid loss= 0.004194948\n",
      "train reg_fs: 0.0017322610365226865\n",
      "Epoch: 3500 train loss=0.003164284 valid loss= 0.004693389\n",
      "train reg_fs: 0.0017111089546233416\n",
      "Epoch: 4000 train loss=0.005161632 valid loss= 0.004429164\n",
      "train reg_fs: 0.0016937055625021458\n",
      "Epoch: 4500 train loss=0.016870448 valid loss= 0.004207100\n",
      "train reg_fs: 0.001678601372987032\n",
      "Epoch: 5000 train loss=0.002768083 valid loss= 0.003946903\n",
      "train reg_fs: 0.0016698427498340607\n",
      "Epoch: 5500 train loss=0.003907484 valid loss= 0.003994076\n",
      "train reg_fs: 0.0016585345147177577\n",
      "Epoch: 6000 train loss=0.003375087 valid loss= 0.003787722\n",
      "train reg_fs: 0.0016487502725794911\n",
      "Epoch: 6500 train loss=0.002109978 valid loss= 0.004050142\n",
      "train reg_fs: 0.001641571638174355\n",
      "Epoch: 7000 train loss=0.002420546 valid loss= 0.004044664\n",
      "train reg_fs: 0.001633359119296074\n",
      "Epoch: 7500 train loss=0.003051847 valid loss= 0.003994598\n",
      "train reg_fs: 0.0016281348653137684\n",
      "Epoch: 8000 train loss=0.002287237 valid loss= 0.003574202\n",
      "train reg_fs: 0.0016208302695304155\n",
      "Epoch: 8500 train loss=0.003063572 valid loss= 0.003719343\n",
      "train reg_fs: 0.0016140531515702605\n",
      "Epoch: 9000 train loss=0.002029923 valid loss= 0.003872596\n",
      "train reg_fs: 0.0016064824303612113\n",
      "Epoch: 9500 train loss=0.002499494 valid loss= 0.004055575\n",
      "train reg_fs: 0.001598808099515736\n",
      "Epoch: 10000 train loss=0.005664369 valid loss= 0.004144799\n",
      "train reg_fs: 0.0015946569619700313\n",
      "Epoch: 10500 train loss=0.002311928 valid loss= 0.004039962\n",
      "train reg_fs: 0.0015860204584896564\n",
      "Epoch: 11000 train loss=0.005668269 valid loss= 0.003859559\n",
      "train reg_fs: 0.001583091332577169\n",
      "Epoch: 11500 train loss=0.008620635 valid loss= 0.004103931\n",
      "train reg_fs: 0.0015775441424921155\n",
      "Epoch: 12000 train loss=0.002818963 valid loss= 0.003935983\n",
      "train reg_fs: 0.0015693468740209937\n",
      "Epoch: 12500 train loss=0.002753464 valid loss= 0.004105583\n",
      "train reg_fs: 0.0015657709445804358\n",
      "Epoch: 13000 train loss=0.003725792 valid loss= 0.003915639\n",
      "train reg_fs: 0.0015566670335829258\n",
      "Epoch: 13500 train loss=0.002324547 valid loss= 0.004230023\n",
      "train reg_fs: 0.0015503230970352888\n",
      "Epoch: 14000 train loss=0.003340698 valid loss= 0.004185104\n",
      "train reg_fs: 0.001544291852042079\n",
      "Epoch: 14500 train loss=0.002484442 valid loss= 0.004316054\n",
      "train reg_fs: 0.0015401554992422462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:32:42,013]\u001b[0m Trial 92 finished with value: 0.0027394668869802764 and parameters: {'lam': 0.002250315467853018, 'learning_rate': 0.09344023255183434, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004508987 valid loss= 0.004241595\n",
      "train reg_fs: 0.0015383214922621846\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027394668869802764\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015972622 valid loss= 0.007029300\n",
      "train reg_fs: 0.0013925638049840927\n",
      "Epoch: 1000 train loss=0.004604285 valid loss= 0.006848117\n",
      "train reg_fs: 0.001359714544378221\n",
      "Epoch: 1500 train loss=0.002835254 valid loss= 0.004457889\n",
      "train reg_fs: 0.001286134822294116\n",
      "Epoch: 2000 train loss=0.006216499 valid loss= 0.003876563\n",
      "train reg_fs: 0.0012368158204481006\n",
      "Epoch: 2500 train loss=0.002692630 valid loss= 0.003874280\n",
      "train reg_fs: 0.0012066179187968373\n",
      "Epoch: 3000 train loss=0.007829839 valid loss= 0.004430730\n",
      "train reg_fs: 0.0011772760190069675\n",
      "Epoch: 3500 train loss=0.003536049 valid loss= 0.004495538\n",
      "train reg_fs: 0.0011523379944264889\n",
      "Epoch: 4000 train loss=0.005309570 valid loss= 0.004067191\n",
      "train reg_fs: 0.0011302850907668471\n",
      "Epoch: 4500 train loss=0.005104030 valid loss= 0.004015975\n",
      "train reg_fs: 0.0011106629390269518\n",
      "Epoch: 5000 train loss=0.002737851 valid loss= 0.003688449\n",
      "train reg_fs: 0.0010961538646370173\n",
      "Epoch: 5500 train loss=0.001527666 valid loss= 0.003382635\n",
      "train reg_fs: 0.001082729548215866\n",
      "Epoch: 6000 train loss=0.001231448 valid loss= 0.003378914\n",
      "train reg_fs: 0.00107229920104146\n",
      "Epoch: 6500 train loss=0.001597804 valid loss= 0.003590648\n",
      "train reg_fs: 0.0010634007630869746\n",
      "Epoch: 7000 train loss=0.001674105 valid loss= 0.003500538\n",
      "train reg_fs: 0.0010553464526310563\n",
      "Epoch: 7500 train loss=0.001406035 valid loss= 0.003420605\n",
      "train reg_fs: 0.001048791571520269\n",
      "Epoch: 8000 train loss=0.001514177 valid loss= 0.003284750\n",
      "train reg_fs: 0.0010421473998576403\n",
      "Epoch: 8500 train loss=0.002081234 valid loss= 0.003390587\n",
      "train reg_fs: 0.0010362358298152685\n",
      "Epoch: 9000 train loss=0.001421261 valid loss= 0.003323005\n",
      "train reg_fs: 0.0010311297373846173\n",
      "Epoch: 9500 train loss=0.003485829 valid loss= 0.003257883\n",
      "train reg_fs: 0.0010263334261253476\n",
      "Epoch: 10000 train loss=0.001433763 valid loss= 0.003345132\n",
      "train reg_fs: 0.0010217505041509867\n",
      "Epoch: 10500 train loss=0.001298697 valid loss= 0.003280336\n",
      "train reg_fs: 0.0010173716582357883\n",
      "Epoch: 11000 train loss=0.001479137 valid loss= 0.003375415\n",
      "train reg_fs: 0.0010133248288184404\n",
      "Epoch: 11500 train loss=0.002878645 valid loss= 0.003278696\n",
      "train reg_fs: 0.0010095051256939769\n",
      "Epoch: 12000 train loss=0.002177072 valid loss= 0.003412298\n",
      "train reg_fs: 0.0010062434012070298\n",
      "Epoch: 12500 train loss=0.002867086 valid loss= 0.003469737\n",
      "train reg_fs: 0.0010030079865828156\n",
      "Epoch: 13000 train loss=0.001899210 valid loss= 0.003642814\n",
      "train reg_fs: 0.001000403892248869\n",
      "Epoch: 13500 train loss=0.008049829 valid loss= 0.003457905\n",
      "train reg_fs: 0.0009979242458939552\n",
      "Epoch: 14000 train loss=0.009184108 valid loss= 0.003568497\n",
      "train reg_fs: 0.000995482550933957\n",
      "Epoch: 14500 train loss=0.001343541 valid loss= 0.003362623\n",
      "train reg_fs: 0.0009932768298313022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:35:19,364]\u001b[0m Trial 93 finished with value: 0.0022725433469783646 and parameters: {'lam': 0.0016037116988802985, 'learning_rate': 0.08355940853516415, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002529446 valid loss= 0.003247345\n",
      "train reg_fs: 0.0009913456160575151\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022725433469783646\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009620987 valid loss= 0.007956538\n",
      "train reg_fs: 0.0030497380066663027\n",
      "Epoch: 1000 train loss=0.010785456 valid loss= 0.007410465\n",
      "train reg_fs: 0.0028270853217691183\n",
      "Epoch: 1500 train loss=0.007612439 valid loss= 0.005104001\n",
      "train reg_fs: 0.002665571868419647\n",
      "Epoch: 2000 train loss=0.005760955 valid loss= 0.004608246\n",
      "train reg_fs: 0.0025929890107363462\n",
      "Epoch: 2500 train loss=0.003751019 valid loss= 0.004876481\n",
      "train reg_fs: 0.0025367685593664646\n",
      "Epoch: 3000 train loss=0.002665625 valid loss= 0.004670284\n",
      "train reg_fs: 0.0024883882142603397\n",
      "Epoch: 3500 train loss=0.013272501 valid loss= 0.005074648\n",
      "train reg_fs: 0.002425271784886718\n",
      "Epoch: 4000 train loss=0.003258914 valid loss= 0.005039982\n",
      "train reg_fs: 0.0023661674931645393\n",
      "Epoch: 4500 train loss=0.003186812 valid loss= 0.004705429\n",
      "train reg_fs: 0.0023257394786924124\n",
      "Epoch: 5000 train loss=0.002805270 valid loss= 0.004526805\n",
      "train reg_fs: 0.002295176964253187\n",
      "Epoch: 5500 train loss=0.003612826 valid loss= 0.004387247\n",
      "train reg_fs: 0.0022706675808876753\n",
      "Epoch: 6000 train loss=0.003243947 valid loss= 0.004508511\n",
      "train reg_fs: 0.002251387806609273\n",
      "Epoch: 6500 train loss=0.005236427 valid loss= 0.004573813\n",
      "train reg_fs: 0.002235797233879566\n",
      "Epoch: 7000 train loss=0.004163432 valid loss= 0.004716081\n",
      "train reg_fs: 0.002222140086814761\n",
      "Epoch: 7500 train loss=0.002956615 valid loss= 0.004623635\n",
      "train reg_fs: 0.0022100326605141163\n",
      "Epoch: 8000 train loss=0.004513879 valid loss= 0.004391002\n",
      "train reg_fs: 0.0022000609897077084\n",
      "Epoch: 8500 train loss=0.003929721 valid loss= 0.004659445\n",
      "train reg_fs: 0.0021912038791924715\n",
      "Epoch: 9000 train loss=0.003302133 valid loss= 0.004612330\n",
      "train reg_fs: 0.0021838564425706863\n",
      "Epoch: 9500 train loss=0.005986646 valid loss= 0.004298095\n",
      "train reg_fs: 0.002177244983613491\n",
      "Epoch: 10000 train loss=0.002843194 valid loss= 0.004646338\n",
      "train reg_fs: 0.002171263564378023\n",
      "Epoch: 10500 train loss=0.002317272 valid loss= 0.004528335\n",
      "train reg_fs: 0.002166340360417962\n",
      "Epoch: 11000 train loss=0.003451697 valid loss= 0.004369808\n",
      "train reg_fs: 0.0021618532482534647\n",
      "Epoch: 11500 train loss=0.002793679 valid loss= 0.004157958\n",
      "train reg_fs: 0.002158035058528185\n",
      "Epoch: 12000 train loss=0.004199948 valid loss= 0.004421225\n",
      "train reg_fs: 0.0021544299088418484\n",
      "Epoch: 12500 train loss=0.004242897 valid loss= 0.004338498\n",
      "train reg_fs: 0.002151157008484006\n",
      "Epoch: 13000 train loss=0.003707963 valid loss= 0.004321147\n",
      "train reg_fs: 0.0021482419688254595\n",
      "Epoch: 13500 train loss=0.004352428 valid loss= 0.004642223\n",
      "train reg_fs: 0.0021457525435835123\n",
      "Epoch: 14000 train loss=0.002436206 valid loss= 0.004531826\n",
      "train reg_fs: 0.0021433974616229534\n",
      "Epoch: 14500 train loss=0.003013726 valid loss= 0.004167106\n",
      "train reg_fs: 0.0021412712521851063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:37:06,774]\u001b[0m Trial 94 finished with value: 0.0025611248129624553 and parameters: {'lam': 0.003537925563684412, 'learning_rate': 0.11319892819920917, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.006203019 valid loss= 0.004649177\n",
      "train reg_fs: 0.0021394307259470224\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025611248129624553\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010301867 valid loss= 0.007650415\n",
      "train reg_fs: 0.0012517347931861877\n",
      "Epoch: 1000 train loss=0.005482693 valid loss= 0.005743735\n",
      "train reg_fs: 0.0012015580432489514\n",
      "Epoch: 1500 train loss=0.005401483 valid loss= 0.003664942\n",
      "train reg_fs: 0.0011431319871917367\n",
      "Epoch: 2000 train loss=0.003865320 valid loss= 0.003453186\n",
      "train reg_fs: 0.0011027574073523283\n",
      "Epoch: 2500 train loss=0.004864039 valid loss= 0.004225391\n",
      "train reg_fs: 0.0010733817471191287\n",
      "Epoch: 3000 train loss=0.002375754 valid loss= 0.003673512\n",
      "train reg_fs: 0.0010524316458031535\n",
      "Epoch: 3500 train loss=0.008475169 valid loss= 0.003821345\n",
      "train reg_fs: 0.0010332107776775956\n",
      "Epoch: 4000 train loss=0.001442457 valid loss= 0.003496898\n",
      "train reg_fs: 0.0010169993620365858\n",
      "Epoch: 4500 train loss=0.002082642 valid loss= 0.004006088\n",
      "train reg_fs: 0.0010028816759586334\n",
      "Epoch: 5000 train loss=0.001525293 valid loss= 0.003437039\n",
      "train reg_fs: 0.000990154454484582\n",
      "Epoch: 5500 train loss=0.003312623 valid loss= 0.003190526\n",
      "train reg_fs: 0.0009795645019039512\n",
      "Epoch: 6000 train loss=0.002409634 valid loss= 0.003251401\n",
      "train reg_fs: 0.0009709890000522137\n",
      "Epoch: 6500 train loss=0.003157233 valid loss= 0.003107163\n",
      "train reg_fs: 0.0009634073940105736\n",
      "Epoch: 7000 train loss=0.003522581 valid loss= 0.003391360\n",
      "train reg_fs: 0.0009563640924170613\n",
      "Epoch: 7500 train loss=0.001785758 valid loss= 0.003595600\n",
      "train reg_fs: 0.0009505857597105205\n",
      "Epoch: 8000 train loss=0.005732010 valid loss= 0.003135909\n",
      "train reg_fs: 0.0009459243156015873\n",
      "Epoch: 8500 train loss=0.003512980 valid loss= 0.003518770\n",
      "train reg_fs: 0.0009410401107743382\n",
      "Epoch: 9000 train loss=0.010559462 valid loss= 0.003210532\n",
      "train reg_fs: 0.0009364096913486719\n",
      "Epoch: 9500 train loss=0.001970830 valid loss= 0.003126707\n",
      "train reg_fs: 0.0009322493569925427\n",
      "Epoch: 10000 train loss=0.001837893 valid loss= 0.003068940\n",
      "train reg_fs: 0.0009285326232202351\n",
      "Epoch: 10500 train loss=0.001556362 valid loss= 0.003346592\n",
      "train reg_fs: 0.0009251551236957312\n",
      "Epoch: 11000 train loss=0.002208001 valid loss= 0.003097273\n",
      "train reg_fs: 0.0009222113876603544\n",
      "Epoch: 11500 train loss=0.002056653 valid loss= 0.002991615\n",
      "train reg_fs: 0.0009193596779368818\n",
      "Epoch: 12000 train loss=0.002473552 valid loss= 0.003337427\n",
      "train reg_fs: 0.0009165172232314944\n",
      "Epoch: 12500 train loss=0.002059607 valid loss= 0.003295391\n",
      "train reg_fs: 0.0009141300106421113\n",
      "Epoch: 13000 train loss=0.002167061 valid loss= 0.003413022\n",
      "train reg_fs: 0.0009120721369981766\n",
      "Epoch: 13500 train loss=0.005710965 valid loss= 0.003125959\n",
      "train reg_fs: 0.0009099555900320411\n",
      "Epoch: 14000 train loss=0.002770084 valid loss= 0.003123005\n",
      "train reg_fs: 0.0009081659372895956\n",
      "Epoch: 14500 train loss=0.002152342 valid loss= 0.003161558\n",
      "train reg_fs: 0.000906373024918139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:38:47,705]\u001b[0m Trial 95 finished with value: 0.0024814360101751776 and parameters: {'lam': 0.0014644552787096384, 'learning_rate': 0.0717351011959479, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001867450 valid loss= 0.003372515\n",
      "train reg_fs: 0.0009048443171195686\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024814360101751776\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011443843 valid loss= 0.007780899\n",
      "train reg_fs: 0.001202553161419928\n",
      "Epoch: 1000 train loss=0.011731837 valid loss= 0.007863726\n",
      "train reg_fs: 0.0011940059484913945\n",
      "Epoch: 1500 train loss=0.005598830 valid loss= 0.005575761\n",
      "train reg_fs: 0.001140434411354363\n",
      "Epoch: 2000 train loss=0.007614321 valid loss= 0.003819565\n",
      "train reg_fs: 0.0010898374021053314\n",
      "Epoch: 2500 train loss=0.004044808 valid loss= 0.003435104\n",
      "train reg_fs: 0.0010512076551094651\n",
      "Epoch: 3000 train loss=0.001814823 valid loss= 0.003489241\n",
      "train reg_fs: 0.001024481258355081\n",
      "Epoch: 3500 train loss=0.005112081 valid loss= 0.004173258\n",
      "train reg_fs: 0.0010058898478746414\n",
      "Epoch: 4000 train loss=0.011451448 valid loss= 0.003773744\n",
      "train reg_fs: 0.0009874479146674275\n",
      "Epoch: 4500 train loss=0.002315443 valid loss= 0.003599372\n",
      "train reg_fs: 0.0009732244652695954\n",
      "Epoch: 5000 train loss=0.004496220 valid loss= 0.003514606\n",
      "train reg_fs: 0.0009634339367039502\n",
      "Epoch: 5500 train loss=0.001687986 valid loss= 0.004085359\n",
      "train reg_fs: 0.0009556275908835232\n",
      "Epoch: 6000 train loss=0.002288809 valid loss= 0.003586673\n",
      "train reg_fs: 0.0009488782961852849\n",
      "Epoch: 6500 train loss=0.005326544 valid loss= 0.003421140\n",
      "train reg_fs: 0.0009415297536179423\n",
      "Epoch: 7000 train loss=0.001855116 valid loss= 0.003556675\n",
      "train reg_fs: 0.0009401366114616394\n",
      "Epoch: 7500 train loss=0.002345846 valid loss= 0.003672883\n",
      "train reg_fs: 0.0009305563871748745\n",
      "Epoch: 8000 train loss=0.003090750 valid loss= 0.003488744\n",
      "train reg_fs: 0.0009259864455088973\n",
      "Epoch: 8500 train loss=0.001745311 valid loss= 0.003752113\n",
      "train reg_fs: 0.0009207009570673108\n",
      "Epoch: 9000 train loss=0.005285571 valid loss= 0.003466636\n",
      "train reg_fs: 0.0009182253270410001\n",
      "Epoch: 9500 train loss=0.001337092 valid loss= 0.003598477\n",
      "train reg_fs: 0.0009151494014076889\n",
      "Epoch: 10000 train loss=0.003285892 valid loss= 0.003913354\n",
      "train reg_fs: 0.0009095603018067777\n",
      "Epoch: 10500 train loss=0.001132581 valid loss= 0.003754972\n",
      "train reg_fs: 0.0009068676736205816\n",
      "Epoch: 11000 train loss=0.002948587 valid loss= 0.003779106\n",
      "train reg_fs: 0.0009007409680634737\n",
      "Epoch: 11500 train loss=0.002772101 valid loss= 0.003712536\n",
      "train reg_fs: 0.000897152058314532\n",
      "Epoch: 12000 train loss=0.001463543 valid loss= 0.003698841\n",
      "train reg_fs: 0.0008957331301644444\n",
      "Epoch: 12500 train loss=0.003307735 valid loss= 0.003663022\n",
      "train reg_fs: 0.0008917715167626739\n",
      "Epoch: 13000 train loss=0.001491384 valid loss= 0.004041260\n",
      "train reg_fs: 0.0008882866241037846\n",
      "Epoch: 13500 train loss=0.001161000 valid loss= 0.003993182\n",
      "train reg_fs: 0.0008835463668219745\n",
      "Epoch: 14000 train loss=0.003600772 valid loss= 0.003996156\n",
      "train reg_fs: 0.0008814666653051972\n",
      "Epoch: 14500 train loss=0.002184640 valid loss= 0.004149306\n",
      "train reg_fs: 0.0008790502324700356\n",
      "Epoch: 15000 train loss=0.003586997 valid loss= 0.004183218\n",
      "train reg_fs: 0.0008784052915871143\n",
      "In trial:---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:42:38,850]\u001b[0m Trial 96 finished with value: 0.003327787811485457 and parameters: {'lam': 0.0013347139666531169, 'learning_rate': 0.18364809663937495, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mse: 0.003327787811485457\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.004954264 valid loss= 0.006027496\n",
      "train reg_fs: 0.0009834698867052794\n",
      "Epoch: 1000 train loss=0.003283072 valid loss= 0.003390649\n",
      "train reg_fs: 0.0009220779757015407\n",
      "Epoch: 1500 train loss=0.002758682 valid loss= 0.003475490\n",
      "train reg_fs: 0.0008968886686488986\n",
      "Epoch: 2000 train loss=0.007252758 valid loss= 0.003090974\n",
      "train reg_fs: 0.0008817839552648365\n",
      "Epoch: 2500 train loss=0.001905974 valid loss= 0.003499691\n",
      "train reg_fs: 0.0008700057514943182\n",
      "Epoch: 3000 train loss=0.002432560 valid loss= 0.003073362\n",
      "train reg_fs: 0.0008619657019153237\n",
      "Epoch: 3500 train loss=0.001975706 valid loss= 0.002787181\n",
      "train reg_fs: 0.0008579411078244448\n",
      "Epoch: 4000 train loss=0.004663636 valid loss= 0.003408825\n",
      "train reg_fs: 0.0008548422483727336\n",
      "Epoch: 4500 train loss=0.001890263 valid loss= 0.002649069\n",
      "train reg_fs: 0.000853064761031419\n",
      "Epoch: 5000 train loss=0.001376081 valid loss= 0.002635465\n",
      "train reg_fs: 0.0008507082238793373\n",
      "Epoch: 5500 train loss=0.001283309 valid loss= 0.002743135\n",
      "train reg_fs: 0.0008486756705678999\n",
      "Epoch: 6000 train loss=0.001546793 valid loss= 0.003024751\n",
      "train reg_fs: 0.0008468921878375113\n",
      "Epoch: 6500 train loss=0.003785407 valid loss= 0.002827512\n",
      "train reg_fs: 0.0008448606240563095\n",
      "Epoch: 7000 train loss=0.003816531 valid loss= 0.002491588\n",
      "train reg_fs: 0.0008429060690104961\n",
      "Epoch: 7500 train loss=0.003152823 valid loss= 0.003232471\n",
      "train reg_fs: 0.0008404265390709043\n",
      "Epoch: 8000 train loss=0.001759482 valid loss= 0.003080524\n",
      "train reg_fs: 0.0008381939842365682\n",
      "Epoch: 8500 train loss=0.002372279 valid loss= 0.002843174\n",
      "train reg_fs: 0.000836177438031882\n",
      "Epoch: 9000 train loss=0.002528252 valid loss= 0.003323990\n",
      "train reg_fs: 0.0008336117607541382\n",
      "Epoch: 9500 train loss=0.002583818 valid loss= 0.002927228\n",
      "train reg_fs: 0.0008319012122228742\n",
      "Epoch: 10000 train loss=0.001146094 valid loss= 0.002935507\n",
      "train reg_fs: 0.0008300513727590442\n",
      "In trial:---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:45:43,899]\u001b[0m Trial 97 finished with value: 0.002133906749976953 and parameters: {'lam': 0.001144763191325964, 'learning_rate': 0.1326667299236413, 'num_epoch': 10000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mse: 0.002133906749976953\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015230522 valid loss= 0.008646961\n",
      "train reg_fs: 0.0021860802080482244\n",
      "Epoch: 1000 train loss=0.008936008 valid loss= 0.007872395\n",
      "train reg_fs: 0.0020885963458567858\n",
      "Epoch: 1500 train loss=0.008598060 valid loss= 0.006956931\n",
      "train reg_fs: 0.0020369139965623617\n",
      "Epoch: 2000 train loss=0.004437241 valid loss= 0.006864606\n",
      "train reg_fs: 0.0020036878995597363\n",
      "Epoch: 2500 train loss=0.005425896 valid loss= 0.005431417\n",
      "train reg_fs: 0.001955258660018444\n",
      "Epoch: 3000 train loss=0.006975546 valid loss= 0.004993855\n",
      "train reg_fs: 0.0019083137158304453\n",
      "Epoch: 3500 train loss=0.005299079 valid loss= 0.005484699\n",
      "train reg_fs: 0.0018727697897702456\n",
      "Epoch: 4000 train loss=0.003506528 valid loss= 0.005342336\n",
      "train reg_fs: 0.0018528789514675736\n",
      "Epoch: 4500 train loss=0.005766712 valid loss= 0.005123743\n",
      "train reg_fs: 0.001835885108448565\n",
      "Epoch: 5000 train loss=0.004491114 valid loss= 0.005466107\n",
      "train reg_fs: 0.0018192245624959469\n",
      "Epoch: 5500 train loss=0.002763747 valid loss= 0.005012901\n",
      "train reg_fs: 0.001805299543775618\n",
      "Epoch: 6000 train loss=0.004285915 valid loss= 0.005264446\n",
      "train reg_fs: 0.0017834327882155776\n",
      "Epoch: 6500 train loss=0.003324093 valid loss= 0.005274938\n",
      "train reg_fs: 0.0017718716990202665\n",
      "Epoch: 7000 train loss=0.004254106 valid loss= 0.005086979\n",
      "train reg_fs: 0.0017590580973774195\n",
      "Epoch: 7500 train loss=0.006130848 valid loss= 0.005035195\n",
      "train reg_fs: 0.0017464666161686182\n",
      "Epoch: 8000 train loss=0.002711682 valid loss= 0.005164325\n",
      "train reg_fs: 0.0017393630696460605\n",
      "Epoch: 8500 train loss=0.004418666 valid loss= 0.005090431\n",
      "train reg_fs: 0.0017308898968622088\n",
      "Epoch: 9000 train loss=0.004570907 valid loss= 0.004981808\n",
      "train reg_fs: 0.0017229111399501562\n",
      "Epoch: 9500 train loss=0.005111109 valid loss= 0.005171074\n",
      "train reg_fs: 0.0017117400420829654\n",
      "Epoch: 10000 train loss=0.012054829 valid loss= 0.004777373\n",
      "train reg_fs: 0.0017036014469340444\n",
      "Epoch: 10500 train loss=0.002236505 valid loss= 0.005501062\n",
      "train reg_fs: 0.0017002163222059608\n",
      "Epoch: 11000 train loss=0.002506263 valid loss= 0.005035541\n",
      "train reg_fs: 0.0016951877623796463\n",
      "Epoch: 11500 train loss=0.003021590 valid loss= 0.004580157\n",
      "train reg_fs: 0.0016875116853043437\n",
      "Epoch: 12000 train loss=0.004343092 valid loss= 0.004876017\n",
      "train reg_fs: 0.0016828234074637294\n",
      "Epoch: 12500 train loss=0.003570213 valid loss= 0.004869141\n",
      "train reg_fs: 0.001678580534644425\n",
      "Epoch: 13000 train loss=0.002061553 valid loss= 0.004911679\n",
      "train reg_fs: 0.0016737421974539757\n",
      "Epoch: 13500 train loss=0.002929230 valid loss= 0.005110460\n",
      "train reg_fs: 0.0016676026862114668\n",
      "Epoch: 14000 train loss=0.006395743 valid loss= 0.004679056\n",
      "train reg_fs: 0.0016619358211755753\n",
      "Epoch: 14500 train loss=0.003331551 valid loss= 0.005075389\n",
      "train reg_fs: 0.0016578278737142682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:47:20,368]\u001b[0m Trial 98 finished with value: 0.003232644159860403 and parameters: {'lam': 0.0024957600111343127, 'learning_rate': 0.1495009657453649, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002007376 valid loss= 0.004863137\n",
      "train reg_fs: 0.0016524852253496647\n",
      "In trial:---------------------\n",
      "validation mse: 0.003232644159860403\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014647719 valid loss= 0.010587271\n",
      "train reg_fs: 0.0027513867244124413\n",
      "Epoch: 1000 train loss=0.017101686 valid loss= 0.010282640\n",
      "train reg_fs: 0.002788819372653961\n",
      "Epoch: 1500 train loss=0.014404890 valid loss= 0.009986005\n",
      "train reg_fs: 0.0027919330168515444\n",
      "Epoch: 2000 train loss=0.011729199 valid loss= 0.010250669\n",
      "train reg_fs: 0.0027749810833483934\n",
      "Epoch: 2500 train loss=0.009193885 valid loss= 0.008901181\n",
      "train reg_fs: 0.002728202613070607\n",
      "Epoch: 3000 train loss=0.005803752 valid loss= 0.008194224\n",
      "train reg_fs: 0.002682604594156146\n",
      "Epoch: 3500 train loss=0.005186225 valid loss= 0.007486320\n",
      "train reg_fs: 0.0026399397756904364\n",
      "Epoch: 4000 train loss=0.009078718 valid loss= 0.007242425\n",
      "train reg_fs: 0.002604009350761771\n",
      "Epoch: 4500 train loss=0.012530883 valid loss= 0.006332257\n",
      "train reg_fs: 0.0025727872271090746\n",
      "Epoch: 5000 train loss=0.006386696 valid loss= 0.005854524\n",
      "train reg_fs: 0.002541015390306711\n",
      "Epoch: 5500 train loss=0.003947048 valid loss= 0.005585250\n",
      "train reg_fs: 0.00250840000808239\n",
      "Epoch: 6000 train loss=0.007676345 valid loss= 0.005409833\n",
      "train reg_fs: 0.0024750116281211376\n",
      "Epoch: 6500 train loss=0.005832101 valid loss= 0.005401951\n",
      "train reg_fs: 0.00244262651540339\n",
      "Epoch: 7000 train loss=0.005293699 valid loss= 0.005148218\n",
      "train reg_fs: 0.002416200004518032\n",
      "Epoch: 7500 train loss=0.004427646 valid loss= 0.004777070\n",
      "train reg_fs: 0.0023929178714752197\n",
      "Epoch: 8000 train loss=0.003789599 valid loss= 0.005009845\n",
      "train reg_fs: 0.0023722494952380657\n",
      "Epoch: 8500 train loss=0.003162842 valid loss= 0.005073522\n",
      "train reg_fs: 0.0023535240907222033\n",
      "Epoch: 9000 train loss=0.007142086 valid loss= 0.005078209\n",
      "train reg_fs: 0.0023353968281298876\n",
      "Epoch: 9500 train loss=0.006696732 valid loss= 0.004837279\n",
      "train reg_fs: 0.002315797610208392\n",
      "Epoch: 10000 train loss=0.007553059 valid loss= 0.005295360\n",
      "train reg_fs: 0.002296589082106948\n",
      "Epoch: 10500 train loss=0.006540683 valid loss= 0.005176012\n",
      "train reg_fs: 0.0022777041886001825\n",
      "Epoch: 11000 train loss=0.004994908 valid loss= 0.005259102\n",
      "train reg_fs: 0.002262042835354805\n",
      "Epoch: 11500 train loss=0.004470236 valid loss= 0.005429336\n",
      "train reg_fs: 0.002243652008473873\n",
      "Epoch: 12000 train loss=0.004415222 valid loss= 0.005425328\n",
      "train reg_fs: 0.0022314211819320917\n",
      "Epoch: 12500 train loss=0.003787640 valid loss= 0.005128827\n",
      "train reg_fs: 0.002217442262917757\n",
      "Epoch: 13000 train loss=0.004210262 valid loss= 0.005262743\n",
      "train reg_fs: 0.00220048357732594\n",
      "Epoch: 13500 train loss=0.004603527 valid loss= 0.005269173\n",
      "train reg_fs: 0.002188871381804347\n",
      "Epoch: 14000 train loss=0.003672652 valid loss= 0.005279861\n",
      "train reg_fs: 0.0021771201863884926\n",
      "Epoch: 14500 train loss=0.002948338 valid loss= 0.005202348\n",
      "train reg_fs: 0.002161397598683834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-07 18:48:56,033]\u001b[0m Trial 99 finished with value: 0.0029075663013642212 and parameters: {'lam': 0.0031975767570962526, 'learning_rate': 0.04882064072302118, 'num_epoch': 15000}. Best is trial 64 with value: 0.0002150571329903749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004830717 valid loss= 0.005179467\n",
      "train reg_fs: 0.00214808015152812\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029075663013642212\n"
     ]
    }
   ],
   "source": [
    "# optimize the model via Optuna and obtain the best model with smallest validation mse\n",
    "best_model = None\n",
    "model = None\n",
    "study = optuna.create_study(pruner=None)\n",
    "study.optimize(llspin_objective, n_trials=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training gate matrix\n",
    "gate_mat_train = best_model.get_prob_alpha(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = study.best_params['learning_rate']\n",
    "best_epoch = study.best_params['num_epoch']\n",
    "best_lam = study.best_params['lam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Finished*************\n",
      "Best model's lambda: 0.001268414399944731\n",
      "Best model's learning rate: 0.14715527279924842\n",
      "Best model's num of epochs: 15000\n",
      "Test mse : 0.00030792004335106085\n",
      "Test r2 : 0.9925697988276159\n"
     ]
    }
   ],
   "source": [
    "# test the best model\n",
    "y_pred_llspin = best_model.test(X_test)[0]\n",
    "            \n",
    "print(\"Trial Finished*************\")\n",
    "print(\"Best model's lambda: {}\".format(best_lam))\n",
    "print(\"Best model's learning rate: {}\".format(best_lr))\n",
    "print(\"Best model's num of epochs: {}\".format(best_epoch))\n",
    "print(\"Test mse : {}\".format(mean_squared_error(y_test.reshape(-1),y_pred_llspin.reshape(-1))))\n",
    "print(\"Test r2 : {}\".format(r2_score(y_test.reshape(-1),y_pred_llspin.reshape(-1),multioutput='raw_values')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the training gates to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.Blues\n",
    "bounds=[0,0.5,1]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "title_size = 30\n",
    "xtick_size = 20\n",
    "ytick_size = 20\n",
    "xlabel_size = 35\n",
    "ylabel_size = 35\n",
    "colorbar_tick_size = 20\n",
    "title_pad = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "sorted_order = np.concatenate((np.where(train_label == 1)[0],np.where(train_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_train[sorted_order,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([1,3,5,7,9])\n",
    "axes[0].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "im2 = axes[1].imshow(gate_mat_train[sorted_order,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([1,3,5,7,9])\n",
    "axes[1].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the test gates to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_mat_test = best_model.get_prob_alpha(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "fig.subplots_adjust(bottom=0.01)\n",
    "\n",
    "sorted_order_test = np.concatenate((np.where(test_label == 1)[0],np.where(test_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_test[sorted_order_test,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([0,9,19,29,39,49])\n",
    "axes[0].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "    \n",
    "im2 = axes[1].imshow(gate_mat_test[sorted_order_test,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([0,9,19,29,39,49])\n",
    "axes[1].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "    \n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
