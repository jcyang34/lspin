{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from lspin_model import Model\n",
    "from utils import DataSet\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm,colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear synthetic data generation\n",
    "\n",
    "Group 1: $X$ ~ $N(1,0.5)$,  $Y = -2X_1 + X_2 - 0.5X_3$\n",
    "\n",
    "Group 2: $X$ ~ $N(-1,0.5)$, $Y = -0.5X_3 + X_4 - 2X_5$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "Xs1 = np.random.normal(loc=1,scale=0.5,size=(300,5))\n",
    "Ys1 = -2*Xs1[:,0]+1*Xs1[:,1]-0.5*Xs1[:,2]\n",
    "\n",
    "Xs2 = np.random.normal(loc=-1,scale=0.5,size=(300,5))\n",
    "Ys2 = -0.5*Xs2[:,2]+1*Xs2[:,3]-2*Xs2[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate((Xs1,Xs2),axis=0)\n",
    "Y_data = np.concatenate((Ys1.reshape(-1,1),Ys2.reshape(-1,1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = Y_data-Y_data.min()\n",
    "Y_data=Y_data/Y_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ground truth group label of each sample\n",
    "case_labels = np.concatenate((np.array([1]*300),np.array([2]*300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = np.concatenate((Y_data,case_labels.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% for validation, 10% for test \n",
    "X_train,X_remain,yc_train,yc_remain = train_test_split(X_data,Y_data,train_size=0.8,shuffle=True,random_state=34)\n",
    "X_valid,X_test,yc_valid,yc_test = train_test_split(X_remain,yc_remain,train_size=0.5,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 10 samples used for training\n",
    "X_train,_,yc_train,_ = train_test_split(X_train,yc_train,train_size=10,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes:\n",
      "10 60 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample sizes:\")\n",
    "print(X_train.shape[0],X_valid.shape[0],X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = yc_train[:,0].reshape(-1,1)\n",
    "y_valid = yc_valid[:,0].reshape(-1,1)\n",
    "y_test = yc_test[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = yc_train[:,1]\n",
    "valid_label = yc_valid[:,1]\n",
    "test_label= yc_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 6, 1.0: 4})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 29, 1.0: 31})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(**{'_data':X_train, '_labels':y_train,\n",
    "                '_valid_data':X_valid, '_valid_labels':y_valid,\n",
    "                '_test_data':X_test, '_test_labels':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference ground truth feature matrix (training/test)\n",
    "ref_feat_mat_train = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in train_label])\n",
    "ref_feat_mat_test = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in test_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLSPIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function for optuna hyper-parameter optimization\n",
    "def llspin_objective(trial):  \n",
    "    global model\n",
    "    \n",
    "    # hyper-parameter specification\n",
    "    params = {     \n",
    "        \"input_node\" : X_train.shape[1], # input dimension for the prediction network\n",
    "        \"hidden_layers_node\" : [100,100,10,1], # number of nodes for each hidden layer of the prediction net\n",
    "        \"output_node\" : 1, # number of nodes for the output layer of the prediction net\n",
    "        \"feature_selection\" : True, # if using the gating net\n",
    "        \"gating_net_hidden_layers_node\": [10], # number of nodes for each hidden layer of the gating net\n",
    "        \"display_step\" : 500 # number of epochs to output info\n",
    "    }\n",
    "    params['activation']= 'none' # linear prediction\n",
    "    params['batch_size']= X_train.shape[0]\n",
    "    \n",
    "    # hyper-parameter to optimize: lambda, learning rate, number of epochs\n",
    "    params['lam'] = trial.suggest_loguniform('lam',1e-3,1e-2)\n",
    "    params['learning_rate'] = trial.suggest_loguniform('learning_rate', 1e-2, 2e-1)\n",
    "    num_epoch = trial.suggest_categorical('num_epoch', [2000,5000,10000,15000])\n",
    "\n",
    "    # specify the model with these parameters and train the model\n",
    "    model_dir =None\n",
    "    model = Model(**params)\n",
    "    train_acces, train_losses, val_acces, val_losses = model.train(trial, dataset, model_dir, num_epoch=num_epoch)\n",
    "\n",
    "    print(\"In trial:---------------------\")\n",
    "    val_prediction = model.test(X_valid)[0]\n",
    "    mse = mean_squared_error(y_valid.reshape(-1),val_prediction.reshape(-1))\n",
    "    print(\"validation mse: {}\".format(mse))\n",
    "    \n",
    "    loss= mse\n",
    "            \n",
    "    return loss\n",
    "        \n",
    "def callback(study,trial):\n",
    "    global best_model\n",
    "    if study.best_trial == trial:\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:52:31,328]\u001b[0m A new study created in memory with name: no-name-c0d16df7-44bc-4384-8cd6-d10d3b72ff74\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:54: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:70: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:259: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:107: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:139: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:179: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:189: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:189: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:191: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:198: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:199: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:216: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017599225 valid loss= 0.009803707\n",
      "train reg_fs: 0.0026826176326721907\n",
      "Epoch: 1000 train loss=0.010520567 valid loss= 0.009543489\n",
      "train reg_fs: 0.002700003096833825\n",
      "Epoch: 1500 train loss=0.009960390 valid loss= 0.008896006\n",
      "train reg_fs: 0.0026686268392950296\n",
      "Epoch: 2000 train loss=0.012702882 valid loss= 0.007787749\n",
      "train reg_fs: 0.0026157291140407324\n",
      "Epoch: 2500 train loss=0.008682169 valid loss= 0.006479782\n",
      "train reg_fs: 0.002568244468420744\n",
      "Epoch: 3000 train loss=0.011089993 valid loss= 0.005771696\n",
      "train reg_fs: 0.0025229600723832846\n",
      "Epoch: 3500 train loss=0.005596307 valid loss= 0.004478981\n",
      "train reg_fs: 0.0024763671681284904\n",
      "Epoch: 4000 train loss=0.007633431 valid loss= 0.003911463\n",
      "train reg_fs: 0.0024313011672347784\n",
      "Epoch: 4500 train loss=0.003870143 valid loss= 0.004132049\n",
      "train reg_fs: 0.002396972617134452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:53:06,933]\u001b[0m Trial 0 finished with value: 0.0019158950122663443 and parameters: {'lam': 0.003109097570843857, 'learning_rate': 0.05286484324645007, 'num_epoch': 5000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003308428 valid loss= 0.004289762\n",
      "train reg_fs: 0.0023707805667072535\n",
      "Optimization Finished!\n",
      "test loss: 0.004358295351266861, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0019158950122663443\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012889587 valid loss= 0.009258475\n",
      "train reg_fs: 0.0028443753253668547\n",
      "Epoch: 1000 train loss=0.016264895 valid loss= 0.008787489\n",
      "train reg_fs: 0.0028587719425559044\n",
      "Epoch: 1500 train loss=0.009756874 valid loss= 0.008535736\n",
      "train reg_fs: 0.002857065526768565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:53:21,028]\u001b[0m Trial 1 finished with value: 0.004561767628598593 and parameters: {'lam': 0.003367740952527124, 'learning_rate': 0.025243603169729154, 'num_epoch': 2000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.004154135 valid loss= 0.007435099\n",
      "train reg_fs: 0.0028377363923937082\n",
      "Optimization Finished!\n",
      "test loss: 0.008847445249557495, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004561767628598593\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007135219 valid loss= 0.009976786\n",
      "train reg_fs: 0.003720809007063508\n",
      "Epoch: 1000 train loss=0.009201998 valid loss= 0.007740718\n",
      "train reg_fs: 0.0036040020640939474\n",
      "Epoch: 1500 train loss=0.008841582 valid loss= 0.006245501\n",
      "train reg_fs: 0.0035132193006575108\n",
      "Epoch: 2000 train loss=0.007754317 valid loss= 0.005703736\n",
      "train reg_fs: 0.0033892765641212463\n",
      "Epoch: 2500 train loss=0.005383029 valid loss= 0.005936324\n",
      "train reg_fs: 0.0033251733984798193\n",
      "Epoch: 3000 train loss=0.010597482 valid loss= 0.006071387\n",
      "train reg_fs: 0.003254116978496313\n",
      "Epoch: 3500 train loss=0.004761461 valid loss= 0.005705884\n",
      "train reg_fs: 0.0031844887416809797\n",
      "Epoch: 4000 train loss=0.003374434 valid loss= 0.005637813\n",
      "train reg_fs: 0.0031311283819377422\n",
      "Epoch: 4500 train loss=0.004729747 valid loss= 0.005319173\n",
      "train reg_fs: 0.0030852765776216984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:53:54,262]\u001b[0m Trial 2 finished with value: 0.0024211690894986914 and parameters: {'lam': 0.0043535096845443, 'learning_rate': 0.14484863377484125, 'num_epoch': 5000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008109301 valid loss= 0.005396350\n",
      "train reg_fs: 0.0030480637215077877\n",
      "Optimization Finished!\n",
      "test loss: 0.005291616544127464, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024211690894986914\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011965651 valid loss= 0.014838692\n",
      "train reg_fs: 0.007900225929915905\n",
      "Epoch: 1000 train loss=0.018202525 valid loss= 0.015104955\n",
      "train reg_fs: 0.007969016209244728\n",
      "Epoch: 1500 train loss=0.032854479 valid loss= 0.014160577\n",
      "train reg_fs: 0.008026977069675922\n",
      "Epoch: 2000 train loss=0.017814379 valid loss= 0.014403672\n",
      "train reg_fs: 0.008067387156188488\n",
      "Epoch: 2500 train loss=0.026844837 valid loss= 0.014861772\n",
      "train reg_fs: 0.00809737853705883\n",
      "Epoch: 3000 train loss=0.022846783 valid loss= 0.014084207\n",
      "train reg_fs: 0.008111383765935898\n",
      "Epoch: 3500 train loss=0.018160027 valid loss= 0.014304592\n",
      "train reg_fs: 0.008116794750094414\n",
      "Epoch: 4000 train loss=0.011439086 valid loss= 0.013635501\n",
      "train reg_fs: 0.008116059936583042\n",
      "Epoch: 4500 train loss=0.020476760 valid loss= 0.013349852\n",
      "train reg_fs: 0.008110365830361843\n",
      "Epoch: 5000 train loss=0.019106617 valid loss= 0.013400776\n",
      "train reg_fs: 0.00809215847402811\n",
      "Epoch: 5500 train loss=0.015709646 valid loss= 0.012870894\n",
      "train reg_fs: 0.008069421164691448\n",
      "Epoch: 6000 train loss=0.012345862 valid loss= 0.013162933\n",
      "train reg_fs: 0.008042850531637669\n",
      "Epoch: 6500 train loss=0.014510352 valid loss= 0.012307926\n",
      "train reg_fs: 0.008013579063117504\n",
      "Epoch: 7000 train loss=0.013817670 valid loss= 0.012350379\n",
      "train reg_fs: 0.007979454472661018\n",
      "Epoch: 7500 train loss=0.014404988 valid loss= 0.012055011\n",
      "train reg_fs: 0.00794290006160736\n",
      "Epoch: 8000 train loss=0.012483995 valid loss= 0.011762256\n",
      "train reg_fs: 0.00789939146488905\n",
      "Epoch: 8500 train loss=0.013033218 valid loss= 0.011350702\n",
      "train reg_fs: 0.007849713787436485\n",
      "Epoch: 9000 train loss=0.012475422 valid loss= 0.011140094\n",
      "train reg_fs: 0.007801078725606203\n",
      "Epoch: 9500 train loss=0.011833549 valid loss= 0.011088787\n",
      "train reg_fs: 0.007748602423816919\n",
      "Epoch: 10000 train loss=0.022929315 valid loss= 0.010934528\n",
      "train reg_fs: 0.007694198749959469\n",
      "Epoch: 10500 train loss=0.010930902 valid loss= 0.010933627\n",
      "train reg_fs: 0.007640156429260969\n",
      "Epoch: 11000 train loss=0.013372563 valid loss= 0.010743599\n",
      "train reg_fs: 0.007578892633318901\n",
      "Epoch: 11500 train loss=0.010164066 valid loss= 0.010576501\n",
      "train reg_fs: 0.00752466032281518\n",
      "Epoch: 12000 train loss=0.012782624 valid loss= 0.010447325\n",
      "train reg_fs: 0.007465368136763573\n",
      "Epoch: 12500 train loss=0.011769174 valid loss= 0.010324875\n",
      "train reg_fs: 0.007403350435197353\n",
      "Epoch: 13000 train loss=0.013297126 valid loss= 0.010314047\n",
      "train reg_fs: 0.00734321866184473\n",
      "Epoch: 13500 train loss=0.010939194 valid loss= 0.010265602\n",
      "train reg_fs: 0.007289786823093891\n",
      "Epoch: 14000 train loss=0.008095527 valid loss= 0.010162914\n",
      "train reg_fs: 0.007233331445604563\n",
      "Epoch: 14500 train loss=0.009064999 valid loss= 0.010216551\n",
      "train reg_fs: 0.007176827639341354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:55:29,371]\u001b[0m Trial 3 finished with value: 0.0025383778103019185 and parameters: {'lam': 0.009312558203049909, 'learning_rate': 0.020541325985025255, 'num_epoch': 15000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.015242752 valid loss= 0.009681478\n",
      "train reg_fs: 0.007128414232283831\n",
      "Optimization Finished!\n",
      "test loss: 0.010543831624090672, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025383778103019185\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013283363 valid loss= 0.007500133\n",
      "train reg_fs: 0.0010628411546349525\n",
      "Epoch: 1000 train loss=0.008317947 valid loss= 0.008411075\n",
      "train reg_fs: 0.0010776271810755134\n",
      "Epoch: 1500 train loss=0.008841781 valid loss= 0.008901252\n",
      "train reg_fs: 0.0010716910474002361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:55:43,895]\u001b[0m Trial 4 finished with value: 0.006346167462504215 and parameters: {'lam': 0.001205503174440379, 'learning_rate': 0.07899067917668938, 'num_epoch': 2000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.005188718 valid loss= 0.007394572\n",
      "train reg_fs: 0.001042633200995624\n",
      "Optimization Finished!\n",
      "test loss: 0.006801971700042486, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006346167462504215\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.024429297 valid loss= 0.009794060\n",
      "train reg_fs: 0.0025349354837089777\n",
      "Epoch: 1000 train loss=0.024867056 valid loss= 0.009684325\n",
      "train reg_fs: 0.0025522171054035425\n",
      "Epoch: 1500 train loss=0.011374202 valid loss= 0.009088317\n",
      "train reg_fs: 0.0025681264232844114\n",
      "Epoch: 2000 train loss=0.019218370 valid loss= 0.009173948\n",
      "train reg_fs: 0.0025839509908109903\n",
      "Epoch: 2500 train loss=0.009424584 valid loss= 0.009139762\n",
      "train reg_fs: 0.0025966118555516005\n",
      "Epoch: 3000 train loss=0.005359564 valid loss= 0.009023453\n",
      "train reg_fs: 0.002607989124953747\n",
      "Epoch: 3500 train loss=0.009212853 valid loss= 0.008783948\n",
      "train reg_fs: 0.0026179752312600613\n",
      "Epoch: 4000 train loss=0.013858124 valid loss= 0.008922284\n",
      "train reg_fs: 0.0026270688977092505\n",
      "Epoch: 4500 train loss=0.014564272 valid loss= 0.008565743\n",
      "train reg_fs: 0.002635361161082983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:56:17,063]\u001b[0m Trial 5 finished with value: 0.005910998167392975 and parameters: {'lam': 0.0029984587342626037, 'learning_rate': 0.010883204429144425, 'num_epoch': 5000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008263897 valid loss= 0.008559898\n",
      "train reg_fs: 0.0026425854302942753\n",
      "Optimization Finished!\n",
      "test loss: 0.010762413032352924, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005910998167392975\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012410039 valid loss= 0.008778282\n",
      "train reg_fs: 0.0009468196658417583\n",
      "Epoch: 1000 train loss=0.007258332 valid loss= 0.008665619\n",
      "train reg_fs: 0.0009555765427649021\n",
      "Epoch: 1500 train loss=0.011216204 valid loss= 0.008852862\n",
      "train reg_fs: 0.0009632044821046293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:56:31,635]\u001b[0m Trial 6 finished with value: 0.006970799637919895 and parameters: {'lam': 0.0011122005355515263, 'learning_rate': 0.014432418717556031, 'num_epoch': 2000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.008551621 valid loss= 0.007939178\n",
      "train reg_fs: 0.0009696453344076872\n",
      "Optimization Finished!\n",
      "test loss: 0.011084811761975288, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006970799637919895\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017673464 valid loss= 0.015181055\n",
      "train reg_fs: 0.007364535704255104\n",
      "Epoch: 1000 train loss=0.021291077 valid loss= 0.014806105\n",
      "train reg_fs: 0.007386370096355677\n",
      "Epoch: 1500 train loss=0.010342569 valid loss= 0.014002466\n",
      "train reg_fs: 0.007163741625845432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:56:45,724]\u001b[0m Trial 7 finished with value: 0.005209892744125329 and parameters: {'lam': 0.008521367651482722, 'learning_rate': 0.07005203928069247, 'num_epoch': 2000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.018440813 valid loss= 0.012271039\n",
      "train reg_fs: 0.0068618482910096645\n",
      "Optimization Finished!\n",
      "test loss: 0.013783765956759453, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005209892744125329\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015865270 valid loss= 0.009908026\n",
      "train reg_fs: 0.001943036331795156\n",
      "Epoch: 1000 train loss=0.013593690 valid loss= 0.009349792\n",
      "train reg_fs: 0.001962430542334914\n",
      "Epoch: 1500 train loss=0.004657848 valid loss= 0.010093950\n",
      "train reg_fs: 0.0019556363113224506\n",
      "Epoch: 2000 train loss=0.016899124 valid loss= 0.009642023\n",
      "train reg_fs: 0.0019309051567688584\n",
      "Epoch: 2500 train loss=0.004161506 valid loss= 0.009113250\n",
      "train reg_fs: 0.0018943569157272577\n",
      "Epoch: 3000 train loss=0.010489115 valid loss= 0.008614630\n",
      "train reg_fs: 0.0018581796903163195\n",
      "Epoch: 3500 train loss=0.006717956 valid loss= 0.008067733\n",
      "train reg_fs: 0.0018308523576706648\n",
      "Epoch: 4000 train loss=0.007813803 valid loss= 0.007808443\n",
      "train reg_fs: 0.0018061280716210604\n",
      "Epoch: 4500 train loss=0.004482639 valid loss= 0.007272202\n",
      "train reg_fs: 0.0017835323233157396\n",
      "Epoch: 5000 train loss=0.006299866 valid loss= 0.006905763\n",
      "train reg_fs: 0.0017610123613849282\n",
      "Epoch: 5500 train loss=0.009529063 valid loss= 0.006126611\n",
      "train reg_fs: 0.0017362722428515553\n",
      "Epoch: 6000 train loss=0.004434463 valid loss= 0.005597873\n",
      "train reg_fs: 0.001703481888398528\n",
      "Epoch: 6500 train loss=0.003399019 valid loss= 0.004898166\n",
      "train reg_fs: 0.0016748127527534962\n",
      "Epoch: 7000 train loss=0.007346402 valid loss= 0.005353137\n",
      "train reg_fs: 0.0016458802856504917\n",
      "Epoch: 7500 train loss=0.003411595 valid loss= 0.005061312\n",
      "train reg_fs: 0.0016225783620029688\n",
      "Epoch: 8000 train loss=0.005249843 valid loss= 0.005103632\n",
      "train reg_fs: 0.001599709503352642\n",
      "Epoch: 8500 train loss=0.002955553 valid loss= 0.004849483\n",
      "train reg_fs: 0.0015772529877722263\n",
      "Epoch: 9000 train loss=0.005221998 valid loss= 0.004741640\n",
      "train reg_fs: 0.0015564360655844212\n",
      "Epoch: 9500 train loss=0.005191715 valid loss= 0.004907593\n",
      "train reg_fs: 0.0015379495453089476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:57:49,919]\u001b[0m Trial 8 finished with value: 0.0031656520449314845 and parameters: {'lam': 0.002275109902953339, 'learning_rate': 0.043489048045279095, 'num_epoch': 10000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003846522 valid loss= 0.004699869\n",
      "train reg_fs: 0.0015221349895000458\n",
      "Optimization Finished!\n",
      "test loss: 0.004752472974359989, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0031656520449314845\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017438743 valid loss= 0.011763918\n",
      "train reg_fs: 0.004780938383191824\n",
      "Epoch: 1000 train loss=0.023087438 valid loss= 0.011925256\n",
      "train reg_fs: 0.004839390050619841\n",
      "Epoch: 1500 train loss=0.011132429 valid loss= 0.010694960\n",
      "train reg_fs: 0.004865658935159445\n",
      "Epoch: 2000 train loss=0.012049356 valid loss= 0.010579817\n",
      "train reg_fs: 0.004870280623435974\n",
      "Epoch: 2500 train loss=0.015440311 valid loss= 0.010339355\n",
      "train reg_fs: 0.004849697928875685\n",
      "Epoch: 3000 train loss=0.006189169 valid loss= 0.010435097\n",
      "train reg_fs: 0.004804507363587618\n",
      "Epoch: 3500 train loss=0.008854603 valid loss= 0.010430496\n",
      "train reg_fs: 0.0047462452203035355\n",
      "Epoch: 4000 train loss=0.011289106 valid loss= 0.009532496\n",
      "train reg_fs: 0.004681705962866545\n",
      "Epoch: 4500 train loss=0.010380613 valid loss= 0.008576392\n",
      "train reg_fs: 0.0046094441786408424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:58:23,301]\u001b[0m Trial 9 finished with value: 0.0035977176458469175 and parameters: {'lam': 0.0056042685673374365, 'learning_rate': 0.026561797184474604, 'num_epoch': 5000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.007916812 valid loss= 0.008185596\n",
      "train reg_fs: 0.0045423139818012714\n",
      "Optimization Finished!\n",
      "test loss: 0.00922396406531334, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0035977176458469175\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015086934 valid loss= 0.005379672\n",
      "train reg_fs: 0.0015042346203699708\n",
      "Epoch: 1000 train loss=0.003748092 valid loss= 0.003759054\n",
      "train reg_fs: 0.0014303105417639017\n",
      "Epoch: 1500 train loss=0.004444505 valid loss= 0.003939445\n",
      "train reg_fs: 0.0014201896265149117\n",
      "Epoch: 2000 train loss=0.004114608 valid loss= 0.004243724\n",
      "train reg_fs: 0.0014217934804037213\n",
      "Epoch: 2500 train loss=0.004244187 valid loss= 0.004437586\n",
      "train reg_fs: 0.0014090214390307665\n",
      "Epoch: 3000 train loss=0.009959837 valid loss= 0.003803302\n",
      "train reg_fs: 0.00138817448168993\n",
      "Epoch: 3500 train loss=0.006269462 valid loss= 0.003955007\n",
      "train reg_fs: 0.0013705934397876263\n",
      "Epoch: 4000 train loss=0.005642560 valid loss= 0.003465519\n",
      "train reg_fs: 0.0013591257156804204\n",
      "Epoch: 4500 train loss=0.004003085 valid loss= 0.003876376\n",
      "train reg_fs: 0.0013510665157809854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:58:56,575]\u001b[0m Trial 10 finished with value: 0.002055121216692203 and parameters: {'lam': 0.0018260342267226027, 'learning_rate': 0.16902384848075502, 'num_epoch': 5000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002632040 valid loss= 0.003372899\n",
      "train reg_fs: 0.0013431836850941181\n",
      "Optimization Finished!\n",
      "test loss: 0.0032872636802494526, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002055121216692203\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009543888 valid loss= 0.007493842\n",
      "train reg_fs: 0.0016573983011767268\n",
      "Epoch: 1000 train loss=0.007309724 valid loss= 0.008589989\n",
      "train reg_fs: 0.0016069612465798855\n",
      "Epoch: 1500 train loss=0.001986773 valid loss= 0.006204158\n",
      "train reg_fs: 0.0015716799534857273\n",
      "Epoch: 2000 train loss=0.006217625 valid loss= 0.006172692\n",
      "train reg_fs: 0.0015443670563399792\n",
      "Epoch: 2500 train loss=0.002703015 valid loss= 0.004777848\n",
      "train reg_fs: 0.0015223704976961017\n",
      "Epoch: 3000 train loss=0.006969748 valid loss= 0.005174747\n",
      "train reg_fs: 0.001511340495198965\n",
      "Epoch: 3500 train loss=0.004062497 valid loss= 0.004497785\n",
      "train reg_fs: 0.0014888389268890023\n",
      "Epoch: 4000 train loss=0.004996014 valid loss= 0.004715838\n",
      "train reg_fs: 0.0014705585781484842\n",
      "Epoch: 4500 train loss=0.003112291 valid loss= 0.004999865\n",
      "train reg_fs: 0.0014522055862471461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 00:59:29,614]\u001b[0m Trial 11 finished with value: 0.003774746111684997 and parameters: {'lam': 0.0018578759280840596, 'learning_rate': 0.19966681191322835, 'num_epoch': 5000}. Best is trial 0 with value: 0.0019158950122663443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002913945 valid loss= 0.005218673\n",
      "train reg_fs: 0.0014362243236973882\n",
      "Optimization Finished!\n",
      "test loss: 0.005533806048333645, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003774746111684997\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011037333 valid loss= 0.007493242\n",
      "train reg_fs: 0.0014820626238361\n",
      "Epoch: 1000 train loss=0.002921403 valid loss= 0.004839448\n",
      "train reg_fs: 0.0014411400770768523\n",
      "Epoch: 1500 train loss=0.004636136 valid loss= 0.003692130\n",
      "train reg_fs: 0.0013896638993173838\n",
      "Epoch: 2000 train loss=0.011354254 valid loss= 0.002959085\n",
      "train reg_fs: 0.001342245377600193\n",
      "Epoch: 2500 train loss=0.002818305 valid loss= 0.002844139\n",
      "train reg_fs: 0.001316593959927559\n",
      "Epoch: 3000 train loss=0.002272474 valid loss= 0.003506027\n",
      "train reg_fs: 0.001300967182032764\n",
      "Epoch: 3500 train loss=0.006249971 valid loss= 0.002816228\n",
      "train reg_fs: 0.0012915028491988778\n",
      "Epoch: 4000 train loss=0.002898016 valid loss= 0.002940176\n",
      "train reg_fs: 0.001284932834096253\n",
      "Epoch: 4500 train loss=0.002068084 valid loss= 0.003725064\n",
      "train reg_fs: 0.001281169825233519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:00:02,636]\u001b[0m Trial 12 finished with value: 0.0016000980845139274 and parameters: {'lam': 0.001707548866075967, 'learning_rate': 0.11351164552423795, 'num_epoch': 5000}. Best is trial 12 with value: 0.0016000980845139274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002250574 valid loss= 0.002857555\n",
      "train reg_fs: 0.001277283183299005\n",
      "Optimization Finished!\n",
      "test loss: 0.002842481480911374, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0016000980845139274\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012104578 valid loss= 0.006016007\n",
      "train reg_fs: 0.0012891606893390417\n",
      "Epoch: 1000 train loss=0.004953785 valid loss= 0.004769636\n",
      "train reg_fs: 0.0012667024275287986\n",
      "Epoch: 1500 train loss=0.013119777 valid loss= 0.003381038\n",
      "train reg_fs: 0.0012119775637984276\n",
      "Epoch: 2000 train loss=0.008891872 valid loss= 0.003104173\n",
      "train reg_fs: 0.0011755652958527207\n",
      "Epoch: 2500 train loss=0.005641773 valid loss= 0.003161077\n",
      "train reg_fs: 0.0011552789947018027\n",
      "Epoch: 3000 train loss=0.006440981 valid loss= 0.003428821\n",
      "train reg_fs: 0.0011412908788770437\n",
      "Epoch: 3500 train loss=0.006324870 valid loss= 0.003089080\n",
      "train reg_fs: 0.0011297540040686727\n",
      "Epoch: 4000 train loss=0.003936912 valid loss= 0.003105747\n",
      "train reg_fs: 0.0011211662786081433\n",
      "Epoch: 4500 train loss=0.002135418 valid loss= 0.003016439\n",
      "train reg_fs: 0.0011156395776197314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:00:35,955]\u001b[0m Trial 13 finished with value: 0.001979254790884879 and parameters: {'lam': 0.0014802313374753268, 'learning_rate': 0.09198560066650034, 'num_epoch': 5000}. Best is trial 12 with value: 0.0016000980845139274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003946026 valid loss= 0.003077067\n",
      "train reg_fs: 0.0011119329137727618\n",
      "Optimization Finished!\n",
      "test loss: 0.0029875347390770912, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001979254790884879\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014741691 valid loss= 0.009670508\n",
      "train reg_fs: 0.002102744299918413\n",
      "Epoch: 1000 train loss=0.009555127 valid loss= 0.007870799\n",
      "train reg_fs: 0.002116461982950568\n",
      "Epoch: 1500 train loss=0.013046194 valid loss= 0.006990056\n",
      "train reg_fs: 0.002106437226757407\n",
      "Epoch: 2000 train loss=0.005440332 valid loss= 0.007101049\n",
      "train reg_fs: 0.0020660990849137306\n",
      "Epoch: 2500 train loss=0.013984112 valid loss= 0.006151279\n",
      "train reg_fs: 0.002016667043790221\n",
      "Epoch: 3000 train loss=0.004072323 valid loss= 0.004277388\n",
      "train reg_fs: 0.001966223120689392\n",
      "Epoch: 3500 train loss=0.006158381 valid loss= 0.004338600\n",
      "train reg_fs: 0.0019197763176634908\n",
      "Epoch: 4000 train loss=0.009862266 valid loss= 0.004003931\n",
      "train reg_fs: 0.0018724885303527117\n",
      "Epoch: 4500 train loss=0.005241404 valid loss= 0.003258473\n",
      "train reg_fs: 0.001829185406677425\n",
      "Epoch: 5000 train loss=0.012333424 valid loss= 0.003347865\n",
      "train reg_fs: 0.0017934454372152686\n",
      "Epoch: 5500 train loss=0.008974788 valid loss= 0.003116993\n",
      "train reg_fs: 0.0017633725656196475\n",
      "Epoch: 6000 train loss=0.005646572 valid loss= 0.003119128\n",
      "train reg_fs: 0.001741005340591073\n",
      "Epoch: 6500 train loss=0.003779478 valid loss= 0.003121453\n",
      "train reg_fs: 0.0017227752832695842\n",
      "Epoch: 7000 train loss=0.004805831 valid loss= 0.003034950\n",
      "train reg_fs: 0.00170411285944283\n",
      "Epoch: 7500 train loss=0.004464509 valid loss= 0.003017830\n",
      "train reg_fs: 0.0016901750350371003\n",
      "Epoch: 8000 train loss=0.003683693 valid loss= 0.002868085\n",
      "train reg_fs: 0.0016781305894255638\n",
      "Epoch: 8500 train loss=0.003764256 valid loss= 0.003111505\n",
      "train reg_fs: 0.0016677838284522295\n",
      "Epoch: 9000 train loss=0.003516897 valid loss= 0.003081484\n",
      "train reg_fs: 0.0016581725794821978\n",
      "Epoch: 9500 train loss=0.003973627 valid loss= 0.002867974\n",
      "train reg_fs: 0.0016502965008839965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:01:40,830]\u001b[0m Trial 14 finished with value: 0.001188616769500771 and parameters: {'lam': 0.002464837388285686, 'learning_rate': 0.04429557518945829, 'num_epoch': 10000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003954059 valid loss= 0.002931652\n",
      "train reg_fs: 0.0016433803830295801\n",
      "Optimization Finished!\n",
      "test loss: 0.003651766572147608, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001188616769500771\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010518822 valid loss= 0.009154238\n",
      "train reg_fs: 0.001951304031535983\n",
      "Epoch: 1000 train loss=0.024430819 valid loss= 0.009559793\n",
      "train reg_fs: 0.0019772632513195276\n",
      "Epoch: 1500 train loss=0.009988625 valid loss= 0.008127637\n",
      "train reg_fs: 0.00197817524895072\n",
      "Epoch: 2000 train loss=0.005767078 valid loss= 0.007694330\n",
      "train reg_fs: 0.001962018432095647\n",
      "Epoch: 2500 train loss=0.007328004 valid loss= 0.006818852\n",
      "train reg_fs: 0.001938093570061028\n",
      "Epoch: 3000 train loss=0.009155928 valid loss= 0.006174891\n",
      "train reg_fs: 0.0019217540975660086\n",
      "Epoch: 3500 train loss=0.016287832 valid loss= 0.005801133\n",
      "train reg_fs: 0.0019073091680184007\n",
      "Epoch: 4000 train loss=0.006070209 valid loss= 0.005365288\n",
      "train reg_fs: 0.001897079637274146\n",
      "Epoch: 4500 train loss=0.006443184 valid loss= 0.005175680\n",
      "train reg_fs: 0.0018863707082346082\n",
      "Epoch: 5000 train loss=0.006660512 valid loss= 0.004485602\n",
      "train reg_fs: 0.0018738742219284177\n",
      "Epoch: 5500 train loss=0.008123034 valid loss= 0.004631255\n",
      "train reg_fs: 0.0018586780643090606\n",
      "Epoch: 6000 train loss=0.007700329 valid loss= 0.004102542\n",
      "train reg_fs: 0.0018415874801576138\n",
      "Epoch: 6500 train loss=0.005202806 valid loss= 0.004413829\n",
      "train reg_fs: 0.0018239462515339255\n",
      "Epoch: 7000 train loss=0.006108907 valid loss= 0.003921968\n",
      "train reg_fs: 0.0018116412684321404\n",
      "Epoch: 7500 train loss=0.003840789 valid loss= 0.004081034\n",
      "train reg_fs: 0.0018054887186735868\n",
      "Epoch: 8000 train loss=0.004225819 valid loss= 0.003963456\n",
      "train reg_fs: 0.0018007123144343495\n",
      "Epoch: 8500 train loss=0.008204664 valid loss= 0.004147006\n",
      "train reg_fs: 0.0017983256839215755\n",
      "Epoch: 9000 train loss=0.005550148 valid loss= 0.004376034\n",
      "train reg_fs: 0.001796314842067659\n",
      "Epoch: 9500 train loss=0.003032274 valid loss= 0.004413392\n",
      "train reg_fs: 0.001794475712813437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:02:45,738]\u001b[0m Trial 15 finished with value: 0.002701767685284526 and parameters: {'lam': 0.0022818836707581237, 'learning_rate': 0.04446453313084925, 'num_epoch': 10000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003872179 valid loss= 0.004505359\n",
      "train reg_fs: 0.0017930682515725493\n",
      "Optimization Finished!\n",
      "test loss: 0.004568408243358135, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002701767685284526\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020088818 valid loss= 0.007026346\n",
      "train reg_fs: 0.001217343844473362\n",
      "Epoch: 1000 train loss=0.004650804 valid loss= 0.006717105\n",
      "train reg_fs: 0.001144515466876328\n",
      "Epoch: 1500 train loss=0.002822463 valid loss= 0.003983107\n",
      "train reg_fs: 0.001057192450389266\n",
      "Epoch: 2000 train loss=0.002389638 valid loss= 0.004755068\n",
      "train reg_fs: 0.0009985847864300013\n",
      "Epoch: 2500 train loss=0.003346324 valid loss= 0.004020947\n",
      "train reg_fs: 0.0009624623926356435\n",
      "Epoch: 3000 train loss=0.001999911 valid loss= 0.003632803\n",
      "train reg_fs: 0.000936285883653909\n",
      "Epoch: 3500 train loss=0.001560811 valid loss= 0.003776175\n",
      "train reg_fs: 0.0009173640282824636\n",
      "Epoch: 4000 train loss=0.001816836 valid loss= 0.003531075\n",
      "train reg_fs: 0.0009033841779455543\n",
      "Epoch: 4500 train loss=0.001920257 valid loss= 0.003484319\n",
      "train reg_fs: 0.0008933822391554713\n",
      "Epoch: 5000 train loss=0.004048882 valid loss= 0.003564122\n",
      "train reg_fs: 0.0008859125664457679\n",
      "Epoch: 5500 train loss=0.003399458 valid loss= 0.003553760\n",
      "train reg_fs: 0.0008801775402389467\n",
      "Epoch: 6000 train loss=0.003554402 valid loss= 0.003420651\n",
      "train reg_fs: 0.0008749595144763589\n",
      "Epoch: 6500 train loss=0.007114198 valid loss= 0.003152846\n",
      "train reg_fs: 0.0008708557579666376\n",
      "Epoch: 7000 train loss=0.001618742 valid loss= 0.003066981\n",
      "train reg_fs: 0.0008673634729348123\n",
      "Epoch: 7500 train loss=0.006125519 valid loss= 0.003123400\n",
      "train reg_fs: 0.0008645118214190006\n",
      "Epoch: 8000 train loss=0.005316234 valid loss= 0.003245658\n",
      "train reg_fs: 0.0008619307191111147\n",
      "Epoch: 8500 train loss=0.001391814 valid loss= 0.003097181\n",
      "train reg_fs: 0.0008598615531809628\n",
      "Epoch: 9000 train loss=0.005589846 valid loss= 0.003313500\n",
      "train reg_fs: 0.0008579033892601728\n",
      "Epoch: 9500 train loss=0.003838290 valid loss= 0.003256374\n",
      "train reg_fs: 0.0008561228751204908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:03:50,627]\u001b[0m Trial 16 finished with value: 0.0022182427071780076 and parameters: {'lam': 0.0013951877574811366, 'learning_rate': 0.12257368779204471, 'num_epoch': 10000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003078718 valid loss= 0.003056957\n",
      "train reg_fs: 0.0008546410244889557\n",
      "Optimization Finished!\n",
      "test loss: 0.002862113295122981, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022182427071780076\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011670704 valid loss= 0.007587658\n",
      "train reg_fs: 0.0008669969392940402\n",
      "Epoch: 1000 train loss=0.008049794 valid loss= 0.007444090\n",
      "train reg_fs: 0.0008810067665763199\n",
      "Epoch: 1500 train loss=0.016474508 valid loss= 0.006808816\n",
      "train reg_fs: 0.0008896002545952797\n",
      "Epoch: 2000 train loss=0.014185769 valid loss= 0.005801558\n",
      "train reg_fs: 0.0008953736396506429\n",
      "Epoch: 2500 train loss=0.007082607 valid loss= 0.007004485\n",
      "train reg_fs: 0.000898435537237674\n",
      "Epoch: 3000 train loss=0.011929817 valid loss= 0.006501300\n",
      "train reg_fs: 0.0008983365842141211\n",
      "Epoch: 3500 train loss=0.005223769 valid loss= 0.006117079\n",
      "train reg_fs: 0.0008960498380474746\n",
      "Epoch: 4000 train loss=0.009080629 valid loss= 0.006802148\n",
      "train reg_fs: 0.0008926842710934579\n",
      "Epoch: 4500 train loss=0.006047736 valid loss= 0.006189929\n",
      "train reg_fs: 0.0008886348805390298\n",
      "Epoch: 5000 train loss=0.011285985 valid loss= 0.006000614\n",
      "train reg_fs: 0.0008831997402012348\n",
      "Epoch: 5500 train loss=0.009811524 valid loss= 0.005636210\n",
      "train reg_fs: 0.0008780623902566731\n",
      "Epoch: 6000 train loss=0.009122840 valid loss= 0.004866207\n",
      "train reg_fs: 0.0008725608349777758\n",
      "Epoch: 6500 train loss=0.005409183 valid loss= 0.004764407\n",
      "train reg_fs: 0.0008685628999955952\n",
      "Epoch: 7000 train loss=0.005409514 valid loss= 0.005011818\n",
      "train reg_fs: 0.0008634250261820853\n",
      "Epoch: 7500 train loss=0.003035586 valid loss= 0.004486653\n",
      "train reg_fs: 0.0008593308157287538\n",
      "Epoch: 8000 train loss=0.004098821 valid loss= 0.004255487\n",
      "train reg_fs: 0.000855531427077949\n",
      "Epoch: 8500 train loss=0.007669571 valid loss= 0.004414260\n",
      "train reg_fs: 0.0008515710360370576\n",
      "Epoch: 9000 train loss=0.003795858 valid loss= 0.004086889\n",
      "train reg_fs: 0.0008484512218274176\n",
      "Epoch: 9500 train loss=0.006276520 valid loss= 0.003854757\n",
      "train reg_fs: 0.0008455399074591696\n",
      "Epoch: 10000 train loss=0.003483798 valid loss= 0.004039316\n",
      "train reg_fs: 0.0008422033279202878\n",
      "Epoch: 10500 train loss=0.007635728 valid loss= 0.003799271\n",
      "train reg_fs: 0.0008385922992601991\n",
      "Epoch: 11000 train loss=0.002124789 valid loss= 0.003975491\n",
      "train reg_fs: 0.0008362401858903468\n",
      "Epoch: 11500 train loss=0.003333698 valid loss= 0.003725685\n",
      "train reg_fs: 0.0008332959259860218\n",
      "Epoch: 12000 train loss=0.002751868 valid loss= 0.003654896\n",
      "train reg_fs: 0.000831028854008764\n",
      "Epoch: 12500 train loss=0.004024043 valid loss= 0.003626894\n",
      "train reg_fs: 0.0008281929767690599\n",
      "Epoch: 13000 train loss=0.003556794 valid loss= 0.003549239\n",
      "train reg_fs: 0.0008247882360592484\n",
      "Epoch: 13500 train loss=0.002642725 valid loss= 0.003579164\n",
      "train reg_fs: 0.0008217907161451876\n",
      "Epoch: 14000 train loss=0.006484060 valid loss= 0.003550023\n",
      "train reg_fs: 0.0008190097287297249\n",
      "Epoch: 14500 train loss=0.005225483 valid loss= 0.003659650\n",
      "train reg_fs: 0.0008159471326507628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:05:27,716]\u001b[0m Trial 17 finished with value: 0.002566502383880257 and parameters: {'lam': 0.0010076879198030891, 'learning_rate': 0.031132229400378755, 'num_epoch': 15000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004122237 valid loss= 0.003387248\n",
      "train reg_fs: 0.0008134509553201497\n",
      "Optimization Finished!\n",
      "test loss: 0.003918431233614683, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002566502383880257\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010787385 valid loss= 0.008186467\n",
      "train reg_fs: 0.0019401428289711475\n",
      "Epoch: 1000 train loss=0.015794309 valid loss= 0.006929010\n",
      "train reg_fs: 0.0018930177902802825\n",
      "Epoch: 1500 train loss=0.012634207 valid loss= 0.005365950\n",
      "train reg_fs: 0.0018256899202242494\n",
      "Epoch: 2000 train loss=0.006275036 valid loss= 0.004434763\n",
      "train reg_fs: 0.001774087082594633\n",
      "Epoch: 2500 train loss=0.003281775 valid loss= 0.004417534\n",
      "train reg_fs: 0.0017460375092923641\n",
      "Epoch: 3000 train loss=0.007888897 valid loss= 0.004384822\n",
      "train reg_fs: 0.0017322369385510683\n",
      "Epoch: 3500 train loss=0.005827102 valid loss= 0.004694010\n",
      "train reg_fs: 0.001722276909276843\n",
      "Epoch: 4000 train loss=0.008573215 valid loss= 0.004599012\n",
      "train reg_fs: 0.0017170098144561052\n",
      "Epoch: 4500 train loss=0.003008353 valid loss= 0.004259659\n",
      "train reg_fs: 0.0017126790480688214\n",
      "Epoch: 5000 train loss=0.005045323 valid loss= 0.004488385\n",
      "train reg_fs: 0.0017094529466703534\n",
      "Epoch: 5500 train loss=0.007196239 valid loss= 0.004213858\n",
      "train reg_fs: 0.0017044921405613422\n",
      "Epoch: 6000 train loss=0.003394773 valid loss= 0.004608774\n",
      "train reg_fs: 0.0016943347873166203\n",
      "Epoch: 6500 train loss=0.003421658 valid loss= 0.004399504\n",
      "train reg_fs: 0.0016797343268990517\n",
      "Epoch: 7000 train loss=0.002812496 valid loss= 0.004488085\n",
      "train reg_fs: 0.0016589852748438716\n",
      "Epoch: 7500 train loss=0.002470253 valid loss= 0.004738918\n",
      "train reg_fs: 0.0016326896147802472\n",
      "Epoch: 8000 train loss=0.002729923 valid loss= 0.003976088\n",
      "train reg_fs: 0.0016115600010380149\n",
      "Epoch: 8500 train loss=0.002791650 valid loss= 0.004194035\n",
      "train reg_fs: 0.001590394414961338\n",
      "Epoch: 9000 train loss=0.007616778 valid loss= 0.004093198\n",
      "train reg_fs: 0.0015745616983622313\n",
      "Epoch: 9500 train loss=0.003294068 valid loss= 0.003753000\n",
      "train reg_fs: 0.001561386394314468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:06:32,952]\u001b[0m Trial 18 finished with value: 0.0024569099587906126 and parameters: {'lam': 0.002301697951926393, 'learning_rate': 0.062031913843521795, 'num_epoch': 10000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005467426 valid loss= 0.004014633\n",
      "train reg_fs: 0.0015484013129025698\n",
      "Optimization Finished!\n",
      "test loss: 0.0037192674353718758, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024569099587906126\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012038191 valid loss= 0.008896755\n",
      "train reg_fs: 0.0036167148500680923\n",
      "Epoch: 1000 train loss=0.015283912 valid loss= 0.007943163\n",
      "train reg_fs: 0.0034172905143350363\n",
      "Epoch: 1500 train loss=0.010002229 valid loss= 0.006381122\n",
      "train reg_fs: 0.0032150419428944588\n",
      "Epoch: 2000 train loss=0.009548806 valid loss= 0.006203355\n",
      "train reg_fs: 0.003110178979113698\n",
      "Epoch: 2500 train loss=0.014128167 valid loss= 0.006575461\n",
      "train reg_fs: 0.003030070336535573\n",
      "Epoch: 3000 train loss=0.005462516 valid loss= 0.006412106\n",
      "train reg_fs: 0.002939297817647457\n",
      "Epoch: 3500 train loss=0.005496585 valid loss= 0.006430835\n",
      "train reg_fs: 0.002835890045389533\n",
      "Epoch: 4000 train loss=0.003467415 valid loss= 0.005631566\n",
      "train reg_fs: 0.0027519597206264734\n",
      "Epoch: 4500 train loss=0.004222807 valid loss= 0.005517791\n",
      "train reg_fs: 0.002697869436815381\n",
      "Epoch: 5000 train loss=0.005280022 valid loss= 0.005252760\n",
      "train reg_fs: 0.002659607445821166\n",
      "Epoch: 5500 train loss=0.003580809 valid loss= 0.005258972\n",
      "train reg_fs: 0.002630661940202117\n",
      "Epoch: 6000 train loss=0.006506650 valid loss= 0.005127970\n",
      "train reg_fs: 0.002609727205708623\n",
      "Epoch: 6500 train loss=0.006950978 valid loss= 0.004870214\n",
      "train reg_fs: 0.002592752454802394\n",
      "Epoch: 7000 train loss=0.003633542 valid loss= 0.004908479\n",
      "train reg_fs: 0.0025799383874982595\n",
      "Epoch: 7500 train loss=0.004893169 valid loss= 0.004825010\n",
      "train reg_fs: 0.002569325501099229\n",
      "Epoch: 8000 train loss=0.003929901 valid loss= 0.005177968\n",
      "train reg_fs: 0.002561133587732911\n",
      "Epoch: 8500 train loss=0.006476432 valid loss= 0.004700984\n",
      "train reg_fs: 0.0025538380723446608\n",
      "Epoch: 9000 train loss=0.003570860 valid loss= 0.004818003\n",
      "train reg_fs: 0.002547814277932048\n",
      "Epoch: 9500 train loss=0.002718808 valid loss= 0.004755347\n",
      "train reg_fs: 0.002542597707360983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:07:37,972]\u001b[0m Trial 19 finished with value: 0.0023291598956897987 and parameters: {'lam': 0.0041665364940078374, 'learning_rate': 0.11208180875480553, 'num_epoch': 10000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002915422 valid loss= 0.004811608\n",
      "train reg_fs: 0.0025381334125995636\n",
      "Optimization Finished!\n",
      "test loss: 0.004634168930351734, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023291598956897987\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018471058 valid loss= 0.008864789\n",
      "train reg_fs: 0.0014895915519446135\n",
      "Epoch: 1000 train loss=0.026374064 valid loss= 0.009379271\n",
      "train reg_fs: 0.0015189958503469825\n",
      "Epoch: 1500 train loss=0.017305741 valid loss= 0.008649908\n",
      "train reg_fs: 0.001534992246888578\n",
      "Epoch: 2000 train loss=0.005902180 valid loss= 0.008814957\n",
      "train reg_fs: 0.0015438144328072667\n",
      "Epoch: 2500 train loss=0.006193914 valid loss= 0.008685604\n",
      "train reg_fs: 0.0015465228352695704\n",
      "Epoch: 3000 train loss=0.009687342 valid loss= 0.007850058\n",
      "train reg_fs: 0.0015419303672388196\n",
      "Epoch: 3500 train loss=0.003745610 valid loss= 0.007684909\n",
      "train reg_fs: 0.0015336923534050584\n",
      "Epoch: 4000 train loss=0.006245969 valid loss= 0.007611916\n",
      "train reg_fs: 0.0015194551087915897\n",
      "Epoch: 4500 train loss=0.004409400 valid loss= 0.006502694\n",
      "train reg_fs: 0.001504426239989698\n",
      "Epoch: 5000 train loss=0.007903761 valid loss= 0.006723687\n",
      "train reg_fs: 0.0014898005174472928\n",
      "Epoch: 5500 train loss=0.004977935 valid loss= 0.005949368\n",
      "train reg_fs: 0.001477397745475173\n",
      "Epoch: 6000 train loss=0.003259725 valid loss= 0.005532551\n",
      "train reg_fs: 0.001464491244405508\n",
      "Epoch: 6500 train loss=0.008840265 valid loss= 0.004710394\n",
      "train reg_fs: 0.001451615709811449\n",
      "Epoch: 7000 train loss=0.003853756 valid loss= 0.004727819\n",
      "train reg_fs: 0.0014396808110177517\n",
      "Epoch: 7500 train loss=0.004834671 valid loss= 0.004192692\n",
      "train reg_fs: 0.0014277176233008504\n",
      "Epoch: 8000 train loss=0.006058424 valid loss= 0.003653025\n",
      "train reg_fs: 0.0014128487091511488\n",
      "Epoch: 8500 train loss=0.009950355 valid loss= 0.003729004\n",
      "train reg_fs: 0.0013997529167681932\n",
      "Epoch: 9000 train loss=0.004101573 valid loss= 0.003845460\n",
      "train reg_fs: 0.0013875216245651245\n",
      "Epoch: 9500 train loss=0.003943795 valid loss= 0.003857883\n",
      "train reg_fs: 0.0013767797499895096\n",
      "Epoch: 10000 train loss=0.005573227 valid loss= 0.003725056\n",
      "train reg_fs: 0.0013663991121575236\n",
      "Epoch: 10500 train loss=0.005059138 valid loss= 0.003574296\n",
      "train reg_fs: 0.0013569062575697899\n",
      "Epoch: 11000 train loss=0.004293556 valid loss= 0.003636043\n",
      "train reg_fs: 0.0013494696468114853\n",
      "Epoch: 11500 train loss=0.002077469 valid loss= 0.003757202\n",
      "train reg_fs: 0.0013418809976428747\n",
      "Epoch: 12000 train loss=0.002191804 valid loss= 0.003625213\n",
      "train reg_fs: 0.0013352829264476895\n",
      "Epoch: 12500 train loss=0.003606795 valid loss= 0.003607838\n",
      "train reg_fs: 0.0013286333996802568\n",
      "Epoch: 13000 train loss=0.002301444 valid loss= 0.003669655\n",
      "train reg_fs: 0.0013226118171587586\n",
      "Epoch: 13500 train loss=0.002693447 valid loss= 0.003734871\n",
      "train reg_fs: 0.0013174348277971148\n",
      "Epoch: 14000 train loss=0.003712257 valid loss= 0.003814974\n",
      "train reg_fs: 0.0013121560914441943\n",
      "Epoch: 14500 train loss=0.003261102 valid loss= 0.003394493\n",
      "train reg_fs: 0.001307597616687417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:09:14,817]\u001b[0m Trial 20 finished with value: 0.0029080466119087334 and parameters: {'lam': 0.001724656415541211, 'learning_rate': 0.038520380144413016, 'num_epoch': 15000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005901225 valid loss= 0.004195197\n",
      "train reg_fs: 0.0013033243594691157\n",
      "Optimization Finished!\n",
      "test loss: 0.0042452216148376465, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029080466119087334\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011498188 valid loss= 0.008568369\n",
      "train reg_fs: 0.0024512100499123335\n",
      "Epoch: 1000 train loss=0.012511847 valid loss= 0.008220449\n",
      "train reg_fs: 0.0024819548707455397\n",
      "Epoch: 1500 train loss=0.012824870 valid loss= 0.007771423\n",
      "train reg_fs: 0.0024690357968211174\n",
      "Epoch: 2000 train loss=0.007227270 valid loss= 0.007544925\n",
      "train reg_fs: 0.0024276371113955975\n",
      "Epoch: 2500 train loss=0.009039121 valid loss= 0.006392390\n",
      "train reg_fs: 0.002371997106820345\n",
      "Epoch: 3000 train loss=0.005846038 valid loss= 0.005435506\n",
      "train reg_fs: 0.0023258149158209562\n",
      "Epoch: 3500 train loss=0.009705249 valid loss= 0.004945960\n",
      "train reg_fs: 0.002280199434608221\n",
      "Epoch: 4000 train loss=0.006299432 valid loss= 0.004480842\n",
      "train reg_fs: 0.002238823566585779\n",
      "Epoch: 4500 train loss=0.004313887 valid loss= 0.004334854\n",
      "train reg_fs: 0.0022094121668487787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:09:47,556]\u001b[0m Trial 21 finished with value: 0.0027721034549112555 and parameters: {'lam': 0.0028513572575922766, 'learning_rate': 0.05313989331230185, 'num_epoch': 5000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.007735585 valid loss= 0.004991398\n",
      "train reg_fs: 0.002189517254009843\n",
      "Optimization Finished!\n",
      "test loss: 0.005337121896445751, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027721034549112555\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019896394 valid loss= 0.010593981\n",
      "train reg_fs: 0.0033723514061421156\n",
      "Epoch: 1000 train loss=0.015136936 valid loss= 0.007244279\n",
      "train reg_fs: 0.0032621652353554964\n",
      "Epoch: 1500 train loss=0.011777388 valid loss= 0.006740606\n",
      "train reg_fs: 0.003180109430104494\n",
      "Epoch: 2000 train loss=0.009558564 valid loss= 0.005117132\n",
      "train reg_fs: 0.003071555169299245\n",
      "Epoch: 2500 train loss=0.005547685 valid loss= 0.004900270\n",
      "train reg_fs: 0.0030119935981929302\n",
      "Epoch: 3000 train loss=0.005698422 valid loss= 0.004913498\n",
      "train reg_fs: 0.002977458294481039\n",
      "Epoch: 3500 train loss=0.004418531 valid loss= 0.005189797\n",
      "train reg_fs: 0.0029578511603176594\n",
      "Epoch: 4000 train loss=0.007347601 valid loss= 0.005089324\n",
      "train reg_fs: 0.00293175783008337\n",
      "Epoch: 4500 train loss=0.003654597 valid loss= 0.004899807\n",
      "train reg_fs: 0.002892598742619157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:10:21,876]\u001b[0m Trial 22 finished with value: 0.002126610864469198 and parameters: {'lam': 0.0039557421154212515, 'learning_rate': 0.09172758657370354, 'num_epoch': 5000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004751305 valid loss= 0.005005802\n",
      "train reg_fs: 0.0028350166976451874\n",
      "Optimization Finished!\n",
      "test loss: 0.00481690838932991, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002126610864469198\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012462484 valid loss= 0.008539845\n",
      "train reg_fs: 0.0022355772089213133\n",
      "Epoch: 1000 train loss=0.018645760 valid loss= 0.007682174\n",
      "train reg_fs: 0.0022182760294526815\n",
      "Epoch: 1500 train loss=0.025892146 valid loss= 0.005997083\n",
      "train reg_fs: 0.002143693855032325\n",
      "Epoch: 2000 train loss=0.011616925 valid loss= 0.004921264\n",
      "train reg_fs: 0.0020755049772560596\n",
      "Epoch: 2500 train loss=0.004661781 valid loss= 0.004455226\n",
      "train reg_fs: 0.002025933237746358\n",
      "Epoch: 3000 train loss=0.005057608 valid loss= 0.004556916\n",
      "train reg_fs: 0.001995065016672015\n",
      "Epoch: 3500 train loss=0.004852644 valid loss= 0.004449107\n",
      "train reg_fs: 0.0019774166867136955\n",
      "Epoch: 4000 train loss=0.004900000 valid loss= 0.004758088\n",
      "train reg_fs: 0.0019649046007543802\n",
      "Epoch: 4500 train loss=0.022216665 valid loss= 0.004903910\n",
      "train reg_fs: 0.0019544425886124372\n",
      "Epoch: 5000 train loss=0.004520108 valid loss= 0.005140054\n",
      "train reg_fs: 0.0019442321499809623\n",
      "Epoch: 5500 train loss=0.006193277 valid loss= 0.005045002\n",
      "train reg_fs: 0.001935115666128695\n",
      "Epoch: 6000 train loss=0.005624922 valid loss= 0.005042369\n",
      "train reg_fs: 0.0019261843990534544\n",
      "Epoch: 6500 train loss=0.004015495 valid loss= 0.005054248\n",
      "train reg_fs: 0.0019177704816684127\n",
      "Epoch: 7000 train loss=0.004309699 valid loss= 0.005257460\n",
      "train reg_fs: 0.001909049111418426\n",
      "Epoch: 7500 train loss=0.004460176 valid loss= 0.005197003\n",
      "train reg_fs: 0.0019010460237041116\n",
      "Epoch: 8000 train loss=0.004837652 valid loss= 0.005200802\n",
      "train reg_fs: 0.0018939485307782888\n",
      "Epoch: 8500 train loss=0.003227658 valid loss= 0.005217146\n",
      "train reg_fs: 0.0018856385722756386\n",
      "Epoch: 9000 train loss=0.005942464 valid loss= 0.005165690\n",
      "train reg_fs: 0.001878575887531042\n",
      "Epoch: 9500 train loss=0.005684742 valid loss= 0.005623476\n",
      "train reg_fs: 0.00187165685929358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:11:26,626]\u001b[0m Trial 23 finished with value: 0.0036272187658251773 and parameters: {'lam': 0.0026130138527351546, 'learning_rate': 0.055981356137058805, 'num_epoch': 10000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003984982 valid loss= 0.005527569\n",
      "train reg_fs: 0.001864536083303392\n",
      "Optimization Finished!\n",
      "test loss: 0.0062276325188577175, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0036272187658251773\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015844811 valid loss= 0.012012288\n",
      "train reg_fs: 0.004600557964295149\n",
      "Epoch: 1000 train loss=0.010259859 valid loss= 0.011731470\n",
      "train reg_fs: 0.004651650320738554\n",
      "Epoch: 1500 train loss=0.015357646 valid loss= 0.010530260\n",
      "train reg_fs: 0.004659496247768402\n",
      "Epoch: 2000 train loss=0.018030867 valid loss= 0.010830977\n",
      "train reg_fs: 0.0046348050236701965\n",
      "Epoch: 2500 train loss=0.008622728 valid loss= 0.010786507\n",
      "train reg_fs: 0.004585475195199251\n",
      "Epoch: 3000 train loss=0.009051530 valid loss= 0.010463469\n",
      "train reg_fs: 0.004523333627730608\n",
      "Epoch: 3500 train loss=0.008240494 valid loss= 0.010072388\n",
      "train reg_fs: 0.004468276631087065\n",
      "Epoch: 4000 train loss=0.010399444 valid loss= 0.009709019\n",
      "train reg_fs: 0.004428252577781677\n",
      "Epoch: 4500 train loss=0.008296624 valid loss= 0.009598126\n",
      "train reg_fs: 0.004397216718643904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:11:59,498]\u001b[0m Trial 24 finished with value: 0.005003593962504257 and parameters: {'lam': 0.00538593117194611, 'learning_rate': 0.03410064844356774, 'num_epoch': 5000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.009614991 valid loss= 0.009524926\n",
      "train reg_fs: 0.004368710331618786\n",
      "Optimization Finished!\n",
      "test loss: 0.01044523436576128, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005003593962504257\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013124517 valid loss= 0.008803839\n",
      "train reg_fs: 0.002944299718365073\n",
      "Epoch: 1000 train loss=0.009057554 valid loss= 0.008919485\n",
      "train reg_fs: 0.002958229510113597\n",
      "Epoch: 1500 train loss=0.010753468 valid loss= 0.007683450\n",
      "train reg_fs: 0.0029175938107073307\n",
      "Epoch: 2000 train loss=0.006593550 valid loss= 0.005949539\n",
      "train reg_fs: 0.0028285617008805275\n",
      "Epoch: 2500 train loss=0.016728353 valid loss= 0.004888595\n",
      "train reg_fs: 0.002752828411757946\n",
      "Epoch: 3000 train loss=0.006163519 valid loss= 0.004708914\n",
      "train reg_fs: 0.00270373048260808\n",
      "Epoch: 3500 train loss=0.006567717 valid loss= 0.004751483\n",
      "train reg_fs: 0.0026755118742585182\n",
      "Epoch: 4000 train loss=0.006942899 valid loss= 0.004593614\n",
      "train reg_fs: 0.0026551431510597467\n",
      "Epoch: 4500 train loss=0.007792169 valid loss= 0.004745628\n",
      "train reg_fs: 0.0026387774851173162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:12:32,197]\u001b[0m Trial 25 finished with value: 0.0024021331337097324 and parameters: {'lam': 0.0034304088774343576, 'learning_rate': 0.05213584791911926, 'num_epoch': 5000}. Best is trial 14 with value: 0.001188616769500771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005838534 valid loss= 0.005033510\n",
      "train reg_fs: 0.002618942176923156\n",
      "Optimization Finished!\n",
      "test loss: 0.00509724672883749, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024021331337097324\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.004266099 valid loss= 0.007019786\n",
      "train reg_fs: 0.001693676458671689\n",
      "Epoch: 1000 train loss=0.012015077 valid loss= 0.006495256\n",
      "train reg_fs: 0.001697532250545919\n",
      "Epoch: 1500 train loss=0.004354533 valid loss= 0.004816311\n",
      "train reg_fs: 0.0016677096718922257\n",
      "Epoch: 2000 train loss=0.003929530 valid loss= 0.003767209\n",
      "train reg_fs: 0.0016025814693421125\n",
      "Epoch: 2500 train loss=0.004385422 valid loss= 0.003683853\n",
      "train reg_fs: 0.0015546012436971068\n",
      "Epoch: 3000 train loss=0.003658772 valid loss= 0.003456912\n",
      "train reg_fs: 0.001530520268715918\n",
      "Epoch: 3500 train loss=0.002601824 valid loss= 0.003154321\n",
      "train reg_fs: 0.0015193740837275982\n",
      "Epoch: 4000 train loss=0.002740370 valid loss= 0.003149803\n",
      "train reg_fs: 0.0015072324313223362\n",
      "Epoch: 4500 train loss=0.002228038 valid loss= 0.003099913\n",
      "train reg_fs: 0.0014916674699634314\n",
      "Epoch: 5000 train loss=0.003172860 valid loss= 0.003211635\n",
      "train reg_fs: 0.0014755588490515947\n",
      "Epoch: 5500 train loss=0.002645645 valid loss= 0.003472586\n",
      "train reg_fs: 0.0014589241473004222\n",
      "Epoch: 6000 train loss=0.003645657 valid loss= 0.002535392\n",
      "train reg_fs: 0.0014447823632508516\n",
      "Epoch: 6500 train loss=0.003486251 valid loss= 0.003683852\n",
      "train reg_fs: 0.0014334411825984716\n",
      "Epoch: 7000 train loss=0.002627939 valid loss= 0.002731215\n",
      "train reg_fs: 0.001421803142875433\n",
      "Epoch: 7500 train loss=0.001856147 valid loss= 0.003146171\n",
      "train reg_fs: 0.0014111670898273587\n",
      "Epoch: 8000 train loss=0.002026060 valid loss= 0.002497988\n",
      "train reg_fs: 0.0014010157901793718\n",
      "Epoch: 8500 train loss=0.002637479 valid loss= 0.002710161\n",
      "train reg_fs: 0.0013921388890594244\n",
      "Epoch: 9000 train loss=0.003378236 valid loss= 0.002452837\n",
      "train reg_fs: 0.0013826804934069514\n",
      "Epoch: 9500 train loss=0.002558144 valid loss= 0.002728226\n",
      "train reg_fs: 0.0013732485240325332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:13:36,778]\u001b[0m Trial 26 finished with value: 0.0006745461816707725 and parameters: {'lam': 0.0019449916576878288, 'learning_rate': 0.07866666396967235, 'num_epoch': 10000}. Best is trial 26 with value: 0.0006745461816707725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003342878 valid loss= 0.002040559\n",
      "train reg_fs: 0.0013651641784235835\n",
      "Optimization Finished!\n",
      "test loss: 0.002066231332719326, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0006745461816707725\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005544310 valid loss= 0.009696436\n",
      "train reg_fs: 0.0013492375146597624\n",
      "Epoch: 1000 train loss=0.007509800 valid loss= 0.010682594\n",
      "train reg_fs: 0.0013719265116378665\n",
      "Epoch: 1500 train loss=0.015441741 valid loss= 0.009948931\n",
      "train reg_fs: 0.0013768760254606605\n",
      "Epoch: 2000 train loss=0.002845099 valid loss= 0.009759213\n",
      "train reg_fs: 0.0013666157610714436\n",
      "Epoch: 2500 train loss=0.005012725 valid loss= 0.008599310\n",
      "train reg_fs: 0.0013559878570958972\n",
      "Epoch: 3000 train loss=0.008575100 valid loss= 0.007291116\n",
      "train reg_fs: 0.0013438338646665215\n",
      "Epoch: 3500 train loss=0.005026872 valid loss= 0.007259096\n",
      "train reg_fs: 0.0013321861624717712\n",
      "Epoch: 4000 train loss=0.003646497 valid loss= 0.007130435\n",
      "train reg_fs: 0.001320402603596449\n",
      "Epoch: 4500 train loss=0.002343023 valid loss= 0.007033812\n",
      "train reg_fs: 0.0013070227578282356\n",
      "Epoch: 5000 train loss=0.001743766 valid loss= 0.007169518\n",
      "train reg_fs: 0.001302863471210003\n",
      "Epoch: 5500 train loss=0.005882932 valid loss= 0.006564005\n",
      "train reg_fs: 0.0012944695772603154\n",
      "Epoch: 6000 train loss=0.003366805 valid loss= 0.007116108\n",
      "train reg_fs: 0.0012917265994474292\n",
      "Epoch: 6500 train loss=0.002488277 valid loss= 0.007271860\n",
      "train reg_fs: 0.0012833094224333763\n",
      "Epoch: 7000 train loss=0.002515631 valid loss= 0.006880431\n",
      "train reg_fs: 0.0012790950713679194\n",
      "Epoch: 7500 train loss=0.004326289 valid loss= 0.006707535\n",
      "train reg_fs: 0.0012776709627360106\n",
      "Epoch: 8000 train loss=0.002634453 valid loss= 0.007143926\n",
      "train reg_fs: 0.0012739860685542226\n",
      "Epoch: 8500 train loss=0.001974545 valid loss= 0.007033249\n",
      "train reg_fs: 0.0012696837075054646\n",
      "Epoch: 9000 train loss=0.003402614 valid loss= 0.006737500\n",
      "train reg_fs: 0.0012665498070418835\n",
      "Epoch: 9500 train loss=0.002857167 valid loss= 0.006876189\n",
      "train reg_fs: 0.0012616063468158245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:14:42,188]\u001b[0m Trial 27 finished with value: 0.005910972438178386 and parameters: {'lam': 0.0015262404354758007, 'learning_rate': 0.10672541011796992, 'num_epoch': 10000}. Best is trial 26 with value: 0.0006745461816707725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002824639 valid loss= 0.007169116\n",
      "train reg_fs: 0.0012587725650519133\n",
      "Optimization Finished!\n",
      "test loss: 0.007104531396180391, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005910972438178386\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014651923 valid loss= 0.007695902\n",
      "train reg_fs: 0.0017292950069531798\n",
      "Epoch: 1000 train loss=0.007524122 valid loss= 0.007926806\n",
      "train reg_fs: 0.0017292068805545568\n",
      "Epoch: 1500 train loss=0.025128139 valid loss= 0.007277033\n",
      "train reg_fs: 0.0016821300378069282\n",
      "Epoch: 2000 train loss=0.012005463 valid loss= 0.005676273\n",
      "train reg_fs: 0.0016102420631796122\n",
      "Epoch: 2500 train loss=0.012378341 valid loss= 0.004719577\n",
      "train reg_fs: 0.0015360171673819423\n",
      "Epoch: 3000 train loss=0.007414886 valid loss= 0.004771720\n",
      "train reg_fs: 0.0014677363215014338\n",
      "Epoch: 3500 train loss=0.011207625 valid loss= 0.004471472\n",
      "train reg_fs: 0.0014252051478251815\n",
      "Epoch: 4000 train loss=0.002819125 valid loss= 0.003872277\n",
      "train reg_fs: 0.0013944476377218962\n",
      "Epoch: 4500 train loss=0.001915444 valid loss= 0.003893085\n",
      "train reg_fs: 0.0013704083394259214\n",
      "Epoch: 5000 train loss=0.008176295 valid loss= 0.003643790\n",
      "train reg_fs: 0.0013522322988137603\n",
      "Epoch: 5500 train loss=0.002619903 valid loss= 0.003703579\n",
      "train reg_fs: 0.001337848836556077\n",
      "Epoch: 6000 train loss=0.002649726 valid loss= 0.004057021\n",
      "train reg_fs: 0.0013269118499010801\n",
      "Epoch: 6500 train loss=0.003263648 valid loss= 0.003800303\n",
      "train reg_fs: 0.0013178687077015638\n",
      "Epoch: 7000 train loss=0.005003881 valid loss= 0.003626778\n",
      "train reg_fs: 0.0013104529352858663\n",
      "Epoch: 7500 train loss=0.004804638 valid loss= 0.003431044\n",
      "train reg_fs: 0.0013036710442975163\n",
      "Epoch: 8000 train loss=0.003134166 valid loss= 0.003556129\n",
      "train reg_fs: 0.0012977462029084563\n",
      "Epoch: 8500 train loss=0.003214902 valid loss= 0.003481677\n",
      "train reg_fs: 0.0012919931905344129\n",
      "Epoch: 9000 train loss=0.001861645 valid loss= 0.003483232\n",
      "train reg_fs: 0.0012865373864769936\n",
      "Epoch: 9500 train loss=0.002010503 valid loss= 0.003881848\n",
      "train reg_fs: 0.0012807677267119288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:15:47,475]\u001b[0m Trial 28 finished with value: 0.002159538023417602 and parameters: {'lam': 0.001990421245133048, 'learning_rate': 0.07584735005342888, 'num_epoch': 10000}. Best is trial 26 with value: 0.0006745461816707725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004087347 valid loss= 0.003428352\n",
      "train reg_fs: 0.0012756837531924248\n",
      "Optimization Finished!\n",
      "test loss: 0.0032548897434026003, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002159538023417602\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011785040 valid loss= 0.007060242\n",
      "train reg_fs: 0.0011046759318560362\n",
      "Epoch: 1000 train loss=0.010638321 valid loss= 0.006740153\n",
      "train reg_fs: 0.001025951118208468\n",
      "Epoch: 1500 train loss=0.005399238 valid loss= 0.003454989\n",
      "train reg_fs: 0.0009565131622366607\n",
      "Epoch: 2000 train loss=0.001627659 valid loss= 0.003686523\n",
      "train reg_fs: 0.0009043345344252884\n",
      "Epoch: 2500 train loss=0.002314718 valid loss= 0.003592587\n",
      "train reg_fs: 0.0008764466037973762\n",
      "Epoch: 3000 train loss=0.003800895 valid loss= 0.003528456\n",
      "train reg_fs: 0.0008555164677090943\n",
      "Epoch: 3500 train loss=0.003509258 valid loss= 0.003391838\n",
      "train reg_fs: 0.000840651395265013\n",
      "Epoch: 4000 train loss=0.001354981 valid loss= 0.003533178\n",
      "train reg_fs: 0.000828241347335279\n",
      "Epoch: 4500 train loss=0.001474451 valid loss= 0.003128362\n",
      "train reg_fs: 0.0008198584546335042\n",
      "Epoch: 5000 train loss=0.007643491 valid loss= 0.003141676\n",
      "train reg_fs: 0.0008130925125442445\n",
      "Epoch: 5500 train loss=0.002066935 valid loss= 0.002954870\n",
      "train reg_fs: 0.0008076695958152413\n",
      "Epoch: 6000 train loss=0.001147104 valid loss= 0.003405782\n",
      "train reg_fs: 0.0008027387084439397\n",
      "Epoch: 6500 train loss=0.000969511 valid loss= 0.003197759\n",
      "train reg_fs: 0.0007987552089616656\n",
      "Epoch: 7000 train loss=0.001020579 valid loss= 0.003199028\n",
      "train reg_fs: 0.0007952552405185997\n",
      "Epoch: 7500 train loss=0.003686902 valid loss= 0.003000470\n",
      "train reg_fs: 0.0007920560892671347\n",
      "Epoch: 8000 train loss=0.007566088 valid loss= 0.003287597\n",
      "train reg_fs: 0.0007895156741142273\n",
      "Epoch: 8500 train loss=0.001704150 valid loss= 0.003375500\n",
      "train reg_fs: 0.0007869470282457769\n",
      "Epoch: 9000 train loss=0.001286560 valid loss= 0.002978844\n",
      "train reg_fs: 0.00078490877058357\n",
      "Epoch: 9500 train loss=0.001261662 valid loss= 0.003068297\n",
      "train reg_fs: 0.0007829006062820554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:16:53,060]\u001b[0m Trial 29 finished with value: 0.0021679565928964697 and parameters: {'lam': 0.001272519705796952, 'learning_rate': 0.13931442917468548, 'num_epoch': 10000}. Best is trial 26 with value: 0.0006745461816707725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.008541444 valid loss= 0.002934535\n",
      "train reg_fs: 0.0007809972739778459\n",
      "Optimization Finished!\n",
      "test loss: 0.00266641890630126, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021679565928964697\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007430590 valid loss= 0.005460948\n",
      "train reg_fs: 0.0020025945268571377\n",
      "Epoch: 1000 train loss=0.005356774 valid loss= 0.004230347\n",
      "train reg_fs: 0.0018869941122829914\n",
      "Epoch: 1500 train loss=0.005137145 valid loss= 0.004048112\n",
      "train reg_fs: 0.0018951265374198556\n",
      "Epoch: 2000 train loss=0.005984245 valid loss= 0.003978043\n",
      "train reg_fs: 0.0018995094578713179\n",
      "Epoch: 2500 train loss=0.007123418 valid loss= 0.003718360\n",
      "train reg_fs: 0.0018598816823214293\n",
      "Epoch: 3000 train loss=0.004760937 valid loss= 0.003672269\n",
      "train reg_fs: 0.0018197515746578574\n",
      "Epoch: 3500 train loss=0.002842937 valid loss= 0.003747882\n",
      "train reg_fs: 0.0017840982181951404\n",
      "Epoch: 4000 train loss=0.007211634 valid loss= 0.003380847\n",
      "train reg_fs: 0.0017516387160867453\n",
      "Epoch: 4500 train loss=0.004717706 valid loss= 0.002206992\n",
      "train reg_fs: 0.0017211466329172254\n",
      "Epoch: 5000 train loss=0.005210866 valid loss= 0.003040325\n",
      "train reg_fs: 0.001699006650596857\n",
      "Epoch: 5500 train loss=0.002923192 valid loss= 0.002134079\n",
      "train reg_fs: 0.0016849106177687645\n",
      "Epoch: 6000 train loss=0.003009095 valid loss= 0.002598593\n",
      "train reg_fs: 0.0016759431455284357\n",
      "Epoch: 6500 train loss=0.006560622 valid loss= 0.002458512\n",
      "train reg_fs: 0.0016697411192581058\n",
      "Epoch: 7000 train loss=0.002050200 valid loss= 0.002673424\n",
      "train reg_fs: 0.0016649269964545965\n",
      "Epoch: 7500 train loss=0.002010045 valid loss= 0.002037804\n",
      "train reg_fs: 0.0016608313890174031\n",
      "Epoch: 8000 train loss=0.002067087 valid loss= 0.002085996\n",
      "train reg_fs: 0.0016579489456489682\n",
      "Epoch: 8500 train loss=0.004354985 valid loss= 0.002894884\n",
      "train reg_fs: 0.0016555554466322064\n",
      "Epoch: 9000 train loss=0.006422615 valid loss= 0.002316282\n",
      "train reg_fs: 0.0016534830210730433\n",
      "Epoch: 9500 train loss=0.002807674 valid loss= 0.002070279\n",
      "train reg_fs: 0.0016519009368494153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:17:57,573]\u001b[0m Trial 30 finished with value: 0.0002134432171233013 and parameters: {'lam': 0.0024685863565374637, 'learning_rate': 0.193657897430231, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005103269 valid loss= 0.001868310\n",
      "train reg_fs: 0.001650455640628934\n",
      "Optimization Finished!\n",
      "test loss: 0.0018434560624882579, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0002134432171233013\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008605832 valid loss= 0.004828142\n",
      "train reg_fs: 0.0020310322288423777\n",
      "Epoch: 1000 train loss=0.007960472 valid loss= 0.003882405\n",
      "train reg_fs: 0.0019384486367926002\n",
      "Epoch: 1500 train loss=0.006055747 valid loss= 0.005116914\n",
      "train reg_fs: 0.001898464048281312\n",
      "Epoch: 2000 train loss=0.003443348 valid loss= 0.003895642\n",
      "train reg_fs: 0.0018088648794218898\n",
      "Epoch: 2500 train loss=0.002413750 valid loss= 0.003751592\n",
      "train reg_fs: 0.0017238208092749119\n",
      "Epoch: 3000 train loss=0.001970413 valid loss= 0.003803459\n",
      "train reg_fs: 0.0016587298596277833\n",
      "Epoch: 3500 train loss=0.007885987 valid loss= 0.003139106\n",
      "train reg_fs: 0.0016134449979290366\n",
      "Epoch: 4000 train loss=0.002415489 valid loss= 0.002857988\n",
      "train reg_fs: 0.0015746090793982148\n",
      "Epoch: 4500 train loss=0.005827097 valid loss= 0.002813484\n",
      "train reg_fs: 0.0015518952859565616\n",
      "Epoch: 5000 train loss=0.004047442 valid loss= 0.002982010\n",
      "train reg_fs: 0.0015367475571110845\n",
      "Epoch: 5500 train loss=0.002024259 valid loss= 0.002780449\n",
      "train reg_fs: 0.0015236540930345654\n",
      "Epoch: 6000 train loss=0.002574116 valid loss= 0.002701278\n",
      "train reg_fs: 0.0015138470334932208\n",
      "Epoch: 6500 train loss=0.002377039 valid loss= 0.003225507\n",
      "train reg_fs: 0.0015067554777488112\n",
      "Epoch: 7000 train loss=0.002514953 valid loss= 0.003244995\n",
      "train reg_fs: 0.001500721788033843\n",
      "Epoch: 7500 train loss=0.003597479 valid loss= 0.003625367\n",
      "train reg_fs: 0.0014961474807932973\n",
      "Epoch: 8000 train loss=0.001832064 valid loss= 0.003311221\n",
      "train reg_fs: 0.0014921013498678803\n",
      "Epoch: 8500 train loss=0.001940533 valid loss= 0.003005721\n",
      "train reg_fs: 0.0014889533631503582\n",
      "Epoch: 9000 train loss=0.002981859 valid loss= 0.002881613\n",
      "train reg_fs: 0.0014864581171423197\n",
      "Epoch: 9500 train loss=0.002046592 valid loss= 0.002694003\n",
      "train reg_fs: 0.001484242849983275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:19:02,109]\u001b[0m Trial 31 finished with value: 0.0020719246357879793 and parameters: {'lam': 0.0025937439488026397, 'learning_rate': 0.19489776372641568, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003708189 valid loss= 0.003609676\n",
      "train reg_fs: 0.0014820537762716413\n",
      "Optimization Finished!\n",
      "test loss: 0.003294999711215496, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020719246357879793\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012876363 valid loss= 0.008365447\n",
      "train reg_fs: 0.0018380448454990983\n",
      "Epoch: 1000 train loss=0.009593061 valid loss= 0.006949042\n",
      "train reg_fs: 0.0018240202916786075\n",
      "Epoch: 1500 train loss=0.005369532 valid loss= 0.005488590\n",
      "train reg_fs: 0.0017422408564016223\n",
      "Epoch: 2000 train loss=0.011407868 valid loss= 0.004117955\n",
      "train reg_fs: 0.00165398302488029\n",
      "Epoch: 2500 train loss=0.002230772 valid loss= 0.003753744\n",
      "train reg_fs: 0.0016048519173637033\n",
      "Epoch: 3000 train loss=0.002423815 valid loss= 0.003703860\n",
      "train reg_fs: 0.0015775137580931187\n",
      "Epoch: 3500 train loss=0.003608292 valid loss= 0.004077112\n",
      "train reg_fs: 0.0015617705648764968\n",
      "Epoch: 4000 train loss=0.002323671 valid loss= 0.003659147\n",
      "train reg_fs: 0.0015490595251321793\n",
      "Epoch: 4500 train loss=0.002795879 valid loss= 0.004067195\n",
      "train reg_fs: 0.0015400690026581287\n",
      "Epoch: 5000 train loss=0.003103632 valid loss= 0.004041283\n",
      "train reg_fs: 0.0015323297120630741\n",
      "Epoch: 5500 train loss=0.005958907 valid loss= 0.003324974\n",
      "train reg_fs: 0.0015262013766914606\n",
      "Epoch: 6000 train loss=0.002374108 valid loss= 0.003410985\n",
      "train reg_fs: 0.0015203641960397363\n",
      "Epoch: 6500 train loss=0.004789296 valid loss= 0.003649842\n",
      "train reg_fs: 0.0015162313356995583\n",
      "Epoch: 7000 train loss=0.002186988 valid loss= 0.003505793\n",
      "train reg_fs: 0.00151096994522959\n",
      "Epoch: 7500 train loss=0.003710621 valid loss= 0.003623121\n",
      "train reg_fs: 0.0015070426743477583\n",
      "Epoch: 8000 train loss=0.001940342 valid loss= 0.003693049\n",
      "train reg_fs: 0.0015033356612548232\n",
      "Epoch: 8500 train loss=0.001971169 valid loss= 0.003497570\n",
      "train reg_fs: 0.0014990214258432388\n",
      "Epoch: 9000 train loss=0.002532060 valid loss= 0.003650404\n",
      "train reg_fs: 0.0014954361831769347\n",
      "Epoch: 9500 train loss=0.003616592 valid loss= 0.003676053\n",
      "train reg_fs: 0.001491860835812986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:20:06,805]\u001b[0m Trial 32 finished with value: 0.0022223181711035498 and parameters: {'lam': 0.0020833702870507293, 'learning_rate': 0.09386005180030577, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002181139 valid loss= 0.003656656\n",
      "train reg_fs: 0.0014892861945554614\n",
      "Optimization Finished!\n",
      "test loss: 0.003530337940901518, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022223181711035498\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006841140 valid loss= 0.007221243\n",
      "train reg_fs: 0.0014221847523003817\n",
      "Epoch: 1000 train loss=0.002730464 valid loss= 0.003735989\n",
      "train reg_fs: 0.0012935863342136145\n",
      "Epoch: 1500 train loss=0.011113622 valid loss= 0.003499026\n",
      "train reg_fs: 0.0011875691125169396\n",
      "Epoch: 2000 train loss=0.002457522 valid loss= 0.002904356\n",
      "train reg_fs: 0.0011359105119481683\n",
      "Epoch: 2500 train loss=0.001788347 valid loss= 0.003166740\n",
      "train reg_fs: 0.0011036331998184323\n",
      "Epoch: 3000 train loss=0.005890706 valid loss= 0.003677809\n",
      "train reg_fs: 0.001083010109141469\n",
      "Epoch: 3500 train loss=0.005837262 valid loss= 0.002729636\n",
      "train reg_fs: 0.0010645209113135934\n",
      "Epoch: 4000 train loss=0.006702764 valid loss= 0.002538377\n",
      "train reg_fs: 0.0010522198863327503\n",
      "Epoch: 4500 train loss=0.001487856 valid loss= 0.003189345\n",
      "train reg_fs: 0.0010407038498669863\n",
      "Epoch: 5000 train loss=0.002002912 valid loss= 0.003102797\n",
      "train reg_fs: 0.0010309107601642609\n",
      "Epoch: 5500 train loss=0.003020145 valid loss= 0.003063017\n",
      "train reg_fs: 0.0010230568004772067\n",
      "Epoch: 6000 train loss=0.001793691 valid loss= 0.003015568\n",
      "train reg_fs: 0.0010171239264309406\n",
      "Epoch: 6500 train loss=0.001578755 valid loss= 0.002562955\n",
      "train reg_fs: 0.001011862768791616\n",
      "Epoch: 7000 train loss=0.002958758 valid loss= 0.002386693\n",
      "train reg_fs: 0.0010075970785692334\n",
      "Epoch: 7500 train loss=0.001858337 valid loss= 0.003347027\n",
      "train reg_fs: 0.0010035359300673008\n",
      "Epoch: 8000 train loss=0.004445182 valid loss= 0.002584129\n",
      "train reg_fs: 0.0009999937610700727\n",
      "Epoch: 8500 train loss=0.006411040 valid loss= 0.003488887\n",
      "train reg_fs: 0.0009971517138183117\n",
      "Epoch: 9000 train loss=0.003334487 valid loss= 0.002808974\n",
      "train reg_fs: 0.0009945683414116502\n",
      "Epoch: 9500 train loss=0.003694125 valid loss= 0.002691265\n",
      "train reg_fs: 0.0009928795043379068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:21:11,046]\u001b[0m Trial 33 finished with value: 0.0017152836109860768 and parameters: {'lam': 0.0017235689721226282, 'learning_rate': 0.15966082578207982, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002312561 valid loss= 0.002743249\n",
      "train reg_fs: 0.0009911489905789495\n",
      "Optimization Finished!\n",
      "test loss: 0.00246197497472167, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0017152836109860768\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012548186 valid loss= 0.007001974\n",
      "train reg_fs: 0.0021605894435197115\n",
      "Epoch: 1000 train loss=0.011002161 valid loss= 0.005672129\n",
      "train reg_fs: 0.002128933323547244\n",
      "Epoch: 1500 train loss=0.004107314 valid loss= 0.004813101\n",
      "train reg_fs: 0.0020063009578734636\n",
      "Epoch: 2000 train loss=0.003923086 valid loss= 0.004181381\n",
      "train reg_fs: 0.001932943006977439\n",
      "Epoch: 2500 train loss=0.002693622 valid loss= 0.004729390\n",
      "train reg_fs: 0.0018898799316957593\n",
      "Epoch: 3000 train loss=0.003400731 valid loss= 0.004976139\n",
      "train reg_fs: 0.0018585295183584094\n",
      "Epoch: 3500 train loss=0.004509742 valid loss= 0.004400860\n",
      "train reg_fs: 0.0018374781357124448\n",
      "Epoch: 4000 train loss=0.003175678 valid loss= 0.004474850\n",
      "train reg_fs: 0.0018218803452327847\n",
      "Epoch: 4500 train loss=0.003687994 valid loss= 0.004003559\n",
      "train reg_fs: 0.0018095290288329124\n",
      "Epoch: 5000 train loss=0.002794414 valid loss= 0.004132589\n",
      "train reg_fs: 0.0017982403514906764\n",
      "Epoch: 5500 train loss=0.005063821 valid loss= 0.004277443\n",
      "train reg_fs: 0.0017888197908177972\n",
      "Epoch: 6000 train loss=0.004381532 valid loss= 0.004676649\n",
      "train reg_fs: 0.001780965249054134\n",
      "Epoch: 6500 train loss=0.003969046 valid loss= 0.003856556\n",
      "train reg_fs: 0.0017731700791046023\n",
      "Epoch: 7000 train loss=0.004602702 valid loss= 0.004151488\n",
      "train reg_fs: 0.0017666226485744119\n",
      "Epoch: 7500 train loss=0.002139501 valid loss= 0.004336968\n",
      "train reg_fs: 0.0017606880282983184\n",
      "Epoch: 8000 train loss=0.002792607 valid loss= 0.004410579\n",
      "train reg_fs: 0.0017557726241648197\n",
      "Epoch: 8500 train loss=0.005517785 valid loss= 0.004093642\n",
      "train reg_fs: 0.0017517019296064973\n",
      "Epoch: 9000 train loss=0.003389199 valid loss= 0.003866249\n",
      "train reg_fs: 0.0017475523054599762\n",
      "Epoch: 9500 train loss=0.003413465 valid loss= 0.003811218\n",
      "train reg_fs: 0.0017444960540160537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:22:16,900]\u001b[0m Trial 34 finished with value: 0.0020212142170850916 and parameters: {'lam': 0.002451009822183381, 'learning_rate': 0.1301292409283617, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002155369 valid loss= 0.003687591\n",
      "train reg_fs: 0.0017418481875211\n",
      "Optimization Finished!\n",
      "test loss: 0.0036297417245805264, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020212142170850916\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010556499 valid loss= 0.009231534\n",
      "train reg_fs: 0.002883919980376959\n",
      "Epoch: 1000 train loss=0.004393409 valid loss= 0.006799178\n",
      "train reg_fs: 0.0027771724853664637\n",
      "Epoch: 1500 train loss=0.008294749 valid loss= 0.006702321\n",
      "train reg_fs: 0.002615875331684947\n",
      "Epoch: 2000 train loss=0.013586630 valid loss= 0.005025886\n",
      "train reg_fs: 0.0025058025494217873\n",
      "Epoch: 2500 train loss=0.004611942 valid loss= 0.004357689\n",
      "train reg_fs: 0.0024256433825939894\n",
      "Epoch: 3000 train loss=0.003378294 valid loss= 0.004655120\n",
      "train reg_fs: 0.002363797975704074\n",
      "Epoch: 3500 train loss=0.005990828 valid loss= 0.003663907\n",
      "train reg_fs: 0.0023022876121103764\n",
      "Epoch: 4000 train loss=0.010278459 valid loss= 0.004427697\n",
      "train reg_fs: 0.0022435372229665518\n",
      "Epoch: 4500 train loss=0.003377265 valid loss= 0.003786996\n",
      "train reg_fs: 0.0021934816613793373\n",
      "Epoch: 5000 train loss=0.002809148 valid loss= 0.003897620\n",
      "train reg_fs: 0.002154434798285365\n",
      "Epoch: 5500 train loss=0.002817685 valid loss= 0.004433009\n",
      "train reg_fs: 0.00212292093783617\n",
      "Epoch: 6000 train loss=0.004674743 valid loss= 0.003575927\n",
      "train reg_fs: 0.0020987766329199076\n",
      "Epoch: 6500 train loss=0.016901894 valid loss= 0.004134892\n",
      "train reg_fs: 0.0020785017404705286\n",
      "Epoch: 7000 train loss=0.003616218 valid loss= 0.004112392\n",
      "train reg_fs: 0.0020623651798814535\n",
      "Epoch: 7500 train loss=0.004864054 valid loss= 0.004322845\n",
      "train reg_fs: 0.0020490745082497597\n",
      "Epoch: 8000 train loss=0.002233752 valid loss= 0.004314682\n",
      "train reg_fs: 0.0020386814139783382\n",
      "Epoch: 8500 train loss=0.004859110 valid loss= 0.004363540\n",
      "train reg_fs: 0.0020292566623538733\n",
      "Epoch: 9000 train loss=0.003212449 valid loss= 0.003659790\n",
      "train reg_fs: 0.002021180000156164\n",
      "Epoch: 9500 train loss=0.005995365 valid loss= 0.003545719\n",
      "train reg_fs: 0.0020144882146269083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:23:22,443]\u001b[0m Trial 35 finished with value: 0.0015309082259185706 and parameters: {'lam': 0.0034283163806037953, 'learning_rate': 0.06470310652235625, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.009299476 valid loss= 0.003618942\n",
      "train reg_fs: 0.0020085058640688658\n",
      "Optimization Finished!\n",
      "test loss: 0.0033952118828892708, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0015309082259185706\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016332770 valid loss= 0.009941706\n",
      "train reg_fs: 0.0030060529243201017\n",
      "Epoch: 1000 train loss=0.020734435 valid loss= 0.009622674\n",
      "train reg_fs: 0.003030085703358054\n",
      "Epoch: 1500 train loss=0.020303149 valid loss= 0.009149132\n",
      "train reg_fs: 0.003047682112082839\n",
      "Epoch: 2000 train loss=0.015450285 valid loss= 0.009131026\n",
      "train reg_fs: 0.0030600985046476126\n",
      "Epoch: 2500 train loss=0.022283874 valid loss= 0.009653269\n",
      "train reg_fs: 0.0030660720076411963\n",
      "Epoch: 3000 train loss=0.014610697 valid loss= 0.008414036\n",
      "train reg_fs: 0.0030665488447993994\n",
      "Epoch: 3500 train loss=0.009974448 valid loss= 0.008590083\n",
      "train reg_fs: 0.0030661174096167088\n",
      "Epoch: 4000 train loss=0.009541820 valid loss= 0.008691750\n",
      "train reg_fs: 0.003062720410525799\n",
      "Epoch: 4500 train loss=0.008251838 valid loss= 0.008664732\n",
      "train reg_fs: 0.003057560184970498\n",
      "Epoch: 5000 train loss=0.012735769 valid loss= 0.008274727\n",
      "train reg_fs: 0.0030511412769556046\n",
      "Epoch: 5500 train loss=0.015388832 valid loss= 0.008608510\n",
      "train reg_fs: 0.003039725124835968\n",
      "Epoch: 6000 train loss=0.014191521 valid loss= 0.007870750\n",
      "train reg_fs: 0.003026155987754464\n",
      "Epoch: 6500 train loss=0.006427990 valid loss= 0.007441306\n",
      "train reg_fs: 0.003012624802067876\n",
      "Epoch: 7000 train loss=0.005829742 valid loss= 0.008266374\n",
      "train reg_fs: 0.0029960554093122482\n",
      "Epoch: 7500 train loss=0.015255054 valid loss= 0.008270970\n",
      "train reg_fs: 0.0029753621201962233\n",
      "Epoch: 8000 train loss=0.004944900 valid loss= 0.007827638\n",
      "train reg_fs: 0.002955110976472497\n",
      "Epoch: 8500 train loss=0.008792250 valid loss= 0.007056109\n",
      "train reg_fs: 0.0029327606316655874\n",
      "Epoch: 9000 train loss=0.007297754 valid loss= 0.007351968\n",
      "train reg_fs: 0.0029099357780069113\n",
      "Epoch: 9500 train loss=0.004918142 valid loss= 0.007079271\n",
      "train reg_fs: 0.002887775655835867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:24:26,694]\u001b[0m Trial 36 finished with value: 0.003711658530712974 and parameters: {'lam': 0.0035450317824794976, 'learning_rate': 0.018298450468566187, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006182957 valid loss= 0.006663979\n",
      "train reg_fs: 0.0028660933021456003\n",
      "Optimization Finished!\n",
      "test loss: 0.006913820281624794, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003711658530712974\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012193127 valid loss= 0.009089615\n",
      "train reg_fs: 0.0025966078974306583\n",
      "Epoch: 1000 train loss=0.013847574 valid loss= 0.009112149\n",
      "train reg_fs: 0.002616151934489608\n",
      "Epoch: 1500 train loss=0.007674354 valid loss= 0.008692231\n",
      "train reg_fs: 0.0025764284655451775\n",
      "Epoch: 2000 train loss=0.007474994 valid loss= 0.008435699\n",
      "train reg_fs: 0.002531834179535508\n",
      "Epoch: 2500 train loss=0.007262534 valid loss= 0.008221970\n",
      "train reg_fs: 0.002506970427930355\n",
      "Epoch: 3000 train loss=0.005865298 valid loss= 0.007873841\n",
      "train reg_fs: 0.0024833332281559706\n",
      "Epoch: 3500 train loss=0.005681486 valid loss= 0.007067524\n",
      "train reg_fs: 0.002481742762029171\n",
      "Epoch: 4000 train loss=0.007837771 valid loss= 0.006165726\n",
      "train reg_fs: 0.0024782035034149885\n",
      "Epoch: 4500 train loss=0.006781366 valid loss= 0.007240335\n",
      "train reg_fs: 0.002471533138304949\n",
      "Epoch: 5000 train loss=0.005583670 valid loss= 0.006528405\n",
      "train reg_fs: 0.002467090729624033\n",
      "Epoch: 5500 train loss=0.003894424 valid loss= 0.006252673\n",
      "train reg_fs: 0.002457014750689268\n",
      "Epoch: 6000 train loss=0.009596961 valid loss= 0.006523266\n",
      "train reg_fs: 0.0024527530185878277\n",
      "Epoch: 6500 train loss=0.003258815 valid loss= 0.006376942\n",
      "train reg_fs: 0.002446049591526389\n",
      "Epoch: 7000 train loss=0.006081875 valid loss= 0.005886019\n",
      "train reg_fs: 0.0024346583522856236\n",
      "Epoch: 7500 train loss=0.003376032 valid loss= 0.006168578\n",
      "train reg_fs: 0.0024254692252725363\n",
      "Epoch: 8000 train loss=0.004176686 valid loss= 0.005608558\n",
      "train reg_fs: 0.002421159762889147\n",
      "Epoch: 8500 train loss=0.004666628 valid loss= 0.005793257\n",
      "train reg_fs: 0.002411884954199195\n",
      "Epoch: 9000 train loss=0.004544324 valid loss= 0.006273810\n",
      "train reg_fs: 0.002403492573648691\n",
      "Epoch: 9500 train loss=0.004739037 valid loss= 0.005632418\n",
      "train reg_fs: 0.002394347684457898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:25:31,230]\u001b[0m Trial 37 finished with value: 0.0033213457808461766 and parameters: {'lam': 0.0030202215839769094, 'learning_rate': 0.06632943697671811, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005079578 valid loss= 0.005778634\n",
      "train reg_fs: 0.0023830756545066833\n",
      "Optimization Finished!\n",
      "test loss: 0.006696309894323349, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0033213457808461766\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017743815 valid loss= 0.011688619\n",
      "train reg_fs: 0.004144033882766962\n",
      "Epoch: 1000 train loss=0.014253607 valid loss= 0.011753039\n",
      "train reg_fs: 0.004205868113785982\n",
      "Epoch: 1500 train loss=0.020420577 valid loss= 0.011989991\n",
      "train reg_fs: 0.004247493110597134\n",
      "Epoch: 2000 train loss=0.009580506 valid loss= 0.011306642\n",
      "train reg_fs: 0.00425531854853034\n",
      "Epoch: 2500 train loss=0.009800130 valid loss= 0.010836903\n",
      "train reg_fs: 0.0042419941164553165\n",
      "Epoch: 3000 train loss=0.012400685 valid loss= 0.011383572\n",
      "train reg_fs: 0.0042092991061508656\n",
      "Epoch: 3500 train loss=0.008988475 valid loss= 0.010587353\n",
      "train reg_fs: 0.004154536407440901\n",
      "Epoch: 4000 train loss=0.007298134 valid loss= 0.010243610\n",
      "train reg_fs: 0.004098306410014629\n",
      "Epoch: 4500 train loss=0.007062582 valid loss= 0.009208706\n",
      "train reg_fs: 0.00405209232121706\n",
      "Epoch: 5000 train loss=0.008004368 valid loss= 0.008434254\n",
      "train reg_fs: 0.004015929531306028\n",
      "Epoch: 5500 train loss=0.008103522 valid loss= 0.007980699\n",
      "train reg_fs: 0.003981613088399172\n",
      "Epoch: 6000 train loss=0.008816026 valid loss= 0.007816041\n",
      "train reg_fs: 0.003946722950786352\n",
      "Epoch: 6500 train loss=0.008010475 valid loss= 0.007201108\n",
      "train reg_fs: 0.003908492159098387\n",
      "Epoch: 7000 train loss=0.012257270 valid loss= 0.006825566\n",
      "train reg_fs: 0.0038655062671750784\n",
      "Epoch: 7500 train loss=0.005358614 valid loss= 0.006445043\n",
      "train reg_fs: 0.003805976826697588\n",
      "Epoch: 8000 train loss=0.013708111 valid loss= 0.006039103\n",
      "train reg_fs: 0.0037455172277987003\n",
      "Epoch: 8500 train loss=0.006720496 valid loss= 0.006141501\n",
      "train reg_fs: 0.0036865887232124805\n",
      "Epoch: 9000 train loss=0.005408445 valid loss= 0.006159886\n",
      "train reg_fs: 0.0036322446539998055\n",
      "Epoch: 9500 train loss=0.005852622 valid loss= 0.006065279\n",
      "train reg_fs: 0.003588838968425989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:26:36,596]\u001b[0m Trial 38 finished with value: 0.0023762271443690973 and parameters: {'lam': 0.004843226379075207, 'learning_rate': 0.03740975578309739, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005920369 valid loss= 0.005931139\n",
      "train reg_fs: 0.003546284046024084\n",
      "Optimization Finished!\n",
      "test loss: 0.0058810473419725895, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023762271443690973\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019665703 valid loss= 0.009889557\n",
      "train reg_fs: 0.002742936834692955\n",
      "Epoch: 1000 train loss=0.010177383 valid loss= 0.010158983\n",
      "train reg_fs: 0.002779428381472826\n",
      "Epoch: 1500 train loss=0.012080937 valid loss= 0.009144633\n",
      "train reg_fs: 0.0028068057727068663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:26:50,807]\u001b[0m Trial 39 finished with value: 0.006276282935897943 and parameters: {'lam': 0.0032054401485879787, 'learning_rate': 0.027478926188539764, 'num_epoch': 2000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.014413976 valid loss= 0.009100471\n",
      "train reg_fs: 0.0028219781816005707\n",
      "Optimization Finished!\n",
      "test loss: 0.01089069340378046, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006276282935897943\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022069693 valid loss= 0.010765752\n",
      "train reg_fs: 0.003072537714615464\n",
      "Epoch: 1000 train loss=0.015916536 valid loss= 0.010511798\n",
      "train reg_fs: 0.0030992659740149975\n",
      "Epoch: 1500 train loss=0.019652259 valid loss= 0.010288905\n",
      "train reg_fs: 0.003117324085906148\n",
      "Epoch: 2000 train loss=0.014644085 valid loss= 0.010056179\n",
      "train reg_fs: 0.0031291181221604347\n",
      "Epoch: 2500 train loss=0.013997345 valid loss= 0.009850929\n",
      "train reg_fs: 0.003132539102807641\n",
      "Epoch: 3000 train loss=0.014973720 valid loss= 0.009938920\n",
      "train reg_fs: 0.003126552328467369\n",
      "Epoch: 3500 train loss=0.007491608 valid loss= 0.010096632\n",
      "train reg_fs: 0.003114677034318447\n",
      "Epoch: 4000 train loss=0.011934035 valid loss= 0.009904351\n",
      "train reg_fs: 0.003090884769335389\n",
      "Epoch: 4500 train loss=0.008219317 valid loss= 0.010014478\n",
      "train reg_fs: 0.003063589334487915\n",
      "Epoch: 5000 train loss=0.017904127 valid loss= 0.009638301\n",
      "train reg_fs: 0.0030364785343408585\n",
      "Epoch: 5500 train loss=0.009157373 valid loss= 0.009464378\n",
      "train reg_fs: 0.0030092187225818634\n",
      "Epoch: 6000 train loss=0.011702331 valid loss= 0.009200900\n",
      "train reg_fs: 0.0029782908968627453\n",
      "Epoch: 6500 train loss=0.009083405 valid loss= 0.008754809\n",
      "train reg_fs: 0.00294657819904387\n",
      "Epoch: 7000 train loss=0.007432571 valid loss= 0.008780387\n",
      "train reg_fs: 0.0029173928778618574\n",
      "Epoch: 7500 train loss=0.008806429 valid loss= 0.008060366\n",
      "train reg_fs: 0.0028910504188388586\n",
      "Epoch: 8000 train loss=0.014750246 valid loss= 0.007911631\n",
      "train reg_fs: 0.002865287009626627\n",
      "Epoch: 8500 train loss=0.011943046 valid loss= 0.007772918\n",
      "train reg_fs: 0.0028401734307408333\n",
      "Epoch: 9000 train loss=0.011196179 valid loss= 0.007452630\n",
      "train reg_fs: 0.0028133331798017025\n",
      "Epoch: 9500 train loss=0.004375738 valid loss= 0.006870237\n",
      "train reg_fs: 0.0027847783640027046\n",
      "Epoch: 10000 train loss=0.005330521 valid loss= 0.006543576\n",
      "train reg_fs: 0.002757413312792778\n",
      "Epoch: 10500 train loss=0.006998315 valid loss= 0.006091300\n",
      "train reg_fs: 0.0027305088005959988\n",
      "Epoch: 11000 train loss=0.004030922 valid loss= 0.006197272\n",
      "train reg_fs: 0.0027031118515878916\n",
      "Epoch: 11500 train loss=0.005742315 valid loss= 0.005908789\n",
      "train reg_fs: 0.0026774327270686626\n",
      "Epoch: 12000 train loss=0.004596587 valid loss= 0.005914438\n",
      "train reg_fs: 0.0026532241608947515\n",
      "Epoch: 12500 train loss=0.004857686 valid loss= 0.005889639\n",
      "train reg_fs: 0.0026295464485883713\n",
      "Epoch: 13000 train loss=0.007395056 valid loss= 0.005785391\n",
      "train reg_fs: 0.0026055157650262117\n",
      "Epoch: 13500 train loss=0.011178305 valid loss= 0.005831704\n",
      "train reg_fs: 0.002583228750154376\n",
      "Epoch: 14000 train loss=0.005290922 valid loss= 0.005772618\n",
      "train reg_fs: 0.002562581794336438\n",
      "Epoch: 14500 train loss=0.003805996 valid loss= 0.006072101\n",
      "train reg_fs: 0.0025426263455301523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:28:25,204]\u001b[0m Trial 40 finished with value: 0.003117190689295701 and parameters: {'lam': 0.0036300682142920704, 'learning_rate': 0.0204659169975434, 'num_epoch': 15000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007279361 valid loss= 0.005680547\n",
      "train reg_fs: 0.0025241835974156857\n",
      "Optimization Finished!\n",
      "test loss: 0.0054652513936161995, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003117190689295701\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020575529 valid loss= 0.009275195\n",
      "train reg_fs: 0.0018403854919597507\n",
      "Epoch: 1000 train loss=0.007851335 valid loss= 0.009731641\n",
      "train reg_fs: 0.0018757261568680406\n",
      "Epoch: 1500 train loss=0.012683623 valid loss= 0.008996702\n",
      "train reg_fs: 0.0018855726812034845\n",
      "Epoch: 2000 train loss=0.005253036 valid loss= 0.009110361\n",
      "train reg_fs: 0.0018828033935278654\n",
      "Epoch: 2500 train loss=0.005564443 valid loss= 0.007860132\n",
      "train reg_fs: 0.001854537520557642\n",
      "Epoch: 3000 train loss=0.007596067 valid loss= 0.006177348\n",
      "train reg_fs: 0.0018123561749234796\n",
      "Epoch: 3500 train loss=0.004463949 valid loss= 0.004569529\n",
      "train reg_fs: 0.001780243474058807\n",
      "Epoch: 4000 train loss=0.004616096 valid loss= 0.004801963\n",
      "train reg_fs: 0.0017583940643817186\n",
      "Epoch: 4500 train loss=0.003075831 valid loss= 0.004301758\n",
      "train reg_fs: 0.0017343437066301703\n",
      "Epoch: 5000 train loss=0.003123046 valid loss= 0.004108491\n",
      "train reg_fs: 0.0017118798568844795\n",
      "Epoch: 5500 train loss=0.005568081 valid loss= 0.003998986\n",
      "train reg_fs: 0.0016849496169015765\n",
      "Epoch: 6000 train loss=0.003560112 valid loss= 0.003781402\n",
      "train reg_fs: 0.0016602842370048165\n",
      "Epoch: 6500 train loss=0.004538839 valid loss= 0.003671246\n",
      "train reg_fs: 0.0016393103869631886\n",
      "Epoch: 7000 train loss=0.002597490 valid loss= 0.004140561\n",
      "train reg_fs: 0.0016203041886910796\n",
      "Epoch: 7500 train loss=0.004639541 valid loss= 0.003753835\n",
      "train reg_fs: 0.0016072592698037624\n",
      "Epoch: 8000 train loss=0.003107707 valid loss= 0.003840345\n",
      "train reg_fs: 0.0015960094751790166\n",
      "Epoch: 8500 train loss=0.002722299 valid loss= 0.003857116\n",
      "train reg_fs: 0.0015829484909772873\n",
      "Epoch: 9000 train loss=0.003369556 valid loss= 0.003835033\n",
      "train reg_fs: 0.001572839799337089\n",
      "Epoch: 9500 train loss=0.004699605 valid loss= 0.003892760\n",
      "train reg_fs: 0.0015630788402631879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:29:29,092]\u001b[0m Trial 41 finished with value: 0.0022582786771874054 and parameters: {'lam': 0.002086592821317462, 'learning_rate': 0.08782229550026326, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002935400 valid loss= 0.003820160\n",
      "train reg_fs: 0.0015561204636469483\n",
      "Optimization Finished!\n",
      "test loss: 0.003829175839200616, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022582786771874054\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020132862 valid loss= 0.010645255\n",
      "train reg_fs: 0.002326102927327156\n",
      "Epoch: 1000 train loss=0.009581395 valid loss= 0.009675378\n",
      "train reg_fs: 0.002337951213121414\n",
      "Epoch: 1500 train loss=0.006964630 valid loss= 0.008775724\n",
      "train reg_fs: 0.0022852078545838594\n",
      "Epoch: 2000 train loss=0.012685773 valid loss= 0.007910625\n",
      "train reg_fs: 0.0022430780809372663\n",
      "Epoch: 2500 train loss=0.010002911 valid loss= 0.007348682\n",
      "train reg_fs: 0.002216341206803918\n",
      "Epoch: 3000 train loss=0.006440091 valid loss= 0.006265490\n",
      "train reg_fs: 0.002191645558923483\n",
      "Epoch: 3500 train loss=0.007953492 valid loss= 0.005704658\n",
      "train reg_fs: 0.002155319321900606\n",
      "Epoch: 4000 train loss=0.005102885 valid loss= 0.005042414\n",
      "train reg_fs: 0.0021088074427098036\n",
      "Epoch: 4500 train loss=0.007918147 valid loss= 0.004990559\n",
      "train reg_fs: 0.0020744851790368557\n",
      "Epoch: 5000 train loss=0.005722486 valid loss= 0.005195998\n",
      "train reg_fs: 0.002053840085864067\n",
      "Epoch: 5500 train loss=0.007080112 valid loss= 0.005301843\n",
      "train reg_fs: 0.0020451105665415525\n",
      "Epoch: 6000 train loss=0.003066335 valid loss= 0.005451321\n",
      "train reg_fs: 0.0020350206177681684\n",
      "Epoch: 6500 train loss=0.005526789 valid loss= 0.005245278\n",
      "train reg_fs: 0.0020284736528992653\n",
      "Epoch: 7000 train loss=0.006419950 valid loss= 0.005373122\n",
      "train reg_fs: 0.0020202314481139183\n",
      "Epoch: 7500 train loss=0.003094987 valid loss= 0.005354615\n",
      "train reg_fs: 0.0020113522186875343\n",
      "Epoch: 8000 train loss=0.004889179 valid loss= 0.005145398\n",
      "train reg_fs: 0.0019998354837298393\n",
      "Epoch: 8500 train loss=0.005899180 valid loss= 0.005154874\n",
      "train reg_fs: 0.001988145988434553\n",
      "Epoch: 9000 train loss=0.004381817 valid loss= 0.005353522\n",
      "train reg_fs: 0.0019684042781591415\n",
      "Epoch: 9500 train loss=0.004308151 valid loss= 0.005401584\n",
      "train reg_fs: 0.0019469603430479765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:30:33,472]\u001b[0m Trial 42 finished with value: 0.0033056741697635875 and parameters: {'lam': 0.002682430207962276, 'learning_rate': 0.07754390159973028, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003841697 valid loss= 0.005232952\n",
      "train reg_fs: 0.0019282238790765405\n",
      "Optimization Finished!\n",
      "test loss: 0.004728782922029495, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0033056741697635875\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011732249 valid loss= 0.007362700\n",
      "train reg_fs: 0.0013927913969382644\n",
      "Epoch: 1000 train loss=0.010382151 valid loss= 0.007054438\n",
      "train reg_fs: 0.001384445931762457\n",
      "Epoch: 1500 train loss=0.006250115 valid loss= 0.005591673\n",
      "train reg_fs: 0.00133350002579391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:30:47,526]\u001b[0m Trial 43 finished with value: 0.002963387862647365 and parameters: {'lam': 0.0016319683006315424, 'learning_rate': 0.05996031940957372, 'num_epoch': 2000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.008477248 valid loss= 0.004276462\n",
      "train reg_fs: 0.0012805224396288395\n",
      "Optimization Finished!\n",
      "test loss: 0.005317735485732555, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002963387862647365\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008494253 valid loss= 0.007708878\n",
      "train reg_fs: 0.0017505718860775232\n",
      "Epoch: 1000 train loss=0.013118867 valid loss= 0.007259129\n",
      "train reg_fs: 0.0017778591718524694\n",
      "Epoch: 1500 train loss=0.006040008 valid loss= 0.006978480\n",
      "train reg_fs: 0.0017916515935212374\n",
      "Epoch: 2000 train loss=0.007614307 valid loss= 0.006815838\n",
      "train reg_fs: 0.001797155593521893\n",
      "Epoch: 2500 train loss=0.009394863 valid loss= 0.006477779\n",
      "train reg_fs: 0.0017961267149075866\n",
      "Epoch: 3000 train loss=0.005275317 valid loss= 0.006821438\n",
      "train reg_fs: 0.001787293003872037\n",
      "Epoch: 3500 train loss=0.008125906 valid loss= 0.005236870\n",
      "train reg_fs: 0.0017740802140906453\n",
      "Epoch: 4000 train loss=0.010259925 valid loss= 0.005618364\n",
      "train reg_fs: 0.001760505372658372\n",
      "Epoch: 4500 train loss=0.005890162 valid loss= 0.005472498\n",
      "train reg_fs: 0.001740851323120296\n",
      "Epoch: 5000 train loss=0.007260664 valid loss= 0.005564045\n",
      "train reg_fs: 0.0017128309700638056\n",
      "Epoch: 5500 train loss=0.003740113 valid loss= 0.005211013\n",
      "train reg_fs: 0.0016856805887073278\n",
      "Epoch: 6000 train loss=0.004003934 valid loss= 0.005160805\n",
      "train reg_fs: 0.0016646248986944556\n",
      "Epoch: 6500 train loss=0.006926685 valid loss= 0.004990539\n",
      "train reg_fs: 0.0016443149652332067\n",
      "Epoch: 7000 train loss=0.005995239 valid loss= 0.004748736\n",
      "train reg_fs: 0.0016315073007717729\n",
      "Epoch: 7500 train loss=0.005291853 valid loss= 0.004644442\n",
      "train reg_fs: 0.0016224178252741694\n",
      "Epoch: 8000 train loss=0.003090623 valid loss= 0.004444075\n",
      "train reg_fs: 0.0016153764445334673\n",
      "Epoch: 8500 train loss=0.002733615 valid loss= 0.004513165\n",
      "train reg_fs: 0.0016086403047665954\n",
      "Epoch: 9000 train loss=0.002947313 valid loss= 0.004856542\n",
      "train reg_fs: 0.0016012697014957666\n",
      "Epoch: 9500 train loss=0.006279280 valid loss= 0.004558151\n",
      "train reg_fs: 0.001594430417753756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:31:51,616]\u001b[0m Trial 44 finished with value: 0.003060420718255074 and parameters: {'lam': 0.002021865571375951, 'learning_rate': 0.0507292163698696, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.008295980 valid loss= 0.004661493\n",
      "train reg_fs: 0.0015897593693807721\n",
      "Optimization Finished!\n",
      "test loss: 0.004589439835399389, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003060420718255074\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014156491 valid loss= 0.007235013\n",
      "train reg_fs: 0.0024252624716609716\n",
      "Epoch: 1000 train loss=0.008353050 valid loss= 0.006278076\n",
      "train reg_fs: 0.002284199697896838\n",
      "Epoch: 1500 train loss=0.006258729 valid loss= 0.005787600\n",
      "train reg_fs: 0.002215846674516797\n",
      "Epoch: 2000 train loss=0.003415684 valid loss= 0.005647933\n",
      "train reg_fs: 0.0021938220597803593\n",
      "Epoch: 2500 train loss=0.004612560 valid loss= 0.005420469\n",
      "train reg_fs: 0.0021919668652117252\n",
      "Epoch: 3000 train loss=0.006725832 valid loss= 0.005017939\n",
      "train reg_fs: 0.0021898166742175817\n",
      "Epoch: 3500 train loss=0.003743716 valid loss= 0.005028531\n",
      "train reg_fs: 0.0021830955520272255\n",
      "Epoch: 4000 train loss=0.003055941 valid loss= 0.005298070\n",
      "train reg_fs: 0.002159683033823967\n",
      "Epoch: 4500 train loss=0.003231777 valid loss= 0.004843592\n",
      "train reg_fs: 0.002121679950505495\n",
      "Epoch: 5000 train loss=0.003228979 valid loss= 0.004543089\n",
      "train reg_fs: 0.0020851725712418556\n",
      "Epoch: 5500 train loss=0.004306362 valid loss= 0.004333133\n",
      "train reg_fs: 0.0020534954965114594\n",
      "Epoch: 6000 train loss=0.003185510 valid loss= 0.004616145\n",
      "train reg_fs: 0.0020245693158358335\n",
      "Epoch: 6500 train loss=0.003219687 valid loss= 0.004024247\n",
      "train reg_fs: 0.0019909075926989317\n",
      "Epoch: 7000 train loss=0.004295005 valid loss= 0.004310778\n",
      "train reg_fs: 0.0019524110248312354\n",
      "Epoch: 7500 train loss=0.004719227 valid loss= 0.004248378\n",
      "train reg_fs: 0.0019098285119980574\n",
      "Epoch: 8000 train loss=0.004727591 valid loss= 0.004155399\n",
      "train reg_fs: 0.0018697266932576895\n",
      "Epoch: 8500 train loss=0.002330430 valid loss= 0.003845302\n",
      "train reg_fs: 0.0018416568636894226\n",
      "Epoch: 9000 train loss=0.003355125 valid loss= 0.004267422\n",
      "train reg_fs: 0.0018157734302803874\n",
      "Epoch: 9500 train loss=0.002862851 valid loss= 0.004104299\n",
      "train reg_fs: 0.0017978422110900283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:33:02,434]\u001b[0m Trial 45 finished with value: 0.00244123442032335 and parameters: {'lam': 0.002852814499852626, 'learning_rate': 0.10564489937073243, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007566052 valid loss= 0.004197945\n",
      "train reg_fs: 0.0017853097524493933\n",
      "Optimization Finished!\n",
      "test loss: 0.003870511893182993, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00244123442032335\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010435840 valid loss= 0.007826751\n",
      "train reg_fs: 0.0012513055698946118\n",
      "Epoch: 1000 train loss=0.005443599 valid loss= 0.008164961\n",
      "train reg_fs: 0.0012678769417107105\n",
      "Epoch: 1500 train loss=0.004645000 valid loss= 0.005206076\n",
      "train reg_fs: 0.0012568084057420492\n",
      "Epoch: 2000 train loss=0.014311136 valid loss= 0.004720905\n",
      "train reg_fs: 0.0012311034370213747\n",
      "Epoch: 2500 train loss=0.004918092 valid loss= 0.004728210\n",
      "train reg_fs: 0.001210238435305655\n",
      "Epoch: 3000 train loss=0.001740470 valid loss= 0.005516194\n",
      "train reg_fs: 0.0011888309381902218\n",
      "Epoch: 3500 train loss=0.003294765 valid loss= 0.005908753\n",
      "train reg_fs: 0.0011668213410302997\n",
      "Epoch: 4000 train loss=0.003523059 valid loss= 0.005977992\n",
      "train reg_fs: 0.0011496890801936388\n",
      "Epoch: 4500 train loss=0.003004108 valid loss= 0.006378764\n",
      "train reg_fs: 0.001134413410909474\n",
      "Epoch: 5000 train loss=0.002338942 valid loss= 0.005816434\n",
      "train reg_fs: 0.0011160835856571794\n",
      "Epoch: 5500 train loss=0.001607646 valid loss= 0.006428967\n",
      "train reg_fs: 0.001108793425373733\n",
      "Epoch: 6000 train loss=0.002391433 valid loss= 0.006680586\n",
      "train reg_fs: 0.0010946044931188226\n",
      "Epoch: 6500 train loss=0.003856601 valid loss= 0.006747788\n",
      "train reg_fs: 0.0010851657716557384\n",
      "Epoch: 7000 train loss=0.001849311 valid loss= 0.006487027\n",
      "train reg_fs: 0.001075741951353848\n",
      "Epoch: 7500 train loss=0.002088636 valid loss= 0.006621135\n",
      "train reg_fs: 0.001071857986971736\n",
      "Epoch: 8000 train loss=0.005684978 valid loss= 0.006961252\n",
      "train reg_fs: 0.001060277340002358\n",
      "Epoch: 8500 train loss=0.002008931 valid loss= 0.006772692\n",
      "train reg_fs: 0.001057007466442883\n",
      "Epoch: 9000 train loss=0.004962942 valid loss= 0.006712128\n",
      "train reg_fs: 0.001049643149599433\n",
      "Epoch: 9500 train loss=0.002158584 valid loss= 0.007027065\n",
      "train reg_fs: 0.0010429287794977427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:34:06,800]\u001b[0m Trial 46 finished with value: 0.005693232592983222 and parameters: {'lam': 0.001383191681010145, 'learning_rate': 0.16789778130746236, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003123123 valid loss= 0.006735804\n",
      "train reg_fs: 0.0010446483502164483\n",
      "Optimization Finished!\n",
      "test loss: 0.0067521510645747185, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005693232592983222\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.025264643 valid loss= 0.008642107\n",
      "train reg_fs: 0.0020076304208487272\n",
      "Epoch: 1000 train loss=0.025302617 valid loss= 0.009025683\n",
      "train reg_fs: 0.0020248242653906345\n",
      "Epoch: 1500 train loss=0.008081537 valid loss= 0.008481262\n",
      "train reg_fs: 0.00199251645244658\n",
      "Epoch: 2000 train loss=0.004122270 valid loss= 0.007380898\n",
      "train reg_fs: 0.001952657476067543\n",
      "Epoch: 2500 train loss=0.005298540 valid loss= 0.006686484\n",
      "train reg_fs: 0.001926678349263966\n",
      "Epoch: 3000 train loss=0.008030360 valid loss= 0.006617150\n",
      "train reg_fs: 0.0018976401770487428\n",
      "Epoch: 3500 train loss=0.010487373 valid loss= 0.005420441\n",
      "train reg_fs: 0.0018583228811621666\n",
      "Epoch: 4000 train loss=0.007890477 valid loss= 0.004590253\n",
      "train reg_fs: 0.001805313746444881\n",
      "Epoch: 4500 train loss=0.004573668 valid loss= 0.004604171\n",
      "train reg_fs: 0.001750580850057304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:34:39,819]\u001b[0m Trial 47 finished with value: 0.0026145509171469064 and parameters: {'lam': 0.0023021603760410266, 'learning_rate': 0.07042908715125305, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004315569 valid loss= 0.004334176\n",
      "train reg_fs: 0.0017067550215870142\n",
      "Optimization Finished!\n",
      "test loss: 0.004146338440477848, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026145509171469064\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012513941 valid loss= 0.007784081\n",
      "train reg_fs: 0.0016326329205185175\n",
      "Epoch: 1000 train loss=0.014649672 valid loss= 0.007097959\n",
      "train reg_fs: 0.001645381678827107\n",
      "Epoch: 1500 train loss=0.019039620 valid loss= 0.006522848\n",
      "train reg_fs: 0.0016341330483555794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:34:54,073]\u001b[0m Trial 48 finished with value: 0.003886618571883286 and parameters: {'lam': 0.0019064118709490564, 'learning_rate': 0.041957905594657244, 'num_epoch': 2000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.006718543 valid loss= 0.005498989\n",
      "train reg_fs: 0.0016015011351555586\n",
      "Optimization Finished!\n",
      "test loss: 0.006749056279659271, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003886618571883286\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013881671 valid loss= 0.006277127\n",
      "train reg_fs: 0.0010409994283691049\n",
      "Epoch: 1000 train loss=0.006563366 valid loss= 0.005836740\n",
      "train reg_fs: 0.0009968060767278075\n",
      "Epoch: 1500 train loss=0.006540330 valid loss= 0.004178845\n",
      "train reg_fs: 0.0009404224110767245\n",
      "Epoch: 2000 train loss=0.004046679 valid loss= 0.003759742\n",
      "train reg_fs: 0.000912784191314131\n",
      "Epoch: 2500 train loss=0.010227090 valid loss= 0.004309002\n",
      "train reg_fs: 0.0008965679444372654\n",
      "Epoch: 3000 train loss=0.003047820 valid loss= 0.004356998\n",
      "train reg_fs: 0.0008866130374372005\n",
      "Epoch: 3500 train loss=0.003543048 valid loss= 0.004428443\n",
      "train reg_fs: 0.0008781425422057509\n",
      "Epoch: 4000 train loss=0.005789647 valid loss= 0.004533543\n",
      "train reg_fs: 0.0008709907997399569\n",
      "Epoch: 4500 train loss=0.003188210 valid loss= 0.004480631\n",
      "train reg_fs: 0.0008652719552628696\n",
      "Epoch: 5000 train loss=0.002411201 valid loss= 0.004795433\n",
      "train reg_fs: 0.0008625743794254959\n",
      "Epoch: 5500 train loss=0.002104617 valid loss= 0.004201953\n",
      "train reg_fs: 0.0008607494528405368\n",
      "Epoch: 6000 train loss=0.002340677 valid loss= 0.004447263\n",
      "train reg_fs: 0.0008570716599933803\n",
      "Epoch: 6500 train loss=0.003846526 valid loss= 0.004124857\n",
      "train reg_fs: 0.0008491083863191307\n",
      "Epoch: 7000 train loss=0.002901870 valid loss= 0.004121559\n",
      "train reg_fs: 0.0008366112597286701\n",
      "Epoch: 7500 train loss=0.005248379 valid loss= 0.004117252\n",
      "train reg_fs: 0.0008210270316340029\n",
      "Epoch: 8000 train loss=0.001860433 valid loss= 0.004217843\n",
      "train reg_fs: 0.0008069141767919064\n",
      "Epoch: 8500 train loss=0.002685224 valid loss= 0.003643802\n",
      "train reg_fs: 0.0007968422141857445\n",
      "Epoch: 9000 train loss=0.002625150 valid loss= 0.003721512\n",
      "train reg_fs: 0.000788084464147687\n",
      "Epoch: 9500 train loss=0.001310679 valid loss= 0.003634780\n",
      "train reg_fs: 0.0007813136908225715\n",
      "Epoch: 10000 train loss=0.005614244 valid loss= 0.003278319\n",
      "train reg_fs: 0.0007759561995044351\n",
      "Epoch: 10500 train loss=0.003021200 valid loss= 0.003418804\n",
      "train reg_fs: 0.0007715757819823921\n",
      "Epoch: 11000 train loss=0.002498557 valid loss= 0.003448747\n",
      "train reg_fs: 0.0007676214445382357\n",
      "Epoch: 11500 train loss=0.001464002 valid loss= 0.003151103\n",
      "train reg_fs: 0.0007643035496585071\n",
      "Epoch: 12000 train loss=0.001489873 valid loss= 0.003122855\n",
      "train reg_fs: 0.000761616334784776\n",
      "Epoch: 12500 train loss=0.003388321 valid loss= 0.002927372\n",
      "train reg_fs: 0.0007591957692056894\n",
      "Epoch: 13000 train loss=0.002325207 valid loss= 0.003152410\n",
      "train reg_fs: 0.0007569837616756558\n",
      "Epoch: 13500 train loss=0.001122280 valid loss= 0.003178613\n",
      "train reg_fs: 0.000754965003579855\n",
      "Epoch: 14000 train loss=0.003408546 valid loss= 0.003003756\n",
      "train reg_fs: 0.0007532355957664549\n",
      "Epoch: 14500 train loss=0.001256634 valid loss= 0.003028817\n",
      "train reg_fs: 0.000751609681174159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:36:29,397]\u001b[0m Trial 49 finished with value: 0.0025719927080549553 and parameters: {'lam': 0.0012110992560366881, 'learning_rate': 0.0828055185620132, 'num_epoch': 15000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001007547 valid loss= 0.003310735\n",
      "train reg_fs: 0.0007500351057387888\n",
      "Optimization Finished!\n",
      "test loss: 0.00295782252214849, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025719927080549553\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007819370 valid loss= 0.009510765\n",
      "train reg_fs: 0.0033175654243677855\n",
      "Epoch: 1000 train loss=0.014511343 valid loss= 0.009765129\n",
      "train reg_fs: 0.003375290660187602\n",
      "Epoch: 1500 train loss=0.011420153 valid loss= 0.009684250\n",
      "train reg_fs: 0.003399220295250416\n",
      "Epoch: 2000 train loss=0.017717976 valid loss= 0.008776397\n",
      "train reg_fs: 0.0033972999081015587\n",
      "Epoch: 2500 train loss=0.010500893 valid loss= 0.009460919\n",
      "train reg_fs: 0.003376794047653675\n",
      "Epoch: 3000 train loss=0.012095425 valid loss= 0.008923575\n",
      "train reg_fs: 0.0033414203207939863\n",
      "Epoch: 3500 train loss=0.007385046 valid loss= 0.007383171\n",
      "train reg_fs: 0.0032911887392401695\n",
      "Epoch: 4000 train loss=0.012131633 valid loss= 0.007277554\n",
      "train reg_fs: 0.0032387031242251396\n",
      "Epoch: 4500 train loss=0.007228160 valid loss= 0.006721860\n",
      "train reg_fs: 0.0031963649671524763\n",
      "Epoch: 5000 train loss=0.005175518 valid loss= 0.005692148\n",
      "train reg_fs: 0.003143619280308485\n",
      "Epoch: 5500 train loss=0.008629763 valid loss= 0.005271098\n",
      "train reg_fs: 0.0030910205096006393\n",
      "Epoch: 6000 train loss=0.004936340 valid loss= 0.004803068\n",
      "train reg_fs: 0.003040455048903823\n",
      "Epoch: 6500 train loss=0.004769984 valid loss= 0.005155704\n",
      "train reg_fs: 0.003001792822033167\n",
      "Epoch: 7000 train loss=0.006199786 valid loss= 0.005226363\n",
      "train reg_fs: 0.0029673026874661446\n",
      "Epoch: 7500 train loss=0.008812481 valid loss= 0.005155541\n",
      "train reg_fs: 0.0029380209743976593\n",
      "Epoch: 8000 train loss=0.007206989 valid loss= 0.005004654\n",
      "train reg_fs: 0.002911466406658292\n",
      "Epoch: 8500 train loss=0.010264596 valid loss= 0.004810761\n",
      "train reg_fs: 0.002886279718950391\n",
      "Epoch: 9000 train loss=0.003591242 valid loss= 0.004413313\n",
      "train reg_fs: 0.00286358711309731\n",
      "Epoch: 9500 train loss=0.003673279 valid loss= 0.004403172\n",
      "train reg_fs: 0.002844161121174693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:37:33,854]\u001b[0m Trial 50 finished with value: 0.001974254612859089 and parameters: {'lam': 0.0038417689883502373, 'learning_rate': 0.047497286408209556, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003369193 valid loss= 0.004790918\n",
      "train reg_fs: 0.0028241416439414024\n",
      "Optimization Finished!\n",
      "test loss: 0.0047037070617079735, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001974254612859089\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014582201 valid loss= 0.007216305\n",
      "train reg_fs: 0.0014526740415021777\n",
      "Epoch: 1000 train loss=0.008397753 valid loss= 0.007870766\n",
      "train reg_fs: 0.001450967276468873\n",
      "Epoch: 1500 train loss=0.004856455 valid loss= 0.005355367\n",
      "train reg_fs: 0.001384756644256413\n",
      "Epoch: 2000 train loss=0.007963107 valid loss= 0.004421829\n",
      "train reg_fs: 0.0013168368022888899\n",
      "Epoch: 2500 train loss=0.003479779 valid loss= 0.004143742\n",
      "train reg_fs: 0.0012896305415779352\n",
      "Epoch: 3000 train loss=0.005996780 valid loss= 0.003766888\n",
      "train reg_fs: 0.0012726152781397104\n",
      "Epoch: 3500 train loss=0.003893782 valid loss= 0.003927025\n",
      "train reg_fs: 0.0012549376115202904\n",
      "Epoch: 4000 train loss=0.005778116 valid loss= 0.004136779\n",
      "train reg_fs: 0.0012391717173159122\n",
      "Epoch: 4500 train loss=0.006341222 valid loss= 0.003735381\n",
      "train reg_fs: 0.001223613042384386\n",
      "Epoch: 5000 train loss=0.004748317 valid loss= 0.004062396\n",
      "train reg_fs: 0.0012100603198632598\n",
      "Epoch: 5500 train loss=0.006615866 valid loss= 0.003737582\n",
      "train reg_fs: 0.0011951869819313288\n",
      "Epoch: 6000 train loss=0.003105613 valid loss= 0.003776436\n",
      "train reg_fs: 0.0011857885401695967\n",
      "Epoch: 6500 train loss=0.005078367 valid loss= 0.003813999\n",
      "train reg_fs: 0.001176991849206388\n",
      "Epoch: 7000 train loss=0.007351586 valid loss= 0.003736757\n",
      "train reg_fs: 0.0011664202902466059\n",
      "Epoch: 7500 train loss=0.002358292 valid loss= 0.004021694\n",
      "train reg_fs: 0.0011544027365744114\n",
      "Epoch: 8000 train loss=0.002363852 valid loss= 0.003691994\n",
      "train reg_fs: 0.001147767179645598\n",
      "Epoch: 8500 train loss=0.002486267 valid loss= 0.004159682\n",
      "train reg_fs: 0.0011395176406949759\n",
      "Epoch: 9000 train loss=0.001541957 valid loss= 0.003841116\n",
      "train reg_fs: 0.0011305982479825616\n",
      "Epoch: 9500 train loss=0.005426016 valid loss= 0.003989200\n",
      "train reg_fs: 0.001122941030189395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:38:38,123]\u001b[0m Trial 51 finished with value: 0.0028712417923252146 and parameters: {'lam': 0.0016281462564652588, 'learning_rate': 0.16818471870337198, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003428989 valid loss= 0.003983404\n",
      "train reg_fs: 0.0011195711558684707\n",
      "Optimization Finished!\n",
      "test loss: 0.003927217796444893, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028712417923252146\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013943773 valid loss= 0.008270225\n",
      "train reg_fs: 0.001863660290837288\n",
      "Epoch: 1000 train loss=0.004370191 valid loss= 0.007189487\n",
      "train reg_fs: 0.001790676498785615\n",
      "Epoch: 1500 train loss=0.010805921 valid loss= 0.005450327\n",
      "train reg_fs: 0.001738892518915236\n",
      "Epoch: 2000 train loss=0.002148598 valid loss= 0.005040373\n",
      "train reg_fs: 0.0016574196051806211\n",
      "Epoch: 2500 train loss=0.004146470 valid loss= 0.005016977\n",
      "train reg_fs: 0.0016190451569855213\n",
      "Epoch: 3000 train loss=0.004100382 valid loss= 0.005089610\n",
      "train reg_fs: 0.0015948008513078094\n",
      "Epoch: 3500 train loss=0.002000697 valid loss= 0.005011985\n",
      "train reg_fs: 0.0015740275848656893\n",
      "Epoch: 4000 train loss=0.003545188 valid loss= 0.005347666\n",
      "train reg_fs: 0.0015476231928914785\n",
      "Epoch: 4500 train loss=0.003059924 valid loss= 0.005172193\n",
      "train reg_fs: 0.0015212477883324027\n",
      "Epoch: 5000 train loss=0.005428335 valid loss= 0.004415602\n",
      "train reg_fs: 0.0014952492201700807\n",
      "Epoch: 5500 train loss=0.002995901 valid loss= 0.004494323\n",
      "train reg_fs: 0.0014803834492340684\n",
      "Epoch: 6000 train loss=0.004082291 valid loss= 0.004584049\n",
      "train reg_fs: 0.0014727370580658317\n",
      "Epoch: 6500 train loss=0.001884284 valid loss= 0.004144619\n",
      "train reg_fs: 0.0014670355012640357\n",
      "Epoch: 7000 train loss=0.004502672 valid loss= 0.004061823\n",
      "train reg_fs: 0.0014658899744972587\n",
      "Epoch: 7500 train loss=0.002582422 valid loss= 0.003940508\n",
      "train reg_fs: 0.001459477818571031\n",
      "Epoch: 8000 train loss=0.004576865 valid loss= 0.004378955\n",
      "train reg_fs: 0.0014600270660594106\n",
      "Epoch: 8500 train loss=0.002750371 valid loss= 0.003879116\n",
      "train reg_fs: 0.0014565899036824703\n",
      "Epoch: 9000 train loss=0.003687691 valid loss= 0.004063260\n",
      "train reg_fs: 0.0014553128276020288\n",
      "Epoch: 9500 train loss=0.002398686 valid loss= 0.004189296\n",
      "train reg_fs: 0.0014505767030641437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:39:42,436]\u001b[0m Trial 52 finished with value: 0.0028619599242091457 and parameters: {'lam': 0.0021700710461516988, 'learning_rate': 0.16191616043628668, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004495995 valid loss= 0.004280576\n",
      "train reg_fs: 0.0014481657417491078\n",
      "Optimization Finished!\n",
      "test loss: 0.003972585313022137, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028619599242091457\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011377958 valid loss= 0.007817229\n",
      "train reg_fs: 0.0015242347726598382\n",
      "Epoch: 1000 train loss=0.004469295 valid loss= 0.004408879\n",
      "train reg_fs: 0.001437709666788578\n",
      "Epoch: 1500 train loss=0.004434657 valid loss= 0.004311106\n",
      "train reg_fs: 0.0013951383298262954\n",
      "Epoch: 2000 train loss=0.002177922 valid loss= 0.004568719\n",
      "train reg_fs: 0.0013573336182162166\n",
      "Epoch: 2500 train loss=0.005891002 valid loss= 0.003962962\n",
      "train reg_fs: 0.0013286008033901453\n",
      "Epoch: 3000 train loss=0.002604504 valid loss= 0.004640518\n",
      "train reg_fs: 0.0013033454306423664\n",
      "Epoch: 3500 train loss=0.003282144 valid loss= 0.003643680\n",
      "train reg_fs: 0.0012779786484315991\n",
      "Epoch: 4000 train loss=0.002222106 valid loss= 0.004191577\n",
      "train reg_fs: 0.0012556042056530714\n",
      "Epoch: 4500 train loss=0.001972289 valid loss= 0.003841854\n",
      "train reg_fs: 0.0012304997071623802\n",
      "Epoch: 5000 train loss=0.001665074 valid loss= 0.003584015\n",
      "train reg_fs: 0.001205267384648323\n",
      "Epoch: 5500 train loss=0.001530462 valid loss= 0.003588412\n",
      "train reg_fs: 0.001188833499327302\n",
      "Epoch: 6000 train loss=0.001887034 valid loss= 0.003500623\n",
      "train reg_fs: 0.0011723553761839867\n",
      "Epoch: 6500 train loss=0.003479737 valid loss= 0.003571972\n",
      "train reg_fs: 0.00115947425365448\n",
      "Epoch: 7000 train loss=0.001863370 valid loss= 0.003513259\n",
      "train reg_fs: 0.0011488664895296097\n",
      "Epoch: 7500 train loss=0.002810269 valid loss= 0.003677191\n",
      "train reg_fs: 0.0011416177731007338\n",
      "Epoch: 8000 train loss=0.002355413 valid loss= 0.003677196\n",
      "train reg_fs: 0.0011341761564835906\n",
      "Epoch: 8500 train loss=0.006956020 valid loss= 0.003523105\n",
      "train reg_fs: 0.001127899973653257\n",
      "Epoch: 9000 train loss=0.003332618 valid loss= 0.003705508\n",
      "train reg_fs: 0.0011234644334763288\n",
      "Epoch: 9500 train loss=0.002271998 valid loss= 0.003378819\n",
      "train reg_fs: 0.001119541935622692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:40:46,962]\u001b[0m Trial 53 finished with value: 0.0021684195979453998 and parameters: {'lam': 0.0018173498718997247, 'learning_rate': 0.1455071834358313, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.010851059 valid loss= 0.003264962\n",
      "train reg_fs: 0.0011163982562720776\n",
      "Optimization Finished!\n",
      "test loss: 0.0030846549198031425, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021684195979453998\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006295483 valid loss= 0.006414234\n",
      "train reg_fs: 0.0014523552963510156\n",
      "Epoch: 1000 train loss=0.004631670 valid loss= 0.003762892\n",
      "train reg_fs: 0.0013542211381718516\n",
      "Epoch: 1500 train loss=0.004593011 valid loss= 0.003774126\n",
      "train reg_fs: 0.0013021022314205766\n",
      "Epoch: 2000 train loss=0.004796673 valid loss= 0.003471421\n",
      "train reg_fs: 0.0012810926418751478\n",
      "Epoch: 2500 train loss=0.004252276 valid loss= 0.003426877\n",
      "train reg_fs: 0.0012687613489106297\n",
      "Epoch: 3000 train loss=0.002701246 valid loss= 0.003181966\n",
      "train reg_fs: 0.0012575803557410836\n",
      "Epoch: 3500 train loss=0.002880814 valid loss= 0.003234552\n",
      "train reg_fs: 0.0012516092974692583\n",
      "Epoch: 4000 train loss=0.002101105 valid loss= 0.003507681\n",
      "train reg_fs: 0.0012417084071785212\n",
      "Epoch: 4500 train loss=0.001320893 valid loss= 0.003280011\n",
      "train reg_fs: 0.001234823022969067\n",
      "Epoch: 5000 train loss=0.004338587 valid loss= 0.003186892\n",
      "train reg_fs: 0.0012282764073461294\n",
      "Epoch: 5500 train loss=0.003806620 valid loss= 0.003231395\n",
      "train reg_fs: 0.0012177795870229602\n",
      "Epoch: 6000 train loss=0.001804277 valid loss= 0.003200710\n",
      "train reg_fs: 0.0012131466064602137\n",
      "Epoch: 6500 train loss=0.001612757 valid loss= 0.003658871\n",
      "train reg_fs: 0.001208355650305748\n",
      "Epoch: 7000 train loss=0.002071227 valid loss= 0.003611166\n",
      "train reg_fs: 0.0011996339308097959\n",
      "Epoch: 7500 train loss=0.001975644 valid loss= 0.003715085\n",
      "train reg_fs: 0.001195411430671811\n",
      "Epoch: 8000 train loss=0.002085583 valid loss= 0.003739047\n",
      "train reg_fs: 0.0011908016167581081\n",
      "Epoch: 8500 train loss=0.001639261 valid loss= 0.003693474\n",
      "train reg_fs: 0.0011826204136013985\n",
      "Epoch: 9000 train loss=0.003105641 valid loss= 0.003479920\n",
      "train reg_fs: 0.0011785930255427957\n",
      "Epoch: 9500 train loss=0.002122854 valid loss= 0.003580729\n",
      "train reg_fs: 0.0011729253455996513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:41:51,349]\u001b[0m Trial 54 finished with value: 0.0024096090729236884 and parameters: {'lam': 0.0017098774359612515, 'learning_rate': 0.1945263530967935, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005508386 valid loss= 0.003541211\n",
      "train reg_fs: 0.0011671019019559026\n",
      "Optimization Finished!\n",
      "test loss: 0.003629121696576476, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024096090729236884\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018493924 valid loss= 0.007397066\n",
      "train reg_fs: 0.002134927548468113\n",
      "Epoch: 1000 train loss=0.006101810 valid loss= 0.005810357\n",
      "train reg_fs: 0.0020267365034669638\n",
      "Epoch: 1500 train loss=0.002974445 valid loss= 0.004361692\n",
      "train reg_fs: 0.0019223091658204794\n",
      "Epoch: 2000 train loss=0.006979041 valid loss= 0.004331725\n",
      "train reg_fs: 0.0018731832969933748\n",
      "Epoch: 2500 train loss=0.003483089 valid loss= 0.004819138\n",
      "train reg_fs: 0.0018507170025259256\n",
      "Epoch: 3000 train loss=0.003640824 valid loss= 0.004568579\n",
      "train reg_fs: 0.0018324897391721606\n",
      "Epoch: 3500 train loss=0.005924106 valid loss= 0.004978971\n",
      "train reg_fs: 0.0018182882340624928\n",
      "Epoch: 4000 train loss=0.007240585 valid loss= 0.005165304\n",
      "train reg_fs: 0.0018037031404674053\n",
      "Epoch: 4500 train loss=0.002828203 valid loss= 0.005380946\n",
      "train reg_fs: 0.0017918464727699757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:42:24,708]\u001b[0m Trial 55 finished with value: 0.003379189373231592 and parameters: {'lam': 0.0024596451616765527, 'learning_rate': 0.11700185310301879, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004018163 valid loss= 0.005197324\n",
      "train reg_fs: 0.0017788450932130218\n",
      "Optimization Finished!\n",
      "test loss: 0.005829662550240755, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003379189373231592\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005480772 valid loss= 0.006715221\n",
      "train reg_fs: 0.0009180264314636588\n",
      "Epoch: 1000 train loss=0.004021751 valid loss= 0.004885041\n",
      "train reg_fs: 0.0008954036165960133\n",
      "Epoch: 1500 train loss=0.009678937 valid loss= 0.003580886\n",
      "train reg_fs: 0.0008630449883639812\n",
      "Epoch: 2000 train loss=0.006268687 valid loss= 0.002432872\n",
      "train reg_fs: 0.0008383468957617879\n",
      "Epoch: 2500 train loss=0.003941202 valid loss= 0.002964538\n",
      "train reg_fs: 0.0008202916942536831\n",
      "Epoch: 3000 train loss=0.007544324 valid loss= 0.002948156\n",
      "train reg_fs: 0.0008078009122982621\n",
      "Epoch: 3500 train loss=0.005935106 valid loss= 0.002649256\n",
      "train reg_fs: 0.0007975537446327507\n",
      "Epoch: 4000 train loss=0.002322031 valid loss= 0.002739695\n",
      "train reg_fs: 0.0007897349423728883\n",
      "Epoch: 4500 train loss=0.001159472 valid loss= 0.002657446\n",
      "train reg_fs: 0.0007840940379537642\n",
      "Epoch: 5000 train loss=0.002620967 valid loss= 0.002923815\n",
      "train reg_fs: 0.0007794519769959152\n",
      "Epoch: 5500 train loss=0.002575043 valid loss= 0.002409970\n",
      "train reg_fs: 0.0007751356461085379\n",
      "Epoch: 6000 train loss=0.003287702 valid loss= 0.002700946\n",
      "train reg_fs: 0.0007706594769842923\n",
      "Epoch: 6500 train loss=0.002814408 valid loss= 0.002252495\n",
      "train reg_fs: 0.0007663445430807769\n",
      "Epoch: 7000 train loss=0.001629645 valid loss= 0.002082683\n",
      "train reg_fs: 0.0007623975398018956\n",
      "Epoch: 7500 train loss=0.001480488 valid loss= 0.002151784\n",
      "train reg_fs: 0.0007579175871796906\n",
      "Epoch: 8000 train loss=0.003538565 valid loss= 0.001794009\n",
      "train reg_fs: 0.0007551083108410239\n",
      "Epoch: 8500 train loss=0.001896975 valid loss= 0.002246993\n",
      "train reg_fs: 0.0007512434967793524\n",
      "Epoch: 9000 train loss=0.001864224 valid loss= 0.002145317\n",
      "train reg_fs: 0.0007482783985324204\n",
      "Epoch: 9500 train loss=0.002821172 valid loss= 0.001929538\n",
      "train reg_fs: 0.0007447672542184591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:43:28,869]\u001b[0m Trial 56 finished with value: 0.0008285928353709445 and parameters: {'lam': 0.0010594999443050083, 'learning_rate': 0.09898155891144222, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003377351 valid loss= 0.001569401\n",
      "train reg_fs: 0.0007419944158755243\n",
      "Optimization Finished!\n",
      "test loss: 0.0015856805257499218, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0008285928353709445\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010030109 valid loss= 0.008329436\n",
      "train reg_fs: 0.0008608723874203861\n",
      "Epoch: 1000 train loss=0.003545112 valid loss= 0.006410945\n",
      "train reg_fs: 0.0008346025133505464\n",
      "Epoch: 1500 train loss=0.005887475 valid loss= 0.005903586\n",
      "train reg_fs: 0.0008053842466324568\n",
      "Epoch: 2000 train loss=0.004348496 valid loss= 0.004504067\n",
      "train reg_fs: 0.0007744297618046403\n",
      "Epoch: 2500 train loss=0.005588918 valid loss= 0.004447449\n",
      "train reg_fs: 0.0007492044824175537\n",
      "Epoch: 3000 train loss=0.003419091 valid loss= 0.004000932\n",
      "train reg_fs: 0.0007343716570176184\n",
      "Epoch: 3500 train loss=0.004146061 valid loss= 0.004071485\n",
      "train reg_fs: 0.0007187218288891017\n",
      "Epoch: 4000 train loss=0.001927205 valid loss= 0.003808274\n",
      "train reg_fs: 0.0007029673433862627\n",
      "Epoch: 4500 train loss=0.007222491 valid loss= 0.003572071\n",
      "train reg_fs: 0.0006904863403178751\n",
      "Epoch: 5000 train loss=0.001016380 valid loss= 0.003641426\n",
      "train reg_fs: 0.0006796418456360698\n",
      "Epoch: 5500 train loss=0.005763104 valid loss= 0.003427075\n",
      "train reg_fs: 0.0006721031968481839\n",
      "Epoch: 6000 train loss=0.002916745 valid loss= 0.003368709\n",
      "train reg_fs: 0.0006660263752564788\n",
      "Epoch: 6500 train loss=0.001328105 valid loss= 0.003214786\n",
      "train reg_fs: 0.000661113706883043\n",
      "Epoch: 7000 train loss=0.001858395 valid loss= 0.003472171\n",
      "train reg_fs: 0.00065669568721205\n",
      "Epoch: 7500 train loss=0.001747260 valid loss= 0.003049800\n",
      "train reg_fs: 0.0006531809340231121\n",
      "Epoch: 8000 train loss=0.001257112 valid loss= 0.002670348\n",
      "train reg_fs: 0.0006502850446850061\n",
      "Epoch: 8500 train loss=0.001697006 valid loss= 0.003029594\n",
      "train reg_fs: 0.0006478475988842547\n",
      "Epoch: 9000 train loss=0.004511056 valid loss= 0.003091559\n",
      "train reg_fs: 0.0006455107941292226\n",
      "Epoch: 9500 train loss=0.002939149 valid loss= 0.003050962\n",
      "train reg_fs: 0.0006436958792619407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:44:33,311]\u001b[0m Trial 57 finished with value: 0.002074366694251819 and parameters: {'lam': 0.0010324129999637935, 'learning_rate': 0.09908859142303666, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001544853 valid loss= 0.002708409\n",
      "train reg_fs: 0.0006418728735297918\n",
      "Optimization Finished!\n",
      "test loss: 0.0024967296048998833, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002074366694251819\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017218295 valid loss= 0.012827283\n",
      "train reg_fs: 0.0063937813974916935\n",
      "Epoch: 1000 train loss=0.012197805 valid loss= 0.010419188\n",
      "train reg_fs: 0.006163731683045626\n",
      "Epoch: 1500 train loss=0.017230108 valid loss= 0.009407369\n",
      "train reg_fs: 0.005945907905697823\n",
      "Epoch: 2000 train loss=0.008803781 valid loss= 0.008443833\n",
      "train reg_fs: 0.005745569244027138\n",
      "Epoch: 2500 train loss=0.007784328 valid loss= 0.008606184\n",
      "train reg_fs: 0.005585538223385811\n",
      "Epoch: 3000 train loss=0.012113241 valid loss= 0.008690390\n",
      "train reg_fs: 0.005438065622001886\n",
      "Epoch: 3500 train loss=0.007152844 valid loss= 0.009057311\n",
      "train reg_fs: 0.005300870630890131\n",
      "Epoch: 4000 train loss=0.007315753 valid loss= 0.009470124\n",
      "train reg_fs: 0.005158110521733761\n",
      "Epoch: 4500 train loss=0.007489127 valid loss= 0.009395618\n",
      "train reg_fs: 0.00502489460632205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:45:06,920]\u001b[0m Trial 58 finished with value: 0.004388038831974988 and parameters: {'lam': 0.007561961252462081, 'learning_rate': 0.06412861173975914, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008245465 valid loss= 0.009466375\n",
      "train reg_fs: 0.004908057861030102\n",
      "Optimization Finished!\n",
      "test loss: 0.009734999388456345, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004388038831974988\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010102138 valid loss= 0.010549917\n",
      "train reg_fs: 0.0038009732961654663\n",
      "Epoch: 1000 train loss=0.013374718 valid loss= 0.009787602\n",
      "train reg_fs: 0.003834802657365799\n",
      "Epoch: 1500 train loss=0.008769719 valid loss= 0.010072290\n",
      "train reg_fs: 0.0038249630015343428\n",
      "Epoch: 2000 train loss=0.009522931 valid loss= 0.009367795\n",
      "train reg_fs: 0.0037670820020139217\n",
      "Epoch: 2500 train loss=0.006456772 valid loss= 0.008699641\n",
      "train reg_fs: 0.0036723304074257612\n",
      "Epoch: 3000 train loss=0.011673357 valid loss= 0.008604446\n",
      "train reg_fs: 0.0035911225713789463\n",
      "Epoch: 3500 train loss=0.014379244 valid loss= 0.008273235\n",
      "train reg_fs: 0.0035311307292431593\n",
      "Epoch: 4000 train loss=0.005552690 valid loss= 0.007906668\n",
      "train reg_fs: 0.0034758076071739197\n",
      "Epoch: 4500 train loss=0.007599753 valid loss= 0.007536297\n",
      "train reg_fs: 0.0034243487752974033\n",
      "Epoch: 5000 train loss=0.005998659 valid loss= 0.008032878\n",
      "train reg_fs: 0.0033753090538084507\n",
      "Epoch: 5500 train loss=0.006043457 valid loss= 0.008028974\n",
      "train reg_fs: 0.0033267990220338106\n",
      "Epoch: 6000 train loss=0.004991197 valid loss= 0.007782160\n",
      "train reg_fs: 0.0032860611099749804\n",
      "Epoch: 6500 train loss=0.005837739 valid loss= 0.008132852\n",
      "train reg_fs: 0.0032546506263315678\n",
      "Epoch: 7000 train loss=0.004605805 valid loss= 0.008950979\n",
      "train reg_fs: 0.0032094698399305344\n",
      "Epoch: 7500 train loss=0.005803115 valid loss= 0.008489547\n",
      "train reg_fs: 0.0031745980959385633\n",
      "Epoch: 8000 train loss=0.004187427 valid loss= 0.008713800\n",
      "train reg_fs: 0.003129464341327548\n",
      "Epoch: 8500 train loss=0.003866090 valid loss= 0.008908952\n",
      "train reg_fs: 0.0030929232016205788\n",
      "Epoch: 9000 train loss=0.003720259 valid loss= 0.009068222\n",
      "train reg_fs: 0.0030586079228669405\n",
      "Epoch: 9500 train loss=0.004558481 valid loss= 0.009664715\n",
      "train reg_fs: 0.003020585747435689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:46:12,592]\u001b[0m Trial 59 finished with value: 0.006254978564308208 and parameters: {'lam': 0.004432714651019528, 'learning_rate': 0.0727245864871525, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004882832 valid loss= 0.009469229\n",
      "train reg_fs: 0.0029918127693235874\n",
      "Optimization Finished!\n",
      "test loss: 0.009757178835570812, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006254978564308208\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009067370 valid loss= 0.009283784\n",
      "train reg_fs: 0.002816007938235998\n",
      "Epoch: 1000 train loss=0.014014618 valid loss= 0.009224469\n",
      "train reg_fs: 0.002856905572116375\n",
      "Epoch: 1500 train loss=0.008855654 valid loss= 0.008991605\n",
      "train reg_fs: 0.0028628590516746044\n",
      "Epoch: 2000 train loss=0.007897791 valid loss= 0.007415149\n",
      "train reg_fs: 0.0028285363223403692\n",
      "Epoch: 2500 train loss=0.007605998 valid loss= 0.007294458\n",
      "train reg_fs: 0.0027856514789164066\n",
      "Epoch: 3000 train loss=0.005163168 valid loss= 0.006594659\n",
      "train reg_fs: 0.0027153983246535063\n",
      "Epoch: 3500 train loss=0.014132580 valid loss= 0.005320411\n",
      "train reg_fs: 0.0026520839892327785\n",
      "Epoch: 4000 train loss=0.004478154 valid loss= 0.004867720\n",
      "train reg_fs: 0.002586283255368471\n",
      "Epoch: 4500 train loss=0.004751842 valid loss= 0.004778901\n",
      "train reg_fs: 0.002520075999200344\n",
      "Epoch: 5000 train loss=0.006252094 valid loss= 0.004836201\n",
      "train reg_fs: 0.0024735305923968554\n",
      "Epoch: 5500 train loss=0.005666455 valid loss= 0.004886182\n",
      "train reg_fs: 0.002438903786242008\n",
      "Epoch: 6000 train loss=0.009136543 valid loss= 0.004434292\n",
      "train reg_fs: 0.0024093776009976864\n",
      "Epoch: 6500 train loss=0.003580448 valid loss= 0.004749716\n",
      "train reg_fs: 0.00238591805100441\n",
      "Epoch: 7000 train loss=0.004728874 valid loss= 0.004325944\n",
      "train reg_fs: 0.0023647472262382507\n",
      "Epoch: 7500 train loss=0.003242230 valid loss= 0.004216903\n",
      "train reg_fs: 0.0023464602418243885\n",
      "Epoch: 8000 train loss=0.002944867 valid loss= 0.004416055\n",
      "train reg_fs: 0.0023295097053050995\n",
      "Epoch: 8500 train loss=0.003903532 valid loss= 0.003698704\n",
      "train reg_fs: 0.002314794808626175\n",
      "Epoch: 9000 train loss=0.004907054 valid loss= 0.004489406\n",
      "train reg_fs: 0.002299407497048378\n",
      "Epoch: 9500 train loss=0.004646414 valid loss= 0.003563088\n",
      "train reg_fs: 0.0022826949134469032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:47:17,440]\u001b[0m Trial 60 finished with value: 0.0016058545632651703 and parameters: {'lam': 0.0032363974348056388, 'learning_rate': 0.05867505748960916, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006047375 valid loss= 0.003889096\n",
      "train reg_fs: 0.0022680419497191906\n",
      "Optimization Finished!\n",
      "test loss: 0.003679674118757248, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0016058545632651703\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011039745 valid loss= 0.009084072\n",
      "train reg_fs: 0.0026751956902444363\n",
      "Epoch: 1000 train loss=0.009873698 valid loss= 0.008793038\n",
      "train reg_fs: 0.002707875333726406\n",
      "Epoch: 1500 train loss=0.009426858 valid loss= 0.008617654\n",
      "train reg_fs: 0.002701380755752325\n",
      "Epoch: 2000 train loss=0.014973715 valid loss= 0.007438325\n",
      "train reg_fs: 0.0026558651588857174\n",
      "Epoch: 2500 train loss=0.008351493 valid loss= 0.006816871\n",
      "train reg_fs: 0.002580516505986452\n",
      "Epoch: 3000 train loss=0.010146635 valid loss= 0.005817017\n",
      "train reg_fs: 0.0025144151877611876\n",
      "Epoch: 3500 train loss=0.005427027 valid loss= 0.005307029\n",
      "train reg_fs: 0.0024551134556531906\n",
      "Epoch: 4000 train loss=0.004762711 valid loss= 0.005463711\n",
      "train reg_fs: 0.002416029805317521\n",
      "Epoch: 4500 train loss=0.011464492 valid loss= 0.005445428\n",
      "train reg_fs: 0.002392395166680217\n",
      "Epoch: 5000 train loss=0.003623701 valid loss= 0.005618702\n",
      "train reg_fs: 0.0023755563888698816\n",
      "Epoch: 5500 train loss=0.004210030 valid loss= 0.005443359\n",
      "train reg_fs: 0.0023651672527194023\n",
      "Epoch: 6000 train loss=0.004864444 valid loss= 0.005867664\n",
      "train reg_fs: 0.002354399999603629\n",
      "Epoch: 6500 train loss=0.004590802 valid loss= 0.005828410\n",
      "train reg_fs: 0.0023428204003721476\n",
      "Epoch: 7000 train loss=0.004058053 valid loss= 0.005809598\n",
      "train reg_fs: 0.0023334098514169455\n",
      "Epoch: 7500 train loss=0.007012670 valid loss= 0.006082034\n",
      "train reg_fs: 0.002327318536117673\n",
      "Epoch: 8000 train loss=0.004106282 valid loss= 0.006106781\n",
      "train reg_fs: 0.002318174345418811\n",
      "Epoch: 8500 train loss=0.003877454 valid loss= 0.006130661\n",
      "train reg_fs: 0.0023079239763319492\n",
      "Epoch: 9000 train loss=0.007567400 valid loss= 0.006099221\n",
      "train reg_fs: 0.002300841035321355\n",
      "Epoch: 9500 train loss=0.004428716 valid loss= 0.006060588\n",
      "train reg_fs: 0.0022926731035113335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:48:22,151]\u001b[0m Trial 61 finished with value: 0.00401497400666652 and parameters: {'lam': 0.003083308694122559, 'learning_rate': 0.055461310497086504, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004454782 valid loss= 0.006313402\n",
      "train reg_fs: 0.002283832523971796\n",
      "Optimization Finished!\n",
      "test loss: 0.006123673170804977, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00401497400666652\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014244535 valid loss= 0.009697923\n",
      "train reg_fs: 0.0024631016422063112\n",
      "Epoch: 1000 train loss=0.011842456 valid loss= 0.009931297\n",
      "train reg_fs: 0.00250485772266984\n",
      "Epoch: 1500 train loss=0.016369045 valid loss= 0.009329613\n",
      "train reg_fs: 0.00252031278796494\n",
      "Epoch: 2000 train loss=0.012765459 valid loss= 0.008549826\n",
      "train reg_fs: 0.002507866593077779\n",
      "Epoch: 2500 train loss=0.009307201 valid loss= 0.008875001\n",
      "train reg_fs: 0.002480741823092103\n",
      "Epoch: 3000 train loss=0.006909502 valid loss= 0.007923430\n",
      "train reg_fs: 0.00245135766454041\n",
      "Epoch: 3500 train loss=0.011532493 valid loss= 0.007499668\n",
      "train reg_fs: 0.002414108719676733\n",
      "Epoch: 4000 train loss=0.005053624 valid loss= 0.007104985\n",
      "train reg_fs: 0.0023826684337109327\n",
      "Epoch: 4500 train loss=0.004303388 valid loss= 0.006981190\n",
      "train reg_fs: 0.0023542295675724745\n",
      "Epoch: 5000 train loss=0.005222305 valid loss= 0.007044234\n",
      "train reg_fs: 0.0023332382552325726\n",
      "Epoch: 5500 train loss=0.004604196 valid loss= 0.006983614\n",
      "train reg_fs: 0.002313446719199419\n",
      "Epoch: 6000 train loss=0.003887847 valid loss= 0.007255513\n",
      "train reg_fs: 0.0022903827484697104\n",
      "Epoch: 6500 train loss=0.004029267 valid loss= 0.006917171\n",
      "train reg_fs: 0.002272586803883314\n",
      "Epoch: 7000 train loss=0.006153631 valid loss= 0.007241075\n",
      "train reg_fs: 0.0022631294559687376\n",
      "Epoch: 7500 train loss=0.003896255 valid loss= 0.007363494\n",
      "train reg_fs: 0.0022477793972939253\n",
      "Epoch: 8000 train loss=0.007000740 valid loss= 0.007240437\n",
      "train reg_fs: 0.002239786321297288\n",
      "Epoch: 8500 train loss=0.003623422 valid loss= 0.006915767\n",
      "train reg_fs: 0.002227704506367445\n",
      "Epoch: 9000 train loss=0.004464773 valid loss= 0.007040025\n",
      "train reg_fs: 0.002217960776761174\n",
      "Epoch: 9500 train loss=0.005537661 valid loss= 0.007562725\n",
      "train reg_fs: 0.002201860537752509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:49:26,702]\u001b[0m Trial 62 finished with value: 0.005012453058888419 and parameters: {'lam': 0.0028117028528287825, 'learning_rate': 0.08326956256808782, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003606158 valid loss= 0.007238587\n",
      "train reg_fs: 0.002192138461396098\n",
      "Optimization Finished!\n",
      "test loss: 0.007909270003437996, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005012453058888419\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013044570 valid loss= 0.009027975\n",
      "train reg_fs: 0.0020935661159455776\n",
      "Epoch: 1000 train loss=0.009715048 valid loss= 0.008959351\n",
      "train reg_fs: 0.0020638254936784506\n",
      "Epoch: 1500 train loss=0.007749688 valid loss= 0.008089585\n",
      "train reg_fs: 0.00201603164896369\n",
      "Epoch: 2000 train loss=0.007935634 valid loss= 0.007595725\n",
      "train reg_fs: 0.0019731370266526937\n",
      "Epoch: 2500 train loss=0.009396735 valid loss= 0.006474897\n",
      "train reg_fs: 0.0019352247472852468\n",
      "Epoch: 3000 train loss=0.011288484 valid loss= 0.006432510\n",
      "train reg_fs: 0.0018913302337750793\n",
      "Epoch: 3500 train loss=0.005699491 valid loss= 0.005551739\n",
      "train reg_fs: 0.0018499639118090272\n",
      "Epoch: 4000 train loss=0.004874141 valid loss= 0.005421895\n",
      "train reg_fs: 0.0018169023096561432\n",
      "Epoch: 4500 train loss=0.009219772 valid loss= 0.005200724\n",
      "train reg_fs: 0.0017913557821884751\n",
      "Epoch: 5000 train loss=0.004512425 valid loss= 0.005525888\n",
      "train reg_fs: 0.0017718911403790116\n",
      "Epoch: 5500 train loss=0.005235953 valid loss= 0.005709733\n",
      "train reg_fs: 0.0017621790757402778\n",
      "Epoch: 6000 train loss=0.005742013 valid loss= 0.005846392\n",
      "train reg_fs: 0.0017512940103188157\n",
      "Epoch: 6500 train loss=0.002446931 valid loss= 0.005535157\n",
      "train reg_fs: 0.001741358544677496\n",
      "Epoch: 7000 train loss=0.006393525 valid loss= 0.005322321\n",
      "train reg_fs: 0.00172738591209054\n",
      "Epoch: 7500 train loss=0.008878930 valid loss= 0.005080645\n",
      "train reg_fs: 0.0017068072920665145\n",
      "Epoch: 8000 train loss=0.003254175 valid loss= 0.004957732\n",
      "train reg_fs: 0.0016845683567225933\n",
      "Epoch: 8500 train loss=0.002792084 valid loss= 0.005334777\n",
      "train reg_fs: 0.001661577494814992\n",
      "Epoch: 9000 train loss=0.002366770 valid loss= 0.004900573\n",
      "train reg_fs: 0.0016402470646426082\n",
      "Epoch: 9500 train loss=0.003447696 valid loss= 0.004392100\n",
      "train reg_fs: 0.0016221852274611592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:50:31,192]\u001b[0m Trial 63 finished with value: 0.0029472661863181393 and parameters: {'lam': 0.0024553823400608014, 'learning_rate': 0.06052177194269965, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002501680 valid loss= 0.004553830\n",
      "train reg_fs: 0.0016058648470789194\n",
      "Optimization Finished!\n",
      "test loss: 0.004136264324188232, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029472661863181393\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019384975 valid loss= 0.009265253\n",
      "train reg_fs: 0.0028353636153042316\n",
      "Epoch: 1000 train loss=0.009171518 valid loss= 0.008159569\n",
      "train reg_fs: 0.0028346662875264883\n",
      "Epoch: 1500 train loss=0.017501719 valid loss= 0.008517911\n",
      "train reg_fs: 0.0027711070142686367\n",
      "Epoch: 2000 train loss=0.006524332 valid loss= 0.007630820\n",
      "train reg_fs: 0.0026989015750586987\n",
      "Epoch: 2500 train loss=0.013263131 valid loss= 0.006190459\n",
      "train reg_fs: 0.00261534727178514\n",
      "Epoch: 3000 train loss=0.007154873 valid loss= 0.005416429\n",
      "train reg_fs: 0.0025393797550350428\n",
      "Epoch: 3500 train loss=0.007442095 valid loss= 0.005342692\n",
      "train reg_fs: 0.0024683198425918818\n",
      "Epoch: 4000 train loss=0.003361783 valid loss= 0.005579997\n",
      "train reg_fs: 0.002402868587523699\n",
      "Epoch: 4500 train loss=0.004212900 valid loss= 0.005683807\n",
      "train reg_fs: 0.002346035558730364\n",
      "Epoch: 5000 train loss=0.005458563 valid loss= 0.005308784\n",
      "train reg_fs: 0.002295279875397682\n",
      "Epoch: 5500 train loss=0.005028016 valid loss= 0.005140364\n",
      "train reg_fs: 0.002251036697998643\n",
      "Epoch: 6000 train loss=0.003685288 valid loss= 0.004836914\n",
      "train reg_fs: 0.0022155605256557465\n",
      "Epoch: 6500 train loss=0.004638550 valid loss= 0.005385925\n",
      "train reg_fs: 0.0021837588865309954\n",
      "Epoch: 7000 train loss=0.003774621 valid loss= 0.004892710\n",
      "train reg_fs: 0.002156535629183054\n",
      "Epoch: 7500 train loss=0.008988131 valid loss= 0.004550947\n",
      "train reg_fs: 0.00213483814150095\n",
      "Epoch: 8000 train loss=0.003712755 valid loss= 0.004777942\n",
      "train reg_fs: 0.0021147034130990505\n",
      "Epoch: 8500 train loss=0.002448133 valid loss= 0.004645249\n",
      "train reg_fs: 0.0020996443927288055\n",
      "Epoch: 9000 train loss=0.004577730 valid loss= 0.004375817\n",
      "train reg_fs: 0.0020862026140093803\n",
      "Epoch: 9500 train loss=0.002672342 valid loss= 0.004435578\n",
      "train reg_fs: 0.0020750178955495358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:51:36,810]\u001b[0m Trial 64 finished with value: 0.0024119733210635477 and parameters: {'lam': 0.0032757998797031686, 'learning_rate': 0.06814661153056753, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002867012 valid loss= 0.004458615\n",
      "train reg_fs: 0.0020647866185754538\n",
      "Optimization Finished!\n",
      "test loss: 0.004220940172672272, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024119733210635477\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007776511 valid loss= 0.007148104\n",
      "train reg_fs: 0.0018836836097761989\n",
      "Epoch: 1000 train loss=0.009153173 valid loss= 0.006434003\n",
      "train reg_fs: 0.0018723866669461131\n",
      "Epoch: 1500 train loss=0.007551228 valid loss= 0.006396784\n",
      "train reg_fs: 0.0018276579212397337\n",
      "Epoch: 2000 train loss=0.005909002 valid loss= 0.004793266\n",
      "train reg_fs: 0.0017803360242396593\n",
      "Epoch: 2500 train loss=0.004390796 valid loss= 0.004404276\n",
      "train reg_fs: 0.0017466181889176369\n",
      "Epoch: 3000 train loss=0.004430117 valid loss= 0.004268195\n",
      "train reg_fs: 0.0017287766095250845\n",
      "Epoch: 3500 train loss=0.007626997 valid loss= 0.004463823\n",
      "train reg_fs: 0.0017169271595776081\n",
      "Epoch: 4000 train loss=0.003359194 valid loss= 0.004377139\n",
      "train reg_fs: 0.0017088630702346563\n",
      "Epoch: 4500 train loss=0.003936562 valid loss= 0.004546479\n",
      "train reg_fs: 0.001699803862720728\n",
      "Epoch: 5000 train loss=0.003100889 valid loss= 0.004563239\n",
      "train reg_fs: 0.001690958859398961\n",
      "Epoch: 5500 train loss=0.003870245 valid loss= 0.004691114\n",
      "train reg_fs: 0.001680114190094173\n",
      "Epoch: 6000 train loss=0.004170012 valid loss= 0.004491109\n",
      "train reg_fs: 0.0016689912881702185\n",
      "Epoch: 6500 train loss=0.013325789 valid loss= 0.004366193\n",
      "train reg_fs: 0.0016583430115133524\n",
      "Epoch: 7000 train loss=0.003730180 valid loss= 0.004127542\n",
      "train reg_fs: 0.0016483906656503677\n",
      "Epoch: 7500 train loss=0.002742090 valid loss= 0.004930937\n",
      "train reg_fs: 0.0016377402935177088\n",
      "Epoch: 8000 train loss=0.002834249 valid loss= 0.004428869\n",
      "train reg_fs: 0.0016289653722196817\n",
      "Epoch: 8500 train loss=0.004038322 valid loss= 0.004286589\n",
      "train reg_fs: 0.0016213024500757456\n",
      "Epoch: 9000 train loss=0.004374240 valid loss= 0.004453612\n",
      "train reg_fs: 0.001614212989807129\n",
      "Epoch: 9500 train loss=0.001843928 valid loss= 0.004069387\n",
      "train reg_fs: 0.001608623773790896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:52:41,535]\u001b[0m Trial 65 finished with value: 0.0024957724128176024 and parameters: {'lam': 0.00219874302520522, 'learning_rate': 0.04803987148561819, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006336126 valid loss= 0.004064438\n",
      "train reg_fs: 0.0016032112762331963\n",
      "Optimization Finished!\n",
      "test loss: 0.004073675721883774, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024957724128176024\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005171132 valid loss= 0.006909765\n",
      "train reg_fs: 0.0009958851151168346\n",
      "Epoch: 1000 train loss=0.004969244 valid loss= 0.007742630\n",
      "train reg_fs: 0.0009975408902391791\n",
      "Epoch: 1500 train loss=0.003341628 valid loss= 0.007445071\n",
      "train reg_fs: 0.0009771520271897316\n",
      "Epoch: 2000 train loss=0.004786694 valid loss= 0.005815206\n",
      "train reg_fs: 0.0009610911947675049\n",
      "Epoch: 2500 train loss=0.010474749 valid loss= 0.005077073\n",
      "train reg_fs: 0.0009504061308689415\n",
      "Epoch: 3000 train loss=0.004374910 valid loss= 0.004884223\n",
      "train reg_fs: 0.0009399547125212848\n",
      "Epoch: 3500 train loss=0.003052405 valid loss= 0.004838163\n",
      "train reg_fs: 0.0009334470960311592\n",
      "Epoch: 4000 train loss=0.006957702 valid loss= 0.004191959\n",
      "train reg_fs: 0.0009254260803572834\n",
      "Epoch: 4500 train loss=0.007095465 valid loss= 0.004624918\n",
      "train reg_fs: 0.000918495818041265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:53:13,927]\u001b[0m Trial 66 finished with value: 0.003519095593848347 and parameters: {'lam': 0.0011327163509613075, 'learning_rate': 0.10152338847945079, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003878399 valid loss= 0.004447358\n",
      "train reg_fs: 0.0009130790713243186\n",
      "Optimization Finished!\n",
      "test loss: 0.005047664977610111, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003519095593848347\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009129351 valid loss= 0.008925227\n",
      "train reg_fs: 0.0033114836551249027\n",
      "Epoch: 1000 train loss=0.007639999 valid loss= 0.009081509\n",
      "train reg_fs: 0.00323458481580019\n",
      "Epoch: 1500 train loss=0.003444748 valid loss= 0.007355659\n",
      "train reg_fs: 0.0030589161906391382\n",
      "Epoch: 2000 train loss=0.004360034 valid loss= 0.006235817\n",
      "train reg_fs: 0.0028726414311677217\n",
      "Epoch: 2500 train loss=0.004336568 valid loss= 0.006063625\n",
      "train reg_fs: 0.002723387908190489\n",
      "Epoch: 3000 train loss=0.004560194 valid loss= 0.005642027\n",
      "train reg_fs: 0.002613698597997427\n",
      "Epoch: 3500 train loss=0.003677579 valid loss= 0.005467844\n",
      "train reg_fs: 0.002536872634664178\n",
      "Epoch: 4000 train loss=0.003186330 valid loss= 0.005013780\n",
      "train reg_fs: 0.0024752377066761255\n",
      "Epoch: 4500 train loss=0.002914032 valid loss= 0.004989572\n",
      "train reg_fs: 0.002432572655379772\n",
      "Epoch: 5000 train loss=0.002916950 valid loss= 0.004873719\n",
      "train reg_fs: 0.0024015665985643864\n",
      "Epoch: 5500 train loss=0.002937668 valid loss= 0.004907772\n",
      "train reg_fs: 0.00237760366871953\n",
      "Epoch: 6000 train loss=0.003547480 valid loss= 0.004905068\n",
      "train reg_fs: 0.002359602600336075\n",
      "Epoch: 6500 train loss=0.004179890 valid loss= 0.004785772\n",
      "train reg_fs: 0.0023457363713532686\n",
      "Epoch: 7000 train loss=0.017052213 valid loss= 0.004599115\n",
      "train reg_fs: 0.0023350699339061975\n",
      "Epoch: 7500 train loss=0.003566899 valid loss= 0.004729915\n",
      "train reg_fs: 0.0023265108466148376\n",
      "Epoch: 8000 train loss=0.003628771 valid loss= 0.004589887\n",
      "train reg_fs: 0.0023190025240182877\n",
      "Epoch: 8500 train loss=0.005658733 valid loss= 0.004348530\n",
      "train reg_fs: 0.002312763361260295\n",
      "Epoch: 9000 train loss=0.004992466 valid loss= 0.004902854\n",
      "train reg_fs: 0.0023075256031006575\n",
      "Epoch: 9500 train loss=0.002586798 valid loss= 0.004226249\n",
      "train reg_fs: 0.0023028419818729162\n",
      "Epoch: 10000 train loss=0.003137728 valid loss= 0.004823769\n",
      "train reg_fs: 0.0022987686097621918\n",
      "Epoch: 10500 train loss=0.003276567 valid loss= 0.004596799\n",
      "train reg_fs: 0.002295290119946003\n",
      "Epoch: 11000 train loss=0.005115899 valid loss= 0.004636762\n",
      "train reg_fs: 0.0022919662296772003\n",
      "Epoch: 11500 train loss=0.003312436 valid loss= 0.004024861\n",
      "train reg_fs: 0.0022893277928233147\n",
      "Epoch: 12000 train loss=0.005028911 valid loss= 0.004427075\n",
      "train reg_fs: 0.0022871100809425116\n",
      "Epoch: 12500 train loss=0.002762226 valid loss= 0.004481220\n",
      "train reg_fs: 0.0022848600056022406\n",
      "Epoch: 13000 train loss=0.003796968 valid loss= 0.004344597\n",
      "train reg_fs: 0.002282840898260474\n",
      "Epoch: 13500 train loss=0.002667355 valid loss= 0.004435556\n",
      "train reg_fs: 0.002281165448948741\n",
      "Epoch: 14000 train loss=0.005336096 valid loss= 0.004600139\n",
      "train reg_fs: 0.002279620850458741\n",
      "Epoch: 14500 train loss=0.002658087 valid loss= 0.004380215\n",
      "train reg_fs: 0.0022782767191529274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:54:49,972]\u001b[0m Trial 67 finished with value: 0.002208770586060245 and parameters: {'lam': 0.0037773832474844614, 'learning_rate': 0.12284091120967645, 'num_epoch': 15000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002415048 valid loss= 0.004427293\n",
      "train reg_fs: 0.00227689603343606\n",
      "Optimization Finished!\n",
      "test loss: 0.004262234549969435, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002208770586060245\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016253620 valid loss= 0.008832194\n",
      "train reg_fs: 0.0023402597289532423\n",
      "Epoch: 1000 train loss=0.008391496 valid loss= 0.008875038\n",
      "train reg_fs: 0.0023703635670244694\n",
      "Epoch: 1500 train loss=0.011403805 valid loss= 0.008356908\n",
      "train reg_fs: 0.0023800430353730917\n",
      "Epoch: 2000 train loss=0.016610952 valid loss= 0.007969871\n",
      "train reg_fs: 0.0023714895360171795\n",
      "Epoch: 2500 train loss=0.009463028 valid loss= 0.007618327\n",
      "train reg_fs: 0.002344536129385233\n",
      "Epoch: 3000 train loss=0.004621100 valid loss= 0.007357819\n",
      "train reg_fs: 0.002308155642822385\n",
      "Epoch: 3500 train loss=0.007666410 valid loss= 0.006974697\n",
      "train reg_fs: 0.0022723828442394733\n",
      "Epoch: 4000 train loss=0.007359988 valid loss= 0.005754591\n",
      "train reg_fs: 0.002239946275949478\n",
      "Epoch: 4500 train loss=0.008950859 valid loss= 0.005112298\n",
      "train reg_fs: 0.002202145289629698\n",
      "Epoch: 5000 train loss=0.003891762 valid loss= 0.004419249\n",
      "train reg_fs: 0.002160554751753807\n",
      "Epoch: 5500 train loss=0.005138227 valid loss= 0.004199957\n",
      "train reg_fs: 0.002126495586708188\n",
      "Epoch: 6000 train loss=0.005526854 valid loss= 0.004235354\n",
      "train reg_fs: 0.0020976050291210413\n",
      "Epoch: 6500 train loss=0.004255576 valid loss= 0.004225857\n",
      "train reg_fs: 0.0020745156798511744\n",
      "Epoch: 7000 train loss=0.003689974 valid loss= 0.004160951\n",
      "train reg_fs: 0.0020526188891381025\n",
      "Epoch: 7500 train loss=0.004288377 valid loss= 0.004218464\n",
      "train reg_fs: 0.0020338587928563356\n",
      "Epoch: 8000 train loss=0.002932580 valid loss= 0.003958681\n",
      "train reg_fs: 0.0020165443420410156\n",
      "Epoch: 8500 train loss=0.011088673 valid loss= 0.004407676\n",
      "train reg_fs: 0.002000985201448202\n",
      "Epoch: 9000 train loss=0.007340767 valid loss= 0.004131507\n",
      "train reg_fs: 0.0019865890499204397\n",
      "Epoch: 9500 train loss=0.003649204 valid loss= 0.004125574\n",
      "train reg_fs: 0.001970002893358469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:55:53,798]\u001b[0m Trial 68 finished with value: 0.0021077445736062445 and parameters: {'lam': 0.0027140132175923737, 'learning_rate': 0.04208654509543434, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005074703 valid loss= 0.004059483\n",
      "train reg_fs: 0.001956261694431305\n",
      "Optimization Finished!\n",
      "test loss: 0.003940656781196594, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021077445736062445\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015083735 valid loss= 0.008453795\n",
      "train reg_fs: 0.0025267291348427534\n",
      "Epoch: 1000 train loss=0.007263578 valid loss= 0.008666264\n",
      "train reg_fs: 0.002496415749192238\n",
      "Epoch: 1500 train loss=0.008443125 valid loss= 0.006836697\n",
      "train reg_fs: 0.0024389319587498903\n",
      "Epoch: 2000 train loss=0.011204377 valid loss= 0.006647138\n",
      "train reg_fs: 0.002395695075392723\n",
      "Epoch: 2500 train loss=0.013441063 valid loss= 0.005417463\n",
      "train reg_fs: 0.002351650269702077\n",
      "Epoch: 3000 train loss=0.006144134 valid loss= 0.005039391\n",
      "train reg_fs: 0.0023046580608934164\n",
      "Epoch: 3500 train loss=0.004508143 valid loss= 0.004971965\n",
      "train reg_fs: 0.0022630849853157997\n",
      "Epoch: 4000 train loss=0.003584924 valid loss= 0.004956619\n",
      "train reg_fs: 0.0022292218636721373\n",
      "Epoch: 4500 train loss=0.004296188 valid loss= 0.005278089\n",
      "train reg_fs: 0.002205722499638796\n",
      "Epoch: 5000 train loss=0.005022916 valid loss= 0.005529472\n",
      "train reg_fs: 0.00218363874591887\n",
      "Epoch: 5500 train loss=0.006113832 valid loss= 0.005489297\n",
      "train reg_fs: 0.002162141026929021\n",
      "Epoch: 6000 train loss=0.005948035 valid loss= 0.005370414\n",
      "train reg_fs: 0.0021432358771562576\n",
      "Epoch: 6500 train loss=0.006519784 valid loss= 0.005752079\n",
      "train reg_fs: 0.0021288376301527023\n",
      "Epoch: 7000 train loss=0.004133776 valid loss= 0.005944712\n",
      "train reg_fs: 0.0021140039898455143\n",
      "Epoch: 7500 train loss=0.003723240 valid loss= 0.006128414\n",
      "train reg_fs: 0.0020992958452552557\n",
      "Epoch: 8000 train loss=0.002706909 valid loss= 0.006054362\n",
      "train reg_fs: 0.0020875411573797464\n",
      "Epoch: 8500 train loss=0.003450042 valid loss= 0.005749311\n",
      "train reg_fs: 0.002078127348795533\n",
      "Epoch: 9000 train loss=0.006099486 valid loss= 0.006145314\n",
      "train reg_fs: 0.0020680574234575033\n",
      "Epoch: 9500 train loss=0.006134141 valid loss= 0.006449633\n",
      "train reg_fs: 0.002060230588540435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:57:00,734]\u001b[0m Trial 69 finished with value: 0.004195955328567663 and parameters: {'lam': 0.002945371982065782, 'learning_rate': 0.058208886098003704, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003118539 valid loss= 0.006304218\n",
      "train reg_fs: 0.0020520940888673067\n",
      "Optimization Finished!\n",
      "test loss: 0.005985668394714594, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004195955328567663\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010919452 valid loss= 0.011369864\n",
      "train reg_fs: 0.003700469620525837\n",
      "Epoch: 1000 train loss=0.018097540 valid loss= 0.010765526\n",
      "train reg_fs: 0.0037385059986263514\n",
      "Epoch: 1500 train loss=0.012922080 valid loss= 0.010524351\n",
      "train reg_fs: 0.0037548555992543697\n",
      "Epoch: 2000 train loss=0.016184954 valid loss= 0.010275614\n",
      "train reg_fs: 0.0037469856906682253\n",
      "Epoch: 2500 train loss=0.013338098 valid loss= 0.009392646\n",
      "train reg_fs: 0.0037135316524654627\n",
      "Epoch: 3000 train loss=0.007479594 valid loss= 0.009021185\n",
      "train reg_fs: 0.0036589843221008778\n",
      "Epoch: 3500 train loss=0.011648607 valid loss= 0.008364901\n",
      "train reg_fs: 0.00357523700222373\n",
      "Epoch: 4000 train loss=0.005607172 valid loss= 0.007485883\n",
      "train reg_fs: 0.0034821738954633474\n",
      "Epoch: 4500 train loss=0.008945365 valid loss= 0.006671555\n",
      "train reg_fs: 0.0033909804187715054\n",
      "Epoch: 5000 train loss=0.009128345 valid loss= 0.006719159\n",
      "train reg_fs: 0.0033240995835512877\n",
      "Epoch: 5500 train loss=0.007070058 valid loss= 0.006395853\n",
      "train reg_fs: 0.0032758936285972595\n",
      "Epoch: 6000 train loss=0.008385438 valid loss= 0.006740328\n",
      "train reg_fs: 0.0032388034742325544\n",
      "Epoch: 6500 train loss=0.007940926 valid loss= 0.006544468\n",
      "train reg_fs: 0.0032105466816574335\n",
      "Epoch: 7000 train loss=0.004216282 valid loss= 0.006498303\n",
      "train reg_fs: 0.0031830905936658382\n",
      "Epoch: 7500 train loss=0.005938586 valid loss= 0.006548304\n",
      "train reg_fs: 0.0031584594398736954\n",
      "Epoch: 8000 train loss=0.004472616 valid loss= 0.006625710\n",
      "train reg_fs: 0.003135939361527562\n",
      "Epoch: 8500 train loss=0.012117124 valid loss= 0.006702223\n",
      "train reg_fs: 0.0031149748247116804\n",
      "Epoch: 9000 train loss=0.004279954 valid loss= 0.006952395\n",
      "train reg_fs: 0.0030946473125368357\n",
      "Epoch: 9500 train loss=0.008931505 valid loss= 0.006913438\n",
      "train reg_fs: 0.0030744068790227175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:58:05,484]\u001b[0m Trial 70 finished with value: 0.0036897703643382356 and parameters: {'lam': 0.004305454609680487, 'learning_rate': 0.030936634694229363, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.009167041 valid loss= 0.006794317\n",
      "train reg_fs: 0.0030547657515853643\n",
      "Optimization Finished!\n",
      "test loss: 0.007322211749851704, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0036897703643382356\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005034609 valid loss= 0.007973399\n",
      "train reg_fs: 0.0012605941155925393\n",
      "Epoch: 1000 train loss=0.005099300 valid loss= 0.006472527\n",
      "train reg_fs: 0.0011900619138032198\n",
      "Epoch: 1500 train loss=0.003092128 valid loss= 0.004392792\n",
      "train reg_fs: 0.0011103571159765124\n",
      "Epoch: 2000 train loss=0.005785737 valid loss= 0.003864651\n",
      "train reg_fs: 0.0010325949406251311\n",
      "Epoch: 2500 train loss=0.002111008 valid loss= 0.003730748\n",
      "train reg_fs: 0.0009923115139827132\n",
      "Epoch: 3000 train loss=0.001292940 valid loss= 0.003401317\n",
      "train reg_fs: 0.0009688091813586652\n",
      "Epoch: 3500 train loss=0.001540952 valid loss= 0.003397782\n",
      "train reg_fs: 0.0009511494426988065\n",
      "Epoch: 4000 train loss=0.002485310 valid loss= 0.003138162\n",
      "train reg_fs: 0.0009380512055940926\n",
      "Epoch: 4500 train loss=0.001835846 valid loss= 0.003369751\n",
      "train reg_fs: 0.0009284315165132284\n",
      "Epoch: 5000 train loss=0.003344420 valid loss= 0.003686842\n",
      "train reg_fs: 0.0009205975220538676\n",
      "Epoch: 5500 train loss=0.001353461 valid loss= 0.003358808\n",
      "train reg_fs: 0.0009148961398750544\n",
      "Epoch: 6000 train loss=0.007026598 valid loss= 0.003740057\n",
      "train reg_fs: 0.0009094115230254829\n",
      "Epoch: 6500 train loss=0.001389809 valid loss= 0.003335936\n",
      "train reg_fs: 0.0009053520625457168\n",
      "Epoch: 7000 train loss=0.001184548 valid loss= 0.003143818\n",
      "train reg_fs: 0.000902025552932173\n",
      "Epoch: 7500 train loss=0.001098134 valid loss= 0.003187459\n",
      "train reg_fs: 0.0008991255308501422\n",
      "Epoch: 8000 train loss=0.001460538 valid loss= 0.003176718\n",
      "train reg_fs: 0.0008967109024524689\n",
      "Epoch: 8500 train loss=0.002288293 valid loss= 0.003298286\n",
      "train reg_fs: 0.0008945268345996737\n",
      "Epoch: 9000 train loss=0.001114468 valid loss= 0.003405015\n",
      "train reg_fs: 0.0008926388691179454\n",
      "Epoch: 9500 train loss=0.001844089 valid loss= 0.003189875\n",
      "train reg_fs: 0.0008909064345061779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:59:12,006]\u001b[0m Trial 71 finished with value: 0.002282607997422044 and parameters: {'lam': 0.0014591595435598707, 'learning_rate': 0.15340611766607612, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002155321 valid loss= 0.003154074\n",
      "train reg_fs: 0.0008894799393601716\n",
      "Optimization Finished!\n",
      "test loss: 0.0029765681829303503, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002282607997422044\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007273301 valid loss= 0.007597625\n",
      "train reg_fs: 0.001559901051223278\n",
      "Epoch: 1000 train loss=0.003141047 valid loss= 0.004403617\n",
      "train reg_fs: 0.0014436003984883428\n",
      "Epoch: 1500 train loss=0.003425047 valid loss= 0.004086030\n",
      "train reg_fs: 0.0013508511474356055\n",
      "Epoch: 2000 train loss=0.001918191 valid loss= 0.004267930\n",
      "train reg_fs: 0.0012872901279479265\n",
      "Epoch: 2500 train loss=0.003539121 valid loss= 0.004234327\n",
      "train reg_fs: 0.0012450235662981868\n",
      "Epoch: 3000 train loss=0.002653296 valid loss= 0.003634466\n",
      "train reg_fs: 0.0012184918159618974\n",
      "Epoch: 3500 train loss=0.002536237 valid loss= 0.003887192\n",
      "train reg_fs: 0.0011987684993073344\n",
      "Epoch: 4000 train loss=0.003335430 valid loss= 0.003764484\n",
      "train reg_fs: 0.0011832816526293755\n",
      "Epoch: 4500 train loss=0.004783395 valid loss= 0.003538989\n",
      "train reg_fs: 0.0011705670040100813\n",
      "Epoch: 5000 train loss=0.002151218 valid loss= 0.003437642\n",
      "train reg_fs: 0.0011604409664869308\n",
      "Epoch: 5500 train loss=0.004055303 valid loss= 0.003383670\n",
      "train reg_fs: 0.0011521871201694012\n",
      "Epoch: 6000 train loss=0.005892976 valid loss= 0.003536178\n",
      "train reg_fs: 0.001145050162449479\n",
      "Epoch: 6500 train loss=0.001550196 valid loss= 0.003059875\n",
      "train reg_fs: 0.001138939755037427\n",
      "Epoch: 7000 train loss=0.002992615 valid loss= 0.003511572\n",
      "train reg_fs: 0.0011342543875798583\n",
      "Epoch: 7500 train loss=0.001541060 valid loss= 0.003561474\n",
      "train reg_fs: 0.0011296720476821065\n",
      "Epoch: 8000 train loss=0.001816837 valid loss= 0.003393699\n",
      "train reg_fs: 0.001126188668422401\n",
      "Epoch: 8500 train loss=0.001368189 valid loss= 0.003443575\n",
      "train reg_fs: 0.0011230321833863854\n",
      "Epoch: 9000 train loss=0.003319234 valid loss= 0.003429554\n",
      "train reg_fs: 0.0011204323964193463\n",
      "Epoch: 9500 train loss=0.004702207 valid loss= 0.003366290\n",
      "train reg_fs: 0.0011182022280991077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:00:17,401]\u001b[0m Trial 72 finished with value: 0.002312025374870091 and parameters: {'lam': 0.001836160537853651, 'learning_rate': 0.18240081749584527, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005236533 valid loss= 0.003404051\n",
      "train reg_fs: 0.001116344821639359\n",
      "Optimization Finished!\n",
      "test loss: 0.00312068872153759, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002312025374870091\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008543915 valid loss= 0.009281321\n",
      "train reg_fs: 0.0016668380703777075\n",
      "Epoch: 1000 train loss=0.013349457 valid loss= 0.008906070\n",
      "train reg_fs: 0.0016791612142696977\n",
      "Epoch: 1500 train loss=0.016135463 valid loss= 0.009282829\n",
      "train reg_fs: 0.001689159544184804\n",
      "Epoch: 2000 train loss=0.025036965 valid loss= 0.008452202\n",
      "train reg_fs: 0.0016978251514956355\n",
      "Epoch: 2500 train loss=0.008824851 valid loss= 0.008293892\n",
      "train reg_fs: 0.0017055085627362132\n",
      "Epoch: 3000 train loss=0.010312855 valid loss= 0.008137868\n",
      "train reg_fs: 0.001711458433419466\n",
      "Epoch: 3500 train loss=0.012372398 valid loss= 0.007816109\n",
      "train reg_fs: 0.0017166024772450328\n",
      "Epoch: 4000 train loss=0.015967378 valid loss= 0.007892347\n",
      "train reg_fs: 0.0017207948258146644\n",
      "Epoch: 4500 train loss=0.011418130 valid loss= 0.007468690\n",
      "train reg_fs: 0.0017237646970897913\n",
      "Epoch: 5000 train loss=0.010642291 valid loss= 0.007323068\n",
      "train reg_fs: 0.0017258579609915614\n",
      "Epoch: 5500 train loss=0.010022053 valid loss= 0.007291954\n",
      "train reg_fs: 0.0017262691399082541\n",
      "Epoch: 6000 train loss=0.008325801 valid loss= 0.007092635\n",
      "train reg_fs: 0.0017256347928196192\n",
      "Epoch: 6500 train loss=0.007537705 valid loss= 0.007010175\n",
      "train reg_fs: 0.0017238748259842396\n",
      "Epoch: 7000 train loss=0.011553089 valid loss= 0.007174765\n",
      "train reg_fs: 0.0017210942460224032\n",
      "Epoch: 7500 train loss=0.009595007 valid loss= 0.006702294\n",
      "train reg_fs: 0.0017169393831864\n",
      "Epoch: 8000 train loss=0.015621034 valid loss= 0.006966525\n",
      "train reg_fs: 0.001711312448605895\n",
      "Epoch: 8500 train loss=0.009920997 valid loss= 0.006880095\n",
      "train reg_fs: 0.0017039927188307047\n",
      "Epoch: 9000 train loss=0.010021758 valid loss= 0.006384443\n",
      "train reg_fs: 0.0016952584264799953\n",
      "Epoch: 9500 train loss=0.008938668 valid loss= 0.006279129\n",
      "train reg_fs: 0.0016846404178068042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:01:24,447]\u001b[0m Trial 73 finished with value: 0.00468599318585558 and parameters: {'lam': 0.0019638030245428353, 'learning_rate': 0.010151726192918592, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007390835 valid loss= 0.006360436\n",
      "train reg_fs: 0.0016738880658522248\n",
      "Optimization Finished!\n",
      "test loss: 0.006918004713952541, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00468599318585558\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008020282 valid loss= 0.006435527\n",
      "train reg_fs: 0.001164918765425682\n",
      "Epoch: 1000 train loss=0.012309343 valid loss= 0.005482026\n",
      "train reg_fs: 0.0011419043876230717\n",
      "Epoch: 1500 train loss=0.002681794 valid loss= 0.003937609\n",
      "train reg_fs: 0.0010719968704506755\n",
      "Epoch: 2000 train loss=0.004684833 valid loss= 0.004063850\n",
      "train reg_fs: 0.001026999787427485\n",
      "Epoch: 2500 train loss=0.006593150 valid loss= 0.003721693\n",
      "train reg_fs: 0.0010049602715298533\n",
      "Epoch: 3000 train loss=0.001787858 valid loss= 0.004593366\n",
      "train reg_fs: 0.000989672727882862\n",
      "Epoch: 3500 train loss=0.001903222 valid loss= 0.003863925\n",
      "train reg_fs: 0.0009785391157492995\n",
      "Epoch: 4000 train loss=0.006900027 valid loss= 0.003892113\n",
      "train reg_fs: 0.0009703643154352903\n",
      "Epoch: 4500 train loss=0.006384811 valid loss= 0.003548657\n",
      "train reg_fs: 0.0009640100179240108\n",
      "Epoch: 5000 train loss=0.002391962 valid loss= 0.003416460\n",
      "train reg_fs: 0.0009589707478880882\n",
      "Epoch: 5500 train loss=0.003501786 valid loss= 0.003312941\n",
      "train reg_fs: 0.0009541736217215657\n",
      "Epoch: 6000 train loss=0.004252051 valid loss= 0.003227655\n",
      "train reg_fs: 0.000949980691075325\n",
      "Epoch: 6500 train loss=0.002072609 valid loss= 0.003619475\n",
      "train reg_fs: 0.0009466715855523944\n",
      "Epoch: 7000 train loss=0.001684743 valid loss= 0.002946405\n",
      "train reg_fs: 0.0009437324479222298\n",
      "Epoch: 7500 train loss=0.002065439 valid loss= 0.003325589\n",
      "train reg_fs: 0.0009412305662408471\n",
      "Epoch: 8000 train loss=0.001977938 valid loss= 0.002992094\n",
      "train reg_fs: 0.00093908078270033\n",
      "Epoch: 8500 train loss=0.001176912 valid loss= 0.003303966\n",
      "train reg_fs: 0.0009371773339807987\n",
      "Epoch: 9000 train loss=0.001700940 valid loss= 0.003674988\n",
      "train reg_fs: 0.0009351737680844963\n",
      "Epoch: 9500 train loss=0.004289812 valid loss= 0.003043862\n",
      "train reg_fs: 0.0009333650232292712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:02:30,529]\u001b[0m Trial 74 finished with value: 0.0022753628086627526 and parameters: {'lam': 0.0013053907103314352, 'learning_rate': 0.13536837138872845, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.011538651 valid loss= 0.003170679\n",
      "train reg_fs: 0.0009319578530266881\n",
      "Optimization Finished!\n",
      "test loss: 0.003029986983165145, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022753628086627526\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006661383 valid loss= 0.006473785\n",
      "train reg_fs: 0.0029505628626793623\n",
      "Epoch: 1000 train loss=0.004868065 valid loss= 0.006625143\n",
      "train reg_fs: 0.0028147604316473007\n",
      "Epoch: 1500 train loss=0.006495086 valid loss= 0.005374757\n",
      "train reg_fs: 0.0026753896381706\n",
      "Epoch: 2000 train loss=0.012679936 valid loss= 0.005558836\n",
      "train reg_fs: 0.002616115612909198\n",
      "Epoch: 2500 train loss=0.003233755 valid loss= 0.005765324\n",
      "train reg_fs: 0.0025585119146853685\n",
      "Epoch: 3000 train loss=0.003909466 valid loss= 0.005291397\n",
      "train reg_fs: 0.0024880613200366497\n",
      "Epoch: 3500 train loss=0.003559155 valid loss= 0.005171405\n",
      "train reg_fs: 0.002413926413282752\n",
      "Epoch: 4000 train loss=0.005435800 valid loss= 0.005256781\n",
      "train reg_fs: 0.0023442264646291733\n",
      "Epoch: 4500 train loss=0.003818989 valid loss= 0.005128074\n",
      "train reg_fs: 0.0022819554433226585\n",
      "Epoch: 5000 train loss=0.005153956 valid loss= 0.004731648\n",
      "train reg_fs: 0.002237076871097088\n",
      "Epoch: 5500 train loss=0.003945874 valid loss= 0.004525827\n",
      "train reg_fs: 0.0022016961593180895\n",
      "Epoch: 6000 train loss=0.004829573 valid loss= 0.004470089\n",
      "train reg_fs: 0.0021745224948972464\n",
      "Epoch: 6500 train loss=0.002665136 valid loss= 0.004327876\n",
      "train reg_fs: 0.002153912326321006\n",
      "Epoch: 7000 train loss=0.003684343 valid loss= 0.004665401\n",
      "train reg_fs: 0.0021384928841143847\n",
      "Epoch: 7500 train loss=0.003589449 valid loss= 0.004507467\n",
      "train reg_fs: 0.0021264576353132725\n",
      "Epoch: 8000 train loss=0.002299587 valid loss= 0.004557393\n",
      "train reg_fs: 0.002117237774655223\n",
      "Epoch: 8500 train loss=0.002980274 valid loss= 0.004378852\n",
      "train reg_fs: 0.002109331777319312\n",
      "Epoch: 9000 train loss=0.005371629 valid loss= 0.004338362\n",
      "train reg_fs: 0.0021028537303209305\n",
      "Epoch: 9500 train loss=0.002303571 valid loss= 0.004399589\n",
      "train reg_fs: 0.0020972799975425005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:03:34,735]\u001b[0m Trial 75 finished with value: 0.0021661245430035104 and parameters: {'lam': 0.003425561477869334, 'learning_rate': 0.11280199137968476, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002387079 valid loss= 0.004214069\n",
      "train reg_fs: 0.0020926969591528177\n",
      "Optimization Finished!\n",
      "test loss: 0.004069620743393898, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021661245430035104\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014329422 valid loss= 0.008636593\n",
      "train reg_fs: 0.0022026081569492817\n",
      "Epoch: 1000 train loss=0.008433489 valid loss= 0.009176907\n",
      "train reg_fs: 0.0022117183543741703\n",
      "Epoch: 1500 train loss=0.007689714 valid loss= 0.008204760\n",
      "train reg_fs: 0.0021538729779422283\n",
      "Epoch: 2000 train loss=0.013068469 valid loss= 0.007513530\n",
      "train reg_fs: 0.0021082679741084576\n",
      "Epoch: 2500 train loss=0.007341475 valid loss= 0.007408763\n",
      "train reg_fs: 0.0020730174146592617\n",
      "Epoch: 3000 train loss=0.005699445 valid loss= 0.005987179\n",
      "train reg_fs: 0.0020448777358978987\n",
      "Epoch: 3500 train loss=0.009057441 valid loss= 0.005623864\n",
      "train reg_fs: 0.002018803032115102\n",
      "Epoch: 4000 train loss=0.004373124 valid loss= 0.004499633\n",
      "train reg_fs: 0.0019915695302188396\n",
      "Epoch: 4500 train loss=0.004720528 valid loss= 0.004278424\n",
      "train reg_fs: 0.0019509801641106606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:04:08,766]\u001b[0m Trial 76 finished with value: 0.0020388100045361118 and parameters: {'lam': 0.0025130602931911633, 'learning_rate': 0.09309699265454331, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003549146 valid loss= 0.003973599\n",
      "train reg_fs: 0.0019036000594496727\n",
      "Optimization Finished!\n",
      "test loss: 0.003955022431910038, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020388100045361118\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020802235 valid loss= 0.007640810\n",
      "train reg_fs: 0.0013742088340222836\n",
      "Epoch: 1000 train loss=0.008931926 valid loss= 0.006797620\n",
      "train reg_fs: 0.0013876858865842223\n",
      "Epoch: 1500 train loss=0.011103616 valid loss= 0.006003939\n",
      "train reg_fs: 0.0013709509512409568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:04:23,195]\u001b[0m Trial 77 finished with value: 0.00469713137989943 and parameters: {'lam': 0.0015744864186683033, 'learning_rate': 0.08291867932307083, 'num_epoch': 2000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.004319896 valid loss= 0.006071822\n",
      "train reg_fs: 0.0013448968529701233\n",
      "Optimization Finished!\n",
      "test loss: 0.006224377080798149, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00469713137989943\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005554932 valid loss= 0.008165254\n",
      "train reg_fs: 0.002018623286858201\n",
      "Epoch: 1000 train loss=0.003577152 valid loss= 0.005808826\n",
      "train reg_fs: 0.001935994834639132\n",
      "Epoch: 1500 train loss=0.003471023 valid loss= 0.004358297\n",
      "train reg_fs: 0.0018654201412573457\n",
      "Epoch: 2000 train loss=0.003747474 valid loss= 0.004324273\n",
      "train reg_fs: 0.0018044422613456845\n",
      "Epoch: 2500 train loss=0.003080630 valid loss= 0.004845861\n",
      "train reg_fs: 0.0017691627144813538\n",
      "Epoch: 3000 train loss=0.004638502 valid loss= 0.004687134\n",
      "train reg_fs: 0.001734023680910468\n",
      "Epoch: 3500 train loss=0.002524513 valid loss= 0.004787271\n",
      "train reg_fs: 0.0016955963801592588\n",
      "Epoch: 4000 train loss=0.003141636 valid loss= 0.004957674\n",
      "train reg_fs: 0.0016519248019903898\n",
      "Epoch: 4500 train loss=0.002743132 valid loss= 0.004529497\n",
      "train reg_fs: 0.001614206819795072\n",
      "Epoch: 5000 train loss=0.002025215 valid loss= 0.004150311\n",
      "train reg_fs: 0.0015836452366784215\n",
      "Epoch: 5500 train loss=0.005268024 valid loss= 0.004014467\n",
      "train reg_fs: 0.0015505903866142035\n",
      "Epoch: 6000 train loss=0.004515449 valid loss= 0.003830336\n",
      "train reg_fs: 0.001526879845187068\n",
      "Epoch: 6500 train loss=0.004356926 valid loss= 0.004047536\n",
      "train reg_fs: 0.001507082604803145\n",
      "Epoch: 7000 train loss=0.001906134 valid loss= 0.003766686\n",
      "train reg_fs: 0.0014922746922820807\n",
      "Epoch: 7500 train loss=0.002128565 valid loss= 0.003873992\n",
      "train reg_fs: 0.0014802163932472467\n",
      "Epoch: 8000 train loss=0.001838424 valid loss= 0.003825455\n",
      "train reg_fs: 0.0014699778985232115\n",
      "Epoch: 8500 train loss=0.004512044 valid loss= 0.004321099\n",
      "train reg_fs: 0.001460396102629602\n",
      "Epoch: 9000 train loss=0.002811174 valid loss= 0.003913315\n",
      "train reg_fs: 0.001453637727536261\n",
      "Epoch: 9500 train loss=0.002034331 valid loss= 0.003749910\n",
      "train reg_fs: 0.0014481425751000643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:05:28,627]\u001b[0m Trial 78 finished with value: 0.0021961747197482284 and parameters: {'lam': 0.002339754086505021, 'learning_rate': 0.12697017663406632, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001622495 valid loss= 0.003618550\n",
      "train reg_fs: 0.0014431476593017578\n",
      "Optimization Finished!\n",
      "test loss: 0.00350006646476686, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021961747197482284\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011615751 valid loss= 0.007518075\n",
      "train reg_fs: 0.00147150456905365\n",
      "Epoch: 1000 train loss=0.008145676 valid loss= 0.006175168\n",
      "train reg_fs: 0.0014355165185406804\n",
      "Epoch: 1500 train loss=0.010823304 valid loss= 0.004471925\n",
      "train reg_fs: 0.0013924536760896444\n",
      "Epoch: 2000 train loss=0.004566198 valid loss= 0.003600670\n",
      "train reg_fs: 0.0013611647300422192\n",
      "Epoch: 2500 train loss=0.004327210 valid loss= 0.003543183\n",
      "train reg_fs: 0.0013465193333104253\n",
      "Epoch: 3000 train loss=0.004317023 valid loss= 0.003497011\n",
      "train reg_fs: 0.0013385963393375278\n",
      "Epoch: 3500 train loss=0.004136893 valid loss= 0.003479573\n",
      "train reg_fs: 0.0013292927760630846\n",
      "Epoch: 4000 train loss=0.003683298 valid loss= 0.003615428\n",
      "train reg_fs: 0.0013185141142457724\n",
      "Epoch: 4500 train loss=0.006871340 valid loss= 0.003818214\n",
      "train reg_fs: 0.0013068589614704251\n",
      "Epoch: 5000 train loss=0.002504690 valid loss= 0.003852151\n",
      "train reg_fs: 0.0012975462013855577\n",
      "Epoch: 5500 train loss=0.002644158 valid loss= 0.003960937\n",
      "train reg_fs: 0.0012889014324173331\n",
      "Epoch: 6000 train loss=0.006003311 valid loss= 0.003843820\n",
      "train reg_fs: 0.0012827269965782762\n",
      "Epoch: 6500 train loss=0.001839821 valid loss= 0.003802834\n",
      "train reg_fs: 0.0012777773663401604\n",
      "Epoch: 7000 train loss=0.005711140 valid loss= 0.003695580\n",
      "train reg_fs: 0.0012735271593555808\n",
      "Epoch: 7500 train loss=0.001841725 valid loss= 0.003664164\n",
      "train reg_fs: 0.001269639004021883\n",
      "Epoch: 8000 train loss=0.001519970 valid loss= 0.003290015\n",
      "train reg_fs: 0.001266016741283238\n",
      "Epoch: 8500 train loss=0.003158947 valid loss= 0.003337254\n",
      "train reg_fs: 0.0012627077521756291\n",
      "Epoch: 9000 train loss=0.002023903 valid loss= 0.003342236\n",
      "train reg_fs: 0.001259227516129613\n",
      "Epoch: 9500 train loss=0.003235872 valid loss= 0.003281559\n",
      "train reg_fs: 0.0012560433242470026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:06:33,127]\u001b[0m Trial 79 finished with value: 0.002316585542741228 and parameters: {'lam': 0.0017045893235980544, 'learning_rate': 0.07502660454550376, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003252367 valid loss= 0.003532840\n",
      "train reg_fs: 0.001253436435945332\n",
      "Optimization Finished!\n",
      "test loss: 0.0033492473885416985, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002316585542741228\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012038649 valid loss= 0.008990534\n",
      "train reg_fs: 0.002688260981813073\n",
      "Epoch: 1000 train loss=0.010134714 valid loss= 0.007834110\n",
      "train reg_fs: 0.0027151615358889103\n",
      "Epoch: 1500 train loss=0.015734227 valid loss= 0.007642815\n",
      "train reg_fs: 0.0027174800634384155\n",
      "Epoch: 2000 train loss=0.008910323 valid loss= 0.007222553\n",
      "train reg_fs: 0.0026908956933766603\n",
      "Epoch: 2500 train loss=0.010893444 valid loss= 0.006582445\n",
      "train reg_fs: 0.0026478474028408527\n",
      "Epoch: 3000 train loss=0.009725938 valid loss= 0.005450787\n",
      "train reg_fs: 0.002596283797174692\n",
      "Epoch: 3500 train loss=0.006084905 valid loss= 0.005089886\n",
      "train reg_fs: 0.00254431483335793\n",
      "Epoch: 4000 train loss=0.008578380 valid loss= 0.004106039\n",
      "train reg_fs: 0.0025000281166285276\n",
      "Epoch: 4500 train loss=0.007274331 valid loss= 0.004086970\n",
      "train reg_fs: 0.002463602228090167\n",
      "Epoch: 5000 train loss=0.006673722 valid loss= 0.004058561\n",
      "train reg_fs: 0.002431434579193592\n",
      "Epoch: 5500 train loss=0.005624320 valid loss= 0.003952852\n",
      "train reg_fs: 0.0024029375053942204\n",
      "Epoch: 6000 train loss=0.007105264 valid loss= 0.004252240\n",
      "train reg_fs: 0.0023775019217282534\n",
      "Epoch: 6500 train loss=0.006721860 valid loss= 0.003931396\n",
      "train reg_fs: 0.0023535231593996286\n",
      "Epoch: 7000 train loss=0.003818489 valid loss= 0.003880027\n",
      "train reg_fs: 0.0023319716565310955\n",
      "Epoch: 7500 train loss=0.004236634 valid loss= 0.003846149\n",
      "train reg_fs: 0.002311582677066326\n",
      "Epoch: 8000 train loss=0.006628126 valid loss= 0.003781172\n",
      "train reg_fs: 0.0022927531972527504\n",
      "Epoch: 8500 train loss=0.004781017 valid loss= 0.003431580\n",
      "train reg_fs: 0.002275946317240596\n",
      "Epoch: 9000 train loss=0.005943643 valid loss= 0.003964417\n",
      "train reg_fs: 0.0022599135991185904\n",
      "Epoch: 9500 train loss=0.002665848 valid loss= 0.003374656\n",
      "train reg_fs: 0.0022457109298557043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:07:38,187]\u001b[0m Trial 80 finished with value: 0.0012135933632913762 and parameters: {'lam': 0.0031519374443361526, 'learning_rate': 0.039660793695081645, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003255564 valid loss= 0.003471053\n",
      "train reg_fs: 0.002234176266938448\n",
      "Optimization Finished!\n",
      "test loss: 0.003397067543119192, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0012135933632913762\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019702703 valid loss= 0.010114104\n",
      "train reg_fs: 0.002723192097619176\n",
      "Epoch: 1000 train loss=0.015429044 valid loss= 0.009154427\n",
      "train reg_fs: 0.002759835682809353\n",
      "Epoch: 1500 train loss=0.017285597 valid loss= 0.008451415\n",
      "train reg_fs: 0.0027745773550122976\n",
      "Epoch: 2000 train loss=0.010636038 valid loss= 0.008553084\n",
      "train reg_fs: 0.0027698089834302664\n",
      "Epoch: 2500 train loss=0.009588558 valid loss= 0.008897841\n",
      "train reg_fs: 0.002748862374573946\n",
      "Epoch: 3000 train loss=0.016951505 valid loss= 0.007607725\n",
      "train reg_fs: 0.0027143158949911594\n",
      "Epoch: 3500 train loss=0.010094486 valid loss= 0.007346680\n",
      "train reg_fs: 0.0026713553816080093\n",
      "Epoch: 4000 train loss=0.011156007 valid loss= 0.007072384\n",
      "train reg_fs: 0.002632453106343746\n",
      "Epoch: 4500 train loss=0.004830298 valid loss= 0.005494008\n",
      "train reg_fs: 0.0025932183489203453\n",
      "Epoch: 5000 train loss=0.003808682 valid loss= 0.005276539\n",
      "train reg_fs: 0.002557873260229826\n",
      "Epoch: 5500 train loss=0.008083239 valid loss= 0.005042397\n",
      "train reg_fs: 0.0025203614495694637\n",
      "Epoch: 6000 train loss=0.006629287 valid loss= 0.005335798\n",
      "train reg_fs: 0.0024863979779183865\n",
      "Epoch: 6500 train loss=0.007285674 valid loss= 0.005094271\n",
      "train reg_fs: 0.0024562368635088205\n",
      "Epoch: 7000 train loss=0.006452730 valid loss= 0.004886870\n",
      "train reg_fs: 0.0024294923059642315\n",
      "Epoch: 7500 train loss=0.006036196 valid loss= 0.004658374\n",
      "train reg_fs: 0.0024116458371281624\n",
      "Epoch: 8000 train loss=0.005219169 valid loss= 0.004645274\n",
      "train reg_fs: 0.002393977949395776\n",
      "Epoch: 8500 train loss=0.004652787 valid loss= 0.004752460\n",
      "train reg_fs: 0.0023793361615389585\n",
      "Epoch: 9000 train loss=0.005585480 valid loss= 0.004934139\n",
      "train reg_fs: 0.0023678431753069162\n",
      "Epoch: 9500 train loss=0.003691879 valid loss= 0.004873793\n",
      "train reg_fs: 0.0023585010785609484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:08:42,252]\u001b[0m Trial 81 finished with value: 0.002156311490159427 and parameters: {'lam': 0.0031907064459656092, 'learning_rate': 0.03750914528758694, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003508166 valid loss= 0.004575633\n",
      "train reg_fs: 0.002350856550037861\n",
      "Optimization Finished!\n",
      "test loss: 0.005255268886685371, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002156311490159427\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010535394 valid loss= 0.010673058\n",
      "train reg_fs: 0.0034342750441282988\n",
      "Epoch: 1000 train loss=0.015670780 valid loss= 0.010170421\n",
      "train reg_fs: 0.0034753482323139906\n",
      "Epoch: 1500 train loss=0.026036683 valid loss= 0.010217555\n",
      "train reg_fs: 0.0034937511663883924\n",
      "Epoch: 2000 train loss=0.022612950 valid loss= 0.010502508\n",
      "train reg_fs: 0.0034963637590408325\n",
      "Epoch: 2500 train loss=0.016782116 valid loss= 0.010043708\n",
      "train reg_fs: 0.0034806078765541315\n",
      "Epoch: 3000 train loss=0.010033954 valid loss= 0.009864524\n",
      "train reg_fs: 0.003447389928624034\n",
      "Epoch: 3500 train loss=0.009513687 valid loss= 0.010464326\n",
      "train reg_fs: 0.0033985525369644165\n",
      "Epoch: 4000 train loss=0.008370235 valid loss= 0.010139274\n",
      "train reg_fs: 0.0033529247157275677\n",
      "Epoch: 4500 train loss=0.008952836 valid loss= 0.010332308\n",
      "train reg_fs: 0.0033072405494749546\n",
      "Epoch: 5000 train loss=0.016354080 valid loss= 0.009781002\n",
      "train reg_fs: 0.0032725976780056953\n",
      "Epoch: 5500 train loss=0.008028721 valid loss= 0.010098975\n",
      "train reg_fs: 0.003244557185098529\n",
      "Epoch: 6000 train loss=0.009488105 valid loss= 0.010159874\n",
      "train reg_fs: 0.003220943035557866\n",
      "Epoch: 6500 train loss=0.009772792 valid loss= 0.010026747\n",
      "train reg_fs: 0.003203694010153413\n",
      "Epoch: 7000 train loss=0.011816295 valid loss= 0.010137897\n",
      "train reg_fs: 0.0031881723552942276\n",
      "Epoch: 7500 train loss=0.007849609 valid loss= 0.009773538\n",
      "train reg_fs: 0.0031714700162410736\n",
      "Epoch: 8000 train loss=0.006799990 valid loss= 0.009722711\n",
      "train reg_fs: 0.0031656178180128336\n",
      "Epoch: 8500 train loss=0.005532841 valid loss= 0.009768569\n",
      "train reg_fs: 0.003162714885547757\n",
      "Epoch: 9000 train loss=0.006896900 valid loss= 0.009630952\n",
      "train reg_fs: 0.0031565800309181213\n",
      "Epoch: 9500 train loss=0.008971447 valid loss= 0.009850954\n",
      "train reg_fs: 0.0031535213347524405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:09:47,023]\u001b[0m Trial 82 finished with value: 0.006395280012895429 and parameters: {'lam': 0.004002629772582174, 'learning_rate': 0.03401543135956849, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004532452 valid loss= 0.009660627\n",
      "train reg_fs: 0.003154384670779109\n",
      "Optimization Finished!\n",
      "test loss: 0.009026325307786465, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006395280012895429\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006863610 valid loss= 0.009293775\n",
      "train reg_fs: 0.0018292368622496724\n",
      "Epoch: 1000 train loss=0.008240206 valid loss= 0.008790735\n",
      "train reg_fs: 0.0018535234266892076\n",
      "Epoch: 1500 train loss=0.014309091 valid loss= 0.007501566\n",
      "train reg_fs: 0.0018518270226195455\n",
      "Epoch: 2000 train loss=0.014410789 valid loss= 0.007812970\n",
      "train reg_fs: 0.0018252385780215263\n",
      "Epoch: 2500 train loss=0.007964415 valid loss= 0.006992408\n",
      "train reg_fs: 0.0017838943749666214\n",
      "Epoch: 3000 train loss=0.006409158 valid loss= 0.005821078\n",
      "train reg_fs: 0.0017402905505150557\n",
      "Epoch: 3500 train loss=0.006758466 valid loss= 0.004575511\n",
      "train reg_fs: 0.0016963317757472396\n",
      "Epoch: 4000 train loss=0.005409207 valid loss= 0.004451813\n",
      "train reg_fs: 0.0016641929978504777\n",
      "Epoch: 4500 train loss=0.006086969 valid loss= 0.004207675\n",
      "train reg_fs: 0.001637787907384336\n",
      "Epoch: 5000 train loss=0.004244522 valid loss= 0.004376080\n",
      "train reg_fs: 0.001615950372070074\n",
      "Epoch: 5500 train loss=0.006228702 valid loss= 0.004418588\n",
      "train reg_fs: 0.0015961999306455255\n",
      "Epoch: 6000 train loss=0.009053644 valid loss= 0.004220437\n",
      "train reg_fs: 0.0015767362201586366\n",
      "Epoch: 6500 train loss=0.003423907 valid loss= 0.004153172\n",
      "train reg_fs: 0.0015596795128658414\n",
      "Epoch: 7000 train loss=0.002205451 valid loss= 0.004256878\n",
      "train reg_fs: 0.001542555051855743\n",
      "Epoch: 7500 train loss=0.009822136 valid loss= 0.004071170\n",
      "train reg_fs: 0.0015248632989823818\n",
      "Epoch: 8000 train loss=0.003071585 valid loss= 0.004039623\n",
      "train reg_fs: 0.001508487155660987\n",
      "Epoch: 8500 train loss=0.002443405 valid loss= 0.004289766\n",
      "train reg_fs: 0.0014927721349522471\n",
      "Epoch: 9000 train loss=0.004970980 valid loss= 0.004254471\n",
      "train reg_fs: 0.0014766169479116797\n",
      "Epoch: 9500 train loss=0.002163598 valid loss= 0.003992371\n",
      "train reg_fs: 0.0014623117167502642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:10:51,144]\u001b[0m Trial 83 finished with value: 0.0028138743970103314 and parameters: {'lam': 0.002118358567150509, 'learning_rate': 0.046049955138863057, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002635196 valid loss= 0.004256861\n",
      "train reg_fs: 0.001448395079933107\n",
      "Optimization Finished!\n",
      "test loss: 0.0038855099119246006, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028138743970103314\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015411878 valid loss= 0.009158259\n",
      "train reg_fs: 0.0022942074574530125\n",
      "Epoch: 1000 train loss=0.018397814 valid loss= 0.009276479\n",
      "train reg_fs: 0.0023140728008002043\n",
      "Epoch: 1500 train loss=0.007185362 valid loss= 0.008813285\n",
      "train reg_fs: 0.0023052128963172436\n",
      "Epoch: 2000 train loss=0.007836035 valid loss= 0.008581417\n",
      "train reg_fs: 0.002271580509841442\n",
      "Epoch: 2500 train loss=0.008672432 valid loss= 0.008484619\n",
      "train reg_fs: 0.002237881300970912\n",
      "Epoch: 3000 train loss=0.009441107 valid loss= 0.008017171\n",
      "train reg_fs: 0.002200008137151599\n",
      "Epoch: 3500 train loss=0.009115825 valid loss= 0.006489955\n",
      "train reg_fs: 0.00215956405736506\n",
      "Epoch: 4000 train loss=0.005200303 valid loss= 0.006416935\n",
      "train reg_fs: 0.002115564653649926\n",
      "Epoch: 4500 train loss=0.004802697 valid loss= 0.005313417\n",
      "train reg_fs: 0.0020700625609606504\n",
      "Epoch: 5000 train loss=0.003694836 valid loss= 0.005150895\n",
      "train reg_fs: 0.0020274820271879435\n",
      "Epoch: 5500 train loss=0.009674711 valid loss= 0.004745111\n",
      "train reg_fs: 0.0019873909186571836\n",
      "Epoch: 6000 train loss=0.002886907 valid loss= 0.005199427\n",
      "train reg_fs: 0.001949089695699513\n",
      "Epoch: 6500 train loss=0.005720931 valid loss= 0.005282620\n",
      "train reg_fs: 0.0019194722408428788\n",
      "Epoch: 7000 train loss=0.003754666 valid loss= 0.005094981\n",
      "train reg_fs: 0.001892615226097405\n",
      "Epoch: 7500 train loss=0.006335904 valid loss= 0.005187836\n",
      "train reg_fs: 0.0018661351641640067\n",
      "Epoch: 8000 train loss=0.003605013 valid loss= 0.004853031\n",
      "train reg_fs: 0.0018424236914142966\n",
      "Epoch: 8500 train loss=0.010288605 valid loss= 0.004920757\n",
      "train reg_fs: 0.0018213547300547361\n",
      "Epoch: 9000 train loss=0.002337032 valid loss= 0.004638319\n",
      "train reg_fs: 0.0018049426143988967\n",
      "Epoch: 9500 train loss=0.003187432 valid loss= 0.004574329\n",
      "train reg_fs: 0.0017901096725836396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:11:55,464]\u001b[0m Trial 84 finished with value: 0.00269949841629611 and parameters: {'lam': 0.00268125528579251, 'learning_rate': 0.040159632393307124, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002936697 valid loss= 0.004475772\n",
      "train reg_fs: 0.0017766231903806329\n",
      "Optimization Finished!\n",
      "test loss: 0.004319500178098679, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00269949841629611\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010525649 valid loss= 0.009146147\n",
      "train reg_fs: 0.0030757198110222816\n",
      "Epoch: 1000 train loss=0.011165981 valid loss= 0.008324667\n",
      "train reg_fs: 0.0030739801004529\n",
      "Epoch: 1500 train loss=0.007172979 valid loss= 0.008763161\n",
      "train reg_fs: 0.003017021343111992\n",
      "Epoch: 2000 train loss=0.007238083 valid loss= 0.007592306\n",
      "train reg_fs: 0.002935160882771015\n",
      "Epoch: 2500 train loss=0.005291921 valid loss= 0.006335123\n",
      "train reg_fs: 0.002847640309482813\n",
      "Epoch: 3000 train loss=0.011536370 valid loss= 0.005626957\n",
      "train reg_fs: 0.002764022909104824\n",
      "Epoch: 3500 train loss=0.004158114 valid loss= 0.005497145\n",
      "train reg_fs: 0.0026889434084296227\n",
      "Epoch: 4000 train loss=0.003996390 valid loss= 0.005790889\n",
      "train reg_fs: 0.002628207905218005\n",
      "Epoch: 4500 train loss=0.006182953 valid loss= 0.006160994\n",
      "train reg_fs: 0.002580153290182352\n",
      "Epoch: 5000 train loss=0.005436883 valid loss= 0.006412154\n",
      "train reg_fs: 0.0025354858953505754\n",
      "Epoch: 5500 train loss=0.004277512 valid loss= 0.006347986\n",
      "train reg_fs: 0.002499916823580861\n",
      "Epoch: 6000 train loss=0.006146331 valid loss= 0.006823019\n",
      "train reg_fs: 0.0024636429734528065\n",
      "Epoch: 6500 train loss=0.005204374 valid loss= 0.006230633\n",
      "train reg_fs: 0.002431649249047041\n",
      "Epoch: 7000 train loss=0.003811563 valid loss= 0.006374875\n",
      "train reg_fs: 0.0024027207400649786\n",
      "Epoch: 7500 train loss=0.005252356 valid loss= 0.006722478\n",
      "train reg_fs: 0.002378288423642516\n",
      "Epoch: 8000 train loss=0.005162608 valid loss= 0.006214083\n",
      "train reg_fs: 0.0023542577400803566\n",
      "Epoch: 8500 train loss=0.006004092 valid loss= 0.006402588\n",
      "train reg_fs: 0.0023347889073193073\n",
      "Epoch: 9000 train loss=0.004081342 valid loss= 0.006473737\n",
      "train reg_fs: 0.0023145638406276703\n",
      "Epoch: 9500 train loss=0.003744917 valid loss= 0.006416120\n",
      "train reg_fs: 0.0022970715072005987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:12:59,861]\u001b[0m Trial 85 finished with value: 0.004057232948398414 and parameters: {'lam': 0.0035866543339866056, 'learning_rate': 0.05293958060276223, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006586808 valid loss= 0.006428394\n",
      "train reg_fs: 0.0022806094493716955\n",
      "Optimization Finished!\n",
      "test loss: 0.006631792057305574, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004057232948398414\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017576640 valid loss= 0.008523119\n",
      "train reg_fs: 0.00246886583045125\n",
      "Epoch: 1000 train loss=0.011190959 valid loss= 0.008134244\n",
      "train reg_fs: 0.002500893548130989\n",
      "Epoch: 1500 train loss=0.013216821 valid loss= 0.007739929\n",
      "train reg_fs: 0.0025218341033905745\n",
      "Epoch: 2000 train loss=0.011390702 valid loss= 0.007446053\n",
      "train reg_fs: 0.002534491941332817\n",
      "Epoch: 2500 train loss=0.006684720 valid loss= 0.006602280\n",
      "train reg_fs: 0.0025386393535882235\n",
      "Epoch: 3000 train loss=0.007924804 valid loss= 0.005971718\n",
      "train reg_fs: 0.002539201406762004\n",
      "Epoch: 3500 train loss=0.005862129 valid loss= 0.006413633\n",
      "train reg_fs: 0.0025359466671943665\n",
      "Epoch: 4000 train loss=0.009713195 valid loss= 0.006386255\n",
      "train reg_fs: 0.0025297380052506924\n",
      "Epoch: 4500 train loss=0.012197841 valid loss= 0.005908382\n",
      "train reg_fs: 0.0025213477201759815\n",
      "Epoch: 5000 train loss=0.004299722 valid loss= 0.006241521\n",
      "train reg_fs: 0.0025090316776186228\n",
      "Epoch: 5500 train loss=0.007125858 valid loss= 0.005725364\n",
      "train reg_fs: 0.0024987724609673023\n",
      "Epoch: 6000 train loss=0.007658212 valid loss= 0.005483601\n",
      "train reg_fs: 0.002483064541593194\n",
      "Epoch: 6500 train loss=0.003768765 valid loss= 0.005539709\n",
      "train reg_fs: 0.0024703529197722673\n",
      "Epoch: 7000 train loss=0.004559578 valid loss= 0.005482858\n",
      "train reg_fs: 0.0024566722568124533\n",
      "Epoch: 7500 train loss=0.008125416 valid loss= 0.005466715\n",
      "train reg_fs: 0.002443714067339897\n",
      "Epoch: 8000 train loss=0.005492799 valid loss= 0.005981804\n",
      "train reg_fs: 0.0024300965014845133\n",
      "Epoch: 8500 train loss=0.003278453 valid loss= 0.005592838\n",
      "train reg_fs: 0.0024152088444679976\n",
      "Epoch: 9000 train loss=0.004925839 valid loss= 0.005351530\n",
      "train reg_fs: 0.002401307923719287\n",
      "Epoch: 9500 train loss=0.010186163 valid loss= 0.005436383\n",
      "train reg_fs: 0.002390387002378702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:14:05,468]\u001b[0m Trial 86 finished with value: 0.0029833109169475585 and parameters: {'lam': 0.0028811292065992603, 'learning_rate': 0.03418652124911518, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.012209343 valid loss= 0.005380533\n",
      "train reg_fs: 0.002380204852670431\n",
      "Optimization Finished!\n",
      "test loss: 0.005342252552509308, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029833109169475585\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005886678 valid loss= 0.007009392\n",
      "train reg_fs: 0.0028609735891222954\n",
      "Epoch: 1000 train loss=0.004269972 valid loss= 0.004493498\n",
      "train reg_fs: 0.0026374072767794132\n",
      "Epoch: 1500 train loss=0.003970721 valid loss= 0.004503740\n",
      "train reg_fs: 0.002540104789659381\n",
      "Epoch: 2000 train loss=0.008380411 valid loss= 0.004092051\n",
      "train reg_fs: 0.0024948827922344208\n",
      "Epoch: 2500 train loss=0.003174564 valid loss= 0.005664585\n",
      "train reg_fs: 0.002463501412421465\n",
      "Epoch: 3000 train loss=0.004401077 valid loss= 0.003826096\n",
      "train reg_fs: 0.0024284939281642437\n",
      "Epoch: 3500 train loss=0.003685219 valid loss= 0.004459977\n",
      "train reg_fs: 0.00239203660748899\n",
      "Epoch: 4000 train loss=0.003043436 valid loss= 0.003782079\n",
      "train reg_fs: 0.00235438859090209\n",
      "Epoch: 4500 train loss=0.003503584 valid loss= 0.003145722\n",
      "train reg_fs: 0.002327092457562685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:14:39,069]\u001b[0m Trial 87 finished with value: 0.0008541683239598427 and parameters: {'lam': 0.0033732740414201684, 'learning_rate': 0.18255053824944764, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003830764 valid loss= 0.003163809\n",
      "train reg_fs: 0.0023072627373039722\n",
      "Optimization Finished!\n",
      "test loss: 0.003104555420577526, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0008541683239598427\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008187570 valid loss= 0.009788334\n",
      "train reg_fs: 0.002786762546747923\n",
      "Epoch: 1000 train loss=0.003240205 valid loss= 0.005688685\n",
      "train reg_fs: 0.00246173026971519\n",
      "Epoch: 1500 train loss=0.006645540 valid loss= 0.005519377\n",
      "train reg_fs: 0.0023786548990756273\n",
      "Epoch: 2000 train loss=0.005080407 valid loss= 0.005691367\n",
      "train reg_fs: 0.002272438956424594\n",
      "Epoch: 2500 train loss=0.007031672 valid loss= 0.005027944\n",
      "train reg_fs: 0.0021924148313701153\n",
      "Epoch: 3000 train loss=0.006786582 valid loss= 0.004778937\n",
      "train reg_fs: 0.0021466505713760853\n",
      "Epoch: 3500 train loss=0.005728688 valid loss= 0.004734115\n",
      "train reg_fs: 0.0021174189168959856\n",
      "Epoch: 4000 train loss=0.004256312 valid loss= 0.004483551\n",
      "train reg_fs: 0.002096126787364483\n",
      "Epoch: 4500 train loss=0.003709835 valid loss= 0.004481922\n",
      "train reg_fs: 0.0020802291110157967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:15:11,967]\u001b[0m Trial 88 finished with value: 0.0023738306583694084 and parameters: {'lam': 0.003362969361762689, 'learning_rate': 0.18459521097883191, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003065180 valid loss= 0.004408434\n",
      "train reg_fs: 0.0020691484678536654\n",
      "Optimization Finished!\n",
      "test loss: 0.004181878641247749, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023738306583694084\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014234401 valid loss= 0.010789676\n",
      "train reg_fs: 0.0039665293879806995\n",
      "Epoch: 1000 train loss=0.008967072 valid loss= 0.010909008\n",
      "train reg_fs: 0.003994188271462917\n",
      "Epoch: 1500 train loss=0.010520195 valid loss= 0.010103652\n",
      "train reg_fs: 0.003951478283852339\n",
      "Epoch: 2000 train loss=0.011433421 valid loss= 0.010606585\n",
      "train reg_fs: 0.003869063686579466\n",
      "Epoch: 2500 train loss=0.011908612 valid loss= 0.009361845\n",
      "train reg_fs: 0.003789004869759083\n",
      "Epoch: 3000 train loss=0.022441171 valid loss= 0.008603890\n",
      "train reg_fs: 0.0037231685128062963\n",
      "Epoch: 3500 train loss=0.008150559 valid loss= 0.008029822\n",
      "train reg_fs: 0.0036636833101511\n",
      "Epoch: 4000 train loss=0.008057758 valid loss= 0.007269987\n",
      "train reg_fs: 0.003590392880141735\n",
      "Epoch: 4500 train loss=0.006901206 valid loss= 0.007076029\n",
      "train reg_fs: 0.003513135015964508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:15:45,399]\u001b[0m Trial 89 finished with value: 0.0029224490209001424 and parameters: {'lam': 0.004640928148877739, 'learning_rate': 0.05058659676000844, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005791103 valid loss= 0.006488733\n",
      "train reg_fs: 0.003432792378589511\n",
      "Optimization Finished!\n",
      "test loss: 0.007554718293249607, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029224490209001424\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019016031 valid loss= 0.010936170\n",
      "train reg_fs: 0.004522178787738085\n",
      "Epoch: 1000 train loss=0.011952462 valid loss= 0.011848468\n",
      "train reg_fs: 0.004467707592993975\n",
      "Epoch: 1500 train loss=0.015194494 valid loss= 0.011534123\n",
      "train reg_fs: 0.00431044353172183\n",
      "Epoch: 2000 train loss=0.008247697 valid loss= 0.009780269\n",
      "train reg_fs: 0.004173131659626961\n",
      "Epoch: 2500 train loss=0.009449047 valid loss= 0.008678028\n",
      "train reg_fs: 0.004068395122885704\n",
      "Epoch: 3000 train loss=0.012009412 valid loss= 0.008201312\n",
      "train reg_fs: 0.003940913360565901\n",
      "Epoch: 3500 train loss=0.006062375 valid loss= 0.006563337\n",
      "train reg_fs: 0.003768281312659383\n",
      "Epoch: 4000 train loss=0.005200440 valid loss= 0.006548817\n",
      "train reg_fs: 0.0036270152777433395\n",
      "Epoch: 4500 train loss=0.006566009 valid loss= 0.006194727\n",
      "train reg_fs: 0.003532606875523925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:16:18,993]\u001b[0m Trial 90 finished with value: 0.0025441881454024355 and parameters: {'lam': 0.005226800767899637, 'learning_rate': 0.08776279781012879, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.004069304 valid loss= 0.006049572\n",
      "train reg_fs: 0.0034671383909881115\n",
      "Optimization Finished!\n",
      "test loss: 0.005646918434649706, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025441881454024355\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009515878 valid loss= 0.008571935\n",
      "train reg_fs: 0.002719433046877384\n",
      "Epoch: 1000 train loss=0.012320349 valid loss= 0.007257966\n",
      "train reg_fs: 0.0026161293499171734\n",
      "Epoch: 1500 train loss=0.008937909 valid loss= 0.005339829\n",
      "train reg_fs: 0.002441350370645523\n",
      "Epoch: 2000 train loss=0.005983365 valid loss= 0.004728849\n",
      "train reg_fs: 0.002359215170145035\n",
      "Epoch: 2500 train loss=0.003007708 valid loss= 0.004809250\n",
      "train reg_fs: 0.0023055740166455507\n",
      "Epoch: 3000 train loss=0.006441932 valid loss= 0.004560810\n",
      "train reg_fs: 0.002247906057164073\n",
      "Epoch: 3500 train loss=0.003449989 valid loss= 0.004622758\n",
      "train reg_fs: 0.002200712449848652\n",
      "Epoch: 4000 train loss=0.003847857 valid loss= 0.004598482\n",
      "train reg_fs: 0.002161112381145358\n",
      "Epoch: 4500 train loss=0.003963566 valid loss= 0.004379401\n",
      "train reg_fs: 0.002126131672412157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:16:51,917]\u001b[0m Trial 91 finished with value: 0.0022544109566865673 and parameters: {'lam': 0.0031048344833091075, 'learning_rate': 0.14669103117275106, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008296927 valid loss= 0.004343036\n",
      "train reg_fs: 0.002087102737277746\n",
      "Optimization Finished!\n",
      "test loss: 0.004103873856365681, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022544109566865673\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.024965659 valid loss= 0.008578278\n",
      "train reg_fs: 0.003133622696623206\n",
      "Epoch: 1000 train loss=0.009705806 valid loss= 0.005992462\n",
      "train reg_fs: 0.002859175205230713\n",
      "Epoch: 1500 train loss=0.006259280 valid loss= 0.006344523\n",
      "train reg_fs: 0.0027605544310063124\n",
      "Epoch: 2000 train loss=0.004614126 valid loss= 0.006617388\n",
      "train reg_fs: 0.0026578872930258512\n",
      "Epoch: 2500 train loss=0.003136630 valid loss= 0.006046161\n",
      "train reg_fs: 0.0025182857643812895\n",
      "Epoch: 3000 train loss=0.004116425 valid loss= 0.005149157\n",
      "train reg_fs: 0.0024076742120087147\n",
      "Epoch: 3500 train loss=0.003020026 valid loss= 0.004782559\n",
      "train reg_fs: 0.0023477545473724604\n",
      "Epoch: 4000 train loss=0.003815591 valid loss= 0.004464065\n",
      "train reg_fs: 0.0023126727901399136\n",
      "Epoch: 4500 train loss=0.004995029 valid loss= 0.004572078\n",
      "train reg_fs: 0.0022880705073475838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:17:25,285]\u001b[0m Trial 92 finished with value: 0.0025637174319602337 and parameters: {'lam': 0.003680338473255969, 'learning_rate': 0.1755246598523688, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.007317159 valid loss= 0.004797779\n",
      "train reg_fs: 0.0022719211410731077\n",
      "Optimization Finished!\n",
      "test loss: 0.004433778114616871, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025637174319602337\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009306506 valid loss= 0.008634417\n",
      "train reg_fs: 0.0019733852241188288\n",
      "Epoch: 1000 train loss=0.007610118 valid loss= 0.005499482\n",
      "train reg_fs: 0.0018184214131906629\n",
      "Epoch: 1500 train loss=0.009559772 valid loss= 0.005292754\n",
      "train reg_fs: 0.0017086535226553679\n",
      "Epoch: 2000 train loss=0.008117616 valid loss= 0.005376807\n",
      "train reg_fs: 0.0016359644941985607\n",
      "Epoch: 2500 train loss=0.003943023 valid loss= 0.005920255\n",
      "train reg_fs: 0.0015823633875697851\n",
      "Epoch: 3000 train loss=0.002435831 valid loss= 0.005495161\n",
      "train reg_fs: 0.001538303098641336\n",
      "Epoch: 3500 train loss=0.004864559 valid loss= 0.005968327\n",
      "train reg_fs: 0.0015031018992885947\n",
      "Epoch: 4000 train loss=0.003773757 valid loss= 0.005574906\n",
      "train reg_fs: 0.00147934106644243\n",
      "Epoch: 4500 train loss=0.004080011 valid loss= 0.005675199\n",
      "train reg_fs: 0.001457825186662376\n",
      "Epoch: 5000 train loss=0.004633490 valid loss= 0.005868911\n",
      "train reg_fs: 0.0014398543862625957\n",
      "Epoch: 5500 train loss=0.003177061 valid loss= 0.005654192\n",
      "train reg_fs: 0.0014265530044212937\n",
      "Epoch: 6000 train loss=0.006899153 valid loss= 0.005372497\n",
      "train reg_fs: 0.0014151291688904166\n",
      "Epoch: 6500 train loss=0.004771376 valid loss= 0.005827505\n",
      "train reg_fs: 0.0014058197848498821\n",
      "Epoch: 7000 train loss=0.003575271 valid loss= 0.005564673\n",
      "train reg_fs: 0.0013976367190480232\n",
      "Epoch: 7500 train loss=0.010483011 valid loss= 0.005857649\n",
      "train reg_fs: 0.001391363563016057\n",
      "Epoch: 8000 train loss=0.007016973 valid loss= 0.005692377\n",
      "train reg_fs: 0.0013856543228030205\n",
      "Epoch: 8500 train loss=0.002783490 valid loss= 0.005942599\n",
      "train reg_fs: 0.0013800367014482617\n",
      "Epoch: 9000 train loss=0.002810842 valid loss= 0.005530244\n",
      "train reg_fs: 0.0013755469117313623\n",
      "Epoch: 9500 train loss=0.007447319 valid loss= 0.005387305\n",
      "train reg_fs: 0.0013710904167965055\n",
      "Epoch: 10000 train loss=0.003225590 valid loss= 0.005470674\n",
      "train reg_fs: 0.001367506687529385\n",
      "Epoch: 10500 train loss=0.003116391 valid loss= 0.005669759\n",
      "train reg_fs: 0.0013640588149428368\n",
      "Epoch: 11000 train loss=0.006652629 valid loss= 0.005771047\n",
      "train reg_fs: 0.0013609181623905897\n",
      "Epoch: 11500 train loss=0.003242842 valid loss= 0.005655631\n",
      "train reg_fs: 0.0013581153471022844\n",
      "Epoch: 12000 train loss=0.002797825 valid loss= 0.005849567\n",
      "train reg_fs: 0.0013560601510107517\n",
      "Epoch: 12500 train loss=0.003607951 valid loss= 0.005528559\n",
      "train reg_fs: 0.0013539729407057166\n",
      "Epoch: 13000 train loss=0.002265259 valid loss= 0.005717802\n",
      "train reg_fs: 0.0013521347427740693\n",
      "Epoch: 13500 train loss=0.002985695 valid loss= 0.005892194\n",
      "train reg_fs: 0.0013500599889084697\n",
      "Epoch: 14000 train loss=0.003262118 valid loss= 0.005730512\n",
      "train reg_fs: 0.0013486911775544286\n",
      "Epoch: 14500 train loss=0.003940380 valid loss= 0.005730083\n",
      "train reg_fs: 0.0013470633421093225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:19:02,176]\u001b[0m Trial 93 finished with value: 0.005250891136339789 and parameters: {'lam': 0.0023393713100135576, 'learning_rate': 0.15597628657422777, 'num_epoch': 15000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005227487 valid loss= 0.006652899\n",
      "train reg_fs: 0.0013457072200253606\n",
      "Optimization Finished!\n",
      "test loss: 0.005843363702297211, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005250891136339789\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.025802543 valid loss= 0.009606578\n",
      "train reg_fs: 0.003037746762856841\n",
      "Epoch: 1000 train loss=0.008417682 valid loss= 0.010112977\n",
      "train reg_fs: 0.0030668957624584436\n",
      "Epoch: 1500 train loss=0.012719015 valid loss= 0.009114372\n",
      "train reg_fs: 0.0030556456185877323\n",
      "Epoch: 2000 train loss=0.008011064 valid loss= 0.007722707\n",
      "train reg_fs: 0.0030094836838543415\n",
      "Epoch: 2500 train loss=0.009016652 valid loss= 0.006702447\n",
      "train reg_fs: 0.0029190124478191137\n",
      "Epoch: 3000 train loss=0.010703311 valid loss= 0.005529194\n",
      "train reg_fs: 0.002834466053172946\n",
      "Epoch: 3500 train loss=0.008169786 valid loss= 0.005073691\n",
      "train reg_fs: 0.0027635886799544096\n",
      "Epoch: 4000 train loss=0.004890873 valid loss= 0.004745784\n",
      "train reg_fs: 0.0027187038213014603\n",
      "Epoch: 4500 train loss=0.006651476 valid loss= 0.005395556\n",
      "train reg_fs: 0.0026870083529502153\n",
      "Epoch: 5000 train loss=0.010837480 valid loss= 0.004627049\n",
      "train reg_fs: 0.002655357588082552\n",
      "Epoch: 5500 train loss=0.005804316 valid loss= 0.004488650\n",
      "train reg_fs: 0.002624639542773366\n",
      "Epoch: 6000 train loss=0.006277541 valid loss= 0.004590502\n",
      "train reg_fs: 0.002594619058072567\n",
      "Epoch: 6500 train loss=0.007249520 valid loss= 0.004978821\n",
      "train reg_fs: 0.00256429985165596\n",
      "Epoch: 7000 train loss=0.003739171 valid loss= 0.004727259\n",
      "train reg_fs: 0.002534163184463978\n",
      "Epoch: 7500 train loss=0.007705492 valid loss= 0.004045985\n",
      "train reg_fs: 0.002508769044652581\n",
      "Epoch: 8000 train loss=0.007095280 valid loss= 0.004094899\n",
      "train reg_fs: 0.002484746742993593\n",
      "Epoch: 8500 train loss=0.005873197 valid loss= 0.004323381\n",
      "train reg_fs: 0.0024642758071422577\n",
      "Epoch: 9000 train loss=0.004982084 valid loss= 0.004047727\n",
      "train reg_fs: 0.002446791622787714\n",
      "Epoch: 9500 train loss=0.005664300 valid loss= 0.003706319\n",
      "train reg_fs: 0.0024325414560735226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:20:08,058]\u001b[0m Trial 94 finished with value: 0.0008916435817805878 and parameters: {'lam': 0.0034949401837038353, 'learning_rate': 0.06579488649080649, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005121208 valid loss= 0.003339474\n",
      "train reg_fs: 0.002419443801045418\n",
      "Optimization Finished!\n",
      "test loss: 0.0033179214224219322, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0008916435817805878\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020557197 valid loss= 0.009926770\n",
      "train reg_fs: 0.003494294360280037\n",
      "Epoch: 1000 train loss=0.009911655 valid loss= 0.010430438\n",
      "train reg_fs: 0.0035132416523993015\n",
      "Epoch: 1500 train loss=0.009612797 valid loss= 0.008946238\n",
      "train reg_fs: 0.0034552025608718395\n",
      "Epoch: 2000 train loss=0.008859787 valid loss= 0.008343617\n",
      "train reg_fs: 0.0033842837437987328\n",
      "Epoch: 2500 train loss=0.010344871 valid loss= 0.007743542\n",
      "train reg_fs: 0.0033253615256398916\n",
      "Epoch: 3000 train loss=0.008292383 valid loss= 0.006565283\n",
      "train reg_fs: 0.0032556382939219475\n",
      "Epoch: 3500 train loss=0.006392935 valid loss= 0.006076841\n",
      "train reg_fs: 0.003167985239997506\n",
      "Epoch: 4000 train loss=0.006349719 valid loss= 0.005442868\n",
      "train reg_fs: 0.003092476399615407\n",
      "Epoch: 4500 train loss=0.003772260 valid loss= 0.005424553\n",
      "train reg_fs: 0.0030243368819355965\n",
      "Epoch: 5000 train loss=0.004286537 valid loss= 0.005502964\n",
      "train reg_fs: 0.0029647962655872107\n",
      "Epoch: 5500 train loss=0.005125079 valid loss= 0.005792812\n",
      "train reg_fs: 0.002912524389103055\n",
      "Epoch: 6000 train loss=0.003738823 valid loss= 0.005663253\n",
      "train reg_fs: 0.002865767804905772\n",
      "Epoch: 6500 train loss=0.005142737 valid loss= 0.005518385\n",
      "train reg_fs: 0.002821044996380806\n",
      "Epoch: 7000 train loss=0.003776172 valid loss= 0.005682038\n",
      "train reg_fs: 0.002781560178846121\n",
      "Epoch: 7500 train loss=0.005973744 valid loss= 0.005476944\n",
      "train reg_fs: 0.002743818098679185\n",
      "Epoch: 8000 train loss=0.004011857 valid loss= 0.005382120\n",
      "train reg_fs: 0.002712041372433305\n",
      "Epoch: 8500 train loss=0.003645781 valid loss= 0.005357457\n",
      "train reg_fs: 0.002685277257114649\n",
      "Epoch: 9000 train loss=0.003650388 valid loss= 0.005204445\n",
      "train reg_fs: 0.0026611522771418095\n",
      "Epoch: 9500 train loss=0.004908020 valid loss= 0.005422167\n",
      "train reg_fs: 0.00264044594950974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:21:13,468]\u001b[0m Trial 95 finished with value: 0.002625688979841693 and parameters: {'lam': 0.004065586427857027, 'learning_rate': 0.05668736311595156, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006364419 valid loss= 0.005230200\n",
      "train reg_fs: 0.002621799474582076\n",
      "Optimization Finished!\n",
      "test loss: 0.005011602304875851, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002625688979841693\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009613323 valid loss= 0.008834057\n",
      "train reg_fs: 0.002645239233970642\n",
      "Epoch: 1000 train loss=0.018895801 valid loss= 0.008222529\n",
      "train reg_fs: 0.0026676759589463472\n",
      "Epoch: 1500 train loss=0.008233738 valid loss= 0.006592278\n",
      "train reg_fs: 0.0026304738130420446\n",
      "Epoch: 2000 train loss=0.005187506 valid loss= 0.006817513\n",
      "train reg_fs: 0.002549549797549844\n",
      "Epoch: 2500 train loss=0.007525953 valid loss= 0.006054393\n",
      "train reg_fs: 0.002443063072860241\n",
      "Epoch: 3000 train loss=0.006413551 valid loss= 0.006043242\n",
      "train reg_fs: 0.0023727943189442158\n",
      "Epoch: 3500 train loss=0.010195117 valid loss= 0.005349878\n",
      "train reg_fs: 0.0023246498312801123\n",
      "Epoch: 4000 train loss=0.003194070 valid loss= 0.005411133\n",
      "train reg_fs: 0.0022851359099149704\n",
      "Epoch: 4500 train loss=0.006644417 valid loss= 0.004852582\n",
      "train reg_fs: 0.0022552337031811476\n",
      "Epoch: 5000 train loss=0.006624286 valid loss= 0.005001513\n",
      "train reg_fs: 0.002229501260444522\n",
      "Epoch: 5500 train loss=0.002827231 valid loss= 0.005029485\n",
      "train reg_fs: 0.0022091406863182783\n",
      "Epoch: 6000 train loss=0.003698900 valid loss= 0.004292842\n",
      "train reg_fs: 0.0021924395114183426\n",
      "Epoch: 6500 train loss=0.002925562 valid loss= 0.004546421\n",
      "train reg_fs: 0.002177666639909148\n",
      "Epoch: 7000 train loss=0.003520834 valid loss= 0.004412338\n",
      "train reg_fs: 0.0021656674798578024\n",
      "Epoch: 7500 train loss=0.003694446 valid loss= 0.004289616\n",
      "train reg_fs: 0.0021536233834922314\n",
      "Epoch: 8000 train loss=0.004500153 valid loss= 0.004469356\n",
      "train reg_fs: 0.002143156947568059\n",
      "Epoch: 8500 train loss=0.002972448 valid loss= 0.004222207\n",
      "train reg_fs: 0.002132986206561327\n",
      "Epoch: 9000 train loss=0.005179775 valid loss= 0.004244529\n",
      "train reg_fs: 0.002121412893757224\n",
      "Epoch: 9500 train loss=0.004763044 valid loss= 0.004461663\n",
      "train reg_fs: 0.0021078521385788918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:22:18,477]\u001b[0m Trial 96 finished with value: 0.0020714887991110315 and parameters: {'lam': 0.0030184737291205706, 'learning_rate': 0.06459776081214079, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003730096 valid loss= 0.004104991\n",
      "train reg_fs: 0.002095981268212199\n",
      "Optimization Finished!\n",
      "test loss: 0.003976740874350071, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0020714887991110315\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015092216 valid loss= 0.009085432\n",
      "train reg_fs: 0.0029775798320770264\n",
      "Epoch: 1000 train loss=0.008633076 valid loss= 0.008265363\n",
      "train reg_fs: 0.002946962136775255\n",
      "Epoch: 1500 train loss=0.013515051 valid loss= 0.006995530\n",
      "train reg_fs: 0.002872925717383623\n",
      "Epoch: 2000 train loss=0.008938536 valid loss= 0.006037733\n",
      "train reg_fs: 0.002813541330397129\n",
      "Epoch: 2500 train loss=0.009573907 valid loss= 0.004694366\n",
      "train reg_fs: 0.0027485876344144344\n",
      "Epoch: 3000 train loss=0.004029990 valid loss= 0.004755609\n",
      "train reg_fs: 0.0027093745302408934\n",
      "Epoch: 3500 train loss=0.004856890 valid loss= 0.004660801\n",
      "train reg_fs: 0.002683991100639105\n",
      "Epoch: 4000 train loss=0.007029674 valid loss= 0.004985891\n",
      "train reg_fs: 0.002659023040905595\n",
      "Epoch: 4500 train loss=0.003943867 valid loss= 0.004991589\n",
      "train reg_fs: 0.0026346873492002487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:22:51,372]\u001b[0m Trial 97 finished with value: 0.002430052313349028 and parameters: {'lam': 0.0034540945447996203, 'learning_rate': 0.0699825169290249, 'num_epoch': 5000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008524591 valid loss= 0.005024664\n",
      "train reg_fs: 0.0026116371154785156\n",
      "Optimization Finished!\n",
      "test loss: 0.004865322262048721, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002430052313349028\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012985078 valid loss= 0.010106044\n",
      "train reg_fs: 0.002413684269413352\n",
      "Epoch: 1000 train loss=0.008038784 valid loss= 0.010616104\n",
      "train reg_fs: 0.0024233043659478426\n",
      "Epoch: 1500 train loss=0.006233637 valid loss= 0.009369059\n",
      "train reg_fs: 0.002397531410679221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:23:05,796]\u001b[0m Trial 98 finished with value: 0.006605660952514808 and parameters: {'lam': 0.002770397577454796, 'learning_rate': 0.07773153706519222, 'num_epoch': 2000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.008055449 valid loss= 0.009004808\n",
      "train reg_fs: 0.0023599022533744574\n",
      "Optimization Finished!\n",
      "test loss: 0.009054679423570633, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006605660952514808\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007352913 valid loss= 0.009224605\n",
      "train reg_fs: 0.002767049940302968\n",
      "Epoch: 1000 train loss=0.012155634 valid loss= 0.008564883\n",
      "train reg_fs: 0.0026032256428152323\n",
      "Epoch: 1500 train loss=0.003135671 valid loss= 0.005407484\n",
      "train reg_fs: 0.0024390427861362696\n",
      "Epoch: 2000 train loss=0.010180074 valid loss= 0.005516628\n",
      "train reg_fs: 0.002303657354786992\n",
      "Epoch: 2500 train loss=0.004752709 valid loss= 0.005484159\n",
      "train reg_fs: 0.002227208111435175\n",
      "Epoch: 3000 train loss=0.004129351 valid loss= 0.004330296\n",
      "train reg_fs: 0.002183539094403386\n",
      "Epoch: 3500 train loss=0.004756151 valid loss= 0.004543507\n",
      "train reg_fs: 0.002154861344024539\n",
      "Epoch: 4000 train loss=0.005970271 valid loss= 0.004270428\n",
      "train reg_fs: 0.0021336886566132307\n",
      "Epoch: 4500 train loss=0.003521095 valid loss= 0.004298046\n",
      "train reg_fs: 0.002118079923093319\n",
      "Epoch: 5000 train loss=0.004052428 valid loss= 0.004147409\n",
      "train reg_fs: 0.0021055166143924\n",
      "Epoch: 5500 train loss=0.004134769 valid loss= 0.004498130\n",
      "train reg_fs: 0.002094610594213009\n",
      "Epoch: 6000 train loss=0.002491923 valid loss= 0.004626117\n",
      "train reg_fs: 0.002085158135741949\n",
      "Epoch: 6500 train loss=0.003296229 valid loss= 0.004502293\n",
      "train reg_fs: 0.002076154574751854\n",
      "Epoch: 7000 train loss=0.002493479 valid loss= 0.004289292\n",
      "train reg_fs: 0.002068097935989499\n",
      "Epoch: 7500 train loss=0.004574552 valid loss= 0.004808420\n",
      "train reg_fs: 0.0020602496806532145\n",
      "Epoch: 8000 train loss=0.006262798 valid loss= 0.004108258\n",
      "train reg_fs: 0.002052175346761942\n",
      "Epoch: 8500 train loss=0.003293099 valid loss= 0.004219470\n",
      "train reg_fs: 0.002044627908617258\n",
      "Epoch: 9000 train loss=0.005240479 valid loss= 0.004651079\n",
      "train reg_fs: 0.0020372788421809673\n",
      "Epoch: 9500 train loss=0.003531095 valid loss= 0.004355370\n",
      "train reg_fs: 0.002029998693615198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:24:10,248]\u001b[0m Trial 99 finished with value: 0.0027494363363999713 and parameters: {'lam': 0.0032574507282349804, 'learning_rate': 0.09856803721184382, 'num_epoch': 10000}. Best is trial 30 with value: 0.0002134432171233013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007425577 valid loss= 0.004748386\n",
      "train reg_fs: 0.002023068955168128\n",
      "Optimization Finished!\n",
      "test loss: 0.00425987783819437, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027494363363999713\n"
     ]
    }
   ],
   "source": [
    "# optimize the model via Optuna and obtain the best model with smallest validation mse\n",
    "best_model = None\n",
    "model = None\n",
    "study = optuna.create_study(pruner=None)\n",
    "study.optimize(llspin_objective, n_trials=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training gate matrix\n",
    "gate_mat_train = best_model.get_prob_alpha(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = study.best_params['learning_rate']\n",
    "best_epoch = study.best_params['num_epoch']\n",
    "best_lam = study.best_params['lam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Finished*************\n",
      "Best model's lambda: 0.0024685863565374637\n",
      "Best model's learning rate: 0.193657897430231\n",
      "Best model's num of epochs: 10000\n",
      "Test mse : 0.0001876552209172821\n",
      "Test r2 : 0.9954718243499533\n"
     ]
    }
   ],
   "source": [
    "# test the best model\n",
    "y_pred_llspin = best_model.test(X_test)[0]\n",
    "            \n",
    "print(\"Trial Finished*************\")\n",
    "print(\"Best model's lambda: {}\".format(best_lam))\n",
    "print(\"Best model's learning rate: {}\".format(best_lr))\n",
    "print(\"Best model's num of epochs: {}\".format(best_epoch))\n",
    "print(\"Test mse : {}\".format(mean_squared_error(y_test.reshape(-1),y_pred_llspin.reshape(-1))))\n",
    "print(\"Test r2 : {}\".format(r2_score(y_test.reshape(-1),y_pred_llspin.reshape(-1),multioutput='raw_values')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the training gates to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.Blues\n",
    "bounds=[0,0.5,1]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "title_size = 30\n",
    "xtick_size = 20\n",
    "ytick_size = 20\n",
    "xlabel_size = 35\n",
    "ylabel_size = 35\n",
    "colorbar_tick_size = 20\n",
    "title_pad = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "sorted_order = np.concatenate((np.where(train_label == 1)[0],np.where(train_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_train[sorted_order,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([1,3,5,7,9])\n",
    "axes[0].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "im2 = axes[1].imshow(gate_mat_train[sorted_order,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([1,3,5,7,9])\n",
    "axes[1].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the test gates to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_mat_test = best_model.get_prob_alpha(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "fig.subplots_adjust(bottom=0.01)\n",
    "\n",
    "sorted_order_test = np.concatenate((np.where(test_label == 1)[0],np.where(test_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_test[sorted_order_test,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([0,9,19,29,39,49])\n",
    "axes[0].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "    \n",
    "im2 = axes[1].imshow(gate_mat_test[sorted_order_test,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([0,9,19,29,39,49])\n",
    "axes[1].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "    \n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
