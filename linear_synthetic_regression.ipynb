{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from LSPIN_model import Model\n",
    "from utils import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear synthetic data generation\n",
    "\n",
    "Group 1: $X$ ~ $N(1,0.5)$,  $Y = -2X_1 + X_2 - 0.5X_3$\n",
    "\n",
    "Group 2: $X$ ~ $N(-1,0.5)$, $Y = -0.5X_3 + X_4 - 2X_5$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "Xs1 = np.random.normal(loc=1,scale=0.5,size=(300,5))\n",
    "Ys1 = -2*Xs1[:,0]+1*Xs1[:,1]-0.5*Xs1[:,2]\n",
    "\n",
    "Xs2 = np.random.normal(loc=-1,scale=0.5,size=(300,5))\n",
    "Ys2 = -0.5*Xs2[:,2]+1*Xs2[:,3]-2*Xs2[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate((Xs1,Xs2),axis=0)\n",
    "Y_data = np.concatenate((Ys1.reshape(-1,1),Ys2.reshape(-1,1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = Y_data-Y_data.min()\n",
    "Y_data=Y_data/Y_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ground truth group label of each sample\n",
    "case_labels = np.concatenate((np.array([1]*300),np.array([2]*300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = np.concatenate((Y_data,case_labels.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% for validation, 10% for test \n",
    "X_train,X_remain,yc_train,yc_remain = train_test_split(X_data,Y_data,train_size=0.8,shuffle=True,random_state=34)\n",
    "X_valid,X_test,yc_valid,yc_test = train_test_split(X_remain,yc_remain,train_size=0.5,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 10 samples used for training\n",
    "X_train,_,yc_train,_ = train_test_split(X_train,yc_train,train_size=10,shuffle=True,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes:\n",
      "10 60 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample sizes:\")\n",
    "print(X_train.shape[0],X_valid.shape[0],X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = yc_train[:,0].reshape(-1,1)\n",
    "y_valid = yc_valid[:,0].reshape(-1,1)\n",
    "y_test = yc_test[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = yc_train[:,1]\n",
    "valid_label = yc_valid[:,1]\n",
    "test_label= yc_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 6, 1.0: 4})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 29, 1.0: 31})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(**{'_data':X_train, '_labels':y_train,\n",
    "                '_valid_data':X_valid, '_valid_labels':y_valid,\n",
    "                '_test_data':X_test, '_test_labels':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference ground truth feature matrix (training/test)\n",
    "ref_feat_mat_train = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in train_label])\n",
    "ref_feat_mat_test = np.array([[1,1,1,0,0] if label == 1 else [0,0,1,1,1] for label in test_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLSPIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llspin_objective(trial):  \n",
    "    global model\n",
    "            \n",
    "    params = {\n",
    "        \"feature_selection\" : True,\n",
    "        \"sigma\" : 0.5,\n",
    "        \"display_step\" : 500,\n",
    "        \"hidden_layers_node\" : [100,100,10,10],\n",
    "        \"batch_normalization\": True,\n",
    "        \"input_node\" : X_train.shape[1],\n",
    "        \"output_node\" : 1\n",
    "    }\n",
    "    params['stddev_input'] = 0.1 \n",
    "    params['activation']= 'none'\n",
    "    params['batch_size']= X_train.shape[0]\n",
    "    params['feature_selection_dimension']=[10]\n",
    "    params['lam'] = trial.suggest_loguniform('lam',1e-3,1e-2)\n",
    "    params['learning_rate'] = trial.suggest_loguniform('learning_rate', 1e-2, 2e-1)\n",
    "    num_epoch = trial.suggest_categorical('num_epoch', [2000,5000,10000,15000])\n",
    "\n",
    "    model_dir =None\n",
    "    model = Model(**params)\n",
    "    train_acces, train_losses, val_acces, val_losses = model.train(trial, dataset, model_dir, num_epoch=num_epoch)\n",
    "\n",
    "    print(\"In trial:---------------------\")\n",
    "    val_prediction = model.test(X_valid)[0]\n",
    "    mse = mean_squared_error(y_valid.reshape(-1),val_prediction.reshape(-1))\n",
    "    print(\"validation mse: {}\".format(mse))\n",
    "    \n",
    "    loss= mse\n",
    "            \n",
    "    return loss\n",
    "        \n",
    "def callback(study,trial):\n",
    "    global best_model\n",
    "    if study.best_trial == trial:\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:23:36,862]\u001b[0m A new study created in memory with name: no-name-bbdf7d45-4091-4016-8979-e26e34531d5e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:53: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:53: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:54: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:243: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:90: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:122: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:162: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:172: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:172: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:174: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:181: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:182: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /tf/localSTG/script/arxiv_lspin/LSPIN_model.py:200: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013654673 valid loss= 0.010960348\n",
      "train reg_fs: 0.004589471034705639\n",
      "Epoch: 1000 train loss=0.013338368 valid loss= 0.010577765\n",
      "train reg_fs: 0.004532516002655029\n",
      "Epoch: 1500 train loss=0.017317429 valid loss= 0.008848630\n",
      "train reg_fs: 0.004269345663487911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:23:51,955]\u001b[0m Trial 0 finished with value: 0.0024490264889776097 and parameters: {'lam': 0.00532267568840898, 'learning_rate': 0.08947279355685521, 'num_epoch': 2000}. Best is trial 0 with value: 0.0024490264889776097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.007848827 valid loss= 0.006619227\n",
      "train reg_fs: 0.0040261694230139256\n",
      "Optimization Finished!\n",
      "test loss: 0.007254479452967644, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024490264889776097\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017422628 valid loss= 0.007202836\n",
      "train reg_fs: 0.001364467665553093\n",
      "Epoch: 1000 train loss=0.012376026 valid loss= 0.006976860\n",
      "train reg_fs: 0.001377518055960536\n",
      "Epoch: 1500 train loss=0.012448343 valid loss= 0.006879329\n",
      "train reg_fs: 0.001365547883324325\n",
      "Epoch: 2000 train loss=0.007617533 valid loss= 0.006667621\n",
      "train reg_fs: 0.0013390748063102365\n",
      "Epoch: 2500 train loss=0.004368822 valid loss= 0.005228508\n",
      "train reg_fs: 0.001314297434873879\n",
      "Epoch: 3000 train loss=0.010911244 valid loss= 0.005350078\n",
      "train reg_fs: 0.001288883970119059\n",
      "Epoch: 3500 train loss=0.004816992 valid loss= 0.004510775\n",
      "train reg_fs: 0.0012646423419937491\n",
      "Epoch: 4000 train loss=0.004171397 valid loss= 0.003891933\n",
      "train reg_fs: 0.0012428212212398648\n",
      "Epoch: 4500 train loss=0.003391155 valid loss= 0.003911261\n",
      "train reg_fs: 0.0012257978087291121\n",
      "Epoch: 5000 train loss=0.003328045 valid loss= 0.003799709\n",
      "train reg_fs: 0.0012143260100856423\n",
      "Epoch: 5500 train loss=0.003711876 valid loss= 0.004394027\n",
      "train reg_fs: 0.001205761800520122\n",
      "Epoch: 6000 train loss=0.006693750 valid loss= 0.003726839\n",
      "train reg_fs: 0.00120078818872571\n",
      "Epoch: 6500 train loss=0.002078115 valid loss= 0.004065823\n",
      "train reg_fs: 0.0011969406623393297\n",
      "Epoch: 7000 train loss=0.003406852 valid loss= 0.004271681\n",
      "train reg_fs: 0.0011946423910558224\n",
      "Epoch: 7500 train loss=0.004052472 valid loss= 0.004559631\n",
      "train reg_fs: 0.0011914737988263369\n",
      "Epoch: 8000 train loss=0.003161794 valid loss= 0.004138529\n",
      "train reg_fs: 0.0011890575988218188\n",
      "Epoch: 8500 train loss=0.015196111 valid loss= 0.004506721\n",
      "train reg_fs: 0.0011863422114402056\n",
      "Epoch: 9000 train loss=0.006741820 valid loss= 0.004294433\n",
      "train reg_fs: 0.0011823326349258423\n",
      "Epoch: 9500 train loss=0.006081064 valid loss= 0.004853993\n",
      "train reg_fs: 0.0011799215571954846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:24:54,791]\u001b[0m Trial 1 finished with value: 0.0030776548926728974 and parameters: {'lam': 0.0015847007688429597, 'learning_rate': 0.050162692182846615, 'num_epoch': 10000}. Best is trial 0 with value: 0.0024490264889776097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002317862 valid loss= 0.004283225\n",
      "train reg_fs: 0.0011795706814154983\n",
      "Optimization Finished!\n",
      "test loss: 0.0041567618027329445, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0030776548926728974\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016085166 valid loss= 0.011680217\n",
      "train reg_fs: 0.005085580516606569\n",
      "Epoch: 1000 train loss=0.013016795 valid loss= 0.012555476\n",
      "train reg_fs: 0.00504174642264843\n",
      "Epoch: 1500 train loss=0.010339711 valid loss= 0.011523009\n",
      "train reg_fs: 0.004947894252836704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:25:08,922]\u001b[0m Trial 2 finished with value: 0.004437518656664881 and parameters: {'lam': 0.006043842962965929, 'learning_rate': 0.04177084602900404, 'num_epoch': 2000}. Best is trial 0 with value: 0.0024490264889776097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.011620639 valid loss= 0.009446233\n",
      "train reg_fs: 0.0048494525253772736\n",
      "Optimization Finished!\n",
      "test loss: 0.011262528598308563, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004437518656664881\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012341027 valid loss= 0.008414185\n",
      "train reg_fs: 0.0011531751370057464\n",
      "Epoch: 1000 train loss=0.006680239 valid loss= 0.007961732\n",
      "train reg_fs: 0.0011756602907553315\n",
      "Epoch: 1500 train loss=0.018868905 valid loss= 0.006327592\n",
      "train reg_fs: 0.0011887582950294018\n",
      "Epoch: 2000 train loss=0.006362008 valid loss= 0.007906013\n",
      "train reg_fs: 0.0011974774533882737\n",
      "Epoch: 2500 train loss=0.007726546 valid loss= 0.007184912\n",
      "train reg_fs: 0.001202726038172841\n",
      "Epoch: 3000 train loss=0.007300777 valid loss= 0.006286074\n",
      "train reg_fs: 0.0012073674006387591\n",
      "Epoch: 3500 train loss=0.007936542 valid loss= 0.006283639\n",
      "train reg_fs: 0.001209284644573927\n",
      "Epoch: 4000 train loss=0.006430004 valid loss= 0.006503778\n",
      "train reg_fs: 0.0012103611370548606\n",
      "Epoch: 4500 train loss=0.008159212 valid loss= 0.005295902\n",
      "train reg_fs: 0.0012099159648641944\n",
      "Epoch: 5000 train loss=0.006110251 valid loss= 0.004246141\n",
      "train reg_fs: 0.0012088887160643935\n",
      "Epoch: 5500 train loss=0.010292660 valid loss= 0.003227213\n",
      "train reg_fs: 0.001205870066769421\n",
      "Epoch: 6000 train loss=0.002920193 valid loss= 0.004114742\n",
      "train reg_fs: 0.0012028373312205076\n",
      "Epoch: 6500 train loss=0.005198504 valid loss= 0.003730966\n",
      "train reg_fs: 0.001199489925056696\n",
      "Epoch: 7000 train loss=0.002274454 valid loss= 0.004051064\n",
      "train reg_fs: 0.001196721801534295\n",
      "Epoch: 7500 train loss=0.004014250 valid loss= 0.003831706\n",
      "train reg_fs: 0.0011930858017876744\n",
      "Epoch: 8000 train loss=0.002491520 valid loss= 0.003827234\n",
      "train reg_fs: 0.0011889126617461443\n",
      "Epoch: 8500 train loss=0.003879158 valid loss= 0.003791657\n",
      "train reg_fs: 0.0011852001771330833\n",
      "Epoch: 9000 train loss=0.002991985 valid loss= 0.003711100\n",
      "train reg_fs: 0.001181083731353283\n",
      "Epoch: 9500 train loss=0.001885315 valid loss= 0.004215764\n",
      "train reg_fs: 0.001176654128357768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:26:14,292]\u001b[0m Trial 3 finished with value: 0.0030847921086823134 and parameters: {'lam': 0.0013287958195412602, 'learning_rate': 0.04627147388379551, 'num_epoch': 10000}. Best is trial 0 with value: 0.0024490264889776097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004637146 valid loss= 0.004252792\n",
      "train reg_fs: 0.0011729757534340024\n",
      "Optimization Finished!\n",
      "test loss: 0.004773435648530722, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0030847921086823134\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.003100527 valid loss= 0.007153228\n",
      "train reg_fs: 0.0009049674263224006\n",
      "Epoch: 1000 train loss=0.009211808 valid loss= 0.005435642\n",
      "train reg_fs: 0.0008527980535291135\n",
      "Epoch: 1500 train loss=0.003527853 valid loss= 0.004942952\n",
      "train reg_fs: 0.0008183852769434452\n",
      "Epoch: 2000 train loss=0.005056193 valid loss= 0.003971014\n",
      "train reg_fs: 0.0008058950188569725\n",
      "Epoch: 2500 train loss=0.003169697 valid loss= 0.004464900\n",
      "train reg_fs: 0.0007986717973835766\n",
      "Epoch: 3000 train loss=0.002493702 valid loss= 0.004485914\n",
      "train reg_fs: 0.0007933845045045018\n",
      "Epoch: 3500 train loss=0.009999719 valid loss= 0.005719044\n",
      "train reg_fs: 0.0007874430739320815\n",
      "Epoch: 4000 train loss=0.001766008 valid loss= 0.005051428\n",
      "train reg_fs: 0.0007746154442429543\n",
      "Epoch: 4500 train loss=0.004005411 valid loss= 0.003903316\n",
      "train reg_fs: 0.0007592610199935734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:26:48,349]\u001b[0m Trial 4 finished with value: 0.00303398544763466 and parameters: {'lam': 0.0010698288836695298, 'learning_rate': 0.10624157029791992, 'num_epoch': 5000}. Best is trial 0 with value: 0.0024490264889776097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002332649 valid loss= 0.003776201\n",
      "train reg_fs: 0.0007447952521033585\n",
      "Optimization Finished!\n",
      "test loss: 0.0033340957015752792, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00303398544763466\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015695347 valid loss= 0.008120083\n",
      "train reg_fs: 0.0017591669457033277\n",
      "Epoch: 1000 train loss=0.016769735 valid loss= 0.008355604\n",
      "train reg_fs: 0.0017558218678459525\n",
      "Epoch: 1500 train loss=0.012866656 valid loss= 0.006170876\n",
      "train reg_fs: 0.0017062922706827521\n",
      "Epoch: 2000 train loss=0.006129302 valid loss= 0.004641738\n",
      "train reg_fs: 0.0016461575869470835\n",
      "Epoch: 2500 train loss=0.004336464 valid loss= 0.003556177\n",
      "train reg_fs: 0.0015940675511956215\n",
      "Epoch: 3000 train loss=0.002323070 valid loss= 0.003165871\n",
      "train reg_fs: 0.0015523415058851242\n",
      "Epoch: 3500 train loss=0.004278734 valid loss= 0.004373170\n",
      "train reg_fs: 0.0015256261685863137\n",
      "Epoch: 4000 train loss=0.003915407 valid loss= 0.003485736\n",
      "train reg_fs: 0.001507872249931097\n",
      "Epoch: 4500 train loss=0.004001492 valid loss= 0.003239060\n",
      "train reg_fs: 0.0014947373420000076\n",
      "Epoch: 5000 train loss=0.002242156 valid loss= 0.002978675\n",
      "train reg_fs: 0.0014832379529252648\n",
      "Epoch: 5500 train loss=0.004370473 valid loss= 0.003460432\n",
      "train reg_fs: 0.0014734092401340604\n",
      "Epoch: 6000 train loss=0.005769849 valid loss= 0.002872447\n",
      "train reg_fs: 0.001464475761167705\n",
      "Epoch: 6500 train loss=0.006285158 valid loss= 0.003181433\n",
      "train reg_fs: 0.0014527440071105957\n",
      "Epoch: 7000 train loss=0.003880828 valid loss= 0.003404416\n",
      "train reg_fs: 0.001442828681319952\n",
      "Epoch: 7500 train loss=0.004015300 valid loss= 0.002990603\n",
      "train reg_fs: 0.001435097772628069\n",
      "Epoch: 8000 train loss=0.005192466 valid loss= 0.003914632\n",
      "train reg_fs: 0.0014255443820729852\n",
      "Epoch: 8500 train loss=0.003846729 valid loss= 0.003478128\n",
      "train reg_fs: 0.0014169823843985796\n",
      "Epoch: 9000 train loss=0.003582810 valid loss= 0.003456715\n",
      "train reg_fs: 0.0014092944329604506\n",
      "Epoch: 9500 train loss=0.002947751 valid loss= 0.002926520\n",
      "train reg_fs: 0.0014046342112123966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:27:55,440]\u001b[0m Trial 5 finished with value: 0.0013449369208300905 and parameters: {'lam': 0.0020251297040490028, 'learning_rate': 0.07422016152094056, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003394773 valid loss= 0.002808537\n",
      "train reg_fs: 0.001398230204358697\n",
      "Optimization Finished!\n",
      "test loss: 0.0035070471931248903, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0013449369208300905\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011844113 valid loss= 0.009296048\n",
      "train reg_fs: 0.0016120241489261389\n",
      "Epoch: 1000 train loss=0.010543466 valid loss= 0.008134441\n",
      "train reg_fs: 0.0016328786732628942\n",
      "Epoch: 1500 train loss=0.008933723 valid loss= 0.008294631\n",
      "train reg_fs: 0.0016483638901263475\n",
      "Epoch: 2000 train loss=0.014679698 valid loss= 0.008634226\n",
      "train reg_fs: 0.0016579811926931143\n",
      "Epoch: 2500 train loss=0.010948313 valid loss= 0.007400280\n",
      "train reg_fs: 0.0016638687811791897\n",
      "Epoch: 3000 train loss=0.008729324 valid loss= 0.007017517\n",
      "train reg_fs: 0.001665027579292655\n",
      "Epoch: 3500 train loss=0.018675754 valid loss= 0.006866698\n",
      "train reg_fs: 0.0016635643551126122\n",
      "Epoch: 4000 train loss=0.009838231 valid loss= 0.006989758\n",
      "train reg_fs: 0.001659568166360259\n",
      "Epoch: 4500 train loss=0.006895788 valid loss= 0.006993397\n",
      "train reg_fs: 0.0016542082885280252\n",
      "Epoch: 5000 train loss=0.014343604 valid loss= 0.007159889\n",
      "train reg_fs: 0.001644900068640709\n",
      "Epoch: 5500 train loss=0.008825906 valid loss= 0.006883990\n",
      "train reg_fs: 0.0016364890616387129\n",
      "Epoch: 6000 train loss=0.003701829 valid loss= 0.006663750\n",
      "train reg_fs: 0.001628222642466426\n",
      "Epoch: 6500 train loss=0.008675683 valid loss= 0.005940361\n",
      "train reg_fs: 0.0016206838190555573\n",
      "Epoch: 7000 train loss=0.007418514 valid loss= 0.006086746\n",
      "train reg_fs: 0.0016130255535244942\n",
      "Epoch: 7500 train loss=0.009315193 valid loss= 0.006276459\n",
      "train reg_fs: 0.0016060166526585817\n",
      "Epoch: 8000 train loss=0.002313070 valid loss= 0.005956792\n",
      "train reg_fs: 0.0015996868023648858\n",
      "Epoch: 8500 train loss=0.008738932 valid loss= 0.005555932\n",
      "train reg_fs: 0.001593886292539537\n",
      "Epoch: 9000 train loss=0.007595737 valid loss= 0.005174861\n",
      "train reg_fs: 0.0015866563189774752\n",
      "Epoch: 9500 train loss=0.005862162 valid loss= 0.005000343\n",
      "train reg_fs: 0.0015802800189703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:29:01,818]\u001b[0m Trial 6 finished with value: 0.0028333605732889537 and parameters: {'lam': 0.0018953900323618364, 'learning_rate': 0.022687623217388826, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003322606 valid loss= 0.004429672\n",
      "train reg_fs: 0.0015728181460872293\n",
      "Optimization Finished!\n",
      "test loss: 0.005282490514218807, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028333605732889537\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009452423 valid loss= 0.006727871\n",
      "train reg_fs: 0.000939234858378768\n",
      "Epoch: 1000 train loss=0.010419076 valid loss= 0.008139777\n",
      "train reg_fs: 0.0009263556567020714\n",
      "Epoch: 1500 train loss=0.011830965 valid loss= 0.006261185\n",
      "train reg_fs: 0.0009008086053654552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:29:16,020]\u001b[0m Trial 7 finished with value: 0.00667442216418122 and parameters: {'lam': 0.001068452421543597, 'learning_rate': 0.11929847123108774, 'num_epoch': 2000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.004995606 valid loss= 0.007580666\n",
      "train reg_fs: 0.0008851818274706602\n",
      "Optimization Finished!\n",
      "test loss: 0.0070760175585746765, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00667442216418122\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016297694 valid loss= 0.014916880\n",
      "train reg_fs: 0.006747206673026085\n",
      "Epoch: 1000 train loss=0.016916536 valid loss= 0.015309377\n",
      "train reg_fs: 0.0066306679509580135\n",
      "Epoch: 1500 train loss=0.012544040 valid loss= 0.013639046\n",
      "train reg_fs: 0.006446318235248327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:29:30,057]\u001b[0m Trial 8 finished with value: 0.006123665788000255 and parameters: {'lam': 0.007954593600689374, 'learning_rate': 0.0741101488195815, 'num_epoch': 2000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.012579444 valid loss= 0.012581348\n",
      "train reg_fs: 0.006278757471591234\n",
      "Optimization Finished!\n",
      "test loss: 0.01333106029778719, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006123665788000255\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008174803 valid loss= 0.007042373\n",
      "train reg_fs: 0.0011941310949623585\n",
      "Epoch: 1000 train loss=0.005637000 valid loss= 0.005899456\n",
      "train reg_fs: 0.0011716425651684403\n",
      "Epoch: 1500 train loss=0.005732570 valid loss= 0.006085094\n",
      "train reg_fs: 0.0011415713233873248\n",
      "Epoch: 2000 train loss=0.007186696 valid loss= 0.004208722\n",
      "train reg_fs: 0.0011175295803695917\n",
      "Epoch: 2500 train loss=0.004132164 valid loss= 0.003318559\n",
      "train reg_fs: 0.0010869152611121535\n",
      "Epoch: 3000 train loss=0.003125550 valid loss= 0.003064306\n",
      "train reg_fs: 0.0010597059736028314\n",
      "Epoch: 3500 train loss=0.003421918 valid loss= 0.002960507\n",
      "train reg_fs: 0.0010408175876364112\n",
      "Epoch: 4000 train loss=0.004788575 valid loss= 0.003302841\n",
      "train reg_fs: 0.0010252415668219328\n",
      "Epoch: 4500 train loss=0.003492661 valid loss= 0.003103407\n",
      "train reg_fs: 0.0010132970055565238\n",
      "Epoch: 5000 train loss=0.002815614 valid loss= 0.003793722\n",
      "train reg_fs: 0.0010055028833448887\n",
      "Epoch: 5500 train loss=0.003701742 valid loss= 0.003116427\n",
      "train reg_fs: 0.0009986584773287177\n",
      "Epoch: 6000 train loss=0.002343636 valid loss= 0.002925932\n",
      "train reg_fs: 0.0009910233784466982\n",
      "Epoch: 6500 train loss=0.001916892 valid loss= 0.003367137\n",
      "train reg_fs: 0.0009850707137957215\n",
      "Epoch: 7000 train loss=0.001946849 valid loss= 0.003046155\n",
      "train reg_fs: 0.0009798617102205753\n",
      "Epoch: 7500 train loss=0.004087367 valid loss= 0.002655770\n",
      "train reg_fs: 0.0009749215678311884\n",
      "Epoch: 8000 train loss=0.001899014 valid loss= 0.002902986\n",
      "train reg_fs: 0.000970819965004921\n",
      "Epoch: 8500 train loss=0.001906490 valid loss= 0.002977829\n",
      "train reg_fs: 0.000967260857578367\n",
      "Epoch: 9000 train loss=0.006032673 valid loss= 0.003338174\n",
      "train reg_fs: 0.0009639706113375723\n",
      "Epoch: 9500 train loss=0.001554445 valid loss= 0.002884213\n",
      "train reg_fs: 0.0009604890365153551\n",
      "Epoch: 10000 train loss=0.002529694 valid loss= 0.003892656\n",
      "train reg_fs: 0.0009562082123011351\n",
      "Epoch: 10500 train loss=0.001792018 valid loss= 0.003452474\n",
      "train reg_fs: 0.0009529950330033898\n",
      "Epoch: 11000 train loss=0.002139926 valid loss= 0.003178485\n",
      "train reg_fs: 0.0009493094403296709\n",
      "Epoch: 11500 train loss=0.002095711 valid loss= 0.003997441\n",
      "train reg_fs: 0.0009458388085477054\n",
      "Epoch: 12000 train loss=0.001886829 valid loss= 0.003098394\n",
      "train reg_fs: 0.0009434540406800807\n",
      "Epoch: 12500 train loss=0.005320730 valid loss= 0.002918508\n",
      "train reg_fs: 0.000940055469982326\n",
      "Epoch: 13000 train loss=0.004355181 valid loss= 0.002721108\n",
      "train reg_fs: 0.0009375717490911484\n",
      "Epoch: 13500 train loss=0.001630409 valid loss= 0.003152570\n",
      "train reg_fs: 0.000935860036406666\n",
      "Epoch: 14000 train loss=0.005544050 valid loss= 0.002961216\n",
      "train reg_fs: 0.0009343037963844836\n",
      "Epoch: 14500 train loss=0.001260228 valid loss= 0.003474892\n",
      "train reg_fs: 0.0009322770638391376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:31:03,452]\u001b[0m Trial 9 finished with value: 0.002185648823010055 and parameters: {'lam': 0.0013502203696489916, 'learning_rate': 0.12254710694468966, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002348130 valid loss= 0.003085067\n",
      "train reg_fs: 0.0009296126663684845\n",
      "Optimization Finished!\n",
      "test loss: 0.0033941762521862984, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002185648823010055\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010736211 valid loss= 0.009270512\n",
      "train reg_fs: 0.002666445216163993\n",
      "Epoch: 1000 train loss=0.011276707 valid loss= 0.008049818\n",
      "train reg_fs: 0.002586519345641136\n",
      "Epoch: 1500 train loss=0.010776542 valid loss= 0.006702060\n",
      "train reg_fs: 0.002468751510605216\n",
      "Epoch: 2000 train loss=0.003830663 valid loss= 0.004919791\n",
      "train reg_fs: 0.002420875011011958\n",
      "Epoch: 2500 train loss=0.005865819 valid loss= 0.005489463\n",
      "train reg_fs: 0.0023706117644906044\n",
      "Epoch: 3000 train loss=0.006671987 valid loss= 0.004899985\n",
      "train reg_fs: 0.0023159978445619345\n",
      "Epoch: 3500 train loss=0.002586711 valid loss= 0.005110247\n",
      "train reg_fs: 0.0022671285551041365\n",
      "Epoch: 4000 train loss=0.003927934 valid loss= 0.004919391\n",
      "train reg_fs: 0.0022179929073899984\n",
      "Epoch: 4500 train loss=0.003441638 valid loss= 0.004691241\n",
      "train reg_fs: 0.0021711173467338085\n",
      "Epoch: 5000 train loss=0.003871984 valid loss= 0.004617663\n",
      "train reg_fs: 0.002129900734871626\n",
      "Epoch: 5500 train loss=0.004702575 valid loss= 0.004511955\n",
      "train reg_fs: 0.0020934538915753365\n",
      "Epoch: 6000 train loss=0.004618187 valid loss= 0.004697554\n",
      "train reg_fs: 0.002075671451166272\n",
      "Epoch: 6500 train loss=0.004234842 valid loss= 0.005333294\n",
      "train reg_fs: 0.0020536319352686405\n",
      "Epoch: 7000 train loss=0.004591012 valid loss= 0.005018887\n",
      "train reg_fs: 0.002038803417235613\n",
      "Epoch: 7500 train loss=0.003635487 valid loss= 0.004550075\n",
      "train reg_fs: 0.0020157231483608484\n",
      "Epoch: 8000 train loss=0.004160961 valid loss= 0.005087503\n",
      "train reg_fs: 0.002004437381401658\n",
      "Epoch: 8500 train loss=0.002539238 valid loss= 0.005060595\n",
      "train reg_fs: 0.0019934552256017923\n",
      "Epoch: 9000 train loss=0.003584690 valid loss= 0.006342907\n",
      "train reg_fs: 0.0019776164554059505\n",
      "Epoch: 9500 train loss=0.004040519 valid loss= 0.004918133\n",
      "train reg_fs: 0.001965497387573123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:32:09,133]\u001b[0m Trial 10 finished with value: 0.0031430992921248446 and parameters: {'lam': 0.0029790218096502116, 'learning_rate': 0.19621225329675504, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004616794 valid loss= 0.005045074\n",
      "train reg_fs: 0.001958562759682536\n",
      "Optimization Finished!\n",
      "test loss: 0.005586166866123676, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0031430992921248446\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011433396 valid loss= 0.008506509\n",
      "train reg_fs: 0.0019202798139303923\n",
      "Epoch: 1000 train loss=0.009933736 valid loss= 0.004574539\n",
      "train reg_fs: 0.0017223363975062966\n",
      "Epoch: 1500 train loss=0.004923693 valid loss= 0.005297045\n",
      "train reg_fs: 0.0016561916563659906\n",
      "Epoch: 2000 train loss=0.005212095 valid loss= 0.004775051\n",
      "train reg_fs: 0.0016243919963017106\n",
      "Epoch: 2500 train loss=0.006356430 valid loss= 0.004971261\n",
      "train reg_fs: 0.001599034876562655\n",
      "Epoch: 3000 train loss=0.005815464 valid loss= 0.007690826\n",
      "train reg_fs: 0.0015749555313959718\n",
      "Epoch: 3500 train loss=0.004358225 valid loss= 0.005519967\n",
      "train reg_fs: 0.0015531884273514152\n",
      "Epoch: 4000 train loss=0.006243575 valid loss= 0.005062880\n",
      "train reg_fs: 0.0015352012123912573\n",
      "Epoch: 4500 train loss=0.003533838 valid loss= 0.005378303\n",
      "train reg_fs: 0.001521972706541419\n",
      "Epoch: 5000 train loss=0.003686036 valid loss= 0.005442517\n",
      "train reg_fs: 0.0015075525734573603\n",
      "Epoch: 5500 train loss=0.004334797 valid loss= 0.006894195\n",
      "train reg_fs: 0.0015071347588673234\n",
      "Epoch: 6000 train loss=0.002766446 valid loss= 0.006467265\n",
      "train reg_fs: 0.0015195162268355489\n",
      "Epoch: 6500 train loss=0.006870210 valid loss= 0.005635015\n",
      "train reg_fs: 0.001545965438708663\n",
      "Epoch: 7000 train loss=0.002593442 valid loss= 0.006000097\n",
      "train reg_fs: 0.0015650755958631635\n",
      "Epoch: 7500 train loss=0.002757594 valid loss= 0.005678450\n",
      "train reg_fs: 0.0015583708882331848\n",
      "Epoch: 8000 train loss=0.002615700 valid loss= 0.006364639\n",
      "train reg_fs: 0.0015533213736489415\n",
      "Epoch: 8500 train loss=0.005736073 valid loss= 0.006118428\n",
      "train reg_fs: 0.0015417442191392183\n",
      "Epoch: 9000 train loss=0.004498795 valid loss= 0.006536223\n",
      "train reg_fs: 0.0015355136711150408\n",
      "Epoch: 9500 train loss=0.001860315 valid loss= 0.005709336\n",
      "train reg_fs: 0.0015277627389878035\n",
      "Epoch: 10000 train loss=0.001991437 valid loss= 0.005385386\n",
      "train reg_fs: 0.0015160528710111976\n",
      "Epoch: 10500 train loss=0.002230382 valid loss= 0.005120715\n",
      "train reg_fs: 0.001514997216872871\n",
      "Epoch: 11000 train loss=0.005041247 valid loss= 0.004694301\n",
      "train reg_fs: 0.0015089772641658783\n",
      "Epoch: 11500 train loss=0.002823064 valid loss= 0.004827243\n",
      "train reg_fs: 0.0014986690366640687\n",
      "Epoch: 12000 train loss=0.003003888 valid loss= 0.005137837\n",
      "train reg_fs: 0.0014883304247632623\n",
      "Epoch: 12500 train loss=0.004624850 valid loss= 0.005042505\n",
      "train reg_fs: 0.0014818728668615222\n",
      "Epoch: 13000 train loss=0.004221315 valid loss= 0.004976157\n",
      "train reg_fs: 0.0014736547600477934\n",
      "Epoch: 13500 train loss=0.002161549 valid loss= 0.005817417\n",
      "train reg_fs: 0.001468668575398624\n",
      "Epoch: 14000 train loss=0.003292625 valid loss= 0.006067474\n",
      "train reg_fs: 0.001461798558011651\n",
      "Epoch: 14500 train loss=0.002234603 valid loss= 0.005874632\n",
      "train reg_fs: 0.001453830860555172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:33:46,416]\u001b[0m Trial 11 finished with value: 0.003963675590550313 and parameters: {'lam': 0.002353774245521596, 'learning_rate': 0.1974006885695881, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002134998 valid loss= 0.005458714\n",
      "train reg_fs: 0.001452022697776556\n",
      "Optimization Finished!\n",
      "test loss: 0.005871794186532497, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003963675590550313\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012367727 valid loss= 0.008432356\n",
      "train reg_fs: 0.0018509217770770192\n",
      "Epoch: 1000 train loss=0.015645407 valid loss= 0.007891736\n",
      "train reg_fs: 0.001861942932009697\n",
      "Epoch: 1500 train loss=0.013819059 valid loss= 0.007455687\n",
      "train reg_fs: 0.0018710666336119175\n",
      "Epoch: 2000 train loss=0.015422263 valid loss= 0.007484918\n",
      "train reg_fs: 0.0018781436374410987\n",
      "Epoch: 2500 train loss=0.020023158 valid loss= 0.007333768\n",
      "train reg_fs: 0.0018839928088709712\n",
      "Epoch: 3000 train loss=0.016507233 valid loss= 0.007278227\n",
      "train reg_fs: 0.001887715538032353\n",
      "Epoch: 3500 train loss=0.021797698 valid loss= 0.007971675\n",
      "train reg_fs: 0.0018911110237240791\n",
      "Epoch: 4000 train loss=0.007589884 valid loss= 0.006984408\n",
      "train reg_fs: 0.0018925416516140103\n",
      "Epoch: 4500 train loss=0.016638851 valid loss= 0.006786244\n",
      "train reg_fs: 0.0018922078888863325\n",
      "Epoch: 5000 train loss=0.010534141 valid loss= 0.006316847\n",
      "train reg_fs: 0.0018900728318840265\n",
      "Epoch: 5500 train loss=0.008582387 valid loss= 0.006872559\n",
      "train reg_fs: 0.0018865996971726418\n",
      "Epoch: 6000 train loss=0.010991270 valid loss= 0.006130704\n",
      "train reg_fs: 0.0018811823101714253\n",
      "Epoch: 6500 train loss=0.009572275 valid loss= 0.006254871\n",
      "train reg_fs: 0.001874454552307725\n",
      "Epoch: 7000 train loss=0.013247719 valid loss= 0.005980906\n",
      "train reg_fs: 0.0018653838196769357\n",
      "Epoch: 7500 train loss=0.011121683 valid loss= 0.005945215\n",
      "train reg_fs: 0.0018558106385171413\n",
      "Epoch: 8000 train loss=0.010352931 valid loss= 0.005657601\n",
      "train reg_fs: 0.0018438532715663314\n",
      "Epoch: 8500 train loss=0.008263377 valid loss= 0.005574554\n",
      "train reg_fs: 0.0018318849615752697\n",
      "Epoch: 9000 train loss=0.005672743 valid loss= 0.004885437\n",
      "train reg_fs: 0.0018195672892034054\n",
      "Epoch: 9500 train loss=0.014565609 valid loss= 0.005349897\n",
      "train reg_fs: 0.001807025051675737\n",
      "Epoch: 10000 train loss=0.006326402 valid loss= 0.004855657\n",
      "train reg_fs: 0.0017939552199095488\n",
      "Epoch: 10500 train loss=0.011145272 valid loss= 0.004820006\n",
      "train reg_fs: 0.0017810743302106857\n",
      "Epoch: 11000 train loss=0.007392722 valid loss= 0.004928957\n",
      "train reg_fs: 0.00176930520683527\n",
      "Epoch: 11500 train loss=0.008115913 valid loss= 0.004822145\n",
      "train reg_fs: 0.001758377649821341\n",
      "Epoch: 12000 train loss=0.008077259 valid loss= 0.004553562\n",
      "train reg_fs: 0.0017478713998571038\n",
      "Epoch: 12500 train loss=0.009941353 valid loss= 0.004403113\n",
      "train reg_fs: 0.001739040482789278\n",
      "Epoch: 13000 train loss=0.008424868 valid loss= 0.004342150\n",
      "train reg_fs: 0.0017309740651398897\n",
      "Epoch: 13500 train loss=0.006116468 valid loss= 0.004314880\n",
      "train reg_fs: 0.0017232170794159174\n",
      "Epoch: 14000 train loss=0.005610507 valid loss= 0.004326232\n",
      "train reg_fs: 0.0017163791926577687\n",
      "Epoch: 14500 train loss=0.005334268 valid loss= 0.004309861\n",
      "train reg_fs: 0.001709884381853044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:35:24,134]\u001b[0m Trial 12 finished with value: 0.0026523082750944597 and parameters: {'lam': 0.002184151984906976, 'learning_rate': 0.010497401528449914, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005415033 valid loss= 0.004368658\n",
      "train reg_fs: 0.0017046141438186169\n",
      "Optimization Finished!\n",
      "test loss: 0.004643776919692755, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026523082750944597\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009529874 valid loss= 0.006242725\n",
      "train reg_fs: 0.0027663076762109995\n",
      "Epoch: 1000 train loss=0.010527480 valid loss= 0.006167867\n",
      "train reg_fs: 0.0026312978006899357\n",
      "Epoch: 1500 train loss=0.005417930 valid loss= 0.005185470\n",
      "train reg_fs: 0.0026054184418171644\n",
      "Epoch: 2000 train loss=0.003677306 valid loss= 0.006350338\n",
      "train reg_fs: 0.0025743634905666113\n",
      "Epoch: 2500 train loss=0.005835816 valid loss= 0.005722532\n",
      "train reg_fs: 0.0024959712754935026\n",
      "Epoch: 3000 train loss=0.007053437 valid loss= 0.005582448\n",
      "train reg_fs: 0.0024182952474802732\n",
      "Epoch: 3500 train loss=0.003141134 valid loss= 0.005267080\n",
      "train reg_fs: 0.0023383835796266794\n",
      "Epoch: 4000 train loss=0.003260234 valid loss= 0.004599943\n",
      "train reg_fs: 0.0022634239867329597\n",
      "Epoch: 4500 train loss=0.002481356 valid loss= 0.004530103\n",
      "train reg_fs: 0.0022085905075073242\n",
      "Epoch: 5000 train loss=0.002918564 valid loss= 0.004801543\n",
      "train reg_fs: 0.0021698358468711376\n",
      "Epoch: 5500 train loss=0.003175217 valid loss= 0.004440604\n",
      "train reg_fs: 0.0021449655760079622\n",
      "Epoch: 6000 train loss=0.004241713 valid loss= 0.004571519\n",
      "train reg_fs: 0.002128106541931629\n",
      "Epoch: 6500 train loss=0.009440394 valid loss= 0.004413891\n",
      "train reg_fs: 0.002115339506417513\n",
      "Epoch: 7000 train loss=0.003193540 valid loss= 0.004227223\n",
      "train reg_fs: 0.0021055040415376425\n",
      "Epoch: 7500 train loss=0.006072955 valid loss= 0.004121729\n",
      "train reg_fs: 0.002097797580063343\n",
      "Epoch: 8000 train loss=0.005132918 valid loss= 0.004311608\n",
      "train reg_fs: 0.0020912319887429476\n",
      "Epoch: 8500 train loss=0.003128686 valid loss= 0.004593832\n",
      "train reg_fs: 0.002085950691252947\n",
      "Epoch: 9000 train loss=0.002488942 valid loss= 0.004240469\n",
      "train reg_fs: 0.0020818940829485655\n",
      "Epoch: 9500 train loss=0.002440016 valid loss= 0.004312886\n",
      "train reg_fs: 0.0020783902145922184\n",
      "Epoch: 10000 train loss=0.003589732 valid loss= 0.004352157\n",
      "train reg_fs: 0.0020751208066940308\n",
      "Epoch: 10500 train loss=0.005035471 valid loss= 0.004164766\n",
      "train reg_fs: 0.002072355942800641\n",
      "Epoch: 11000 train loss=0.003628374 valid loss= 0.004420173\n",
      "train reg_fs: 0.0020699449814856052\n",
      "Epoch: 11500 train loss=0.003675868 valid loss= 0.004090112\n",
      "train reg_fs: 0.002067946596071124\n",
      "Epoch: 12000 train loss=0.004102050 valid loss= 0.004381556\n",
      "train reg_fs: 0.0020659342408180237\n",
      "Epoch: 12500 train loss=0.005119226 valid loss= 0.004205054\n",
      "train reg_fs: 0.002064302796497941\n",
      "Epoch: 13000 train loss=0.002654237 valid loss= 0.004370752\n",
      "train reg_fs: 0.002062929095700383\n",
      "Epoch: 13500 train loss=0.006656828 valid loss= 0.004466207\n",
      "train reg_fs: 0.002061427105218172\n",
      "Epoch: 14000 train loss=0.006514039 valid loss= 0.004162305\n",
      "train reg_fs: 0.0020601842552423477\n",
      "Epoch: 14500 train loss=0.002810895 valid loss= 0.004445228\n",
      "train reg_fs: 0.0020590065978467464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:37:00,316]\u001b[0m Trial 13 finished with value: 0.0024635571986346724 and parameters: {'lam': 0.0034178118442152465, 'learning_rate': 0.13247940590705715, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004533586 valid loss= 0.004467534\n",
      "train reg_fs: 0.0020579935517162085\n",
      "Optimization Finished!\n",
      "test loss: 0.004172367509454489, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024635571986346724\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014441572 valid loss= 0.006467480\n",
      "train reg_fs: 0.0011342060752213001\n",
      "Epoch: 1000 train loss=0.007074348 valid loss= 0.006569075\n",
      "train reg_fs: 0.0011014834744855762\n",
      "Epoch: 1500 train loss=0.005510825 valid loss= 0.004758568\n",
      "train reg_fs: 0.0010531679727137089\n",
      "Epoch: 2000 train loss=0.004048588 valid loss= 0.004779466\n",
      "train reg_fs: 0.0010198075324296951\n",
      "Epoch: 2500 train loss=0.005845431 valid loss= 0.004030028\n",
      "train reg_fs: 0.0009994949214160442\n",
      "Epoch: 3000 train loss=0.003745652 valid loss= 0.004834965\n",
      "train reg_fs: 0.000983054400421679\n",
      "Epoch: 3500 train loss=0.006597848 valid loss= 0.004435159\n",
      "train reg_fs: 0.0009699109359644353\n",
      "Epoch: 4000 train loss=0.005398256 valid loss= 0.005124124\n",
      "train reg_fs: 0.0009595140581950545\n",
      "Epoch: 4500 train loss=0.004440770 valid loss= 0.004549141\n",
      "train reg_fs: 0.0009507073555141687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:37:33,493]\u001b[0m Trial 14 finished with value: 0.0033453693455688847 and parameters: {'lam': 0.001339599204914743, 'learning_rate': 0.06605719549760504, 'num_epoch': 5000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.008350701 valid loss= 0.004314220\n",
      "train reg_fs: 0.0009416316752322018\n",
      "Optimization Finished!\n",
      "test loss: 0.004914944991469383, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0033453693455688847\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012410738 valid loss= 0.010689290\n",
      "train reg_fs: 0.0028676181100308895\n",
      "Epoch: 1000 train loss=0.020529434 valid loss= 0.011354736\n",
      "train reg_fs: 0.0029030628502368927\n",
      "Epoch: 1500 train loss=0.015671661 valid loss= 0.010675156\n",
      "train reg_fs: 0.0029270504601299763\n",
      "Epoch: 2000 train loss=0.010554910 valid loss= 0.009319733\n",
      "train reg_fs: 0.002937750890851021\n",
      "Epoch: 2500 train loss=0.020705417 valid loss= 0.009799549\n",
      "train reg_fs: 0.0029354209545999765\n",
      "Epoch: 3000 train loss=0.007576585 valid loss= 0.008694489\n",
      "train reg_fs: 0.0029228648636490107\n",
      "Epoch: 3500 train loss=0.014452634 valid loss= 0.008685421\n",
      "train reg_fs: 0.0029000169597566128\n",
      "Epoch: 4000 train loss=0.010529096 valid loss= 0.007935736\n",
      "train reg_fs: 0.0028696570079773664\n",
      "Epoch: 4500 train loss=0.007748860 valid loss= 0.008064772\n",
      "train reg_fs: 0.002835290739312768\n",
      "Epoch: 5000 train loss=0.011993918 valid loss= 0.008701300\n",
      "train reg_fs: 0.0028050027322024107\n",
      "Epoch: 5500 train loss=0.009726204 valid loss= 0.007855947\n",
      "train reg_fs: 0.0027821736875921488\n",
      "Epoch: 6000 train loss=0.016980099 valid loss= 0.007161477\n",
      "train reg_fs: 0.0027576577849686146\n",
      "Epoch: 6500 train loss=0.008594330 valid loss= 0.007337412\n",
      "train reg_fs: 0.0027396129444241524\n",
      "Epoch: 7000 train loss=0.010346504 valid loss= 0.007200019\n",
      "train reg_fs: 0.002722166944295168\n",
      "Epoch: 7500 train loss=0.011768959 valid loss= 0.007646540\n",
      "train reg_fs: 0.0027051945216953754\n",
      "Epoch: 8000 train loss=0.009643262 valid loss= 0.007038324\n",
      "train reg_fs: 0.002689467277377844\n",
      "Epoch: 8500 train loss=0.007463991 valid loss= 0.006521080\n",
      "train reg_fs: 0.0026721209287643433\n",
      "Epoch: 9000 train loss=0.005588239 valid loss= 0.006272878\n",
      "train reg_fs: 0.0026505894493311644\n",
      "Epoch: 9500 train loss=0.007292079 valid loss= 0.006508693\n",
      "train reg_fs: 0.0026320526376366615\n",
      "Epoch: 10000 train loss=0.007639275 valid loss= 0.006136243\n",
      "train reg_fs: 0.0026117742527276278\n",
      "Epoch: 10500 train loss=0.022400552 valid loss= 0.006096221\n",
      "train reg_fs: 0.0025868925731629133\n",
      "Epoch: 11000 train loss=0.006377520 valid loss= 0.005331186\n",
      "train reg_fs: 0.002560978289693594\n",
      "Epoch: 11500 train loss=0.005049327 valid loss= 0.005223402\n",
      "train reg_fs: 0.0025322844740003347\n",
      "Epoch: 12000 train loss=0.005666824 valid loss= 0.005039978\n",
      "train reg_fs: 0.0025022998452186584\n",
      "Epoch: 12500 train loss=0.009290537 valid loss= 0.004915516\n",
      "train reg_fs: 0.002476469613611698\n",
      "Epoch: 13000 train loss=0.004282373 valid loss= 0.004876568\n",
      "train reg_fs: 0.0024537118151783943\n",
      "Epoch: 13500 train loss=0.007794187 valid loss= 0.004662559\n",
      "train reg_fs: 0.0024362257681787014\n",
      "Epoch: 14000 train loss=0.004795451 valid loss= 0.004965171\n",
      "train reg_fs: 0.0024210112169384956\n",
      "Epoch: 14500 train loss=0.005478109 valid loss= 0.005245304\n",
      "train reg_fs: 0.0024073789827525616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:39:09,483]\u001b[0m Trial 15 finished with value: 0.002518618103036162 and parameters: {'lam': 0.0033707169812279797, 'learning_rate': 0.026252064316590978, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004306134 valid loss= 0.005039907\n",
      "train reg_fs: 0.0023964804131537676\n",
      "Optimization Finished!\n",
      "test loss: 0.005425359588116407, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002518618103036162\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016721575 valid loss= 0.009648535\n",
      "train reg_fs: 0.0014359480701386929\n",
      "Epoch: 1000 train loss=0.008177251 valid loss= 0.004349315\n",
      "train reg_fs: 0.0013485056115314364\n",
      "Epoch: 1500 train loss=0.002293374 valid loss= 0.004581021\n",
      "train reg_fs: 0.0013068715343251824\n",
      "Epoch: 2000 train loss=0.006465931 valid loss= 0.003653259\n",
      "train reg_fs: 0.001279531279578805\n",
      "Epoch: 2500 train loss=0.001825018 valid loss= 0.004249738\n",
      "train reg_fs: 0.0012571796542033553\n",
      "Epoch: 3000 train loss=0.001766462 valid loss= 0.003028904\n",
      "train reg_fs: 0.0012455007527023554\n",
      "Epoch: 3500 train loss=0.002155992 valid loss= 0.003776782\n",
      "train reg_fs: 0.001235556323081255\n",
      "Epoch: 4000 train loss=0.002354134 valid loss= 0.003537669\n",
      "train reg_fs: 0.001229971880093217\n",
      "Epoch: 4500 train loss=0.001424633 valid loss= 0.002984543\n",
      "train reg_fs: 0.0012238642666488886\n",
      "Epoch: 5000 train loss=0.004267380 valid loss= 0.002511122\n",
      "train reg_fs: 0.0012205105740576982\n",
      "Epoch: 5500 train loss=0.003543316 valid loss= 0.002946181\n",
      "train reg_fs: 0.0012156838783994317\n",
      "Epoch: 6000 train loss=0.002952702 valid loss= 0.003095199\n",
      "train reg_fs: 0.0012097059516236186\n",
      "Epoch: 6500 train loss=0.001553393 valid loss= 0.003302057\n",
      "train reg_fs: 0.0012011233484372497\n",
      "Epoch: 7000 train loss=0.002405166 valid loss= 0.002766559\n",
      "train reg_fs: 0.0011915437644347548\n",
      "Epoch: 7500 train loss=0.002171781 valid loss= 0.002387193\n",
      "train reg_fs: 0.001182782812975347\n",
      "Epoch: 8000 train loss=0.010488340 valid loss= 0.002133215\n",
      "train reg_fs: 0.0011732160346582532\n",
      "Epoch: 8500 train loss=0.005372375 valid loss= 0.002198684\n",
      "train reg_fs: 0.0011628710199147463\n",
      "Epoch: 9000 train loss=0.002497786 valid loss= 0.003670704\n",
      "train reg_fs: 0.0011550216004252434\n",
      "Epoch: 9500 train loss=0.001922375 valid loss= 0.002028390\n",
      "train reg_fs: 0.0011479360982775688\n",
      "Epoch: 10000 train loss=0.002153696 valid loss= 0.002063378\n",
      "train reg_fs: 0.0011423110263422132\n",
      "Epoch: 10500 train loss=0.002856063 valid loss= 0.002078737\n",
      "train reg_fs: 0.0011378256604075432\n",
      "Epoch: 11000 train loss=0.002291836 valid loss= 0.001862946\n",
      "train reg_fs: 0.0011351971188560128\n",
      "Epoch: 11500 train loss=0.001564746 valid loss= 0.001772253\n",
      "train reg_fs: 0.0011323728831484914\n",
      "Epoch: 12000 train loss=0.001542190 valid loss= 0.002084293\n",
      "train reg_fs: 0.0011300843907520175\n",
      "Epoch: 12500 train loss=0.002434888 valid loss= 0.001810261\n",
      "train reg_fs: 0.0011281068436801434\n",
      "Epoch: 13000 train loss=0.001408576 valid loss= 0.001498787\n",
      "train reg_fs: 0.0011266476940363646\n",
      "Epoch: 13500 train loss=0.002337546 valid loss= 0.002220497\n",
      "train reg_fs: 0.0011250709649175406\n",
      "Epoch: 14000 train loss=0.002735197 valid loss= 0.001341023\n",
      "train reg_fs: 0.00112392648588866\n",
      "Epoch: 14500 train loss=0.002370446 valid loss= 0.001173073\n",
      "train reg_fs: 0.0011230648960918188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:40:44,812]\u001b[0m Trial 16 finished with value: 0.0015753009051880716 and parameters: {'lam': 0.001676522148818826, 'learning_rate': 0.15329053038359358, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005979174 valid loss= 0.002700164\n",
      "train reg_fs: 0.001122223329730332\n",
      "Optimization Finished!\n",
      "test loss: 0.00268810847774148, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0015753009051880716\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010087652 valid loss= 0.009879354\n",
      "train reg_fs: 0.002259792760014534\n",
      "Epoch: 1000 train loss=0.008187950 valid loss= 0.009646036\n",
      "train reg_fs: 0.002136122900992632\n",
      "Epoch: 1500 train loss=0.006143319 valid loss= 0.008850206\n",
      "train reg_fs: 0.002065501641482115\n",
      "Epoch: 2000 train loss=0.007567917 valid loss= 0.007293887\n",
      "train reg_fs: 0.0019901026971638203\n",
      "Epoch: 2500 train loss=0.008628758 valid loss= 0.005746254\n",
      "train reg_fs: 0.0018916493281722069\n",
      "Epoch: 3000 train loss=0.004966107 valid loss= 0.005311480\n",
      "train reg_fs: 0.0018361688125878572\n",
      "Epoch: 3500 train loss=0.003999709 valid loss= 0.005394055\n",
      "train reg_fs: 0.00176426291000098\n",
      "Epoch: 4000 train loss=0.011606738 valid loss= 0.004564029\n",
      "train reg_fs: 0.0017105323495343328\n",
      "Epoch: 4500 train loss=0.009054596 valid loss= 0.003873792\n",
      "train reg_fs: 0.0016764354659244418\n",
      "Epoch: 5000 train loss=0.006444182 valid loss= 0.004571213\n",
      "train reg_fs: 0.0016551263397559524\n",
      "Epoch: 5500 train loss=0.002693578 valid loss= 0.003715010\n",
      "train reg_fs: 0.0016386082861572504\n",
      "Epoch: 6000 train loss=0.002283948 valid loss= 0.003814925\n",
      "train reg_fs: 0.0016271581407636404\n",
      "Epoch: 6500 train loss=0.002914458 valid loss= 0.004966461\n",
      "train reg_fs: 0.0016189174493774772\n",
      "Epoch: 7000 train loss=0.002575660 valid loss= 0.003621860\n",
      "train reg_fs: 0.0016125148395076394\n",
      "Epoch: 7500 train loss=0.006719314 valid loss= 0.004283841\n",
      "train reg_fs: 0.0016072773141786456\n",
      "Epoch: 8000 train loss=0.004718028 valid loss= 0.003597822\n",
      "train reg_fs: 0.0016033448046073318\n",
      "Epoch: 8500 train loss=0.005994239 valid loss= 0.003536837\n",
      "train reg_fs: 0.0015996878501027822\n",
      "Epoch: 9000 train loss=0.002190755 valid loss= 0.003773246\n",
      "train reg_fs: 0.0015969324158504605\n",
      "Epoch: 9500 train loss=0.002398366 valid loss= 0.004198626\n",
      "train reg_fs: 0.0015946917701512575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:41:47,415]\u001b[0m Trial 17 finished with value: 0.00236251515052621 and parameters: {'lam': 0.002629436657454452, 'learning_rate': 0.1708318586740588, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002225144 valid loss= 0.003918998\n",
      "train reg_fs: 0.0015924843028187752\n",
      "Optimization Finished!\n",
      "test loss: 0.0036921442952007055, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00236251515052621\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017691750 valid loss= 0.009505933\n",
      "train reg_fs: 0.0036874369252473116\n",
      "Epoch: 1000 train loss=0.013716058 valid loss= 0.009027750\n",
      "train reg_fs: 0.003707942785695195\n",
      "Epoch: 1500 train loss=0.010582120 valid loss= 0.007805631\n",
      "train reg_fs: 0.0036769614089280367\n",
      "Epoch: 2000 train loss=0.008288705 valid loss= 0.007795049\n",
      "train reg_fs: 0.003616341156885028\n",
      "Epoch: 2500 train loss=0.010206505 valid loss= 0.007296572\n",
      "train reg_fs: 0.0035331961698830128\n",
      "Epoch: 3000 train loss=0.008606187 valid loss= 0.006066756\n",
      "train reg_fs: 0.003462366061285138\n",
      "Epoch: 3500 train loss=0.010708990 valid loss= 0.005738780\n",
      "train reg_fs: 0.0034091519191861153\n",
      "Epoch: 4000 train loss=0.009249101 valid loss= 0.005845511\n",
      "train reg_fs: 0.003371989820152521\n",
      "Epoch: 4500 train loss=0.005575506 valid loss= 0.005616463\n",
      "train reg_fs: 0.003342675045132637\n",
      "Epoch: 5000 train loss=0.008671540 valid loss= 0.005857273\n",
      "train reg_fs: 0.0033177926670759916\n",
      "Epoch: 5500 train loss=0.004056153 valid loss= 0.005885314\n",
      "train reg_fs: 0.0032950174063444138\n",
      "Epoch: 6000 train loss=0.010867072 valid loss= 0.005704421\n",
      "train reg_fs: 0.0032714256085455418\n",
      "Epoch: 6500 train loss=0.004606273 valid loss= 0.005706456\n",
      "train reg_fs: 0.0032490717712789774\n",
      "Epoch: 7000 train loss=0.005350616 valid loss= 0.005683899\n",
      "train reg_fs: 0.0032291081734001637\n",
      "Epoch: 7500 train loss=0.008478930 valid loss= 0.005534713\n",
      "train reg_fs: 0.0032116519287228584\n",
      "Epoch: 8000 train loss=0.005502018 valid loss= 0.005843999\n",
      "train reg_fs: 0.0031951204873621464\n",
      "Epoch: 8500 train loss=0.006904840 valid loss= 0.005293124\n",
      "train reg_fs: 0.003179519437253475\n",
      "Epoch: 9000 train loss=0.005872771 valid loss= 0.005260277\n",
      "train reg_fs: 0.003165504662320018\n",
      "Epoch: 9500 train loss=0.005914270 valid loss= 0.005734245\n",
      "train reg_fs: 0.0031522465869784355\n",
      "Epoch: 10000 train loss=0.006045420 valid loss= 0.005732046\n",
      "train reg_fs: 0.003141803666949272\n",
      "Epoch: 10500 train loss=0.004994892 valid loss= 0.005506624\n",
      "train reg_fs: 0.003131927689537406\n",
      "Epoch: 11000 train loss=0.005413055 valid loss= 0.005159124\n",
      "train reg_fs: 0.0031227420549839735\n",
      "Epoch: 11500 train loss=0.004236152 valid loss= 0.005241494\n",
      "train reg_fs: 0.003113248385488987\n",
      "Epoch: 12000 train loss=0.006493222 valid loss= 0.005106315\n",
      "train reg_fs: 0.003105218056589365\n",
      "Epoch: 12500 train loss=0.012729977 valid loss= 0.005697945\n",
      "train reg_fs: 0.003097133943811059\n",
      "Epoch: 13000 train loss=0.005034794 valid loss= 0.004932282\n",
      "train reg_fs: 0.003089610254392028\n",
      "Epoch: 13500 train loss=0.008579154 valid loss= 0.005756267\n",
      "train reg_fs: 0.0030831003095954657\n",
      "Epoch: 14000 train loss=0.003200175 valid loss= 0.005250810\n",
      "train reg_fs: 0.0030757717322558165\n",
      "Epoch: 14500 train loss=0.011479945 valid loss= 0.005403056\n",
      "train reg_fs: 0.0030691148713231087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:43:22,692]\u001b[0m Trial 18 finished with value: 0.0022778146548199656 and parameters: {'lam': 0.004309630379431637, 'learning_rate': 0.03358710599251489, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003416276 valid loss= 0.005242261\n",
      "train reg_fs: 0.0030636463779956102\n",
      "Optimization Finished!\n",
      "test loss: 0.005121775437146425, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022778146548199656\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016194392 valid loss= 0.007769928\n",
      "train reg_fs: 0.0015162514755502343\n",
      "Epoch: 1000 train loss=0.007911502 valid loss= 0.010189590\n",
      "train reg_fs: 0.001528499647974968\n",
      "Epoch: 1500 train loss=0.015875136 valid loss= 0.008779153\n",
      "train reg_fs: 0.0015105917118489742\n",
      "Epoch: 2000 train loss=0.007736585 valid loss= 0.007356291\n",
      "train reg_fs: 0.0014792175497859716\n",
      "Epoch: 2500 train loss=0.007800485 valid loss= 0.005195354\n",
      "train reg_fs: 0.001443218905478716\n",
      "Epoch: 3000 train loss=0.006814620 valid loss= 0.005005207\n",
      "train reg_fs: 0.0014108931645751\n",
      "Epoch: 3500 train loss=0.007686341 valid loss= 0.003823217\n",
      "train reg_fs: 0.0013872548006474972\n",
      "Epoch: 4000 train loss=0.004241108 valid loss= 0.003964673\n",
      "train reg_fs: 0.001364103052765131\n",
      "Epoch: 4500 train loss=0.004868259 valid loss= 0.003726292\n",
      "train reg_fs: 0.0013433927670121193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:43:54,990]\u001b[0m Trial 19 finished with value: 0.0027557045727506476 and parameters: {'lam': 0.0017530728254850586, 'learning_rate': 0.06040209101579248, 'num_epoch': 5000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.006907029 valid loss= 0.004092418\n",
      "train reg_fs: 0.001327339094132185\n",
      "Optimization Finished!\n",
      "test loss: 0.003917609341442585, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027557045727506476\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008017704 valid loss= 0.010739509\n",
      "train reg_fs: 0.0016345750773325562\n",
      "Epoch: 1000 train loss=0.004058283 valid loss= 0.004970442\n",
      "train reg_fs: 0.001490123919211328\n",
      "Epoch: 1500 train loss=0.007005488 valid loss= 0.004942817\n",
      "train reg_fs: 0.0014344144146889448\n",
      "Epoch: 2000 train loss=0.003090592 valid loss= 0.004888075\n",
      "train reg_fs: 0.0013882238417863846\n",
      "Epoch: 2500 train loss=0.014458654 valid loss= 0.005093328\n",
      "train reg_fs: 0.0013430453836917877\n",
      "Epoch: 3000 train loss=0.002629671 valid loss= 0.003972471\n",
      "train reg_fs: 0.001309935818426311\n",
      "Epoch: 3500 train loss=0.004099377 valid loss= 0.004344606\n",
      "train reg_fs: 0.001286814920604229\n",
      "Epoch: 4000 train loss=0.006951712 valid loss= 0.006220661\n",
      "train reg_fs: 0.00127033784519881\n",
      "Epoch: 4500 train loss=0.004292978 valid loss= 0.003457482\n",
      "train reg_fs: 0.0012568945530802011\n",
      "Epoch: 5000 train loss=0.004376712 valid loss= 0.003397326\n",
      "train reg_fs: 0.0012463409220799804\n",
      "Epoch: 5500 train loss=0.003158910 valid loss= 0.003870148\n",
      "train reg_fs: 0.0012368542375043035\n",
      "Epoch: 6000 train loss=0.001549631 valid loss= 0.003665728\n",
      "train reg_fs: 0.0012284127296879888\n",
      "Epoch: 6500 train loss=0.006407469 valid loss= 0.003827849\n",
      "train reg_fs: 0.0012214594753459096\n",
      "Epoch: 7000 train loss=0.001720018 valid loss= 0.003543571\n",
      "train reg_fs: 0.0012153801508247852\n",
      "Epoch: 7500 train loss=0.004127431 valid loss= 0.003624777\n",
      "train reg_fs: 0.0012102711480110884\n",
      "Epoch: 8000 train loss=0.002913061 valid loss= 0.003287588\n",
      "train reg_fs: 0.0012060032458975911\n",
      "Epoch: 8500 train loss=0.002180754 valid loss= 0.003257461\n",
      "train reg_fs: 0.0012023631716147065\n",
      "Epoch: 9000 train loss=0.001895321 valid loss= 0.003831741\n",
      "train reg_fs: 0.0011993590742349625\n",
      "Epoch: 9500 train loss=0.002804112 valid loss= 0.003040223\n",
      "train reg_fs: 0.0011966570746153593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:44:57,944]\u001b[0m Trial 20 finished with value: 0.0029981396983123727 and parameters: {'lam': 0.0019514504499736063, 'learning_rate': 0.14984689572226959, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001576750 valid loss= 0.004169448\n",
      "train reg_fs: 0.0011942392447963357\n",
      "Optimization Finished!\n",
      "test loss: 0.003802374703809619, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0029981396983123727\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006803643 valid loss= 0.007655710\n",
      "train reg_fs: 0.001175468205474317\n",
      "Epoch: 1000 train loss=0.004954238 valid loss= 0.006558969\n",
      "train reg_fs: 0.001115350634790957\n",
      "Epoch: 1500 train loss=0.004405248 valid loss= 0.004797408\n",
      "train reg_fs: 0.0010609938763082027\n",
      "Epoch: 2000 train loss=0.002471223 valid loss= 0.003730766\n",
      "train reg_fs: 0.0010128699941560626\n",
      "Epoch: 2500 train loss=0.005834795 valid loss= 0.003790047\n",
      "train reg_fs: 0.0009796746307983994\n",
      "Epoch: 3000 train loss=0.004346260 valid loss= 0.004013717\n",
      "train reg_fs: 0.0009531945106573403\n",
      "Epoch: 3500 train loss=0.002249317 valid loss= 0.003855405\n",
      "train reg_fs: 0.0009341331315226853\n",
      "Epoch: 4000 train loss=0.002564283 valid loss= 0.003679691\n",
      "train reg_fs: 0.0009196661412715912\n",
      "Epoch: 4500 train loss=0.002185625 valid loss= 0.003656859\n",
      "train reg_fs: 0.0009077940485440195\n",
      "Epoch: 5000 train loss=0.002234117 valid loss= 0.003504921\n",
      "train reg_fs: 0.0008987794280983508\n",
      "Epoch: 5500 train loss=0.002958741 valid loss= 0.003556083\n",
      "train reg_fs: 0.0008917207596823573\n",
      "Epoch: 6000 train loss=0.001418271 valid loss= 0.004004431\n",
      "train reg_fs: 0.0008855824125930667\n",
      "Epoch: 6500 train loss=0.002500594 valid loss= 0.004000380\n",
      "train reg_fs: 0.0008801963413134217\n",
      "Epoch: 7000 train loss=0.005656511 valid loss= 0.003242145\n",
      "train reg_fs: 0.0008757657487876713\n",
      "Epoch: 7500 train loss=0.002692384 valid loss= 0.003393446\n",
      "train reg_fs: 0.0008718694443814456\n",
      "Epoch: 8000 train loss=0.001293038 valid loss= 0.003072682\n",
      "train reg_fs: 0.0008684570784680545\n",
      "Epoch: 8500 train loss=0.004221180 valid loss= 0.003008369\n",
      "train reg_fs: 0.0008653918630443513\n",
      "Epoch: 9000 train loss=0.004536101 valid loss= 0.003324170\n",
      "train reg_fs: 0.0008627696079201996\n",
      "Epoch: 9500 train loss=0.002288018 valid loss= 0.003111192\n",
      "train reg_fs: 0.0008603206370025873\n",
      "Epoch: 10000 train loss=0.004622606 valid loss= 0.002950389\n",
      "train reg_fs: 0.0008581825532019138\n",
      "Epoch: 10500 train loss=0.001351661 valid loss= 0.003550596\n",
      "train reg_fs: 0.0008563623414374888\n",
      "Epoch: 11000 train loss=0.001668494 valid loss= 0.003271176\n",
      "train reg_fs: 0.0008546858443878591\n",
      "Epoch: 11500 train loss=0.001496100 valid loss= 0.003423284\n",
      "train reg_fs: 0.0008532326901331544\n",
      "Epoch: 12000 train loss=0.005096093 valid loss= 0.003147434\n",
      "train reg_fs: 0.0008519565453752875\n",
      "Epoch: 12500 train loss=0.004715294 valid loss= 0.002985303\n",
      "train reg_fs: 0.0008507748716510832\n",
      "Epoch: 13000 train loss=0.003734992 valid loss= 0.003282332\n",
      "train reg_fs: 0.0008495396468788385\n",
      "Epoch: 13500 train loss=0.001981436 valid loss= 0.003274535\n",
      "train reg_fs: 0.000848511466756463\n",
      "Epoch: 14000 train loss=0.001736480 valid loss= 0.003433549\n",
      "train reg_fs: 0.00084755226271227\n",
      "Epoch: 14500 train loss=0.005171373 valid loss= 0.003009919\n",
      "train reg_fs: 0.000846613897010684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:46:31,353]\u001b[0m Trial 21 finished with value: 0.0022245718699463236 and parameters: {'lam': 0.0013893265975041442, 'learning_rate': 0.09858570781949395, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002446522 valid loss= 0.003053122\n",
      "train reg_fs: 0.0008458082447759807\n",
      "Optimization Finished!\n",
      "test loss: 0.0028297959361225367, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022245718699463236\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014244047 valid loss= 0.008659625\n",
      "train reg_fs: 0.0009894402464851737\n",
      "Epoch: 1000 train loss=0.007836783 valid loss= 0.009148190\n",
      "train reg_fs: 0.0009798966348171234\n",
      "Epoch: 1500 train loss=0.006955075 valid loss= 0.007343770\n",
      "train reg_fs: 0.0009620492346584797\n",
      "Epoch: 2000 train loss=0.005790167 valid loss= 0.007057752\n",
      "train reg_fs: 0.0009527463698759675\n",
      "Epoch: 2500 train loss=0.011811500 valid loss= 0.006538075\n",
      "train reg_fs: 0.0009457706473767757\n",
      "Epoch: 3000 train loss=0.003053769 valid loss= 0.006619768\n",
      "train reg_fs: 0.0009411702631041408\n",
      "Epoch: 3500 train loss=0.006091675 valid loss= 0.006314028\n",
      "train reg_fs: 0.0009402838768437505\n",
      "Epoch: 4000 train loss=0.002777117 valid loss= 0.006823951\n",
      "train reg_fs: 0.0009415500680916011\n",
      "Epoch: 4500 train loss=0.003190984 valid loss= 0.007291741\n",
      "train reg_fs: 0.0009424203308299184\n",
      "Epoch: 5000 train loss=0.009028764 valid loss= 0.005329295\n",
      "train reg_fs: 0.0009457938140258193\n",
      "Epoch: 5500 train loss=0.003982794 valid loss= 0.005059530\n",
      "train reg_fs: 0.000947524094954133\n",
      "Epoch: 6000 train loss=0.002745457 valid loss= 0.005301575\n",
      "train reg_fs: 0.0009485036134719849\n",
      "Epoch: 6500 train loss=0.003464209 valid loss= 0.005720931\n",
      "train reg_fs: 0.0009533845004625618\n",
      "Epoch: 7000 train loss=0.003635162 valid loss= 0.004773844\n",
      "train reg_fs: 0.0009546426008455455\n",
      "Epoch: 7500 train loss=0.002843745 valid loss= 0.004957676\n",
      "train reg_fs: 0.0009547346271574497\n",
      "Epoch: 8000 train loss=0.003377157 valid loss= 0.004655583\n",
      "train reg_fs: 0.0009564148494973779\n",
      "Epoch: 8500 train loss=0.001939617 valid loss= 0.004869563\n",
      "train reg_fs: 0.0009546554647386074\n",
      "Epoch: 9000 train loss=0.003310147 valid loss= 0.004634263\n",
      "train reg_fs: 0.0009531065588817\n",
      "Epoch: 9500 train loss=0.002963820 valid loss= 0.004961457\n",
      "train reg_fs: 0.0009530656388960779\n",
      "Epoch: 10000 train loss=0.005137601 valid loss= 0.004464334\n",
      "train reg_fs: 0.0009536217548884451\n",
      "Epoch: 10500 train loss=0.002172416 valid loss= 0.004589552\n",
      "train reg_fs: 0.0009545623906888068\n",
      "Epoch: 11000 train loss=0.002281888 valid loss= 0.004908124\n",
      "train reg_fs: 0.0009548162342980504\n",
      "Epoch: 11500 train loss=0.003332156 valid loss= 0.004835417\n",
      "train reg_fs: 0.0009560227626934648\n",
      "Epoch: 12000 train loss=0.004194004 valid loss= 0.004894597\n",
      "train reg_fs: 0.0009559578029438853\n",
      "Epoch: 12500 train loss=0.003522692 valid loss= 0.005029340\n",
      "train reg_fs: 0.0009544907952658832\n",
      "Epoch: 13000 train loss=0.002672837 valid loss= 0.005424833\n",
      "train reg_fs: 0.0009537229198031127\n",
      "Epoch: 13500 train loss=0.002076366 valid loss= 0.005279464\n",
      "train reg_fs: 0.000953272741753608\n",
      "Epoch: 14000 train loss=0.011438027 valid loss= 0.004932262\n",
      "train reg_fs: 0.000951574940700084\n",
      "Epoch: 14500 train loss=0.001816518 valid loss= 0.005518530\n",
      "train reg_fs: 0.0009497475111857057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:48:05,086]\u001b[0m Trial 22 finished with value: 0.004561928998462613 and parameters: {'lam': 0.0011378793970056758, 'learning_rate': 0.07939890392670751, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001861306 valid loss= 0.005513822\n",
      "train reg_fs: 0.0009489152580499649\n",
      "Optimization Finished!\n",
      "test loss: 0.005821384489536285, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004561928998462613\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013987438 valid loss= 0.009672301\n",
      "train reg_fs: 0.0019662294071167707\n",
      "Epoch: 1000 train loss=0.006859593 valid loss= 0.008232731\n",
      "train reg_fs: 0.00192767393309623\n",
      "Epoch: 1500 train loss=0.008130248 valid loss= 0.006785716\n",
      "train reg_fs: 0.0018913004314526916\n",
      "Epoch: 2000 train loss=0.006714999 valid loss= 0.006496402\n",
      "train reg_fs: 0.001869874307885766\n",
      "Epoch: 2500 train loss=0.004732477 valid loss= 0.004795441\n",
      "train reg_fs: 0.0018476974219083786\n",
      "Epoch: 3000 train loss=0.004264231 valid loss= 0.005893985\n",
      "train reg_fs: 0.0018163557397201657\n",
      "Epoch: 3500 train loss=0.009235497 valid loss= 0.004814065\n",
      "train reg_fs: 0.001791299437172711\n",
      "Epoch: 4000 train loss=0.004980900 valid loss= 0.005073254\n",
      "train reg_fs: 0.0017406236147508025\n",
      "Epoch: 4500 train loss=0.003293465 valid loss= 0.005063034\n",
      "train reg_fs: 0.0017049460439011455\n",
      "Epoch: 5000 train loss=0.003279693 valid loss= 0.004014827\n",
      "train reg_fs: 0.001670879079028964\n",
      "Epoch: 5500 train loss=0.002458122 valid loss= 0.004186855\n",
      "train reg_fs: 0.0016499619232490659\n",
      "Epoch: 6000 train loss=0.003581851 valid loss= 0.004510956\n",
      "train reg_fs: 0.0016340134898200631\n",
      "Epoch: 6500 train loss=0.003078582 valid loss= 0.004509897\n",
      "train reg_fs: 0.0016177126672118902\n",
      "Epoch: 7000 train loss=0.002531196 valid loss= 0.004176549\n",
      "train reg_fs: 0.001603639335371554\n",
      "Epoch: 7500 train loss=0.003240698 valid loss= 0.004475008\n",
      "train reg_fs: 0.0015935306437313557\n",
      "Epoch: 8000 train loss=0.003767336 valid loss= 0.004234293\n",
      "train reg_fs: 0.001583930104970932\n",
      "Epoch: 8500 train loss=0.002256707 valid loss= 0.004403112\n",
      "train reg_fs: 0.0015709323342889547\n",
      "Epoch: 9000 train loss=0.002461698 valid loss= 0.005615450\n",
      "train reg_fs: 0.0015614317962899804\n",
      "Epoch: 9500 train loss=0.003099191 valid loss= 0.004574786\n",
      "train reg_fs: 0.0015512986574321985\n",
      "Epoch: 10000 train loss=0.002348485 valid loss= 0.005413267\n",
      "train reg_fs: 0.0015435452805832028\n",
      "Epoch: 10500 train loss=0.002497316 valid loss= 0.005091372\n",
      "train reg_fs: 0.001534097595140338\n",
      "Epoch: 11000 train loss=0.002600215 valid loss= 0.004751111\n",
      "train reg_fs: 0.0015268558636307716\n",
      "Epoch: 11500 train loss=0.003607967 valid loss= 0.005290353\n",
      "train reg_fs: 0.0015176031738519669\n",
      "Epoch: 12000 train loss=0.004473097 valid loss= 0.005008998\n",
      "train reg_fs: 0.0015137713635340333\n",
      "Epoch: 12500 train loss=0.001775159 valid loss= 0.004917319\n",
      "train reg_fs: 0.0015075206756591797\n",
      "Epoch: 13000 train loss=0.003903579 valid loss= 0.004995572\n",
      "train reg_fs: 0.0015044370666146278\n",
      "Epoch: 13500 train loss=0.001968869 valid loss= 0.005300120\n",
      "train reg_fs: 0.0015016577672213316\n",
      "Epoch: 14000 train loss=0.002309114 valid loss= 0.005872499\n",
      "train reg_fs: 0.0014951227931305766\n",
      "Epoch: 14500 train loss=0.002637647 valid loss= 0.005390769\n",
      "train reg_fs: 0.0014908883022144437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:49:38,509]\u001b[0m Trial 23 finished with value: 0.003629548029270813 and parameters: {'lam': 0.0022931958806571666, 'learning_rate': 0.13766828059360456, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003342133 valid loss= 0.005069633\n",
      "train reg_fs: 0.0014862464740872383\n",
      "Optimization Finished!\n",
      "test loss: 0.004987688269466162, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003629548029270813\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005545334 valid loss= 0.006395373\n",
      "train reg_fs: 0.0013810921227559447\n",
      "Epoch: 1000 train loss=0.005749593 valid loss= 0.005368931\n",
      "train reg_fs: 0.0012670550495386124\n",
      "Epoch: 1500 train loss=0.003703074 valid loss= 0.004800647\n",
      "train reg_fs: 0.001219889265485108\n",
      "Epoch: 2000 train loss=0.003437176 valid loss= 0.004882082\n",
      "train reg_fs: 0.0012118113227188587\n",
      "Epoch: 2500 train loss=0.011497151 valid loss= 0.004120023\n",
      "train reg_fs: 0.0012124982895329595\n",
      "Epoch: 3000 train loss=0.007040782 valid loss= 0.003942410\n",
      "train reg_fs: 0.0012062255991622806\n",
      "Epoch: 3500 train loss=0.005531205 valid loss= 0.003836759\n",
      "train reg_fs: 0.0011848771246150136\n",
      "Epoch: 4000 train loss=0.002910359 valid loss= 0.003793377\n",
      "train reg_fs: 0.0011635982664301991\n",
      "Epoch: 4500 train loss=0.011383708 valid loss= 0.003684906\n",
      "train reg_fs: 0.0011476819636300206\n",
      "Epoch: 5000 train loss=0.002901111 valid loss= 0.003908340\n",
      "train reg_fs: 0.0011365050449967384\n",
      "Epoch: 5500 train loss=0.002227168 valid loss= 0.003613119\n",
      "train reg_fs: 0.0011266039218753576\n",
      "Epoch: 6000 train loss=0.005199890 valid loss= 0.003221469\n",
      "train reg_fs: 0.001121586887165904\n",
      "Epoch: 6500 train loss=0.006782247 valid loss= 0.003123155\n",
      "train reg_fs: 0.0011158084962517023\n",
      "Epoch: 7000 train loss=0.003655167 valid loss= 0.003495073\n",
      "train reg_fs: 0.0011105533922091126\n",
      "Epoch: 7500 train loss=0.001921540 valid loss= 0.003030714\n",
      "train reg_fs: 0.0011050947941839695\n",
      "Epoch: 8000 train loss=0.001549781 valid loss= 0.003208395\n",
      "train reg_fs: 0.0011012682225555182\n",
      "Epoch: 8500 train loss=0.001297106 valid loss= 0.003386554\n",
      "train reg_fs: 0.0010979261714965105\n",
      "Epoch: 9000 train loss=0.003957901 valid loss= 0.003041333\n",
      "train reg_fs: 0.001095050829462707\n",
      "Epoch: 9500 train loss=0.003037270 valid loss= 0.003041768\n",
      "train reg_fs: 0.001090800971724093\n",
      "Epoch: 10000 train loss=0.001822930 valid loss= 0.003673343\n",
      "train reg_fs: 0.0010848400415852666\n",
      "Epoch: 10500 train loss=0.001521288 valid loss= 0.002933176\n",
      "train reg_fs: 0.001084397081285715\n",
      "Epoch: 11000 train loss=0.001825220 valid loss= 0.003464245\n",
      "train reg_fs: 0.0010810666717588902\n",
      "Epoch: 11500 train loss=0.004737600 valid loss= 0.003221140\n",
      "train reg_fs: 0.0010774197289720178\n",
      "Epoch: 12000 train loss=0.002777017 valid loss= 0.003085934\n",
      "train reg_fs: 0.001074135536327958\n",
      "Epoch: 12500 train loss=0.001649870 valid loss= 0.003775612\n",
      "train reg_fs: 0.0010742804734036326\n",
      "Epoch: 13000 train loss=0.001670804 valid loss= 0.003524579\n",
      "train reg_fs: 0.0010710746282711625\n",
      "Epoch: 13500 train loss=0.001849352 valid loss= 0.003395558\n",
      "train reg_fs: 0.0010701160645112395\n",
      "Epoch: 14000 train loss=0.006619621 valid loss= 0.003520458\n",
      "train reg_fs: 0.0010675420053303242\n",
      "Epoch: 14500 train loss=0.001485649 valid loss= 0.003745382\n",
      "train reg_fs: 0.001062456052750349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:51:13,125]\u001b[0m Trial 24 finished with value: 0.0023345473190287125 and parameters: {'lam': 0.0015754650137513777, 'learning_rate': 0.19988260334812277, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005431103 valid loss= 0.003360264\n",
      "train reg_fs: 0.001062624854966998\n",
      "Optimization Finished!\n",
      "test loss: 0.0035131853073835373, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023345473190287125\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015930438 valid loss= 0.007480230\n",
      "train reg_fs: 0.0013462716015055776\n",
      "Epoch: 1000 train loss=0.010229512 valid loss= 0.006380116\n",
      "train reg_fs: 0.0013152107130736113\n",
      "Epoch: 1500 train loss=0.004481439 valid loss= 0.005443331\n",
      "train reg_fs: 0.001281594973988831\n",
      "Epoch: 2000 train loss=0.003107026 valid loss= 0.004007121\n",
      "train reg_fs: 0.0012417638208717108\n",
      "Epoch: 2500 train loss=0.004369428 valid loss= 0.003824550\n",
      "train reg_fs: 0.001214413670822978\n",
      "Epoch: 3000 train loss=0.004155032 valid loss= 0.004487896\n",
      "train reg_fs: 0.0012033823877573013\n",
      "Epoch: 3500 train loss=0.003675145 valid loss= 0.003722817\n",
      "train reg_fs: 0.0011923906859010458\n",
      "Epoch: 4000 train loss=0.007247694 valid loss= 0.003795333\n",
      "train reg_fs: 0.0011777151376008987\n",
      "Epoch: 4500 train loss=0.003277484 valid loss= 0.003732304\n",
      "train reg_fs: 0.0011630122317001224\n",
      "Epoch: 5000 train loss=0.002314204 valid loss= 0.004329351\n",
      "train reg_fs: 0.0011509413598105311\n",
      "Epoch: 5500 train loss=0.001468019 valid loss= 0.003699763\n",
      "train reg_fs: 0.0011414180044084787\n",
      "Epoch: 6000 train loss=0.002404440 valid loss= 0.003389619\n",
      "train reg_fs: 0.0011336312163621187\n",
      "Epoch: 6500 train loss=0.005727034 valid loss= 0.003398804\n",
      "train reg_fs: 0.001128682866692543\n",
      "Epoch: 7000 train loss=0.002499911 valid loss= 0.003227798\n",
      "train reg_fs: 0.0011237250873818994\n",
      "Epoch: 7500 train loss=0.003217969 valid loss= 0.002859271\n",
      "train reg_fs: 0.0011200492735952139\n",
      "Epoch: 8000 train loss=0.004754396 valid loss= 0.002781244\n",
      "train reg_fs: 0.001116757863201201\n",
      "Epoch: 8500 train loss=0.003179867 valid loss= 0.003252919\n",
      "train reg_fs: 0.0011144562158733606\n",
      "Epoch: 9000 train loss=0.002772290 valid loss= 0.003466440\n",
      "train reg_fs: 0.0011117103276774287\n",
      "Epoch: 9500 train loss=0.003022736 valid loss= 0.003488885\n",
      "train reg_fs: 0.001109230681322515\n",
      "Epoch: 10000 train loss=0.004532755 valid loss= 0.003334756\n",
      "train reg_fs: 0.001108343480154872\n",
      "Epoch: 10500 train loss=0.001888547 valid loss= 0.003415825\n",
      "train reg_fs: 0.001106933574192226\n",
      "Epoch: 11000 train loss=0.001983784 valid loss= 0.003383055\n",
      "train reg_fs: 0.0011059355456382036\n",
      "Epoch: 11500 train loss=0.001583037 valid loss= 0.002921910\n",
      "train reg_fs: 0.0011046339059248567\n",
      "Epoch: 12000 train loss=0.006302433 valid loss= 0.003046806\n",
      "train reg_fs: 0.001103148446418345\n",
      "Epoch: 12500 train loss=0.002071014 valid loss= 0.003485349\n",
      "train reg_fs: 0.0011019862722605467\n",
      "Epoch: 13000 train loss=0.002900583 valid loss= 0.003004894\n",
      "train reg_fs: 0.001100964960642159\n",
      "Epoch: 13500 train loss=0.010419871 valid loss= 0.003005462\n",
      "train reg_fs: 0.001099743996746838\n",
      "Epoch: 14000 train loss=0.002351284 valid loss= 0.003516905\n",
      "train reg_fs: 0.0010987824061885476\n",
      "Epoch: 14500 train loss=0.001574107 valid loss= 0.003647894\n",
      "train reg_fs: 0.001097841770388186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:52:46,496]\u001b[0m Trial 25 finished with value: 0.001979746912840714 and parameters: {'lam': 0.001548899603270594, 'learning_rate': 0.10887058522085268, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002791689 valid loss= 0.003030431\n",
      "train reg_fs: 0.0010968634160235524\n",
      "Optimization Finished!\n",
      "test loss: 0.0028909887187182903, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001979746912840714\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013569830 valid loss= 0.009351915\n",
      "train reg_fs: 0.0022564013488590717\n",
      "Epoch: 1000 train loss=0.008907795 valid loss= 0.010961510\n",
      "train reg_fs: 0.002205688739195466\n",
      "Epoch: 1500 train loss=0.008943637 valid loss= 0.007658613\n",
      "train reg_fs: 0.0021407008171081543\n",
      "Epoch: 2000 train loss=0.007558824 valid loss= 0.005896121\n",
      "train reg_fs: 0.0020950206089764833\n",
      "Epoch: 2500 train loss=0.007142119 valid loss= 0.006758591\n",
      "train reg_fs: 0.0020445934496819973\n",
      "Epoch: 3000 train loss=0.004200763 valid loss= 0.004543036\n",
      "train reg_fs: 0.0019924768712371588\n",
      "Epoch: 3500 train loss=0.004293117 valid loss= 0.004837320\n",
      "train reg_fs: 0.0019444759236648679\n",
      "Epoch: 4000 train loss=0.002884494 valid loss= 0.004560167\n",
      "train reg_fs: 0.0019083628430962563\n",
      "Epoch: 4500 train loss=0.004108753 valid loss= 0.005592838\n",
      "train reg_fs: 0.001875216607004404\n",
      "Epoch: 5000 train loss=0.004195989 valid loss= 0.004345369\n",
      "train reg_fs: 0.0018409532494843006\n",
      "Epoch: 5500 train loss=0.003009600 valid loss= 0.004420012\n",
      "train reg_fs: 0.001816118718124926\n",
      "Epoch: 6000 train loss=0.003598383 valid loss= 0.004695259\n",
      "train reg_fs: 0.0017934114439412951\n",
      "Epoch: 6500 train loss=0.002830264 valid loss= 0.004247411\n",
      "train reg_fs: 0.0017729592509567738\n",
      "Epoch: 7000 train loss=0.002400722 valid loss= 0.004295836\n",
      "train reg_fs: 0.0017533083446323872\n",
      "Epoch: 7500 train loss=0.003084550 valid loss= 0.004193948\n",
      "train reg_fs: 0.0017382457153871655\n",
      "Epoch: 8000 train loss=0.002241719 valid loss= 0.004188860\n",
      "train reg_fs: 0.0017260105814784765\n",
      "Epoch: 8500 train loss=0.004980299 valid loss= 0.004016584\n",
      "train reg_fs: 0.001715172897092998\n",
      "Epoch: 9000 train loss=0.002550220 valid loss= 0.004157794\n",
      "train reg_fs: 0.0017056550132110715\n",
      "Epoch: 9500 train loss=0.002334902 valid loss= 0.004035916\n",
      "train reg_fs: 0.001696823164820671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:53:50,173]\u001b[0m Trial 26 finished with value: 0.0021712067933383856 and parameters: {'lam': 0.0026242580504076715, 'learning_rate': 0.08977481464261965, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003206483 valid loss= 0.003874725\n",
      "train reg_fs: 0.0016890980768948793\n",
      "Optimization Finished!\n",
      "test loss: 0.003544355509802699, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021712067933383856\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020704322 valid loss= 0.008586992\n",
      "train reg_fs: 0.0014889721060171723\n",
      "Epoch: 1000 train loss=0.015118787 valid loss= 0.009368028\n",
      "train reg_fs: 0.0015115798451006413\n",
      "Epoch: 1500 train loss=0.005247502 valid loss= 0.009370195\n",
      "train reg_fs: 0.001511779730208218\n",
      "Epoch: 2000 train loss=0.008566182 valid loss= 0.008844823\n",
      "train reg_fs: 0.0015002270229160786\n",
      "Epoch: 2500 train loss=0.015997112 valid loss= 0.007326541\n",
      "train reg_fs: 0.001481999410316348\n",
      "Epoch: 3000 train loss=0.004329236 valid loss= 0.007593003\n",
      "train reg_fs: 0.001466734567657113\n",
      "Epoch: 3500 train loss=0.006850651 valid loss= 0.007050769\n",
      "train reg_fs: 0.0014538706745952368\n",
      "Epoch: 4000 train loss=0.007380337 valid loss= 0.006622595\n",
      "train reg_fs: 0.0014468145091086626\n",
      "Epoch: 4500 train loss=0.004370354 valid loss= 0.007042942\n",
      "train reg_fs: 0.0014390844153240323\n",
      "Epoch: 5000 train loss=0.004421964 valid loss= 0.006730743\n",
      "train reg_fs: 0.0014346977695822716\n",
      "Epoch: 5500 train loss=0.005388062 valid loss= 0.006287980\n",
      "train reg_fs: 0.001431759214028716\n",
      "Epoch: 6000 train loss=0.002947870 valid loss= 0.006576512\n",
      "train reg_fs: 0.0014274923596531153\n",
      "Epoch: 6500 train loss=0.005100774 valid loss= 0.006392732\n",
      "train reg_fs: 0.0014265024801716208\n",
      "Epoch: 7000 train loss=0.005059924 valid loss= 0.005847613\n",
      "train reg_fs: 0.001425787340849638\n",
      "Epoch: 7500 train loss=0.003199044 valid loss= 0.006306435\n",
      "train reg_fs: 0.0014230819651857018\n",
      "Epoch: 8000 train loss=0.004146641 valid loss= 0.005564682\n",
      "train reg_fs: 0.0014222414465621114\n",
      "Epoch: 8500 train loss=0.002619006 valid loss= 0.005579602\n",
      "train reg_fs: 0.001420147018507123\n",
      "Epoch: 9000 train loss=0.002474670 valid loss= 0.005864205\n",
      "train reg_fs: 0.0014173458330333233\n",
      "Epoch: 9500 train loss=0.003119577 valid loss= 0.005368730\n",
      "train reg_fs: 0.0014169048517942429\n",
      "Epoch: 10000 train loss=0.003421457 valid loss= 0.004888945\n",
      "train reg_fs: 0.0014147039037197828\n",
      "Epoch: 10500 train loss=0.002868928 valid loss= 0.005094749\n",
      "train reg_fs: 0.001413106918334961\n",
      "Epoch: 11000 train loss=0.003025713 valid loss= 0.005251184\n",
      "train reg_fs: 0.0014087507734075189\n",
      "Epoch: 11500 train loss=0.003952711 valid loss= 0.005526239\n",
      "train reg_fs: 0.0014065890572965145\n",
      "Epoch: 12000 train loss=0.003038709 valid loss= 0.005211412\n",
      "train reg_fs: 0.0014045715797692537\n",
      "Epoch: 12500 train loss=0.002083989 valid loss= 0.005249330\n",
      "train reg_fs: 0.0014028082368895411\n",
      "Epoch: 13000 train loss=0.001903248 valid loss= 0.005309717\n",
      "train reg_fs: 0.0014021897222846746\n",
      "Epoch: 13500 train loss=0.004149853 valid loss= 0.005182574\n",
      "train reg_fs: 0.0013999177608639002\n",
      "Epoch: 14000 train loss=0.005818228 valid loss= 0.004936737\n",
      "train reg_fs: 0.0013973648892715573\n",
      "Epoch: 14500 train loss=0.005774164 valid loss= 0.005052025\n",
      "train reg_fs: 0.0013952128356322646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:55:23,854]\u001b[0m Trial 27 finished with value: 0.004172947182884559 and parameters: {'lam': 0.0017184866938930801, 'learning_rate': 0.05847412351121358, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001967515 valid loss= 0.005583431\n",
      "train reg_fs: 0.0013909201370552182\n",
      "Optimization Finished!\n",
      "test loss: 0.006411137990653515, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004172947182884559\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017857276 valid loss= 0.008324930\n",
      "train reg_fs: 0.0017863083630800247\n",
      "Epoch: 1000 train loss=0.013071232 valid loss= 0.006886561\n",
      "train reg_fs: 0.0017465808195993304\n",
      "Epoch: 1500 train loss=0.004885756 valid loss= 0.007847972\n",
      "train reg_fs: 0.001703063491731882\n",
      "Epoch: 2000 train loss=0.009533161 valid loss= 0.005146116\n",
      "train reg_fs: 0.0016906074015423656\n",
      "Epoch: 2500 train loss=0.003954298 valid loss= 0.005347110\n",
      "train reg_fs: 0.0016653247876092792\n",
      "Epoch: 3000 train loss=0.002645317 valid loss= 0.004913397\n",
      "train reg_fs: 0.0016465414082631469\n",
      "Epoch: 3500 train loss=0.003979840 valid loss= 0.005110940\n",
      "train reg_fs: 0.0016200677491724491\n",
      "Epoch: 4000 train loss=0.004032612 valid loss= 0.006235984\n",
      "train reg_fs: 0.0015958367148414254\n",
      "Epoch: 4500 train loss=0.004215364 valid loss= 0.005744406\n",
      "train reg_fs: 0.001571783795952797\n",
      "Epoch: 5000 train loss=0.002066465 valid loss= 0.006261820\n",
      "train reg_fs: 0.0015402015997096896\n",
      "Epoch: 5500 train loss=0.002914001 valid loss= 0.005987426\n",
      "train reg_fs: 0.0015108260558918118\n",
      "Epoch: 6000 train loss=0.004274741 valid loss= 0.006029727\n",
      "train reg_fs: 0.0014851052546873689\n",
      "Epoch: 6500 train loss=0.002537898 valid loss= 0.006120116\n",
      "train reg_fs: 0.0014623281313106418\n",
      "Epoch: 7000 train loss=0.003498057 valid loss= 0.005917395\n",
      "train reg_fs: 0.0014502030098810792\n",
      "Epoch: 7500 train loss=0.003307517 valid loss= 0.006372332\n",
      "train reg_fs: 0.0014347321121022105\n",
      "Epoch: 8000 train loss=0.002209469 valid loss= 0.006251210\n",
      "train reg_fs: 0.0014257327420637012\n",
      "Epoch: 8500 train loss=0.003111953 valid loss= 0.006031423\n",
      "train reg_fs: 0.001414890750311315\n",
      "Epoch: 9000 train loss=0.004282680 valid loss= 0.006140653\n",
      "train reg_fs: 0.0014048159355297685\n",
      "Epoch: 9500 train loss=0.002336983 valid loss= 0.007081425\n",
      "train reg_fs: 0.0013956044567748904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:56:27,050]\u001b[0m Trial 28 finished with value: 0.004835148097047378 and parameters: {'lam': 0.0020458797703547422, 'learning_rate': 0.160568264913485, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001991268 valid loss= 0.006276602\n",
      "train reg_fs: 0.0013857590965926647\n",
      "Optimization Finished!\n",
      "test loss: 0.0062989057041704655, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004835148097047378\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009075019 valid loss= 0.004373632\n",
      "train reg_fs: 0.000987668172456324\n",
      "Epoch: 1000 train loss=0.002589808 valid loss= 0.004618783\n",
      "train reg_fs: 0.0009392909123562276\n",
      "Epoch: 1500 train loss=0.003738458 valid loss= 0.003324348\n",
      "train reg_fs: 0.0009145972435362637\n",
      "Epoch: 2000 train loss=0.003128853 valid loss= 0.003435804\n",
      "train reg_fs: 0.0008994847885333002\n",
      "Epoch: 2500 train loss=0.003725636 valid loss= 0.003339170\n",
      "train reg_fs: 0.0008883794071152806\n",
      "Epoch: 3000 train loss=0.002614401 valid loss= 0.003071490\n",
      "train reg_fs: 0.000879356695804745\n",
      "Epoch: 3500 train loss=0.006785141 valid loss= 0.002942918\n",
      "train reg_fs: 0.0008727485546842217\n",
      "Epoch: 4000 train loss=0.005377113 valid loss= 0.003140561\n",
      "train reg_fs: 0.0008674940327182412\n",
      "Epoch: 4500 train loss=0.002587970 valid loss= 0.004078211\n",
      "train reg_fs: 0.0008634126279503107\n",
      "Epoch: 5000 train loss=0.001313744 valid loss= 0.002826361\n",
      "train reg_fs: 0.0008598616113886237\n",
      "Epoch: 5500 train loss=0.001484987 valid loss= 0.003022191\n",
      "train reg_fs: 0.0008573014056310058\n",
      "Epoch: 6000 train loss=0.002559559 valid loss= 0.003750244\n",
      "train reg_fs: 0.0008550558122806251\n",
      "Epoch: 6500 train loss=0.001225489 valid loss= 0.003202143\n",
      "train reg_fs: 0.000852503115311265\n",
      "Epoch: 7000 train loss=0.001669195 valid loss= 0.003767937\n",
      "train reg_fs: 0.0008505862788297236\n",
      "Epoch: 7500 train loss=0.004252381 valid loss= 0.003384282\n",
      "train reg_fs: 0.0008489820174872875\n",
      "Epoch: 8000 train loss=0.001578231 valid loss= 0.003101406\n",
      "train reg_fs: 0.0008474831120111048\n",
      "Epoch: 8500 train loss=0.004484799 valid loss= 0.002743473\n",
      "train reg_fs: 0.0008459887467324734\n",
      "Epoch: 9000 train loss=0.004030269 valid loss= 0.002926277\n",
      "train reg_fs: 0.0008445865823887289\n",
      "Epoch: 9500 train loss=0.001592027 valid loss= 0.003028212\n",
      "train reg_fs: 0.0008436106727458537\n",
      "Epoch: 10000 train loss=0.002338796 valid loss= 0.002967504\n",
      "train reg_fs: 0.0008427615975961089\n",
      "Epoch: 10500 train loss=0.003556908 valid loss= 0.002967471\n",
      "train reg_fs: 0.0008420194499194622\n",
      "Epoch: 11000 train loss=0.002970567 valid loss= 0.003351055\n",
      "train reg_fs: 0.0008410635637119412\n",
      "Epoch: 11500 train loss=0.001847175 valid loss= 0.003069622\n",
      "train reg_fs: 0.0008402664680033922\n",
      "Epoch: 12000 train loss=0.002904162 valid loss= 0.003064642\n",
      "train reg_fs: 0.0008396009216085076\n",
      "Epoch: 12500 train loss=0.004587354 valid loss= 0.003070544\n",
      "train reg_fs: 0.0008387448615394533\n",
      "Epoch: 13000 train loss=0.002491437 valid loss= 0.002762473\n",
      "train reg_fs: 0.0008382434607483447\n",
      "Epoch: 13500 train loss=0.003652086 valid loss= 0.002397331\n",
      "train reg_fs: 0.0008376114419661462\n",
      "Epoch: 14000 train loss=0.001179048 valid loss= 0.003199677\n",
      "train reg_fs: 0.0008371602743864059\n",
      "Epoch: 14500 train loss=0.007782887 valid loss= 0.002368423\n",
      "train reg_fs: 0.0008366122492589056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:57:59,987]\u001b[0m Trial 29 finished with value: 0.0017981506694318623 and parameters: {'lam': 0.0011828187781289783, 'learning_rate': 0.08555632148806043, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001655982 valid loss= 0.002598202\n",
      "train reg_fs: 0.0008360063075087965\n",
      "Optimization Finished!\n",
      "test loss: 0.002575899474322796, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0017981506694318623\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009760990 valid loss= 0.006582099\n",
      "train reg_fs: 0.0010331652592867613\n",
      "Epoch: 1000 train loss=0.004376018 valid loss= 0.011525590\n",
      "train reg_fs: 0.0010139516089111567\n",
      "Epoch: 1500 train loss=0.005026329 valid loss= 0.006879151\n",
      "train reg_fs: 0.0009507248760201037\n",
      "Epoch: 2000 train loss=0.009271581 valid loss= 0.005590560\n",
      "train reg_fs: 0.0008910439792089164\n",
      "Epoch: 2500 train loss=0.004182633 valid loss= 0.003942695\n",
      "train reg_fs: 0.0008536649402230978\n",
      "Epoch: 3000 train loss=0.005272374 valid loss= 0.004228026\n",
      "train reg_fs: 0.0008290742989629507\n",
      "Epoch: 3500 train loss=0.001782269 valid loss= 0.004293739\n",
      "train reg_fs: 0.0008119145641103387\n",
      "Epoch: 4000 train loss=0.001712995 valid loss= 0.003952032\n",
      "train reg_fs: 0.0007987320423126221\n",
      "Epoch: 4500 train loss=0.001176856 valid loss= 0.003445131\n",
      "train reg_fs: 0.0007890706183388829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 21:58:32,461]\u001b[0m Trial 30 finished with value: 0.002957014193849284 and parameters: {'lam': 0.0011929801858505957, 'learning_rate': 0.08572626136425722, 'num_epoch': 5000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.003941906 valid loss= 0.003740757\n",
      "train reg_fs: 0.0007813483825884759\n",
      "Optimization Finished!\n",
      "test loss: 0.0034059970639646053, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002957014193849284\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013851978 valid loss= 0.008804202\n",
      "train reg_fs: 0.001303787576034665\n",
      "Epoch: 1000 train loss=0.009012440 valid loss= 0.008594737\n",
      "train reg_fs: 0.0013175959466025233\n",
      "Epoch: 1500 train loss=0.018823886 valid loss= 0.008465553\n",
      "train reg_fs: 0.0013089985586702824\n",
      "Epoch: 2000 train loss=0.006529512 valid loss= 0.006746946\n",
      "train reg_fs: 0.0012822498101741076\n",
      "Epoch: 2500 train loss=0.003569728 valid loss= 0.006262413\n",
      "train reg_fs: 0.001239614561200142\n",
      "Epoch: 3000 train loss=0.004832499 valid loss= 0.004878986\n",
      "train reg_fs: 0.001194132724776864\n",
      "Epoch: 3500 train loss=0.004324543 valid loss= 0.004778177\n",
      "train reg_fs: 0.0011582195293158293\n",
      "Epoch: 4000 train loss=0.006444930 valid loss= 0.004739634\n",
      "train reg_fs: 0.001131983008235693\n",
      "Epoch: 4500 train loss=0.012365553 valid loss= 0.004353182\n",
      "train reg_fs: 0.0011081320699304342\n",
      "Epoch: 5000 train loss=0.004661663 valid loss= 0.004309881\n",
      "train reg_fs: 0.001088174874894321\n",
      "Epoch: 5500 train loss=0.003297805 valid loss= 0.004404468\n",
      "train reg_fs: 0.0010690217604860663\n",
      "Epoch: 6000 train loss=0.002526157 valid loss= 0.003871370\n",
      "train reg_fs: 0.0010531112784519792\n",
      "Epoch: 6500 train loss=0.006167159 valid loss= 0.004363417\n",
      "train reg_fs: 0.0010377932339906693\n",
      "Epoch: 7000 train loss=0.002289578 valid loss= 0.003759308\n",
      "train reg_fs: 0.0010250670602545142\n",
      "Epoch: 7500 train loss=0.003771243 valid loss= 0.004522088\n",
      "train reg_fs: 0.0010145383421331644\n",
      "Epoch: 8000 train loss=0.003017097 valid loss= 0.003434684\n",
      "train reg_fs: 0.0010059692431241274\n",
      "Epoch: 8500 train loss=0.008318797 valid loss= 0.003528954\n",
      "train reg_fs: 0.0009982078336179256\n",
      "Epoch: 9000 train loss=0.004210981 valid loss= 0.003484650\n",
      "train reg_fs: 0.0009915175614878535\n",
      "Epoch: 9500 train loss=0.008611998 valid loss= 0.003134324\n",
      "train reg_fs: 0.0009856738615781069\n",
      "Epoch: 10000 train loss=0.003384498 valid loss= 0.003466390\n",
      "train reg_fs: 0.0009802862768992782\n",
      "Epoch: 10500 train loss=0.006498824 valid loss= 0.003632625\n",
      "train reg_fs: 0.0009753839112818241\n",
      "Epoch: 11000 train loss=0.007244016 valid loss= 0.003192066\n",
      "train reg_fs: 0.0009711466263979673\n",
      "Epoch: 11500 train loss=0.002890119 valid loss= 0.003842711\n",
      "train reg_fs: 0.0009668225538916886\n",
      "Epoch: 12000 train loss=0.002743983 valid loss= 0.003558903\n",
      "train reg_fs: 0.0009630101267248392\n",
      "Epoch: 12500 train loss=0.001331241 valid loss= 0.003214415\n",
      "train reg_fs: 0.0009589373366907239\n",
      "Epoch: 13000 train loss=0.003479202 valid loss= 0.003164742\n",
      "train reg_fs: 0.0009559013997204602\n",
      "Epoch: 13500 train loss=0.004934440 valid loss= 0.002883444\n",
      "train reg_fs: 0.0009526645881123841\n",
      "Epoch: 14000 train loss=0.009780482 valid loss= 0.003705969\n",
      "train reg_fs: 0.0009494720725342631\n",
      "Epoch: 14500 train loss=0.003779007 valid loss= 0.003311387\n",
      "train reg_fs: 0.0009466499323025346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:00:06,894]\u001b[0m Trial 31 finished with value: 0.0023990655325277273 and parameters: {'lam': 0.0014936189733862919, 'learning_rate': 0.0727585410738165, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004507556 valid loss= 0.003335134\n",
      "train reg_fs: 0.0009439378627575934\n",
      "Optimization Finished!\n",
      "test loss: 0.0030674913432449102, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023990655325277273\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011551302 valid loss= 0.006922170\n",
      "train reg_fs: 0.001502275001257658\n",
      "Epoch: 1000 train loss=0.014895972 valid loss= 0.008187233\n",
      "train reg_fs: 0.0015079142758622766\n",
      "Epoch: 1500 train loss=0.008857139 valid loss= 0.007602987\n",
      "train reg_fs: 0.001472307019867003\n",
      "Epoch: 2000 train loss=0.006902242 valid loss= 0.005401602\n",
      "train reg_fs: 0.0014370714779943228\n",
      "Epoch: 2500 train loss=0.008098998 valid loss= 0.004897133\n",
      "train reg_fs: 0.0014092271449044347\n",
      "Epoch: 3000 train loss=0.005815982 valid loss= 0.005202568\n",
      "train reg_fs: 0.0013901143101975322\n",
      "Epoch: 3500 train loss=0.004094914 valid loss= 0.003787996\n",
      "train reg_fs: 0.0013707781909033656\n",
      "Epoch: 4000 train loss=0.003623964 valid loss= 0.004190740\n",
      "train reg_fs: 0.0013505516108125448\n",
      "Epoch: 4500 train loss=0.003616289 valid loss= 0.003360656\n",
      "train reg_fs: 0.0013275054516270757\n",
      "Epoch: 5000 train loss=0.005201270 valid loss= 0.003562969\n",
      "train reg_fs: 0.001307483995333314\n",
      "Epoch: 5500 train loss=0.004132670 valid loss= 0.003324110\n",
      "train reg_fs: 0.00128749362193048\n",
      "Epoch: 6000 train loss=0.002189027 valid loss= 0.003559622\n",
      "train reg_fs: 0.001274883863516152\n",
      "Epoch: 6500 train loss=0.001870971 valid loss= 0.003676351\n",
      "train reg_fs: 0.0012632302241399884\n",
      "Epoch: 7000 train loss=0.001893696 valid loss= 0.003933301\n",
      "train reg_fs: 0.0012507438659667969\n",
      "Epoch: 7500 train loss=0.002174062 valid loss= 0.003911490\n",
      "train reg_fs: 0.0012398161925375462\n",
      "Epoch: 8000 train loss=0.003752136 valid loss= 0.003743920\n",
      "train reg_fs: 0.0012333642225712538\n",
      "Epoch: 8500 train loss=0.002137423 valid loss= 0.003942062\n",
      "train reg_fs: 0.0012253503082320094\n",
      "Epoch: 9000 train loss=0.001928519 valid loss= 0.003688456\n",
      "train reg_fs: 0.001221287646330893\n",
      "Epoch: 9500 train loss=0.001737520 valid loss= 0.003663390\n",
      "train reg_fs: 0.0012170992558822036\n",
      "Epoch: 10000 train loss=0.002930060 valid loss= 0.004288825\n",
      "train reg_fs: 0.0012092126999050379\n",
      "Epoch: 10500 train loss=0.003659891 valid loss= 0.003797615\n",
      "train reg_fs: 0.0012039217399433255\n",
      "Epoch: 11000 train loss=0.004276159 valid loss= 0.003790745\n",
      "train reg_fs: 0.0012004718882963061\n",
      "Epoch: 11500 train loss=0.004127843 valid loss= 0.003678001\n",
      "train reg_fs: 0.001195661025121808\n",
      "Epoch: 12000 train loss=0.002214804 valid loss= 0.004396458\n",
      "train reg_fs: 0.0011940804542973638\n",
      "Epoch: 12500 train loss=0.004174007 valid loss= 0.003825348\n",
      "train reg_fs: 0.0011876573553308845\n",
      "Epoch: 13000 train loss=0.002487985 valid loss= 0.003783248\n",
      "train reg_fs: 0.0011846789857372642\n",
      "Epoch: 13500 train loss=0.002033503 valid loss= 0.004117241\n",
      "train reg_fs: 0.0011815675534307957\n",
      "Epoch: 14000 train loss=0.001923633 valid loss= 0.003909807\n",
      "train reg_fs: 0.0011785574024543166\n",
      "Epoch: 14500 train loss=0.002465026 valid loss= 0.003793825\n",
      "train reg_fs: 0.001173399738036096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:01:40,763]\u001b[0m Trial 32 finished with value: 0.002905562770015507 and parameters: {'lam': 0.0016977783435698538, 'learning_rate': 0.10646501135729769, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001972637 valid loss= 0.004062360\n",
      "train reg_fs: 0.0011731775011867285\n",
      "Optimization Finished!\n",
      "test loss: 0.004403607454150915, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002905562770015507\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012139406 valid loss= 0.009732820\n",
      "train reg_fs: 0.0010635699145495892\n",
      "Epoch: 1000 train loss=0.004239845 valid loss= 0.009716401\n",
      "train reg_fs: 0.0010707381879910827\n",
      "Epoch: 1500 train loss=0.006238216 valid loss= 0.008161533\n",
      "train reg_fs: 0.0010557131608948112\n",
      "Epoch: 2000 train loss=0.010579196 valid loss= 0.006543212\n",
      "train reg_fs: 0.001028742059133947\n",
      "Epoch: 2500 train loss=0.005584686 valid loss= 0.005949929\n",
      "train reg_fs: 0.0010047395480796695\n",
      "Epoch: 3000 train loss=0.005053114 valid loss= 0.005525048\n",
      "train reg_fs: 0.0009782714769244194\n",
      "Epoch: 3500 train loss=0.005849336 valid loss= 0.004583259\n",
      "train reg_fs: 0.0009553025010973215\n",
      "Epoch: 4000 train loss=0.003154653 valid loss= 0.004030047\n",
      "train reg_fs: 0.0009351039188914001\n",
      "Epoch: 4500 train loss=0.006151092 valid loss= 0.004175658\n",
      "train reg_fs: 0.0009186311508528888\n",
      "Epoch: 5000 train loss=0.008848055 valid loss= 0.004806462\n",
      "train reg_fs: 0.0009039205033332109\n",
      "Epoch: 5500 train loss=0.002585464 valid loss= 0.004333779\n",
      "train reg_fs: 0.0008883615955710411\n",
      "Epoch: 6000 train loss=0.002502889 valid loss= 0.003930704\n",
      "train reg_fs: 0.0008728522807359695\n",
      "Epoch: 6500 train loss=0.004550735 valid loss= 0.004480054\n",
      "train reg_fs: 0.0008594979299232364\n",
      "Epoch: 7000 train loss=0.003088887 valid loss= 0.004070774\n",
      "train reg_fs: 0.000846513023134321\n",
      "Epoch: 7500 train loss=0.001239682 valid loss= 0.003983475\n",
      "train reg_fs: 0.0008362142834812403\n",
      "Epoch: 8000 train loss=0.001201349 valid loss= 0.003721895\n",
      "train reg_fs: 0.000826392148155719\n",
      "Epoch: 8500 train loss=0.003210193 valid loss= 0.003602119\n",
      "train reg_fs: 0.0008182575111277401\n",
      "Epoch: 9000 train loss=0.001636372 valid loss= 0.003219542\n",
      "train reg_fs: 0.000811921781860292\n",
      "Epoch: 9500 train loss=0.006432020 valid loss= 0.003863629\n",
      "train reg_fs: 0.0008058746461756527\n",
      "Epoch: 10000 train loss=0.001115966 valid loss= 0.003398299\n",
      "train reg_fs: 0.0008008971926756203\n",
      "Epoch: 10500 train loss=0.001524929 valid loss= 0.003502381\n",
      "train reg_fs: 0.0007964320247992873\n",
      "Epoch: 11000 train loss=0.001391211 valid loss= 0.003598784\n",
      "train reg_fs: 0.0007925493991933763\n",
      "Epoch: 11500 train loss=0.002812135 valid loss= 0.003313585\n",
      "train reg_fs: 0.0007889819098636508\n",
      "Epoch: 12000 train loss=0.001193045 valid loss= 0.003174148\n",
      "train reg_fs: 0.0007859758916310966\n",
      "Epoch: 12500 train loss=0.003129456 valid loss= 0.003091207\n",
      "train reg_fs: 0.0007832929259166121\n",
      "Epoch: 13000 train loss=0.004801711 valid loss= 0.003008841\n",
      "train reg_fs: 0.0007808264927007258\n",
      "Epoch: 13500 train loss=0.002764246 valid loss= 0.002962040\n",
      "train reg_fs: 0.0007785691996105015\n",
      "Epoch: 14000 train loss=0.005033106 valid loss= 0.003069086\n",
      "train reg_fs: 0.0007765336777083576\n",
      "Epoch: 14500 train loss=0.001272267 valid loss= 0.003418532\n",
      "train reg_fs: 0.0007747046765871346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:03:15,204]\u001b[0m Trial 33 finished with value: 0.002295924112615886 and parameters: {'lam': 0.0012348731695270235, 'learning_rate': 0.0543445856877343, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001396001 valid loss= 0.003059799\n",
      "train reg_fs: 0.0007729917415417731\n",
      "Optimization Finished!\n",
      "test loss: 0.002902308711782098, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002295924112615886\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019391157 valid loss= 0.007435556\n",
      "train reg_fs: 0.0008898995583876967\n",
      "Epoch: 1000 train loss=0.017769078 valid loss= 0.007417295\n",
      "train reg_fs: 0.0009011779329739511\n",
      "Epoch: 1500 train loss=0.005573427 valid loss= 0.007338311\n",
      "train reg_fs: 0.0009074663976207376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:03:28,998]\u001b[0m Trial 34 finished with value: 0.006473260296826511 and parameters: {'lam': 0.0010315949734497026, 'learning_rate': 0.03954899303955241, 'num_epoch': 2000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.007066891 valid loss= 0.007385740\n",
      "train reg_fs: 0.0009089453378692269\n",
      "Optimization Finished!\n",
      "test loss: 0.007957419380545616, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006473260296826511\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017784666 valid loss= 0.006881427\n",
      "train reg_fs: 0.0013589569134637713\n",
      "Epoch: 1000 train loss=0.008335610 valid loss= 0.007522824\n",
      "train reg_fs: 0.0013536236947402358\n",
      "Epoch: 1500 train loss=0.003527266 valid loss= 0.005033619\n",
      "train reg_fs: 0.0012993382988497615\n",
      "Epoch: 2000 train loss=0.003844715 valid loss= 0.004360280\n",
      "train reg_fs: 0.0012447513872757554\n",
      "Epoch: 2500 train loss=0.004377787 valid loss= 0.004524073\n",
      "train reg_fs: 0.0012266933917999268\n",
      "Epoch: 3000 train loss=0.005378065 valid loss= 0.003469331\n",
      "train reg_fs: 0.0012220737989991903\n",
      "Epoch: 3500 train loss=0.004865720 valid loss= 0.003535481\n",
      "train reg_fs: 0.0012178887845948339\n",
      "Epoch: 4000 train loss=0.004512164 valid loss= 0.004217765\n",
      "train reg_fs: 0.001212535658851266\n",
      "Epoch: 4500 train loss=0.003061790 valid loss= 0.004187830\n",
      "train reg_fs: 0.00120315991807729\n",
      "Epoch: 5000 train loss=0.004677752 valid loss= 0.003683179\n",
      "train reg_fs: 0.001192885567434132\n",
      "Epoch: 5500 train loss=0.002207515 valid loss= 0.004272995\n",
      "train reg_fs: 0.0011824703542515635\n",
      "Epoch: 6000 train loss=0.012554604 valid loss= 0.003599293\n",
      "train reg_fs: 0.0011734559666365385\n",
      "Epoch: 6500 train loss=0.002334027 valid loss= 0.003731962\n",
      "train reg_fs: 0.001164494315162301\n",
      "Epoch: 7000 train loss=0.002359750 valid loss= 0.003540447\n",
      "train reg_fs: 0.0011577634140849113\n",
      "Epoch: 7500 train loss=0.002214542 valid loss= 0.003800159\n",
      "train reg_fs: 0.0011516071390360594\n",
      "Epoch: 8000 train loss=0.014766853 valid loss= 0.004080149\n",
      "train reg_fs: 0.0011460608802735806\n",
      "Epoch: 8500 train loss=0.001819375 valid loss= 0.003564765\n",
      "train reg_fs: 0.001140303909778595\n",
      "Epoch: 9000 train loss=0.003220869 valid loss= 0.003635262\n",
      "train reg_fs: 0.00113400025293231\n",
      "Epoch: 9500 train loss=0.002167009 valid loss= 0.003573243\n",
      "train reg_fs: 0.0011287304805591702\n",
      "Epoch: 10000 train loss=0.001313929 valid loss= 0.003405720\n",
      "train reg_fs: 0.0011217991122975945\n",
      "Epoch: 10500 train loss=0.001495759 valid loss= 0.004110087\n",
      "train reg_fs: 0.001116024679504335\n",
      "Epoch: 11000 train loss=0.002957487 valid loss= 0.003669476\n",
      "train reg_fs: 0.001109234755858779\n",
      "Epoch: 11500 train loss=0.002757790 valid loss= 0.003292351\n",
      "train reg_fs: 0.00110481190495193\n",
      "Epoch: 12000 train loss=0.001540759 valid loss= 0.003639317\n",
      "train reg_fs: 0.00110176473390311\n",
      "Epoch: 12500 train loss=0.001823981 valid loss= 0.003496529\n",
      "train reg_fs: 0.0010982831008732319\n",
      "Epoch: 13000 train loss=0.001885962 valid loss= 0.003064927\n",
      "train reg_fs: 0.0010955884354189038\n",
      "Epoch: 13500 train loss=0.002035989 valid loss= 0.003675168\n",
      "train reg_fs: 0.0010920879431068897\n",
      "Epoch: 14000 train loss=0.002568018 valid loss= 0.003884807\n",
      "train reg_fs: 0.001088482211343944\n",
      "Epoch: 14500 train loss=0.003131544 valid loss= 0.003562895\n",
      "train reg_fs: 0.0010855684522539377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:05:02,167]\u001b[0m Trial 35 finished with value: 0.0025757821375519416 and parameters: {'lam': 0.001555205863718959, 'learning_rate': 0.09515899356176569, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003506047 valid loss= 0.003637134\n",
      "train reg_fs: 0.0010830883402377367\n",
      "Optimization Finished!\n",
      "test loss: 0.0033678074833005667, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025757821375519416\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008970210 valid loss= 0.008095969\n",
      "train reg_fs: 0.0017041643150150776\n",
      "Epoch: 1000 train loss=0.016889999 valid loss= 0.008087455\n",
      "train reg_fs: 0.0016988341230899096\n",
      "Epoch: 1500 train loss=0.014684707 valid loss= 0.009765444\n",
      "train reg_fs: 0.0016660986002534628\n",
      "Epoch: 2000 train loss=0.009531700 valid loss= 0.007712129\n",
      "train reg_fs: 0.0016327006742358208\n",
      "Epoch: 2500 train loss=0.004813606 valid loss= 0.009649164\n",
      "train reg_fs: 0.0016166409477591515\n",
      "Epoch: 3000 train loss=0.007470241 valid loss= 0.007515149\n",
      "train reg_fs: 0.001601496827788651\n",
      "Epoch: 3500 train loss=0.004894524 valid loss= 0.007650141\n",
      "train reg_fs: 0.0015931854723021388\n",
      "Epoch: 4000 train loss=0.004718585 valid loss= 0.006923322\n",
      "train reg_fs: 0.00159512460231781\n",
      "Epoch: 4500 train loss=0.011488780 valid loss= 0.007745055\n",
      "train reg_fs: 0.0015935917617753148\n",
      "Epoch: 5000 train loss=0.004947373 valid loss= 0.006657587\n",
      "train reg_fs: 0.001591403386555612\n",
      "Epoch: 5500 train loss=0.008075268 valid loss= 0.005481295\n",
      "train reg_fs: 0.0015909686917439103\n",
      "Epoch: 6000 train loss=0.003009328 valid loss= 0.006325119\n",
      "train reg_fs: 0.0015866408357396722\n",
      "Epoch: 6500 train loss=0.003050379 valid loss= 0.005754304\n",
      "train reg_fs: 0.001577878720127046\n",
      "Epoch: 7000 train loss=0.002529743 valid loss= 0.005799211\n",
      "train reg_fs: 0.0015705428086221218\n",
      "Epoch: 7500 train loss=0.004093792 valid loss= 0.005907170\n",
      "train reg_fs: 0.0015674682799726725\n",
      "Epoch: 8000 train loss=0.006077215 valid loss= 0.006169661\n",
      "train reg_fs: 0.001560567761771381\n",
      "Epoch: 8500 train loss=0.004332689 valid loss= 0.005951314\n",
      "train reg_fs: 0.0015533764380961657\n",
      "Epoch: 9000 train loss=0.003994789 valid loss= 0.006371982\n",
      "train reg_fs: 0.0015453394735231996\n",
      "Epoch: 9500 train loss=0.002411222 valid loss= 0.006175234\n",
      "train reg_fs: 0.0015364134451374412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:06:05,347]\u001b[0m Trial 36 finished with value: 0.005030074490077721 and parameters: {'lam': 0.0019277969402009551, 'learning_rate': 0.1188935897706509, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003546356 valid loss= 0.006574898\n",
      "train reg_fs: 0.0015339874662458897\n",
      "Optimization Finished!\n",
      "test loss: 0.007039978168904781, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.005030074490077721\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010775196 valid loss= 0.008364955\n",
      "train reg_fs: 0.002195240231230855\n",
      "Epoch: 1000 train loss=0.012996446 valid loss= 0.010717670\n",
      "train reg_fs: 0.0022118990309536457\n",
      "Epoch: 1500 train loss=0.005735165 valid loss= 0.008197731\n",
      "train reg_fs: 0.002186616649851203\n",
      "Epoch: 2000 train loss=0.011091573 valid loss= 0.007794114\n",
      "train reg_fs: 0.0021330395247787237\n",
      "Epoch: 2500 train loss=0.008435999 valid loss= 0.005887774\n",
      "train reg_fs: 0.0020644429605454206\n",
      "Epoch: 3000 train loss=0.008687289 valid loss= 0.004656753\n",
      "train reg_fs: 0.002009096322581172\n",
      "Epoch: 3500 train loss=0.006188735 valid loss= 0.004553696\n",
      "train reg_fs: 0.001963328802958131\n",
      "Epoch: 4000 train loss=0.004441924 valid loss= 0.004754406\n",
      "train reg_fs: 0.001929677091538906\n",
      "Epoch: 4500 train loss=0.011041654 valid loss= 0.005076120\n",
      "train reg_fs: 0.0018994547426700592\n",
      "Epoch: 5000 train loss=0.007998928 valid loss= 0.004347135\n",
      "train reg_fs: 0.001867783023044467\n",
      "Epoch: 5500 train loss=0.006842100 valid loss= 0.005710639\n",
      "train reg_fs: 0.0018397188978269696\n",
      "Epoch: 6000 train loss=0.002682404 valid loss= 0.004632245\n",
      "train reg_fs: 0.0018122848123311996\n",
      "Epoch: 6500 train loss=0.007685070 valid loss= 0.004674776\n",
      "train reg_fs: 0.0017889563459903002\n",
      "Epoch: 7000 train loss=0.004747224 valid loss= 0.004326884\n",
      "train reg_fs: 0.0017672113608568907\n",
      "Epoch: 7500 train loss=0.007278137 valid loss= 0.004968808\n",
      "train reg_fs: 0.0017490092432126403\n",
      "Epoch: 8000 train loss=0.004926969 valid loss= 0.004137347\n",
      "train reg_fs: 0.0017329580150544643\n",
      "Epoch: 8500 train loss=0.015980268 valid loss= 0.003950690\n",
      "train reg_fs: 0.0017198296263813972\n",
      "Epoch: 9000 train loss=0.002472637 valid loss= 0.003951185\n",
      "train reg_fs: 0.0017081672558560967\n",
      "Epoch: 9500 train loss=0.003596972 valid loss= 0.003743086\n",
      "train reg_fs: 0.0016981950029730797\n",
      "Epoch: 10000 train loss=0.005989626 valid loss= 0.004135608\n",
      "train reg_fs: 0.0016885161167010665\n",
      "Epoch: 10500 train loss=0.002625131 valid loss= 0.004092388\n",
      "train reg_fs: 0.00168034213129431\n",
      "Epoch: 11000 train loss=0.010500363 valid loss= 0.003899993\n",
      "train reg_fs: 0.0016725565074011683\n",
      "Epoch: 11500 train loss=0.002205035 valid loss= 0.004031568\n",
      "train reg_fs: 0.001665817340835929\n",
      "Epoch: 12000 train loss=0.003615513 valid loss= 0.004621573\n",
      "train reg_fs: 0.0016588533762842417\n",
      "Epoch: 12500 train loss=0.003120645 valid loss= 0.003636750\n",
      "train reg_fs: 0.0016523151425644755\n",
      "Epoch: 13000 train loss=0.003797156 valid loss= 0.004502265\n",
      "train reg_fs: 0.0016462524654343724\n",
      "Epoch: 13500 train loss=0.004759490 valid loss= 0.004166393\n",
      "train reg_fs: 0.0016403355402871966\n",
      "Epoch: 14000 train loss=0.002275977 valid loss= 0.004032166\n",
      "train reg_fs: 0.0016349439974874258\n",
      "Epoch: 14500 train loss=0.003613272 valid loss= 0.004165580\n",
      "train reg_fs: 0.0016292993677780032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:07:39,054]\u001b[0m Trial 37 finished with value: 0.0024782824306701545 and parameters: {'lam': 0.002542031768588258, 'learning_rate': 0.049073121236153774, 'num_epoch': 15000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004395976 valid loss= 0.004087918\n",
      "train reg_fs: 0.0016241306439042091\n",
      "Optimization Finished!\n",
      "test loss: 0.0038965281564742327, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024782824306701545\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.022107836 valid loss= 0.010182051\n",
      "train reg_fs: 0.002597206272184849\n",
      "Epoch: 1000 train loss=0.010655012 valid loss= 0.010262765\n",
      "train reg_fs: 0.0026455377228558064\n",
      "Epoch: 1500 train loss=0.011075188 valid loss= 0.009671509\n",
      "train reg_fs: 0.002670713933184743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:07:53,542]\u001b[0m Trial 38 finished with value: 0.006673179659110131 and parameters: {'lam': 0.0029695438790599345, 'learning_rate': 0.07062714996476933, 'num_epoch': 2000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.014273980 valid loss= 0.009343589\n",
      "train reg_fs: 0.0026721840258687735\n",
      "Optimization Finished!\n",
      "test loss: 0.009689394384622574, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006673179659110131\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009844045 valid loss= 0.007744820\n",
      "train reg_fs: 0.000895832316018641\n",
      "Epoch: 1000 train loss=0.008935120 valid loss= 0.005553773\n",
      "train reg_fs: 0.0008710355032235384\n",
      "Epoch: 1500 train loss=0.006310255 valid loss= 0.004075943\n",
      "train reg_fs: 0.0008307186653837562\n",
      "Epoch: 2000 train loss=0.004395712 valid loss= 0.005112465\n",
      "train reg_fs: 0.0008029743330553174\n",
      "Epoch: 2500 train loss=0.002752968 valid loss= 0.003147156\n",
      "train reg_fs: 0.0007856975425966084\n",
      "Epoch: 3000 train loss=0.004812468 valid loss= 0.003153182\n",
      "train reg_fs: 0.0007712073856964707\n",
      "Epoch: 3500 train loss=0.002848267 valid loss= 0.003955562\n",
      "train reg_fs: 0.0007547155255451798\n",
      "Epoch: 4000 train loss=0.002774969 valid loss= 0.003147603\n",
      "train reg_fs: 0.0007401499315164983\n",
      "Epoch: 4500 train loss=0.001459679 valid loss= 0.003415988\n",
      "train reg_fs: 0.0007255611126311123\n",
      "Epoch: 5000 train loss=0.004588761 valid loss= 0.002960627\n",
      "train reg_fs: 0.0007161736721172929\n",
      "Epoch: 5500 train loss=0.005371355 valid loss= 0.003128759\n",
      "train reg_fs: 0.0007051844149827957\n",
      "Epoch: 6000 train loss=0.003746313 valid loss= 0.003938680\n",
      "train reg_fs: 0.000697319395840168\n",
      "Epoch: 6500 train loss=0.001661521 valid loss= 0.003279802\n",
      "train reg_fs: 0.0006885288748890162\n",
      "Epoch: 7000 train loss=0.003538512 valid loss= 0.003757604\n",
      "train reg_fs: 0.0006829986814409494\n",
      "Epoch: 7500 train loss=0.001126565 valid loss= 0.003039201\n",
      "train reg_fs: 0.0006772172055207193\n",
      "Epoch: 8000 train loss=0.003681838 valid loss= 0.002885091\n",
      "train reg_fs: 0.00067258341005072\n",
      "Epoch: 8500 train loss=0.002554147 valid loss= 0.003175600\n",
      "train reg_fs: 0.0006687126005999744\n",
      "Epoch: 9000 train loss=0.001216704 valid loss= 0.003041521\n",
      "train reg_fs: 0.0006644988316111267\n",
      "Epoch: 9500 train loss=0.003181977 valid loss= 0.003664825\n",
      "train reg_fs: 0.0006612614379264414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:08:56,893]\u001b[0m Trial 39 finished with value: 0.002961068653915446 and parameters: {'lam': 0.0010210545371002544, 'learning_rate': 0.10466993333431915, 'num_epoch': 10000}. Best is trial 5 with value: 0.0013449369208300905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002569126 valid loss= 0.003616019\n",
      "train reg_fs: 0.0006583656067959964\n",
      "Optimization Finished!\n",
      "test loss: 0.00323085836134851, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002961068653915446\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015004729 valid loss= 0.008897839\n",
      "train reg_fs: 0.0033852446358650923\n",
      "Epoch: 1000 train loss=0.007871927 valid loss= 0.004921313\n",
      "train reg_fs: 0.003141616703942418\n",
      "Epoch: 1500 train loss=0.003748546 valid loss= 0.005609924\n",
      "train reg_fs: 0.003022541757673025\n",
      "Epoch: 2000 train loss=0.003720200 valid loss= 0.004607941\n",
      "train reg_fs: 0.0029533379711210728\n",
      "Epoch: 2500 train loss=0.003537389 valid loss= 0.004583530\n",
      "train reg_fs: 0.0028934732545167208\n",
      "Epoch: 3000 train loss=0.005420237 valid loss= 0.004274939\n",
      "train reg_fs: 0.0028404726181179285\n",
      "Epoch: 3500 train loss=0.006041370 valid loss= 0.003726511\n",
      "train reg_fs: 0.0027992515824735165\n",
      "Epoch: 4000 train loss=0.006761400 valid loss= 0.005381488\n",
      "train reg_fs: 0.0027736322954297066\n",
      "Epoch: 4500 train loss=0.004483277 valid loss= 0.003605031\n",
      "train reg_fs: 0.0027560563758015633\n",
      "Epoch: 5000 train loss=0.003606710 valid loss= 0.003185738\n",
      "train reg_fs: 0.0027446704916656017\n",
      "Epoch: 5500 train loss=0.003774686 valid loss= 0.003014353\n",
      "train reg_fs: 0.0027363861445337534\n",
      "Epoch: 6000 train loss=0.003181503 valid loss= 0.002955386\n",
      "train reg_fs: 0.0027309241704642773\n",
      "Epoch: 6500 train loss=0.008833028 valid loss= 0.003607218\n",
      "train reg_fs: 0.002726274076849222\n",
      "Epoch: 7000 train loss=0.005321034 valid loss= 0.005110330\n",
      "train reg_fs: 0.0027229199185967445\n",
      "Epoch: 7500 train loss=0.007379408 valid loss= 0.003143348\n",
      "train reg_fs: 0.0027199776377528906\n",
      "Epoch: 8000 train loss=0.009403585 valid loss= 0.003205344\n",
      "train reg_fs: 0.0027174304705113173\n",
      "Epoch: 8500 train loss=0.006597757 valid loss= 0.003319979\n",
      "train reg_fs: 0.0027154646813869476\n",
      "Epoch: 9000 train loss=0.007873540 valid loss= 0.003392224\n",
      "train reg_fs: 0.002713777357712388\n",
      "Epoch: 9500 train loss=0.003058420 valid loss= 0.003024075\n",
      "train reg_fs: 0.00271248840726912\n",
      "Epoch: 10000 train loss=0.005107596 valid loss= 0.003263063\n",
      "train reg_fs: 0.0027111913077533245\n",
      "Epoch: 10500 train loss=0.005141746 valid loss= 0.003226830\n",
      "train reg_fs: 0.0027102073654532433\n",
      "Epoch: 11000 train loss=0.007351006 valid loss= 0.002987336\n",
      "train reg_fs: 0.002709343796595931\n",
      "Epoch: 11500 train loss=0.003771069 valid loss= 0.003261139\n",
      "train reg_fs: 0.0027085542678833008\n",
      "Epoch: 12000 train loss=0.003551726 valid loss= 0.003036250\n",
      "train reg_fs: 0.002707857172936201\n",
      "Epoch: 12500 train loss=0.015323449 valid loss= 0.003396445\n",
      "train reg_fs: 0.002707249950617552\n",
      "Epoch: 13000 train loss=0.003632137 valid loss= 0.003182812\n",
      "train reg_fs: 0.002706650411710143\n",
      "Epoch: 13500 train loss=0.003703741 valid loss= 0.003776745\n",
      "train reg_fs: 0.0027061738073825836\n",
      "Epoch: 14000 train loss=0.003771434 valid loss= 0.003048493\n",
      "train reg_fs: 0.0027056464459747076\n",
      "Epoch: 14500 train loss=0.002948365 valid loss= 0.003447723\n",
      "train reg_fs: 0.00270517123863101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:10:31,569]\u001b[0m Trial 40 finished with value: 0.0002758848348645575 and parameters: {'lam': 0.0040673743054347265, 'learning_rate': 0.1681500997512317, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003564879 valid loss= 0.002985622\n",
      "train reg_fs: 0.00270473794080317\n",
      "Optimization Finished!\n",
      "test loss: 0.003015825990587473, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0002758848348645575\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009481054 valid loss= 0.010049015\n",
      "train reg_fs: 0.003687680931761861\n",
      "Epoch: 1000 train loss=0.017589362 valid loss= 0.008998257\n",
      "train reg_fs: 0.0032936183270066977\n",
      "Epoch: 1500 train loss=0.012309533 valid loss= 0.006275180\n",
      "train reg_fs: 0.00304134888574481\n",
      "Epoch: 2000 train loss=0.007675970 valid loss= 0.005215994\n",
      "train reg_fs: 0.002879943000152707\n",
      "Epoch: 2500 train loss=0.003473315 valid loss= 0.005059883\n",
      "train reg_fs: 0.002772520063444972\n",
      "Epoch: 3000 train loss=0.004804729 valid loss= 0.005106488\n",
      "train reg_fs: 0.0026960382238030434\n",
      "Epoch: 3500 train loss=0.005276080 valid loss= 0.006613715\n",
      "train reg_fs: 0.0026395153254270554\n",
      "Epoch: 4000 train loss=0.004692364 valid loss= 0.004040925\n",
      "train reg_fs: 0.002598182065412402\n",
      "Epoch: 4500 train loss=0.004879232 valid loss= 0.003786962\n",
      "train reg_fs: 0.002568424679338932\n",
      "Epoch: 5000 train loss=0.002907835 valid loss= 0.004225783\n",
      "train reg_fs: 0.002547805430367589\n",
      "Epoch: 5500 train loss=0.005786826 valid loss= 0.004593407\n",
      "train reg_fs: 0.002531324280425906\n",
      "Epoch: 6000 train loss=0.005501798 valid loss= 0.004112205\n",
      "train reg_fs: 0.002518455497920513\n",
      "Epoch: 6500 train loss=0.003126274 valid loss= 0.004104599\n",
      "train reg_fs: 0.0025081627536565065\n",
      "Epoch: 7000 train loss=0.005838529 valid loss= 0.004532841\n",
      "train reg_fs: 0.002500174567103386\n",
      "Epoch: 7500 train loss=0.003909769 valid loss= 0.004279536\n",
      "train reg_fs: 0.0024938106071203947\n",
      "Epoch: 8000 train loss=0.004158009 valid loss= 0.004238443\n",
      "train reg_fs: 0.0024883325677365065\n",
      "Epoch: 8500 train loss=0.004306103 valid loss= 0.005717159\n",
      "train reg_fs: 0.0024837995879352093\n",
      "Epoch: 9000 train loss=0.003327677 valid loss= 0.004321126\n",
      "train reg_fs: 0.0024799148086458445\n",
      "Epoch: 9500 train loss=0.004752260 valid loss= 0.004281836\n",
      "train reg_fs: 0.002476762980222702\n",
      "Epoch: 10000 train loss=0.003347376 valid loss= 0.003930724\n",
      "train reg_fs: 0.00247388263233006\n",
      "Epoch: 10500 train loss=0.005855558 valid loss= 0.004605881\n",
      "train reg_fs: 0.0024714809842407703\n",
      "Epoch: 11000 train loss=0.003002556 valid loss= 0.004050140\n",
      "train reg_fs: 0.002469199476763606\n",
      "Epoch: 11500 train loss=0.004242748 valid loss= 0.004621056\n",
      "train reg_fs: 0.0024673065636307\n",
      "Epoch: 12000 train loss=0.002815067 valid loss= 0.004032137\n",
      "train reg_fs: 0.002465470228344202\n",
      "Epoch: 12500 train loss=0.003259170 valid loss= 0.003835642\n",
      "train reg_fs: 0.002463891636580229\n",
      "Epoch: 13000 train loss=0.006480608 valid loss= 0.004361046\n",
      "train reg_fs: 0.002462374744936824\n",
      "Epoch: 13500 train loss=0.009132823 valid loss= 0.004570126\n",
      "train reg_fs: 0.0024611351545900106\n",
      "Epoch: 14000 train loss=0.003564412 valid loss= 0.004821043\n",
      "train reg_fs: 0.0024599742610007524\n",
      "Epoch: 14500 train loss=0.002661143 valid loss= 0.003593620\n",
      "train reg_fs: 0.0024588163942098618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:12:05,081]\u001b[0m Trial 41 finished with value: 0.0027552287964152013 and parameters: {'lam': 0.004335604807273677, 'learning_rate': 0.17001996167883704, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003260222 valid loss= 0.005302392\n",
      "train reg_fs: 0.0024578042794018984\n",
      "Optimization Finished!\n",
      "test loss: 0.00490899384021759, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027552287964152013\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014337892 valid loss= 0.009379898\n",
      "train reg_fs: 0.004588049370795488\n",
      "Epoch: 1000 train loss=0.012692813 valid loss= 0.007954789\n",
      "train reg_fs: 0.004383990075439215\n",
      "Epoch: 1500 train loss=0.005531132 valid loss= 0.007232397\n",
      "train reg_fs: 0.004106841515749693\n",
      "Epoch: 2000 train loss=0.009648584 valid loss= 0.006437172\n",
      "train reg_fs: 0.0039679822511971\n",
      "Epoch: 2500 train loss=0.004816006 valid loss= 0.005978514\n",
      "train reg_fs: 0.0038435093592852354\n",
      "Epoch: 3000 train loss=0.008002791 valid loss= 0.005330821\n",
      "train reg_fs: 0.0037440855521708727\n",
      "Epoch: 3500 train loss=0.004931335 valid loss= 0.004345731\n",
      "train reg_fs: 0.003673620754852891\n",
      "Epoch: 4000 train loss=0.005431041 valid loss= 0.005866342\n",
      "train reg_fs: 0.003628758480772376\n",
      "Epoch: 4500 train loss=0.006260390 valid loss= 0.005102289\n",
      "train reg_fs: 0.003586114151403308\n",
      "Epoch: 5000 train loss=0.004412302 valid loss= 0.004236851\n",
      "train reg_fs: 0.003559584030881524\n",
      "Epoch: 5500 train loss=0.007125940 valid loss= 0.004625147\n",
      "train reg_fs: 0.003518452635034919\n",
      "Epoch: 6000 train loss=0.005258105 valid loss= 0.004005214\n",
      "train reg_fs: 0.003470526309683919\n",
      "Epoch: 6500 train loss=0.006482811 valid loss= 0.004490866\n",
      "train reg_fs: 0.0033967241179198027\n",
      "Epoch: 7000 train loss=0.005854184 valid loss= 0.005253188\n",
      "train reg_fs: 0.003324073040857911\n",
      "Epoch: 7500 train loss=0.006533554 valid loss= 0.004821679\n",
      "train reg_fs: 0.0032368542160838842\n",
      "Epoch: 8000 train loss=0.003991118 valid loss= 0.004449437\n",
      "train reg_fs: 0.0031762439757585526\n",
      "Epoch: 8500 train loss=0.004618308 valid loss= 0.004895381\n",
      "train reg_fs: 0.0031387582421302795\n",
      "Epoch: 9000 train loss=0.011623388 valid loss= 0.005228944\n",
      "train reg_fs: 0.003114126855507493\n",
      "Epoch: 9500 train loss=0.004512819 valid loss= 0.005152791\n",
      "train reg_fs: 0.003096019383519888\n",
      "Epoch: 10000 train loss=0.003960210 valid loss= 0.005663571\n",
      "train reg_fs: 0.003082801355049014\n",
      "Epoch: 10500 train loss=0.004227991 valid loss= 0.006105571\n",
      "train reg_fs: 0.0030726043041795492\n",
      "Epoch: 11000 train loss=0.003235895 valid loss= 0.005149573\n",
      "train reg_fs: 0.003064351622015238\n",
      "Epoch: 11500 train loss=0.004147225 valid loss= 0.004718843\n",
      "train reg_fs: 0.0030579902231693268\n",
      "Epoch: 12000 train loss=0.003607821 valid loss= 0.005179529\n",
      "train reg_fs: 0.0030526812188327312\n",
      "Epoch: 12500 train loss=0.004535437 valid loss= 0.004904744\n",
      "train reg_fs: 0.00304786441847682\n",
      "Epoch: 13000 train loss=0.003937275 valid loss= 0.005000173\n",
      "train reg_fs: 0.003043706528842449\n",
      "Epoch: 13500 train loss=0.003385168 valid loss= 0.004037499\n",
      "train reg_fs: 0.0030401444528251886\n",
      "Epoch: 14000 train loss=0.005347855 valid loss= 0.004939736\n",
      "train reg_fs: 0.003036827314645052\n",
      "Epoch: 14500 train loss=0.003448132 valid loss= 0.004396460\n",
      "train reg_fs: 0.003033952321857214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:13:39,541]\u001b[0m Trial 42 finished with value: 0.003555772148143592 and parameters: {'lam': 0.005318401935722128, 'learning_rate': 0.11687663978315446, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005511152 valid loss= 0.006697598\n",
      "train reg_fs: 0.003031505737453699\n",
      "Optimization Finished!\n",
      "test loss: 0.006166442297399044, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003555772148143592\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.012744201 valid loss= 0.008120480\n",
      "train reg_fs: 0.003554679686203599\n",
      "Epoch: 1000 train loss=0.012932445 valid loss= 0.005411985\n",
      "train reg_fs: 0.0032656167168170214\n",
      "Epoch: 1500 train loss=0.005323767 valid loss= 0.005234393\n",
      "train reg_fs: 0.0031547609250992537\n",
      "Epoch: 2000 train loss=0.004784245 valid loss= 0.006215546\n",
      "train reg_fs: 0.003090021200478077\n",
      "Epoch: 2500 train loss=0.005493546 valid loss= 0.004980822\n",
      "train reg_fs: 0.0030590740498155355\n",
      "Epoch: 3000 train loss=0.008357307 valid loss= 0.004755786\n",
      "train reg_fs: 0.0030363781843334436\n",
      "Epoch: 3500 train loss=0.004325747 valid loss= 0.004801751\n",
      "train reg_fs: 0.0030212467536330223\n",
      "Epoch: 4000 train loss=0.009995852 valid loss= 0.004719310\n",
      "train reg_fs: 0.0030086454935371876\n",
      "Epoch: 4500 train loss=0.003757617 valid loss= 0.004599299\n",
      "train reg_fs: 0.002994840033352375\n",
      "Epoch: 5000 train loss=0.008479932 valid loss= 0.004745409\n",
      "train reg_fs: 0.002981924219056964\n",
      "Epoch: 5500 train loss=0.006646267 valid loss= 0.005479733\n",
      "train reg_fs: 0.002969268010929227\n",
      "Epoch: 6000 train loss=0.004776469 valid loss= 0.005386371\n",
      "train reg_fs: 0.0029557710513472557\n",
      "Epoch: 6500 train loss=0.005671785 valid loss= 0.004524135\n",
      "train reg_fs: 0.002942244056612253\n",
      "Epoch: 7000 train loss=0.003310873 valid loss= 0.005426356\n",
      "train reg_fs: 0.0029285780619829893\n",
      "Epoch: 7500 train loss=0.004102928 valid loss= 0.004996075\n",
      "train reg_fs: 0.0029140778351575136\n",
      "Epoch: 8000 train loss=0.005890469 valid loss= 0.004716406\n",
      "train reg_fs: 0.0028954739682376385\n",
      "Epoch: 8500 train loss=0.005739578 valid loss= 0.006803066\n",
      "train reg_fs: 0.0028761534485965967\n",
      "Epoch: 9000 train loss=0.005544263 valid loss= 0.004282194\n",
      "train reg_fs: 0.002855615923181176\n",
      "Epoch: 9500 train loss=0.003720477 valid loss= 0.005383157\n",
      "train reg_fs: 0.0028320096898823977\n",
      "Epoch: 10000 train loss=0.005236104 valid loss= 0.004858664\n",
      "train reg_fs: 0.0028070728294551373\n",
      "Epoch: 10500 train loss=0.005543008 valid loss= 0.004269423\n",
      "train reg_fs: 0.0027847730088979006\n",
      "Epoch: 11000 train loss=0.003291672 valid loss= 0.006210361\n",
      "train reg_fs: 0.0027623060159385204\n",
      "Epoch: 11500 train loss=0.003868395 valid loss= 0.005172307\n",
      "train reg_fs: 0.002743488410487771\n",
      "Epoch: 12000 train loss=0.004991385 valid loss= 0.004578431\n",
      "train reg_fs: 0.002728927182033658\n",
      "Epoch: 12500 train loss=0.004259919 valid loss= 0.005147176\n",
      "train reg_fs: 0.002714232774451375\n",
      "Epoch: 13000 train loss=0.003386930 valid loss= 0.004704569\n",
      "train reg_fs: 0.0027025893796235323\n",
      "Epoch: 13500 train loss=0.004211261 valid loss= 0.004709763\n",
      "train reg_fs: 0.0026907126884907484\n",
      "Epoch: 14000 train loss=0.002957077 valid loss= 0.004772774\n",
      "train reg_fs: 0.0026807321701198816\n",
      "Epoch: 14500 train loss=0.006133446 valid loss= 0.004232693\n",
      "train reg_fs: 0.002670776564627886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:15:13,015]\u001b[0m Trial 43 finished with value: 0.0033128614183162977 and parameters: {'lam': 0.004154751947827184, 'learning_rate': 0.14195816961943844, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005553416 valid loss= 0.005909234\n",
      "train reg_fs: 0.002661436330527067\n",
      "Optimization Finished!\n",
      "test loss: 0.005479268729686737, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0033128614183162977\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013816695 valid loss= 0.013924636\n",
      "train reg_fs: 0.006112669128924608\n",
      "Epoch: 1000 train loss=0.009983534 valid loss= 0.010835852\n",
      "train reg_fs: 0.006044302135705948\n",
      "Epoch: 1500 train loss=0.007603499 valid loss= 0.010332586\n",
      "train reg_fs: 0.00587362190708518\n",
      "Epoch: 2000 train loss=0.009510651 valid loss= 0.008331377\n",
      "train reg_fs: 0.005642075557261705\n",
      "Epoch: 2500 train loss=0.008116784 valid loss= 0.008771591\n",
      "train reg_fs: 0.0054331752471625805\n",
      "Epoch: 3000 train loss=0.013049163 valid loss= 0.007942627\n",
      "train reg_fs: 0.005253454204648733\n",
      "Epoch: 3500 train loss=0.007403046 valid loss= 0.008625055\n",
      "train reg_fs: 0.005084672477096319\n",
      "Epoch: 4000 train loss=0.007849863 valid loss= 0.008884925\n",
      "train reg_fs: 0.004939564503729343\n",
      "Epoch: 4500 train loss=0.006677910 valid loss= 0.008941689\n",
      "train reg_fs: 0.004776644054800272\n",
      "Epoch: 5000 train loss=0.007953128 valid loss= 0.008795259\n",
      "train reg_fs: 0.004640274681150913\n",
      "Epoch: 5500 train loss=0.006744463 valid loss= 0.009237420\n",
      "train reg_fs: 0.004512515850365162\n",
      "Epoch: 6000 train loss=0.007428892 valid loss= 0.008819947\n",
      "train reg_fs: 0.004391264636069536\n",
      "Epoch: 6500 train loss=0.007226126 valid loss= 0.008991471\n",
      "train reg_fs: 0.004288440104573965\n",
      "Epoch: 7000 train loss=0.008044410 valid loss= 0.009247037\n",
      "train reg_fs: 0.004203122574836016\n",
      "Epoch: 7500 train loss=0.006076887 valid loss= 0.009013055\n",
      "train reg_fs: 0.0041264742612838745\n",
      "Epoch: 8000 train loss=0.006733672 valid loss= 0.009242845\n",
      "train reg_fs: 0.004066846799105406\n",
      "Epoch: 8500 train loss=0.005670855 valid loss= 0.009449370\n",
      "train reg_fs: 0.004012109711766243\n",
      "Epoch: 9000 train loss=0.006966897 valid loss= 0.009631131\n",
      "train reg_fs: 0.003961165901273489\n",
      "Epoch: 9500 train loss=0.005662247 valid loss= 0.009403015\n",
      "train reg_fs: 0.003921776544302702\n",
      "Epoch: 10000 train loss=0.007528818 valid loss= 0.009184441\n",
      "train reg_fs: 0.0038767624646425247\n",
      "Epoch: 10500 train loss=0.005751518 valid loss= 0.010490580\n",
      "train reg_fs: 0.00384115194901824\n",
      "Epoch: 11000 train loss=0.005355166 valid loss= 0.010105081\n",
      "train reg_fs: 0.003805939108133316\n",
      "Epoch: 11500 train loss=0.006745279 valid loss= 0.009347059\n",
      "train reg_fs: 0.003779754973948002\n",
      "Epoch: 12000 train loss=0.004408346 valid loss= 0.009792674\n",
      "train reg_fs: 0.0037554132286459208\n",
      "Epoch: 12500 train loss=0.004870237 valid loss= 0.010196956\n",
      "train reg_fs: 0.00372895784676075\n",
      "Epoch: 13000 train loss=0.006098859 valid loss= 0.009497155\n",
      "train reg_fs: 0.003710731863975525\n",
      "Epoch: 13500 train loss=0.005897787 valid loss= 0.010370530\n",
      "train reg_fs: 0.0036926742177456617\n",
      "Epoch: 14000 train loss=0.005114206 valid loss= 0.009873077\n",
      "train reg_fs: 0.0036795376800000668\n",
      "Epoch: 14500 train loss=0.005064833 valid loss= 0.010119166\n",
      "train reg_fs: 0.0036707287654280663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:16:47,471]\u001b[0m Trial 44 finished with value: 0.006250990284677341 and parameters: {'lam': 0.006906732140667946, 'learning_rate': 0.1773683484237222, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005118869 valid loss= 0.010064842\n",
      "train reg_fs: 0.0036556951235979795\n",
      "Optimization Finished!\n",
      "test loss: 0.010453149676322937, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006250990284677341\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007924399 valid loss= 0.010591228\n",
      "train reg_fs: 0.0033526006154716015\n",
      "Epoch: 1000 train loss=0.011161679 valid loss= 0.008608226\n",
      "train reg_fs: 0.0032819383777678013\n",
      "Epoch: 1500 train loss=0.011774359 valid loss= 0.007633950\n",
      "train reg_fs: 0.003204390872269869\n",
      "Epoch: 2000 train loss=0.006813767 valid loss= 0.006457776\n",
      "train reg_fs: 0.0031218351796269417\n",
      "Epoch: 2500 train loss=0.005831894 valid loss= 0.005743071\n",
      "train reg_fs: 0.003028132487088442\n",
      "Epoch: 3000 train loss=0.008112866 valid loss= 0.006116660\n",
      "train reg_fs: 0.0029809516854584217\n",
      "Epoch: 3500 train loss=0.004522575 valid loss= 0.005788626\n",
      "train reg_fs: 0.0029577200766652822\n",
      "Epoch: 4000 train loss=0.006122644 valid loss= 0.006062446\n",
      "train reg_fs: 0.0029440296348184347\n",
      "Epoch: 4500 train loss=0.006016620 valid loss= 0.006762397\n",
      "train reg_fs: 0.00293362676165998\n",
      "Epoch: 5000 train loss=0.006874867 valid loss= 0.005707221\n",
      "train reg_fs: 0.002916310913860798\n",
      "Epoch: 5500 train loss=0.004226573 valid loss= 0.005880083\n",
      "train reg_fs: 0.0028863681945949793\n",
      "Epoch: 6000 train loss=0.006420147 valid loss= 0.005210996\n",
      "train reg_fs: 0.0028505236841738224\n",
      "Epoch: 6500 train loss=0.005294206 valid loss= 0.005687444\n",
      "train reg_fs: 0.002820670837536454\n",
      "Epoch: 7000 train loss=0.006895938 valid loss= 0.005423892\n",
      "train reg_fs: 0.0027999533340334892\n",
      "Epoch: 7500 train loss=0.003892319 valid loss= 0.005318780\n",
      "train reg_fs: 0.0027834190987050533\n",
      "Epoch: 8000 train loss=0.009328100 valid loss= 0.005227744\n",
      "train reg_fs: 0.002770580817013979\n",
      "Epoch: 8500 train loss=0.003749164 valid loss= 0.005879662\n",
      "train reg_fs: 0.002759445458650589\n",
      "Epoch: 9000 train loss=0.003520658 valid loss= 0.004962743\n",
      "train reg_fs: 0.002748434664681554\n",
      "Epoch: 9500 train loss=0.006932578 valid loss= 0.004700381\n",
      "train reg_fs: 0.0027377589140087366\n",
      "Epoch: 10000 train loss=0.007037992 valid loss= 0.004500089\n",
      "train reg_fs: 0.002728336723521352\n",
      "Epoch: 10500 train loss=0.003479202 valid loss= 0.004702740\n",
      "train reg_fs: 0.0027214542496949434\n",
      "Epoch: 11000 train loss=0.005062697 valid loss= 0.004545623\n",
      "train reg_fs: 0.002715418580919504\n",
      "Epoch: 11500 train loss=0.004821246 valid loss= 0.004605010\n",
      "train reg_fs: 0.002707422012463212\n",
      "Epoch: 12000 train loss=0.005521830 valid loss= 0.004466163\n",
      "train reg_fs: 0.0026943592820316553\n",
      "Epoch: 12500 train loss=0.004644196 valid loss= 0.004498411\n",
      "train reg_fs: 0.0026833449956029654\n",
      "Epoch: 13000 train loss=0.004359562 valid loss= 0.004551084\n",
      "train reg_fs: 0.0026714822743088007\n",
      "Epoch: 13500 train loss=0.005526679 valid loss= 0.004847035\n",
      "train reg_fs: 0.0026487282011657953\n",
      "Epoch: 14000 train loss=0.003798674 valid loss= 0.004615079\n",
      "train reg_fs: 0.0026234870310872793\n",
      "Epoch: 14500 train loss=0.003208382 valid loss= 0.004567714\n",
      "train reg_fs: 0.0025898844469338655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:18:22,217]\u001b[0m Trial 45 finished with value: 0.0022337842418575305 and parameters: {'lam': 0.003896554687105263, 'learning_rate': 0.07965131806043363, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.003419420 valid loss= 0.004708201\n",
      "train reg_fs: 0.002549388911575079\n",
      "Optimization Finished!\n",
      "test loss: 0.0045456537045538425, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022337842418575305\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015112642 valid loss= 0.010096610\n",
      "train reg_fs: 0.004469635896384716\n",
      "Epoch: 1000 train loss=0.006641729 valid loss= 0.009470878\n",
      "train reg_fs: 0.004298695363104343\n",
      "Epoch: 1500 train loss=0.010474677 valid loss= 0.009439717\n",
      "train reg_fs: 0.004102025181055069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:18:36,087]\u001b[0m Trial 46 finished with value: 0.0031033665541554964 and parameters: {'lam': 0.005190735016034281, 'learning_rate': 0.1195024268269337, 'num_epoch': 2000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.006205417 valid loss= 0.007161303\n",
      "train reg_fs: 0.003916698042303324\n",
      "Optimization Finished!\n",
      "test loss: 0.0068518901243805885, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0031033665541554964\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014583594 valid loss= 0.007807225\n",
      "train reg_fs: 0.0010715731186792254\n",
      "Epoch: 1000 train loss=0.019834772 valid loss= 0.007247883\n",
      "train reg_fs: 0.0010804875055328012\n",
      "Epoch: 1500 train loss=0.007021603 valid loss= 0.006739398\n",
      "train reg_fs: 0.0010872947750613093\n",
      "Epoch: 2000 train loss=0.011950968 valid loss= 0.006439710\n",
      "train reg_fs: 0.0010912936413660645\n",
      "Epoch: 2500 train loss=0.005886776 valid loss= 0.006353796\n",
      "train reg_fs: 0.0010937376646324992\n",
      "Epoch: 3000 train loss=0.005293598 valid loss= 0.007196874\n",
      "train reg_fs: 0.0010929802665486932\n",
      "Epoch: 3500 train loss=0.019384528 valid loss= 0.005521839\n",
      "train reg_fs: 0.0010903511429205537\n",
      "Epoch: 4000 train loss=0.006087129 valid loss= 0.006821651\n",
      "train reg_fs: 0.0010854564607143402\n",
      "Epoch: 4500 train loss=0.011729910 valid loss= 0.004982592\n",
      "train reg_fs: 0.0010781253222376108\n",
      "Epoch: 5000 train loss=0.012098193 valid loss= 0.005582722\n",
      "train reg_fs: 0.0010685811284929514\n",
      "Epoch: 5500 train loss=0.005409286 valid loss= 0.006162513\n",
      "train reg_fs: 0.0010567925637587905\n",
      "Epoch: 6000 train loss=0.005310869 valid loss= 0.005607195\n",
      "train reg_fs: 0.001043058349750936\n",
      "Epoch: 6500 train loss=0.013148799 valid loss= 0.005012914\n",
      "train reg_fs: 0.0010286199394613504\n",
      "Epoch: 7000 train loss=0.002876984 valid loss= 0.004843440\n",
      "train reg_fs: 0.0010133243631571531\n",
      "Epoch: 7500 train loss=0.003584132 valid loss= 0.004064922\n",
      "train reg_fs: 0.000999042997136712\n",
      "Epoch: 8000 train loss=0.004292083 valid loss= 0.004289835\n",
      "train reg_fs: 0.0009868905181065202\n",
      "Epoch: 8500 train loss=0.003330388 valid loss= 0.004117016\n",
      "train reg_fs: 0.0009762518457137048\n",
      "Epoch: 9000 train loss=0.005665588 valid loss= 0.003807900\n",
      "train reg_fs: 0.0009677466005086899\n",
      "Epoch: 9500 train loss=0.003217162 valid loss= 0.003672572\n",
      "train reg_fs: 0.0009595599840395153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:19:38,936]\u001b[0m Trial 47 finished with value: 0.00215136534481647 and parameters: {'lam': 0.0012609082799824754, 'learning_rate': 0.0154814699094561, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001904184 valid loss= 0.003110153\n",
      "train reg_fs: 0.0009523718035779893\n",
      "Optimization Finished!\n",
      "test loss: 0.003005321603268385, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.00215136534481647\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.019323749 valid loss= 0.008417798\n",
      "train reg_fs: 0.0013115068431943655\n",
      "Epoch: 1000 train loss=0.008584712 valid loss= 0.009242866\n",
      "train reg_fs: 0.0013105013640597463\n",
      "Epoch: 1500 train loss=0.009765835 valid loss= 0.010049103\n",
      "train reg_fs: 0.0012703962856903672\n",
      "Epoch: 2000 train loss=0.004360992 valid loss= 0.008644567\n",
      "train reg_fs: 0.0012394761433824897\n",
      "Epoch: 2500 train loss=0.005551307 valid loss= 0.007956881\n",
      "train reg_fs: 0.0012231272412464023\n",
      "Epoch: 3000 train loss=0.004089342 valid loss= 0.008191548\n",
      "train reg_fs: 0.0012194152222946286\n",
      "Epoch: 3500 train loss=0.007323643 valid loss= 0.005907641\n",
      "train reg_fs: 0.0012175989104434848\n",
      "Epoch: 4000 train loss=0.002494184 valid loss= 0.006744477\n",
      "train reg_fs: 0.001216067816130817\n",
      "Epoch: 4500 train loss=0.003942681 valid loss= 0.005290783\n",
      "train reg_fs: 0.001214560936205089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:20:11,467]\u001b[0m Trial 48 finished with value: 0.0039682584133132045 and parameters: {'lam': 0.0014718494344900998, 'learning_rate': 0.1369696357651421, 'num_epoch': 5000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.002503586 valid loss= 0.005201049\n",
      "train reg_fs: 0.0012121162144467235\n",
      "Optimization Finished!\n",
      "test loss: 0.0054799821227788925, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0039682584133132045\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005719757 valid loss= 0.009265440\n",
      "train reg_fs: 0.0015042878221720457\n",
      "Epoch: 1000 train loss=0.005585573 valid loss= 0.004715188\n",
      "train reg_fs: 0.0014105095760896802\n",
      "Epoch: 1500 train loss=0.005642054 valid loss= 0.002979521\n",
      "train reg_fs: 0.001297570881433785\n",
      "Epoch: 2000 train loss=0.005481248 valid loss= 0.002773949\n",
      "train reg_fs: 0.0012366650626063347\n",
      "Epoch: 2500 train loss=0.006250112 valid loss= 0.002309292\n",
      "train reg_fs: 0.0011933459900319576\n",
      "Epoch: 3000 train loss=0.020079061 valid loss= 0.003393030\n",
      "train reg_fs: 0.0011642632307484746\n",
      "Epoch: 3500 train loss=0.003086341 valid loss= 0.002551759\n",
      "train reg_fs: 0.001134146354161203\n",
      "Epoch: 4000 train loss=0.004363014 valid loss= 0.002404198\n",
      "train reg_fs: 0.0011134058004245162\n",
      "Epoch: 4500 train loss=0.004584143 valid loss= 0.002657698\n",
      "train reg_fs: 0.001100946799851954\n",
      "Epoch: 5000 train loss=0.001936377 valid loss= 0.002528459\n",
      "train reg_fs: 0.0010833317646756768\n",
      "Epoch: 5500 train loss=0.005242908 valid loss= 0.002811677\n",
      "train reg_fs: 0.0010654714424163103\n",
      "Epoch: 6000 train loss=0.003963159 valid loss= 0.003089937\n",
      "train reg_fs: 0.0010529957944527268\n",
      "Epoch: 6500 train loss=0.003804596 valid loss= 0.002796501\n",
      "train reg_fs: 0.0010333112441003323\n",
      "Epoch: 7000 train loss=0.002633847 valid loss= 0.003399912\n",
      "train reg_fs: 0.0010199480457231402\n",
      "Epoch: 7500 train loss=0.001505152 valid loss= 0.002531671\n",
      "train reg_fs: 0.0010112114250659943\n",
      "Epoch: 8000 train loss=0.001712152 valid loss= 0.002224828\n",
      "train reg_fs: 0.001004664460197091\n",
      "Epoch: 8500 train loss=0.001319519 valid loss= 0.002474179\n",
      "train reg_fs: 0.0009998546447604895\n",
      "Epoch: 9000 train loss=0.003501165 valid loss= 0.002729573\n",
      "train reg_fs: 0.0009960462339222431\n",
      "Epoch: 9500 train loss=0.001383281 valid loss= 0.002886620\n",
      "train reg_fs: 0.0009927501669153571\n",
      "Epoch: 10000 train loss=0.002749093 valid loss= 0.002111968\n",
      "train reg_fs: 0.000990352127701044\n",
      "Epoch: 10500 train loss=0.001342565 valid loss= 0.002447320\n",
      "train reg_fs: 0.000988256768323481\n",
      "Epoch: 11000 train loss=0.001808952 valid loss= 0.002300320\n",
      "train reg_fs: 0.0009865396423265338\n",
      "Epoch: 11500 train loss=0.001733313 valid loss= 0.003159336\n",
      "train reg_fs: 0.0009850719943642616\n",
      "Epoch: 12000 train loss=0.002335978 valid loss= 0.004257519\n",
      "train reg_fs: 0.0009836929384618998\n",
      "Epoch: 12500 train loss=0.002348743 valid loss= 0.002911476\n",
      "train reg_fs: 0.0009826547466218472\n",
      "Epoch: 13000 train loss=0.002406113 valid loss= 0.002428431\n",
      "train reg_fs: 0.0009817081736400723\n",
      "Epoch: 13500 train loss=0.001645166 valid loss= 0.002970675\n",
      "train reg_fs: 0.0009809662587940693\n",
      "Epoch: 14000 train loss=0.001845511 valid loss= 0.003597695\n",
      "train reg_fs: 0.0009801819687709212\n",
      "Epoch: 14500 train loss=0.002613218 valid loss= 0.002200514\n",
      "train reg_fs: 0.000979535048827529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:21:46,347]\u001b[0m Trial 49 finished with value: 0.0009201818207478737 and parameters: {'lam': 0.001721127893971163, 'learning_rate': 0.19788280716827264, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001634301 valid loss= 0.001935954\n",
      "train reg_fs: 0.0009789379546418786\n",
      "Optimization Finished!\n",
      "test loss: 0.0017228217329829931, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0009201818207478737\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009929206 valid loss= 0.009456473\n",
      "train reg_fs: 0.0018994673155248165\n",
      "Epoch: 1000 train loss=0.008534734 valid loss= 0.006568584\n",
      "train reg_fs: 0.0017909903544932604\n",
      "Epoch: 1500 train loss=0.012307948 valid loss= 0.006756928\n",
      "train reg_fs: 0.0016910190461203456\n",
      "Epoch: 2000 train loss=0.002303260 valid loss= 0.004078095\n",
      "train reg_fs: 0.0015769792953506112\n",
      "Epoch: 2500 train loss=0.004894887 valid loss= 0.003751183\n",
      "train reg_fs: 0.0015041116857901216\n",
      "Epoch: 3000 train loss=0.002239732 valid loss= 0.003611728\n",
      "train reg_fs: 0.0014592830557376146\n",
      "Epoch: 3500 train loss=0.002344578 valid loss= 0.003401124\n",
      "train reg_fs: 0.0014246250502765179\n",
      "Epoch: 4000 train loss=0.002595126 valid loss= 0.003827262\n",
      "train reg_fs: 0.0014012687606737018\n",
      "Epoch: 4500 train loss=0.001727140 valid loss= 0.003789598\n",
      "train reg_fs: 0.0013825184432789683\n",
      "Epoch: 5000 train loss=0.002832778 valid loss= 0.003505379\n",
      "train reg_fs: 0.0013673990033566952\n",
      "Epoch: 5500 train loss=0.003891811 valid loss= 0.004167287\n",
      "train reg_fs: 0.0013546699192374945\n",
      "Epoch: 6000 train loss=0.003247235 valid loss= 0.003915545\n",
      "train reg_fs: 0.0013445845106616616\n",
      "Epoch: 6500 train loss=0.001855201 valid loss= 0.003722003\n",
      "train reg_fs: 0.001336613204330206\n",
      "Epoch: 7000 train loss=0.004050295 valid loss= 0.004423803\n",
      "train reg_fs: 0.0013298314297571778\n",
      "Epoch: 7500 train loss=0.001381296 valid loss= 0.003725093\n",
      "train reg_fs: 0.001323795411735773\n",
      "Epoch: 8000 train loss=0.001504643 valid loss= 0.003520563\n",
      "train reg_fs: 0.0013187845470383763\n",
      "Epoch: 8500 train loss=0.002984740 valid loss= 0.003663761\n",
      "train reg_fs: 0.0013146772980690002\n",
      "Epoch: 9000 train loss=0.003858876 valid loss= 0.004065198\n",
      "train reg_fs: 0.001311104977503419\n",
      "Epoch: 9500 train loss=0.001824521 valid loss= 0.004010534\n",
      "train reg_fs: 0.0013082667719572783\n",
      "Epoch: 10000 train loss=0.004697967 valid loss= 0.003214172\n",
      "train reg_fs: 0.0013059508055448532\n",
      "Epoch: 10500 train loss=0.003141761 valid loss= 0.003899627\n",
      "train reg_fs: 0.0013039092300459743\n",
      "Epoch: 11000 train loss=0.003651623 valid loss= 0.003579282\n",
      "train reg_fs: 0.0013021733611822128\n",
      "Epoch: 11500 train loss=0.001467128 valid loss= 0.003397282\n",
      "train reg_fs: 0.0013005995424464345\n",
      "Epoch: 12000 train loss=0.003783168 valid loss= 0.003354065\n",
      "train reg_fs: 0.0012990926625207067\n",
      "Epoch: 12500 train loss=0.001609114 valid loss= 0.003547861\n",
      "train reg_fs: 0.0012978443410247564\n",
      "Epoch: 13000 train loss=0.001881193 valid loss= 0.004135052\n",
      "train reg_fs: 0.0012966814683750272\n",
      "Epoch: 13500 train loss=0.001927973 valid loss= 0.003595805\n",
      "train reg_fs: 0.0012956472346559167\n",
      "Epoch: 14000 train loss=0.005652178 valid loss= 0.003761719\n",
      "train reg_fs: 0.0012947397772222757\n",
      "Epoch: 14500 train loss=0.001671476 valid loss= 0.003461884\n",
      "train reg_fs: 0.0012938888976350427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:23:20,937]\u001b[0m Trial 50 finished with value: 0.002597394071410014 and parameters: {'lam': 0.0021460553648206915, 'learning_rate': 0.17754846808335584, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.007923455 valid loss= 0.003857344\n",
      "train reg_fs: 0.0012930993689224124\n",
      "Optimization Finished!\n",
      "test loss: 0.003443028312176466, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002597394071410014\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008321014 valid loss= 0.008810267\n",
      "train reg_fs: 0.0014591086655855179\n",
      "Epoch: 1000 train loss=0.009843362 valid loss= 0.005575730\n",
      "train reg_fs: 0.0013465379597619176\n",
      "Epoch: 1500 train loss=0.010647681 valid loss= 0.004286116\n",
      "train reg_fs: 0.0012743608094751835\n",
      "Epoch: 2000 train loss=0.003665256 valid loss= 0.004947344\n",
      "train reg_fs: 0.0012154931901022792\n",
      "Epoch: 2500 train loss=0.007200655 valid loss= 0.004436565\n",
      "train reg_fs: 0.001159571809694171\n",
      "Epoch: 3000 train loss=0.001893176 valid loss= 0.004373972\n",
      "train reg_fs: 0.0011258121812716126\n",
      "Epoch: 3500 train loss=0.001797403 valid loss= 0.004420550\n",
      "train reg_fs: 0.001104486989788711\n",
      "Epoch: 4000 train loss=0.002231601 valid loss= 0.003182992\n",
      "train reg_fs: 0.0010890295961871743\n",
      "Epoch: 4500 train loss=0.002458158 valid loss= 0.003089661\n",
      "train reg_fs: 0.0010785532649606466\n",
      "Epoch: 5000 train loss=0.002248381 valid loss= 0.003585832\n",
      "train reg_fs: 0.0010700019774958491\n",
      "Epoch: 5500 train loss=0.004572380 valid loss= 0.003607144\n",
      "train reg_fs: 0.0010625997092574835\n",
      "Epoch: 6000 train loss=0.002507790 valid loss= 0.004055224\n",
      "train reg_fs: 0.0010568458819761872\n",
      "Epoch: 6500 train loss=0.006345085 valid loss= 0.003582675\n",
      "train reg_fs: 0.0010524255922064185\n",
      "Epoch: 7000 train loss=0.005578382 valid loss= 0.003386706\n",
      "train reg_fs: 0.0010485252132639289\n",
      "Epoch: 7500 train loss=0.001614142 valid loss= 0.003358574\n",
      "train reg_fs: 0.0010450819972902536\n",
      "Epoch: 8000 train loss=0.002640275 valid loss= 0.003077822\n",
      "train reg_fs: 0.00104224169626832\n",
      "Epoch: 8500 train loss=0.001650188 valid loss= 0.003814252\n",
      "train reg_fs: 0.0010398698505014181\n",
      "Epoch: 9000 train loss=0.006170482 valid loss= 0.003206370\n",
      "train reg_fs: 0.0010378246661275625\n",
      "Epoch: 9500 train loss=0.002706560 valid loss= 0.003415460\n",
      "train reg_fs: 0.0010359565494582057\n",
      "Epoch: 10000 train loss=0.002243539 valid loss= 0.003756990\n",
      "train reg_fs: 0.0010344372130930424\n",
      "Epoch: 10500 train loss=0.006587406 valid loss= 0.003379661\n",
      "train reg_fs: 0.0010329985525459051\n",
      "Epoch: 11000 train loss=0.005591647 valid loss= 0.003464129\n",
      "train reg_fs: 0.001031765597872436\n",
      "Epoch: 11500 train loss=0.006027884 valid loss= 0.002909536\n",
      "train reg_fs: 0.001030615414492786\n",
      "Epoch: 12000 train loss=0.008645199 valid loss= 0.003381849\n",
      "train reg_fs: 0.0010295824613422155\n",
      "Epoch: 12500 train loss=0.003019368 valid loss= 0.003555004\n",
      "train reg_fs: 0.0010286635952070355\n",
      "Epoch: 13000 train loss=0.001826037 valid loss= 0.003256007\n",
      "train reg_fs: 0.0010277843102812767\n",
      "Epoch: 13500 train loss=0.001141697 valid loss= 0.003145593\n",
      "train reg_fs: 0.0010269759222865105\n",
      "Epoch: 14000 train loss=0.001741603 valid loss= 0.003238226\n",
      "train reg_fs: 0.0010262535652145743\n",
      "Epoch: 14500 train loss=0.003861045 valid loss= 0.002946453\n",
      "train reg_fs: 0.0010255776578560472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:24:53,718]\u001b[0m Trial 51 finished with value: 0.0027066443959795575 and parameters: {'lam': 0.0016994219154854882, 'learning_rate': 0.1527538361864573, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001389276 valid loss= 0.003706479\n",
      "train reg_fs: 0.0010250101331621408\n",
      "Optimization Finished!\n",
      "test loss: 0.0033192220143973827, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027066443959795575\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008908894 valid loss= 0.010279254\n",
      "train reg_fs: 0.0015989103121683002\n",
      "Epoch: 1000 train loss=0.005567216 valid loss= 0.008469452\n",
      "train reg_fs: 0.0016006974037736654\n",
      "Epoch: 1500 train loss=0.006020954 valid loss= 0.007621096\n",
      "train reg_fs: 0.0015602442435920238\n",
      "Epoch: 2000 train loss=0.010145569 valid loss= 0.005078098\n",
      "train reg_fs: 0.0014894279884174466\n",
      "Epoch: 2500 train loss=0.003549725 valid loss= 0.003971325\n",
      "train reg_fs: 0.0014287058729678392\n",
      "Epoch: 3000 train loss=0.002718946 valid loss= 0.004221071\n",
      "train reg_fs: 0.0013995497720316052\n",
      "Epoch: 3500 train loss=0.003732642 valid loss= 0.004493051\n",
      "train reg_fs: 0.001373186009004712\n",
      "Epoch: 4000 train loss=0.003802461 valid loss= 0.003650634\n",
      "train reg_fs: 0.00135615817271173\n",
      "Epoch: 4500 train loss=0.003944231 valid loss= 0.003657812\n",
      "train reg_fs: 0.0013369761873036623\n",
      "Epoch: 5000 train loss=0.003985038 valid loss= 0.004243740\n",
      "train reg_fs: 0.001316145295277238\n",
      "Epoch: 5500 train loss=0.003129365 valid loss= 0.003723166\n",
      "train reg_fs: 0.0013023768551647663\n",
      "Epoch: 6000 train loss=0.002467382 valid loss= 0.003548671\n",
      "train reg_fs: 0.0012903522001579404\n",
      "Epoch: 6500 train loss=0.002763448 valid loss= 0.003816072\n",
      "train reg_fs: 0.0012809305917471647\n",
      "Epoch: 7000 train loss=0.003550392 valid loss= 0.003360461\n",
      "train reg_fs: 0.00126986438408494\n",
      "Epoch: 7500 train loss=0.003565099 valid loss= 0.003195134\n",
      "train reg_fs: 0.0012608866672962904\n",
      "Epoch: 8000 train loss=0.004981175 valid loss= 0.003536986\n",
      "train reg_fs: 0.0012505084741860628\n",
      "Epoch: 8500 train loss=0.003044327 valid loss= 0.003607974\n",
      "train reg_fs: 0.0012425996828824282\n",
      "Epoch: 9000 train loss=0.002519792 valid loss= 0.003332412\n",
      "train reg_fs: 0.0012342017143964767\n",
      "Epoch: 9500 train loss=0.002075684 valid loss= 0.003461004\n",
      "train reg_fs: 0.0012277872301638126\n",
      "Epoch: 10000 train loss=0.003530331 valid loss= 0.003237928\n",
      "train reg_fs: 0.00122259056661278\n",
      "Epoch: 10500 train loss=0.003987650 valid loss= 0.003280307\n",
      "train reg_fs: 0.001215668860822916\n",
      "Epoch: 11000 train loss=0.002006343 valid loss= 0.003288737\n",
      "train reg_fs: 0.001208948204293847\n",
      "Epoch: 11500 train loss=0.006795217 valid loss= 0.003330549\n",
      "train reg_fs: 0.0012042258167639375\n",
      "Epoch: 12000 train loss=0.003339351 valid loss= 0.003056659\n",
      "train reg_fs: 0.0011990839848294854\n",
      "Epoch: 12500 train loss=0.002146589 valid loss= 0.003723934\n",
      "train reg_fs: 0.0011953337816521525\n",
      "Epoch: 13000 train loss=0.002447925 valid loss= 0.003245685\n",
      "train reg_fs: 0.0011917796218767762\n",
      "Epoch: 13500 train loss=0.002758016 valid loss= 0.003274897\n",
      "train reg_fs: 0.0011887996224686503\n",
      "Epoch: 14000 train loss=0.002160868 valid loss= 0.003604405\n",
      "train reg_fs: 0.0011856787605211139\n",
      "Epoch: 14500 train loss=0.006865188 valid loss= 0.003396506\n",
      "train reg_fs: 0.0011828979477286339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:26:28,823]\u001b[0m Trial 52 finished with value: 0.002131039682036164 and parameters: {'lam': 0.001823049487816488, 'learning_rate': 0.10819121986389112, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001289446 valid loss= 0.003312143\n",
      "train reg_fs: 0.001179600483737886\n",
      "Optimization Finished!\n",
      "test loss: 0.003158463863655925, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002131039682036164\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011994445 valid loss= 0.009814845\n",
      "train reg_fs: 0.001174653647467494\n",
      "Epoch: 1000 train loss=0.004172697 valid loss= 0.003185254\n",
      "train reg_fs: 0.0010871309787034988\n",
      "Epoch: 1500 train loss=0.004942718 valid loss= 0.003136498\n",
      "train reg_fs: 0.0010479970369488\n",
      "Epoch: 2000 train loss=0.008396561 valid loss= 0.003315165\n",
      "train reg_fs: 0.00102782784961164\n",
      "Epoch: 2500 train loss=0.008787550 valid loss= 0.004231477\n",
      "train reg_fs: 0.001019171322695911\n",
      "Epoch: 3000 train loss=0.003458883 valid loss= 0.003879887\n",
      "train reg_fs: 0.0010110433213412762\n",
      "Epoch: 3500 train loss=0.005631294 valid loss= 0.006443365\n",
      "train reg_fs: 0.0010046460665762424\n",
      "Epoch: 4000 train loss=0.002015803 valid loss= 0.002968839\n",
      "train reg_fs: 0.0010008265962824225\n",
      "Epoch: 4500 train loss=0.001724088 valid loss= 0.003555319\n",
      "train reg_fs: 0.0009975037537515163\n",
      "Epoch: 5000 train loss=0.001906107 valid loss= 0.004161839\n",
      "train reg_fs: 0.000994408968836069\n",
      "Epoch: 5500 train loss=0.001646799 valid loss= 0.002761311\n",
      "train reg_fs: 0.0009915283881127834\n",
      "Epoch: 6000 train loss=0.005405642 valid loss= 0.002997761\n",
      "train reg_fs: 0.0009885253384709358\n",
      "Epoch: 6500 train loss=0.004590534 valid loss= 0.003083959\n",
      "train reg_fs: 0.0009869369678199291\n",
      "Epoch: 7000 train loss=0.007758642 valid loss= 0.002675582\n",
      "train reg_fs: 0.000984765007160604\n",
      "Epoch: 7500 train loss=0.001439046 valid loss= 0.003338726\n",
      "train reg_fs: 0.0009829236660152674\n",
      "Epoch: 8000 train loss=0.004582874 valid loss= 0.003681790\n",
      "train reg_fs: 0.000981503282673657\n",
      "Epoch: 8500 train loss=0.002721459 valid loss= 0.003056870\n",
      "train reg_fs: 0.000979773118160665\n",
      "Epoch: 9000 train loss=0.003271018 valid loss= 0.002815847\n",
      "train reg_fs: 0.0009779524989426136\n",
      "Epoch: 9500 train loss=0.002423988 valid loss= 0.002754228\n",
      "train reg_fs: 0.0009755043429322541\n",
      "Epoch: 10000 train loss=0.001422270 valid loss= 0.003639663\n",
      "train reg_fs: 0.0009723555995151401\n",
      "Epoch: 10500 train loss=0.006324606 valid loss= 0.002997829\n",
      "train reg_fs: 0.0009696949273347855\n",
      "Epoch: 11000 train loss=0.002733641 valid loss= 0.002974764\n",
      "train reg_fs: 0.0009688442223705351\n",
      "Epoch: 11500 train loss=0.001307988 valid loss= 0.003275435\n",
      "train reg_fs: 0.0009672865271568298\n",
      "Epoch: 12000 train loss=0.002683631 valid loss= 0.003245472\n",
      "train reg_fs: 0.0009655498433858156\n",
      "Epoch: 12500 train loss=0.001667835 valid loss= 0.003568192\n",
      "train reg_fs: 0.0009629661799408495\n",
      "Epoch: 13000 train loss=0.001592326 valid loss= 0.003237984\n",
      "train reg_fs: 0.0009609299013391137\n",
      "Epoch: 13500 train loss=0.001444260 valid loss= 0.003211969\n",
      "train reg_fs: 0.0009574245777912438\n",
      "Epoch: 14000 train loss=0.002762967 valid loss= 0.003103838\n",
      "train reg_fs: 0.0009559556492604315\n",
      "Epoch: 14500 train loss=0.001655556 valid loss= 0.003443334\n",
      "train reg_fs: 0.0009554302669130266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:28:03,925]\u001b[0m Trial 53 finished with value: 0.0030889731797733044 and parameters: {'lam': 0.0013913468697615986, 'learning_rate': 0.19167013053838722, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.013999267 valid loss= 0.004003381\n",
      "train reg_fs: 0.0009508205112069845\n",
      "Optimization Finished!\n",
      "test loss: 0.004824869334697723, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0030889731797733044\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006947957 valid loss= 0.007323849\n",
      "train reg_fs: 0.0030347774736583233\n",
      "Epoch: 1000 train loss=0.008656442 valid loss= 0.006667288\n",
      "train reg_fs: 0.002710502129048109\n",
      "Epoch: 1500 train loss=0.006863672 valid loss= 0.006641316\n",
      "train reg_fs: 0.002556334715336561\n",
      "Epoch: 2000 train loss=0.004768892 valid loss= 0.007285698\n",
      "train reg_fs: 0.0024586208164691925\n",
      "Epoch: 2500 train loss=0.003803719 valid loss= 0.006918484\n",
      "train reg_fs: 0.0023948915768414736\n",
      "Epoch: 3000 train loss=0.005183257 valid loss= 0.006884119\n",
      "train reg_fs: 0.0023361067287623882\n",
      "Epoch: 3500 train loss=0.004916100 valid loss= 0.006922203\n",
      "train reg_fs: 0.0022959443740546703\n",
      "Epoch: 4000 train loss=0.008991917 valid loss= 0.006273622\n",
      "train reg_fs: 0.00226121349260211\n",
      "Epoch: 4500 train loss=0.004380806 valid loss= 0.006808040\n",
      "train reg_fs: 0.0022331990767270327\n",
      "Epoch: 5000 train loss=0.004042780 valid loss= 0.006791453\n",
      "train reg_fs: 0.0022105828393250704\n",
      "Epoch: 5500 train loss=0.004430727 valid loss= 0.007119983\n",
      "train reg_fs: 0.0021923372987657785\n",
      "Epoch: 6000 train loss=0.005901513 valid loss= 0.006105625\n",
      "train reg_fs: 0.002176464069634676\n",
      "Epoch: 6500 train loss=0.003320925 valid loss= 0.007002112\n",
      "train reg_fs: 0.0021624655928462744\n",
      "Epoch: 7000 train loss=0.005776800 valid loss= 0.007200154\n",
      "train reg_fs: 0.0021512696985155344\n",
      "Epoch: 7500 train loss=0.006607777 valid loss= 0.006424205\n",
      "train reg_fs: 0.002141118748113513\n",
      "Epoch: 8000 train loss=0.003723195 valid loss= 0.006932662\n",
      "train reg_fs: 0.0021332211326807737\n",
      "Epoch: 8500 train loss=0.004865863 valid loss= 0.006538559\n",
      "train reg_fs: 0.0021265146788209677\n",
      "Epoch: 9000 train loss=0.006427619 valid loss= 0.006267687\n",
      "train reg_fs: 0.002120309742167592\n",
      "Epoch: 9500 train loss=0.005850138 valid loss= 0.006982974\n",
      "train reg_fs: 0.0021151630207896233\n",
      "Epoch: 10000 train loss=0.009277617 valid loss= 0.005884171\n",
      "train reg_fs: 0.002110549248754978\n",
      "Epoch: 10500 train loss=0.004498464 valid loss= 0.006855739\n",
      "train reg_fs: 0.00210608821362257\n",
      "Epoch: 11000 train loss=0.004758329 valid loss= 0.005658425\n",
      "train reg_fs: 0.002102510305121541\n",
      "Epoch: 11500 train loss=0.004286738 valid loss= 0.006341489\n",
      "train reg_fs: 0.002099638804793358\n",
      "Epoch: 12000 train loss=0.004010062 valid loss= 0.007294733\n",
      "train reg_fs: 0.002096602227538824\n",
      "Epoch: 12500 train loss=0.003596484 valid loss= 0.006796399\n",
      "train reg_fs: 0.0020935286302119493\n",
      "Epoch: 13000 train loss=0.004204082 valid loss= 0.006462685\n",
      "train reg_fs: 0.002090948401018977\n",
      "Epoch: 13500 train loss=0.004048296 valid loss= 0.006756686\n",
      "train reg_fs: 0.0020888186991214752\n",
      "Epoch: 14000 train loss=0.003669486 valid loss= 0.007132539\n",
      "train reg_fs: 0.0020869318395853043\n",
      "Epoch: 14500 train loss=0.004275140 valid loss= 0.006901115\n",
      "train reg_fs: 0.0020850205328315496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:29:42,333]\u001b[0m Trial 54 finished with value: 0.004705361708815099 and parameters: {'lam': 0.0036358447222034147, 'learning_rate': 0.12917161084083564, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.004501295 valid loss= 0.006871749\n",
      "train reg_fs: 0.002083337167277932\n",
      "Optimization Finished!\n",
      "test loss: 0.006323664449155331, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004705361708815099\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008489649 valid loss= 0.007390453\n",
      "train reg_fs: 0.0020736793521791697\n",
      "Epoch: 1000 train loss=0.005920291 valid loss= 0.005295581\n",
      "train reg_fs: 0.0019987267442047596\n",
      "Epoch: 1500 train loss=0.004618892 valid loss= 0.004568328\n",
      "train reg_fs: 0.0019150084117427468\n",
      "Epoch: 2000 train loss=0.015426903 valid loss= 0.003916143\n",
      "train reg_fs: 0.0018720917869359255\n",
      "Epoch: 2500 train loss=0.007099748 valid loss= 0.003567633\n",
      "train reg_fs: 0.001847516861744225\n",
      "Epoch: 3000 train loss=0.003525351 valid loss= 0.004634155\n",
      "train reg_fs: 0.0018293361645191908\n",
      "Epoch: 3500 train loss=0.003775086 valid loss= 0.003690490\n",
      "train reg_fs: 0.0018178133759647608\n",
      "Epoch: 4000 train loss=0.002686273 valid loss= 0.003940463\n",
      "train reg_fs: 0.0018085415940731764\n",
      "Epoch: 4500 train loss=0.006736551 valid loss= 0.003595143\n",
      "train reg_fs: 0.0018020104616880417\n",
      "Epoch: 5000 train loss=0.002388027 valid loss= 0.004073688\n",
      "train reg_fs: 0.001796388067305088\n",
      "Epoch: 5500 train loss=0.005310276 valid loss= 0.003977884\n",
      "train reg_fs: 0.0017918290104717016\n",
      "Epoch: 6000 train loss=0.006258831 valid loss= 0.003373384\n",
      "train reg_fs: 0.0017875672783702612\n",
      "Epoch: 6500 train loss=0.006235415 valid loss= 0.004147968\n",
      "train reg_fs: 0.00178424920886755\n",
      "Epoch: 7000 train loss=0.006550367 valid loss= 0.003732292\n",
      "train reg_fs: 0.0017808603588491678\n",
      "Epoch: 7500 train loss=0.003350721 valid loss= 0.003465856\n",
      "train reg_fs: 0.001778254983946681\n",
      "Epoch: 8000 train loss=0.003319177 valid loss= 0.004196190\n",
      "train reg_fs: 0.00177570094820112\n",
      "Epoch: 8500 train loss=0.007786863 valid loss= 0.003583663\n",
      "train reg_fs: 0.001773183816112578\n",
      "Epoch: 9000 train loss=0.005334976 valid loss= 0.003894437\n",
      "train reg_fs: 0.0017702807672321796\n",
      "Epoch: 9500 train loss=0.002908326 valid loss= 0.004087493\n",
      "train reg_fs: 0.001767695532180369\n",
      "Epoch: 10000 train loss=0.002706118 valid loss= 0.003903029\n",
      "train reg_fs: 0.0017653517425060272\n",
      "Epoch: 10500 train loss=0.004137541 valid loss= 0.003437200\n",
      "train reg_fs: 0.001762460102327168\n",
      "Epoch: 11000 train loss=0.003642431 valid loss= 0.003434663\n",
      "train reg_fs: 0.001759494305588305\n",
      "Epoch: 11500 train loss=0.003475710 valid loss= 0.004209539\n",
      "train reg_fs: 0.0017574779922142625\n",
      "Epoch: 12000 train loss=0.002583013 valid loss= 0.003924337\n",
      "train reg_fs: 0.0017550617922097445\n",
      "Epoch: 12500 train loss=0.003045716 valid loss= 0.003869209\n",
      "train reg_fs: 0.0017523375572636724\n",
      "Epoch: 13000 train loss=0.002466360 valid loss= 0.003824207\n",
      "train reg_fs: 0.0017496234504505992\n",
      "Epoch: 13500 train loss=0.002798044 valid loss= 0.004007679\n",
      "train reg_fs: 0.0017472471809014678\n",
      "Epoch: 14000 train loss=0.002020269 valid loss= 0.003920192\n",
      "train reg_fs: 0.0017446521669626236\n",
      "Epoch: 14500 train loss=0.001987148 valid loss= 0.004160467\n",
      "train reg_fs: 0.001741941669024527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:31:16,975]\u001b[0m Trial 55 finished with value: 0.002369524706762306 and parameters: {'lam': 0.0024149278008134966, 'learning_rate': 0.06380243416716322, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002800740 valid loss= 0.004046219\n",
      "train reg_fs: 0.0017393813468515873\n",
      "Optimization Finished!\n",
      "test loss: 0.0038232803344726562, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002369524706762306\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.018821038 valid loss= 0.010009025\n",
      "train reg_fs: 0.004226266406476498\n",
      "Epoch: 1000 train loss=0.011131702 valid loss= 0.009931924\n",
      "train reg_fs: 0.004234234802424908\n",
      "Epoch: 1500 train loss=0.012904387 valid loss= 0.010411555\n",
      "train reg_fs: 0.004149941261857748\n",
      "Epoch: 2000 train loss=0.012132667 valid loss= 0.009226752\n",
      "train reg_fs: 0.004003704525530338\n",
      "Epoch: 2500 train loss=0.008652992 valid loss= 0.008284589\n",
      "train reg_fs: 0.003848942695185542\n",
      "Epoch: 3000 train loss=0.006900281 valid loss= 0.007307228\n",
      "train reg_fs: 0.0037061015609651804\n",
      "Epoch: 3500 train loss=0.011049271 valid loss= 0.007162871\n",
      "train reg_fs: 0.003584478981792927\n",
      "Epoch: 4000 train loss=0.006339616 valid loss= 0.007326261\n",
      "train reg_fs: 0.003490724600851536\n",
      "Epoch: 4500 train loss=0.008310548 valid loss= 0.007517395\n",
      "train reg_fs: 0.0034207282587885857\n",
      "Epoch: 5000 train loss=0.006417033 valid loss= 0.007458176\n",
      "train reg_fs: 0.0033631527330726385\n",
      "Epoch: 5500 train loss=0.006287706 valid loss= 0.007744469\n",
      "train reg_fs: 0.0033147039357572794\n",
      "Epoch: 6000 train loss=0.006417136 valid loss= 0.007704915\n",
      "train reg_fs: 0.003282777965068817\n",
      "Epoch: 6500 train loss=0.004486938 valid loss= 0.007818798\n",
      "train reg_fs: 0.003262527519837022\n",
      "Epoch: 7000 train loss=0.003955185 valid loss= 0.007913087\n",
      "train reg_fs: 0.0032494482584297657\n",
      "Epoch: 7500 train loss=0.004243811 valid loss= 0.007860582\n",
      "train reg_fs: 0.0032333629205822945\n",
      "Epoch: 8000 train loss=0.004968264 valid loss= 0.008031946\n",
      "train reg_fs: 0.003216283628717065\n",
      "Epoch: 8500 train loss=0.005181995 valid loss= 0.007788351\n",
      "train reg_fs: 0.0032108693849295378\n",
      "Epoch: 9000 train loss=0.004951634 valid loss= 0.008265405\n",
      "train reg_fs: 0.0031863097101449966\n",
      "Epoch: 9500 train loss=0.014652506 valid loss= 0.007002858\n",
      "train reg_fs: 0.003176941769197583\n",
      "Epoch: 10000 train loss=0.005567695 valid loss= 0.007409025\n",
      "train reg_fs: 0.0031648417934775352\n",
      "Epoch: 10500 train loss=0.005130788 valid loss= 0.007465114\n",
      "train reg_fs: 0.003149661934003234\n",
      "Epoch: 11000 train loss=0.004189851 valid loss= 0.006723898\n",
      "train reg_fs: 0.0031402381137013435\n",
      "Epoch: 11500 train loss=0.004999311 valid loss= 0.007432078\n",
      "train reg_fs: 0.0031316292006522417\n",
      "Epoch: 12000 train loss=0.003590544 valid loss= 0.007097608\n",
      "train reg_fs: 0.003115703584626317\n",
      "Epoch: 12500 train loss=0.003989362 valid loss= 0.006948521\n",
      "train reg_fs: 0.003102843649685383\n",
      "Epoch: 13000 train loss=0.004411303 valid loss= 0.006840061\n",
      "train reg_fs: 0.0030909590423107147\n",
      "Epoch: 13500 train loss=0.005372411 valid loss= 0.006704896\n",
      "train reg_fs: 0.0030826518777757883\n",
      "Epoch: 14000 train loss=0.005267185 valid loss= 0.007353126\n",
      "train reg_fs: 0.0030662717763334513\n",
      "Epoch: 14500 train loss=0.003761291 valid loss= 0.007277209\n",
      "train reg_fs: 0.003053073538467288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:32:51,260]\u001b[0m Trial 56 finished with value: 0.0037852120134061035 and parameters: {'lam': 0.004873705524745731, 'learning_rate': 0.08341422489805722, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.005724733 valid loss= 0.006912969\n",
      "train reg_fs: 0.0030408864840865135\n",
      "Optimization Finished!\n",
      "test loss: 0.00730329193174839, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0037852120134061035\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.006220439 valid loss= 0.004309793\n",
      "train reg_fs: 0.0009229322313331068\n",
      "Epoch: 1000 train loss=0.002522205 valid loss= 0.003815419\n",
      "train reg_fs: 0.0008797931368462741\n",
      "Epoch: 1500 train loss=0.011292412 valid loss= 0.003370041\n",
      "train reg_fs: 0.0008609879878349602\n",
      "Epoch: 2000 train loss=0.003150233 valid loss= 0.003098076\n",
      "train reg_fs: 0.00084861577488482\n",
      "Epoch: 2500 train loss=0.003726723 valid loss= 0.002118095\n",
      "train reg_fs: 0.0008445626008324325\n",
      "Epoch: 3000 train loss=0.002534551 valid loss= 0.002749442\n",
      "train reg_fs: 0.0008437474025413394\n",
      "Epoch: 3500 train loss=0.001793353 valid loss= 0.002837931\n",
      "train reg_fs: 0.0008453811169601977\n",
      "Epoch: 4000 train loss=0.002040305 valid loss= 0.002612828\n",
      "train reg_fs: 0.0008465771679766476\n",
      "Epoch: 4500 train loss=0.003178757 valid loss= 0.002056770\n",
      "train reg_fs: 0.0008472731569781899\n",
      "Epoch: 5000 train loss=0.001807875 valid loss= 0.004420116\n",
      "train reg_fs: 0.0008471576729789376\n",
      "Epoch: 5500 train loss=0.002918372 valid loss= 0.003112715\n",
      "train reg_fs: 0.0008474905625917017\n",
      "Epoch: 6000 train loss=0.001563720 valid loss= 0.002335222\n",
      "train reg_fs: 0.0008473979542031884\n",
      "Epoch: 6500 train loss=0.002054162 valid loss= 0.002661479\n",
      "train reg_fs: 0.0008474433561787009\n",
      "Epoch: 7000 train loss=0.002903522 valid loss= 0.002646905\n",
      "train reg_fs: 0.0008474120404571295\n",
      "Epoch: 7500 train loss=0.001529564 valid loss= 0.002810268\n",
      "train reg_fs: 0.0008474196074530482\n",
      "Epoch: 8000 train loss=0.001017011 valid loss= 0.002673297\n",
      "train reg_fs: 0.0008475143695250154\n",
      "Epoch: 8500 train loss=0.001578868 valid loss= 0.002555425\n",
      "train reg_fs: 0.0008473813068121672\n",
      "Epoch: 9000 train loss=0.002377299 valid loss= 0.002385622\n",
      "train reg_fs: 0.0008471561595797539\n",
      "Epoch: 9500 train loss=0.002925084 valid loss= 0.002699573\n",
      "train reg_fs: 0.0008466042345389724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:33:54,363]\u001b[0m Trial 57 finished with value: 0.001965579224872559 and parameters: {'lam': 0.001137288920451839, 'learning_rate': 0.19815495554075324, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.001333425 valid loss= 0.002787808\n",
      "train reg_fs: 0.0008457820513285697\n",
      "Optimization Finished!\n",
      "test loss: 0.0026275189593434334, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001965579224872559\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015891522 valid loss= 0.008348634\n",
      "train reg_fs: 0.0025802378077059984\n",
      "Epoch: 1000 train loss=0.006759809 valid loss= 0.008950827\n",
      "train reg_fs: 0.0025735520757734776\n",
      "Epoch: 1500 train loss=0.007208661 valid loss= 0.006038095\n",
      "train reg_fs: 0.0025114312302321196\n",
      "Epoch: 2000 train loss=0.010418581 valid loss= 0.004982342\n",
      "train reg_fs: 0.0024224580265581608\n",
      "Epoch: 2500 train loss=0.003801274 valid loss= 0.005430657\n",
      "train reg_fs: 0.0023642699234187603\n",
      "Epoch: 3000 train loss=0.005339522 valid loss= 0.004368850\n",
      "train reg_fs: 0.002325981855392456\n",
      "Epoch: 3500 train loss=0.010888304 valid loss= 0.004454041\n",
      "train reg_fs: 0.002297148806974292\n",
      "Epoch: 4000 train loss=0.003915038 valid loss= 0.004519501\n",
      "train reg_fs: 0.0022718736436218023\n",
      "Epoch: 4500 train loss=0.003349491 valid loss= 0.004851936\n",
      "train reg_fs: 0.0022481803316622972\n",
      "Epoch: 5000 train loss=0.006885539 valid loss= 0.004070692\n",
      "train reg_fs: 0.0022260788828134537\n",
      "Epoch: 5500 train loss=0.005386361 valid loss= 0.004167369\n",
      "train reg_fs: 0.002205291762948036\n",
      "Epoch: 6000 train loss=0.015465340 valid loss= 0.003351138\n",
      "train reg_fs: 0.002184760058298707\n",
      "Epoch: 6500 train loss=0.005211335 valid loss= 0.004029439\n",
      "train reg_fs: 0.002165496349334717\n",
      "Epoch: 7000 train loss=0.005912691 valid loss= 0.004240050\n",
      "train reg_fs: 0.0021465879399329424\n",
      "Epoch: 7500 train loss=0.003718077 valid loss= 0.003366630\n",
      "train reg_fs: 0.002128925872966647\n",
      "Epoch: 8000 train loss=0.002880307 valid loss= 0.004014625\n",
      "train reg_fs: 0.0021129525266587734\n",
      "Epoch: 8500 train loss=0.004115994 valid loss= 0.003159099\n",
      "train reg_fs: 0.002097046934068203\n",
      "Epoch: 9000 train loss=0.003612662 valid loss= 0.004010565\n",
      "train reg_fs: 0.0020822198130190372\n",
      "Epoch: 9500 train loss=0.004060305 valid loss= 0.003654720\n",
      "train reg_fs: 0.0020667139906436205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:34:58,682]\u001b[0m Trial 58 finished with value: 0.0016620565063598899 and parameters: {'lam': 0.00302327428363537, 'learning_rate': 0.04346445325695655, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003003898 valid loss= 0.003736243\n",
      "train reg_fs: 0.0020470961462706327\n",
      "Optimization Finished!\n",
      "test loss: 0.003445700742304325, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0016620565063598899\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016548380 valid loss= 0.008610677\n",
      "train reg_fs: 0.00251570506952703\n",
      "Epoch: 1000 train loss=0.008348770 valid loss= 0.006803525\n",
      "train reg_fs: 0.0024942525196820498\n",
      "Epoch: 1500 train loss=0.007226947 valid loss= 0.004839289\n",
      "train reg_fs: 0.0024168093223124743\n",
      "Epoch: 2000 train loss=0.014330947 valid loss= 0.005521155\n",
      "train reg_fs: 0.0023552135098725557\n",
      "Epoch: 2500 train loss=0.012015812 valid loss= 0.004466559\n",
      "train reg_fs: 0.002316456288099289\n",
      "Epoch: 3000 train loss=0.004384688 valid loss= 0.004952649\n",
      "train reg_fs: 0.0022931222338229418\n",
      "Epoch: 3500 train loss=0.007693840 valid loss= 0.004119175\n",
      "train reg_fs: 0.0022742405999451876\n",
      "Epoch: 4000 train loss=0.006442848 valid loss= 0.004344637\n",
      "train reg_fs: 0.002256335923448205\n",
      "Epoch: 4500 train loss=0.009923388 valid loss= 0.004661743\n",
      "train reg_fs: 0.0022419379092752934\n",
      "Epoch: 5000 train loss=0.002596195 valid loss= 0.004364266\n",
      "train reg_fs: 0.0022289175540208817\n",
      "Epoch: 5500 train loss=0.003782814 valid loss= 0.004850714\n",
      "train reg_fs: 0.0022173316683620214\n",
      "Epoch: 6000 train loss=0.002783556 valid loss= 0.005015713\n",
      "train reg_fs: 0.002207827987149358\n",
      "Epoch: 6500 train loss=0.002851739 valid loss= 0.004685609\n",
      "train reg_fs: 0.002198198577389121\n",
      "Epoch: 7000 train loss=0.003573261 valid loss= 0.004187550\n",
      "train reg_fs: 0.0021900669671595097\n",
      "Epoch: 7500 train loss=0.002924808 valid loss= 0.004404379\n",
      "train reg_fs: 0.0021839439868927\n",
      "Epoch: 8000 train loss=0.008897239 valid loss= 0.004583370\n",
      "train reg_fs: 0.002178095281124115\n",
      "Epoch: 8500 train loss=0.002913881 valid loss= 0.004361389\n",
      "train reg_fs: 0.0021725986152887344\n",
      "Epoch: 9000 train loss=0.003856116 valid loss= 0.004260151\n",
      "train reg_fs: 0.0021684328094124794\n",
      "Epoch: 9500 train loss=0.002679419 valid loss= 0.003899374\n",
      "train reg_fs: 0.002164584817364812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:36:02,446]\u001b[0m Trial 59 finished with value: 0.002091407377033151 and parameters: {'lam': 0.0029503017321402757, 'learning_rate': 0.042001623959182055, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003846107 valid loss= 0.004221279\n",
      "train reg_fs: 0.002159930532798171\n",
      "Optimization Finished!\n",
      "test loss: 0.004004324786365032, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002091407377033151\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010542285 valid loss= 0.012498768\n",
      "train reg_fs: 0.005315758287906647\n",
      "Epoch: 1000 train loss=0.025641868 valid loss= 0.012317175\n",
      "train reg_fs: 0.005325051490217447\n",
      "Epoch: 1500 train loss=0.013104029 valid loss= 0.011951218\n",
      "train reg_fs: 0.005269492510706186\n",
      "Epoch: 2000 train loss=0.012380619 valid loss= 0.012436597\n",
      "train reg_fs: 0.005146103911101818\n",
      "Epoch: 2500 train loss=0.019980978 valid loss= 0.011318829\n",
      "train reg_fs: 0.005000022239983082\n",
      "Epoch: 3000 train loss=0.010633389 valid loss= 0.010067555\n",
      "train reg_fs: 0.004855376202613115\n",
      "Epoch: 3500 train loss=0.008436863 valid loss= 0.009205597\n",
      "train reg_fs: 0.004715695045888424\n",
      "Epoch: 4000 train loss=0.011786049 valid loss= 0.008337655\n",
      "train reg_fs: 0.004594950936734676\n",
      "Epoch: 4500 train loss=0.007519124 valid loss= 0.007596473\n",
      "train reg_fs: 0.004495370201766491\n",
      "Epoch: 5000 train loss=0.005747217 valid loss= 0.007772792\n",
      "train reg_fs: 0.004414877854287624\n",
      "Epoch: 5500 train loss=0.009313049 valid loss= 0.008140314\n",
      "train reg_fs: 0.004349542316049337\n",
      "Epoch: 6000 train loss=0.007039495 valid loss= 0.008024517\n",
      "train reg_fs: 0.004289031494408846\n",
      "Epoch: 6500 train loss=0.008070103 valid loss= 0.007563096\n",
      "train reg_fs: 0.004237083252519369\n",
      "Epoch: 7000 train loss=0.005609653 valid loss= 0.007814649\n",
      "train reg_fs: 0.00418881606310606\n",
      "Epoch: 7500 train loss=0.007529127 valid loss= 0.007354403\n",
      "train reg_fs: 0.004148493055254221\n",
      "Epoch: 8000 train loss=0.009227619 valid loss= 0.006953736\n",
      "train reg_fs: 0.004108516499400139\n",
      "Epoch: 8500 train loss=0.004463114 valid loss= 0.007096340\n",
      "train reg_fs: 0.004073913674801588\n",
      "Epoch: 9000 train loss=0.004649353 valid loss= 0.006858950\n",
      "train reg_fs: 0.004045345354825258\n",
      "Epoch: 9500 train loss=0.007313634 valid loss= 0.006646170\n",
      "train reg_fs: 0.0040204706601798534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:37:05,553]\u001b[0m Trial 60 finished with value: 0.0026371377512494367 and parameters: {'lam': 0.006267318569894336, 'learning_rate': 0.031261777022827064, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007138222 valid loss= 0.006620100\n",
      "train reg_fs: 0.003999025095254183\n",
      "Optimization Finished!\n",
      "test loss: 0.006448319181799889, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026371377512494367\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016319437 valid loss= 0.007955953\n",
      "train reg_fs: 0.0009766187286004424\n",
      "Epoch: 1000 train loss=0.010498550 valid loss= 0.008301464\n",
      "train reg_fs: 0.0009946634527295828\n",
      "Epoch: 1500 train loss=0.006005542 valid loss= 0.008307763\n",
      "train reg_fs: 0.0010051612043753266\n",
      "Epoch: 2000 train loss=0.004251872 valid loss= 0.008718683\n",
      "train reg_fs: 0.0010130222653970122\n",
      "Epoch: 2500 train loss=0.013648306 valid loss= 0.007904792\n",
      "train reg_fs: 0.0010176642099395394\n",
      "Epoch: 3000 train loss=0.004021247 valid loss= 0.008044259\n",
      "train reg_fs: 0.0010191347682848573\n",
      "Epoch: 3500 train loss=0.006257659 valid loss= 0.006904135\n",
      "train reg_fs: 0.0010191458277404308\n",
      "Epoch: 4000 train loss=0.009818495 valid loss= 0.006842824\n",
      "train reg_fs: 0.0010163739789277315\n",
      "Epoch: 4500 train loss=0.004242114 valid loss= 0.007058146\n",
      "train reg_fs: 0.0010129312286153436\n",
      "Epoch: 5000 train loss=0.001839319 valid loss= 0.007100875\n",
      "train reg_fs: 0.0010069917188957334\n",
      "Epoch: 5500 train loss=0.005928575 valid loss= 0.006353860\n",
      "train reg_fs: 0.0010005751391872764\n",
      "Epoch: 6000 train loss=0.003967850 valid loss= 0.005397270\n",
      "train reg_fs: 0.0009922836907207966\n",
      "Epoch: 6500 train loss=0.004121881 valid loss= 0.006121589\n",
      "train reg_fs: 0.0009846987668424845\n",
      "Epoch: 7000 train loss=0.005410320 valid loss= 0.005791788\n",
      "train reg_fs: 0.0009774321224540472\n",
      "Epoch: 7500 train loss=0.004674859 valid loss= 0.005411948\n",
      "train reg_fs: 0.0009720547823235393\n",
      "Epoch: 8000 train loss=0.005898630 valid loss= 0.005702906\n",
      "train reg_fs: 0.0009649929124861956\n",
      "Epoch: 8500 train loss=0.005974423 valid loss= 0.005191934\n",
      "train reg_fs: 0.0009575227159075439\n",
      "Epoch: 9000 train loss=0.005444070 valid loss= 0.004894728\n",
      "train reg_fs: 0.000953232345636934\n",
      "Epoch: 9500 train loss=0.005982124 valid loss= 0.004825553\n",
      "train reg_fs: 0.0009497927967458963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:38:07,803]\u001b[0m Trial 61 finished with value: 0.004285770025313344 and parameters: {'lam': 0.0011340995583123158, 'learning_rate': 0.03759970197843972, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003390367 valid loss= 0.005245230\n",
      "train reg_fs: 0.0009457705891691148\n",
      "Optimization Finished!\n",
      "test loss: 0.005686493124812841, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004285770025313344\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005064320 valid loss= 0.008259609\n",
      "train reg_fs: 0.0027057980187237263\n",
      "Epoch: 1000 train loss=0.004677557 valid loss= 0.005319034\n",
      "train reg_fs: 0.002422956982627511\n",
      "Epoch: 1500 train loss=0.008047817 valid loss= 0.004507641\n",
      "train reg_fs: 0.0023132720962166786\n",
      "Epoch: 2000 train loss=0.002589263 valid loss= 0.004376662\n",
      "train reg_fs: 0.0022142406087368727\n",
      "Epoch: 2500 train loss=0.013616635 valid loss= 0.004296995\n",
      "train reg_fs: 0.002139946911484003\n",
      "Epoch: 3000 train loss=0.003363802 valid loss= 0.004273367\n",
      "train reg_fs: 0.002093222923576832\n",
      "Epoch: 3500 train loss=0.004520814 valid loss= 0.004552942\n",
      "train reg_fs: 0.002061682753264904\n",
      "Epoch: 4000 train loss=0.004578044 valid loss= 0.003983047\n",
      "train reg_fs: 0.0020319537725299597\n",
      "Epoch: 4500 train loss=0.002494843 valid loss= 0.004217765\n",
      "train reg_fs: 0.0020025463309139013\n",
      "Epoch: 5000 train loss=0.002669969 valid loss= 0.003327779\n",
      "train reg_fs: 0.001973638543859124\n",
      "Epoch: 5500 train loss=0.003477424 valid loss= 0.003718782\n",
      "train reg_fs: 0.0019473418360576034\n",
      "Epoch: 6000 train loss=0.002364930 valid loss= 0.003858275\n",
      "train reg_fs: 0.0019251100020483136\n",
      "Epoch: 6500 train loss=0.002846433 valid loss= 0.003711110\n",
      "train reg_fs: 0.0019093763548880816\n",
      "Epoch: 7000 train loss=0.009569188 valid loss= 0.003676932\n",
      "train reg_fs: 0.00189640570897609\n",
      "Epoch: 7500 train loss=0.004434552 valid loss= 0.004702422\n",
      "train reg_fs: 0.0018865196034312248\n",
      "Epoch: 8000 train loss=0.002699476 valid loss= 0.003357180\n",
      "train reg_fs: 0.001877189613878727\n",
      "Epoch: 8500 train loss=0.004323572 valid loss= 0.003840428\n",
      "train reg_fs: 0.001869735773652792\n",
      "Epoch: 9000 train loss=0.003581565 valid loss= 0.004223355\n",
      "train reg_fs: 0.001864166115410626\n",
      "Epoch: 9500 train loss=0.004520958 valid loss= 0.003408254\n",
      "train reg_fs: 0.0018596069421619177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:39:10,887]\u001b[0m Trial 62 finished with value: 0.0014304474892209054 and parameters: {'lam': 0.0032364395436789914, 'learning_rate': 0.19716899654959472, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002872448 valid loss= 0.003348364\n",
      "train reg_fs: 0.001855619833804667\n",
      "Optimization Finished!\n",
      "test loss: 0.003133228048682213, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0014304474892209054\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016313873 valid loss= 0.009868023\n",
      "train reg_fs: 0.0029598958790302277\n",
      "Epoch: 1000 train loss=0.015111675 valid loss= 0.007346485\n",
      "train reg_fs: 0.002954852534458041\n",
      "Epoch: 1500 train loss=0.010277787 valid loss= 0.007495612\n",
      "train reg_fs: 0.002887231996282935\n",
      "Epoch: 2000 train loss=0.006053368 valid loss= 0.006682700\n",
      "train reg_fs: 0.002812897088006139\n",
      "Epoch: 2500 train loss=0.006437856 valid loss= 0.005331662\n",
      "train reg_fs: 0.002743345685303211\n",
      "Epoch: 3000 train loss=0.005411084 valid loss= 0.004867108\n",
      "train reg_fs: 0.002687950851395726\n",
      "Epoch: 3500 train loss=0.004363448 valid loss= 0.005140583\n",
      "train reg_fs: 0.002652063500136137\n",
      "Epoch: 4000 train loss=0.007791458 valid loss= 0.004587043\n",
      "train reg_fs: 0.002631022594869137\n",
      "Epoch: 4500 train loss=0.004729285 valid loss= 0.004655298\n",
      "train reg_fs: 0.0026162555441260338\n",
      "Epoch: 5000 train loss=0.004202341 valid loss= 0.004395667\n",
      "train reg_fs: 0.00260566477663815\n",
      "Epoch: 5500 train loss=0.005654722 valid loss= 0.004392034\n",
      "train reg_fs: 0.0025880930479615927\n",
      "Epoch: 6000 train loss=0.002986499 valid loss= 0.004607599\n",
      "train reg_fs: 0.002567390212789178\n",
      "Epoch: 6500 train loss=0.008262817 valid loss= 0.004249286\n",
      "train reg_fs: 0.0025446992367506027\n",
      "Epoch: 7000 train loss=0.009874227 valid loss= 0.004236990\n",
      "train reg_fs: 0.002519570291042328\n",
      "Epoch: 7500 train loss=0.009075983 valid loss= 0.004071309\n",
      "train reg_fs: 0.0024953356478363276\n",
      "Epoch: 8000 train loss=0.005309361 valid loss= 0.004204131\n",
      "train reg_fs: 0.0024718986824154854\n",
      "Epoch: 8500 train loss=0.003986610 valid loss= 0.003989412\n",
      "train reg_fs: 0.0024478035047650337\n",
      "Epoch: 9000 train loss=0.002763940 valid loss= 0.003970893\n",
      "train reg_fs: 0.0024251211434602737\n",
      "Epoch: 9500 train loss=0.004943122 valid loss= 0.003596806\n",
      "train reg_fs: 0.002399657852947712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:40:13,847]\u001b[0m Trial 63 finished with value: 0.0013480366373052296 and parameters: {'lam': 0.0034448453778577557, 'learning_rate': 0.05442620409472219, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005821832 valid loss= 0.003685674\n",
      "train reg_fs: 0.002378342440351844\n",
      "Optimization Finished!\n",
      "test loss: 0.003964276984333992, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0013480366373052296\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014507771 valid loss= 0.009549910\n",
      "train reg_fs: 0.002979073440656066\n",
      "Epoch: 1000 train loss=0.017081274 valid loss= 0.007379259\n",
      "train reg_fs: 0.002964936662465334\n",
      "Epoch: 1500 train loss=0.009283977 valid loss= 0.006506686\n",
      "train reg_fs: 0.0029042011592537165\n",
      "Epoch: 2000 train loss=0.017413013 valid loss= 0.005633072\n",
      "train reg_fs: 0.0028381238225847483\n",
      "Epoch: 2500 train loss=0.005354486 valid loss= 0.005368005\n",
      "train reg_fs: 0.002775399014353752\n",
      "Epoch: 3000 train loss=0.006269769 valid loss= 0.004559493\n",
      "train reg_fs: 0.0027294454630464315\n",
      "Epoch: 3500 train loss=0.005226239 valid loss= 0.005766506\n",
      "train reg_fs: 0.0027053547091782093\n",
      "Epoch: 4000 train loss=0.012489207 valid loss= 0.004949478\n",
      "train reg_fs: 0.0026903911493718624\n",
      "Epoch: 4500 train loss=0.004131887 valid loss= 0.005157754\n",
      "train reg_fs: 0.0026809966657310724\n",
      "Epoch: 5000 train loss=0.004957885 valid loss= 0.004896501\n",
      "train reg_fs: 0.002675475552678108\n",
      "Epoch: 5500 train loss=0.005532668 valid loss= 0.005508251\n",
      "train reg_fs: 0.002668944885954261\n",
      "Epoch: 6000 train loss=0.007342817 valid loss= 0.004453209\n",
      "train reg_fs: 0.0026581231504678726\n",
      "Epoch: 6500 train loss=0.007185728 valid loss= 0.005083610\n",
      "train reg_fs: 0.002642036648467183\n",
      "Epoch: 7000 train loss=0.003451145 valid loss= 0.004161624\n",
      "train reg_fs: 0.0026198814157396555\n",
      "Epoch: 7500 train loss=0.006013758 valid loss= 0.004408485\n",
      "train reg_fs: 0.002596659120172262\n",
      "Epoch: 8000 train loss=0.009082330 valid loss= 0.003833401\n",
      "train reg_fs: 0.00257358280941844\n",
      "Epoch: 8500 train loss=0.005235111 valid loss= 0.004971935\n",
      "train reg_fs: 0.0025506222154945135\n",
      "Epoch: 9000 train loss=0.002934332 valid loss= 0.004766304\n",
      "train reg_fs: 0.0025290718767791986\n",
      "Epoch: 9500 train loss=0.004195702 valid loss= 0.003424030\n",
      "train reg_fs: 0.002509121783077717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:41:17,598]\u001b[0m Trial 64 finished with value: 0.001113464681781026 and parameters: {'lam': 0.0034925163947090434, 'learning_rate': 0.04692619697592163, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003212197 valid loss= 0.003613401\n",
      "train reg_fs: 0.002491651102900505\n",
      "Optimization Finished!\n",
      "test loss: 0.003519651247188449, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001113464681781026\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016959179 valid loss= 0.010051616\n",
      "train reg_fs: 0.002819107146933675\n",
      "Epoch: 1000 train loss=0.014982224 valid loss= 0.007765283\n",
      "train reg_fs: 0.0027900347486138344\n",
      "Epoch: 1500 train loss=0.009394997 valid loss= 0.006670869\n",
      "train reg_fs: 0.0026987099554389715\n",
      "Epoch: 2000 train loss=0.005275022 valid loss= 0.004900750\n",
      "train reg_fs: 0.0026140930131077766\n",
      "Epoch: 2500 train loss=0.007634605 valid loss= 0.004810017\n",
      "train reg_fs: 0.0025528105907142162\n",
      "Epoch: 3000 train loss=0.007751272 valid loss= 0.004994064\n",
      "train reg_fs: 0.0025254101492464542\n",
      "Epoch: 3500 train loss=0.008635614 valid loss= 0.005439512\n",
      "train reg_fs: 0.0025043319910764694\n",
      "Epoch: 4000 train loss=0.005651473 valid loss= 0.005040312\n",
      "train reg_fs: 0.0024933896493166685\n",
      "Epoch: 4500 train loss=0.004636465 valid loss= 0.005037666\n",
      "train reg_fs: 0.0024835397489368916\n",
      "Epoch: 5000 train loss=0.006893464 valid loss= 0.005755756\n",
      "train reg_fs: 0.0024757469072937965\n",
      "Epoch: 5500 train loss=0.003381821 valid loss= 0.005257587\n",
      "train reg_fs: 0.002470005303621292\n",
      "Epoch: 6000 train loss=0.009675158 valid loss= 0.004448480\n",
      "train reg_fs: 0.002463735407218337\n",
      "Epoch: 6500 train loss=0.007261422 valid loss= 0.005762887\n",
      "train reg_fs: 0.002459420822560787\n",
      "Epoch: 7000 train loss=0.004205644 valid loss= 0.005370913\n",
      "train reg_fs: 0.00245364080183208\n",
      "Epoch: 7500 train loss=0.006464822 valid loss= 0.005002895\n",
      "train reg_fs: 0.0024419263936579227\n",
      "Epoch: 8000 train loss=0.004240382 valid loss= 0.004848416\n",
      "train reg_fs: 0.002433372661471367\n",
      "Epoch: 8500 train loss=0.003376323 valid loss= 0.004406276\n",
      "train reg_fs: 0.0024265828542411327\n",
      "Epoch: 9000 train loss=0.002896629 valid loss= 0.005135921\n",
      "train reg_fs: 0.0024237516336143017\n",
      "Epoch: 9500 train loss=0.005498827 valid loss= 0.004833557\n",
      "train reg_fs: 0.00241514528170228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:42:20,834]\u001b[0m Trial 65 finished with value: 0.0026302144403466997 and parameters: {'lam': 0.0033121638209456104, 'learning_rate': 0.051699033496570714, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004102418 valid loss= 0.005106758\n",
      "train reg_fs: 0.0024063442833721638\n",
      "Optimization Finished!\n",
      "test loss: 0.005035854876041412, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0026302144403466997\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011889083 valid loss= 0.010691278\n",
      "train reg_fs: 0.00396394357085228\n",
      "Epoch: 1000 train loss=0.015808040 valid loss= 0.009774739\n",
      "train reg_fs: 0.003963768947869539\n",
      "Epoch: 1500 train loss=0.012760913 valid loss= 0.009168792\n",
      "train reg_fs: 0.003908331971615553\n",
      "Epoch: 2000 train loss=0.008711544 valid loss= 0.010095842\n",
      "train reg_fs: 0.0038190733175724745\n",
      "Epoch: 2500 train loss=0.006571069 valid loss= 0.009290468\n",
      "train reg_fs: 0.0037437218707054853\n",
      "Epoch: 3000 train loss=0.008418670 valid loss= 0.008344873\n",
      "train reg_fs: 0.003671205136924982\n",
      "Epoch: 3500 train loss=0.009186146 valid loss= 0.006557876\n",
      "train reg_fs: 0.0035958809312433004\n",
      "Epoch: 4000 train loss=0.005927317 valid loss= 0.006298461\n",
      "train reg_fs: 0.003520923899486661\n",
      "Epoch: 4500 train loss=0.012545562 valid loss= 0.006917593\n",
      "train reg_fs: 0.003453576937317848\n",
      "Epoch: 5000 train loss=0.005001865 valid loss= 0.006479792\n",
      "train reg_fs: 0.003398209111765027\n",
      "Epoch: 5500 train loss=0.005986810 valid loss= 0.006715341\n",
      "train reg_fs: 0.003348840866237879\n",
      "Epoch: 6000 train loss=0.005791705 valid loss= 0.007221316\n",
      "train reg_fs: 0.003318269969895482\n",
      "Epoch: 6500 train loss=0.007004314 valid loss= 0.006702026\n",
      "train reg_fs: 0.003290923312306404\n",
      "Epoch: 7000 train loss=0.007650700 valid loss= 0.006530463\n",
      "train reg_fs: 0.0032676197588443756\n",
      "Epoch: 7500 train loss=0.005500059 valid loss= 0.006965889\n",
      "train reg_fs: 0.003248607972636819\n",
      "Epoch: 8000 train loss=0.007885788 valid loss= 0.006908481\n",
      "train reg_fs: 0.0032339715398848057\n",
      "Epoch: 8500 train loss=0.006112303 valid loss= 0.007124268\n",
      "train reg_fs: 0.003218871308490634\n",
      "Epoch: 9000 train loss=0.005770663 valid loss= 0.007299159\n",
      "train reg_fs: 0.0032010958530008793\n",
      "Epoch: 9500 train loss=0.006202567 valid loss= 0.007645238\n",
      "train reg_fs: 0.0031943931244313717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:43:23,621]\u001b[0m Trial 66 finished with value: 0.003855585527253756 and parameters: {'lam': 0.004643337083440494, 'learning_rate': 0.04750681433666899, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.007988855 valid loss= 0.007149553\n",
      "train reg_fs: 0.003178329672664404\n",
      "Optimization Finished!\n",
      "test loss: 0.00689900666475296, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003855585527253756\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014479476 valid loss= 0.009169627\n",
      "train reg_fs: 0.0023156525567173958\n",
      "Epoch: 1000 train loss=0.015396326 valid loss= 0.008277943\n",
      "train reg_fs: 0.0023108236491680145\n",
      "Epoch: 1500 train loss=0.007704524 valid loss= 0.008197335\n",
      "train reg_fs: 0.0022796320263296366\n",
      "Epoch: 2000 train loss=0.008475281 valid loss= 0.007152381\n",
      "train reg_fs: 0.002227794611826539\n",
      "Epoch: 2500 train loss=0.006250546 valid loss= 0.006795333\n",
      "train reg_fs: 0.002183218952268362\n",
      "Epoch: 3000 train loss=0.005626872 valid loss= 0.006090897\n",
      "train reg_fs: 0.0021417695097625256\n",
      "Epoch: 3500 train loss=0.003284741 valid loss= 0.005416809\n",
      "train reg_fs: 0.002098497236147523\n",
      "Epoch: 4000 train loss=0.006662555 valid loss= 0.005605292\n",
      "train reg_fs: 0.002060606377199292\n",
      "Epoch: 4500 train loss=0.004726947 valid loss= 0.005334543\n",
      "train reg_fs: 0.0020324960350990295\n",
      "Epoch: 5000 train loss=0.003910505 valid loss= 0.005421835\n",
      "train reg_fs: 0.002011711010709405\n",
      "Epoch: 5500 train loss=0.003936849 valid loss= 0.005616724\n",
      "train reg_fs: 0.0019938775803893805\n",
      "Epoch: 6000 train loss=0.004932185 valid loss= 0.005093043\n",
      "train reg_fs: 0.001979254186153412\n",
      "Epoch: 6500 train loss=0.004343187 valid loss= 0.005188524\n",
      "train reg_fs: 0.00196879543364048\n",
      "Epoch: 7000 train loss=0.006937026 valid loss= 0.005088655\n",
      "train reg_fs: 0.001960206776857376\n",
      "Epoch: 7500 train loss=0.007237855 valid loss= 0.005317428\n",
      "train reg_fs: 0.0019530811114236712\n",
      "Epoch: 8000 train loss=0.005425962 valid loss= 0.005268577\n",
      "train reg_fs: 0.0019453172571957111\n",
      "Epoch: 8500 train loss=0.004439650 valid loss= 0.005206614\n",
      "train reg_fs: 0.001938044442795217\n",
      "Epoch: 9000 train loss=0.002909489 valid loss= 0.005778720\n",
      "train reg_fs: 0.0019311646465212107\n",
      "Epoch: 9500 train loss=0.004101292 valid loss= 0.004947565\n",
      "train reg_fs: 0.00192292220890522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:44:26,843]\u001b[0m Trial 67 finished with value: 0.003396533117594567 and parameters: {'lam': 0.0027364632382052565, 'learning_rate': 0.0355054687681665, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004105936 valid loss= 0.005339600\n",
      "train reg_fs: 0.0019120550714433193\n",
      "Optimization Finished!\n",
      "test loss: 0.005124437622725964, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003396533117594567\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.017596675 valid loss= 0.010168564\n",
      "train reg_fs: 0.003072908613830805\n",
      "Epoch: 1000 train loss=0.007516950 valid loss= 0.011569018\n",
      "train reg_fs: 0.0031067722011357546\n",
      "Epoch: 1500 train loss=0.013095533 valid loss= 0.010698910\n",
      "train reg_fs: 0.0031167047563940287\n",
      "Epoch: 2000 train loss=0.009995108 valid loss= 0.010648943\n",
      "train reg_fs: 0.003107653232291341\n",
      "Epoch: 2500 train loss=0.009729958 valid loss= 0.009675777\n",
      "train reg_fs: 0.0030785370618104935\n",
      "Epoch: 3000 train loss=0.015421977 valid loss= 0.009158374\n",
      "train reg_fs: 0.003045877907425165\n",
      "Epoch: 3500 train loss=0.013921434 valid loss= 0.009233009\n",
      "train reg_fs: 0.003015939611941576\n",
      "Epoch: 4000 train loss=0.008052553 valid loss= 0.007991560\n",
      "train reg_fs: 0.0029926144052296877\n",
      "Epoch: 4500 train loss=0.005799818 valid loss= 0.008131816\n",
      "train reg_fs: 0.002967214910313487\n",
      "Epoch: 5000 train loss=0.005955939 valid loss= 0.008221230\n",
      "train reg_fs: 0.002945488318800926\n",
      "Epoch: 5500 train loss=0.011941934 valid loss= 0.007022394\n",
      "train reg_fs: 0.0029205824248492718\n",
      "Epoch: 6000 train loss=0.013540303 valid loss= 0.006278159\n",
      "train reg_fs: 0.002887844806537032\n",
      "Epoch: 6500 train loss=0.005927679 valid loss= 0.005914391\n",
      "train reg_fs: 0.002843566006049514\n",
      "Epoch: 7000 train loss=0.006083728 valid loss= 0.005835581\n",
      "train reg_fs: 0.0027995354030281305\n",
      "Epoch: 7500 train loss=0.006332768 valid loss= 0.005194288\n",
      "train reg_fs: 0.0027542344760149717\n",
      "Epoch: 8000 train loss=0.004945074 valid loss= 0.005394229\n",
      "train reg_fs: 0.002714843489229679\n",
      "Epoch: 8500 train loss=0.004563048 valid loss= 0.005488419\n",
      "train reg_fs: 0.0026738520245999098\n",
      "Epoch: 9000 train loss=0.007487660 valid loss= 0.005415081\n",
      "train reg_fs: 0.002637692494317889\n",
      "Epoch: 9500 train loss=0.005447092 valid loss= 0.005509901\n",
      "train reg_fs: 0.002602696418762207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:45:29,946]\u001b[0m Trial 68 finished with value: 0.0030190211228712195 and parameters: {'lam': 0.0035971926157127884, 'learning_rate': 0.031045179155012575, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003507760 valid loss= 0.005600264\n",
      "train reg_fs: 0.002570739947259426\n",
      "Optimization Finished!\n",
      "test loss: 0.005470572970807552, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0030190211228712195\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011932830 valid loss= 0.010621365\n",
      "train reg_fs: 0.0033855170477181673\n",
      "Epoch: 1000 train loss=0.007412628 valid loss= 0.011349075\n",
      "train reg_fs: 0.0033911403734236956\n",
      "Epoch: 1500 train loss=0.009842094 valid loss= 0.008818071\n",
      "train reg_fs: 0.00331201427616179\n",
      "Epoch: 2000 train loss=0.011999315 valid loss= 0.007510060\n",
      "train reg_fs: 0.003173582721501589\n",
      "Epoch: 2500 train loss=0.010632877 valid loss= 0.005947173\n",
      "train reg_fs: 0.0030634510330855846\n",
      "Epoch: 3000 train loss=0.008713480 valid loss= 0.005358679\n",
      "train reg_fs: 0.002997112227603793\n",
      "Epoch: 3500 train loss=0.003971461 valid loss= 0.005841598\n",
      "train reg_fs: 0.002942162798717618\n",
      "Epoch: 4000 train loss=0.008544976 valid loss= 0.005345661\n",
      "train reg_fs: 0.0028983945958316326\n",
      "Epoch: 4500 train loss=0.004447925 valid loss= 0.005594130\n",
      "train reg_fs: 0.002845318056643009\n",
      "Epoch: 5000 train loss=0.003895160 valid loss= 0.005838141\n",
      "train reg_fs: 0.0027941465377807617\n",
      "Epoch: 5500 train loss=0.004883375 valid loss= 0.005515411\n",
      "train reg_fs: 0.0027377610094845295\n",
      "Epoch: 6000 train loss=0.013764031 valid loss= 0.005861471\n",
      "train reg_fs: 0.002689722692593932\n",
      "Epoch: 6500 train loss=0.004309926 valid loss= 0.004897465\n",
      "train reg_fs: 0.00264909234829247\n",
      "Epoch: 7000 train loss=0.005532180 valid loss= 0.004697751\n",
      "train reg_fs: 0.002613106742501259\n",
      "Epoch: 7500 train loss=0.005415981 valid loss= 0.005423466\n",
      "train reg_fs: 0.0025850553065538406\n",
      "Epoch: 8000 train loss=0.005352676 valid loss= 0.004428087\n",
      "train reg_fs: 0.0025608069263398647\n",
      "Epoch: 8500 train loss=0.008220292 valid loss= 0.004557142\n",
      "train reg_fs: 0.00253925914876163\n",
      "Epoch: 9000 train loss=0.003253825 valid loss= 0.004624214\n",
      "train reg_fs: 0.00251882360316813\n",
      "Epoch: 9500 train loss=0.009253878 valid loss= 0.004423324\n",
      "train reg_fs: 0.00249805161729455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:46:33,341]\u001b[0m Trial 69 finished with value: 0.002421585804389695 and parameters: {'lam': 0.003923955986691007, 'learning_rate': 0.05806095567652534, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005992197 valid loss= 0.004944871\n",
      "train reg_fs: 0.002480082679539919\n",
      "Optimization Finished!\n",
      "test loss: 0.0045430161990225315, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002421585804389695\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016804071 valid loss= 0.008066434\n",
      "train reg_fs: 0.002402188954874873\n",
      "Epoch: 1000 train loss=0.014089159 valid loss= 0.011158552\n",
      "train reg_fs: 0.0022448282688856125\n",
      "Epoch: 1500 train loss=0.007030323 valid loss= 0.007784775\n",
      "train reg_fs: 0.0021454673260450363\n",
      "Epoch: 2000 train loss=0.005148924 valid loss= 0.005118787\n",
      "train reg_fs: 0.0020725594367831945\n",
      "Epoch: 2500 train loss=0.004909000 valid loss= 0.005824149\n",
      "train reg_fs: 0.0020296950824558735\n",
      "Epoch: 3000 train loss=0.004007358 valid loss= 0.006144780\n",
      "train reg_fs: 0.002015575533732772\n",
      "Epoch: 3500 train loss=0.004799764 valid loss= 0.005454361\n",
      "train reg_fs: 0.002009403193369508\n",
      "Epoch: 4000 train loss=0.002889822 valid loss= 0.006069716\n",
      "train reg_fs: 0.001997550716623664\n",
      "Epoch: 4500 train loss=0.003253941 valid loss= 0.005366318\n",
      "train reg_fs: 0.0019930137787014246\n",
      "Epoch: 5000 train loss=0.004035231 valid loss= 0.005783577\n",
      "train reg_fs: 0.0019803494215011597\n",
      "Epoch: 5500 train loss=0.003888494 valid loss= 0.005392080\n",
      "train reg_fs: 0.0019721915014088154\n",
      "Epoch: 6000 train loss=0.003512361 valid loss= 0.005935603\n",
      "train reg_fs: 0.001962163019925356\n",
      "Epoch: 6500 train loss=0.006573786 valid loss= 0.005218240\n",
      "train reg_fs: 0.0019489664118736982\n",
      "Epoch: 7000 train loss=0.003340738 valid loss= 0.005707720\n",
      "train reg_fs: 0.0019380509620532393\n",
      "Epoch: 7500 train loss=0.003355008 valid loss= 0.005001618\n",
      "train reg_fs: 0.0019254519138485193\n",
      "Epoch: 8000 train loss=0.002753991 valid loss= 0.005431148\n",
      "train reg_fs: 0.0019125319086015224\n",
      "Epoch: 8500 train loss=0.002705033 valid loss= 0.005277044\n",
      "train reg_fs: 0.001903232536278665\n",
      "Epoch: 9000 train loss=0.003443025 valid loss= 0.006603180\n",
      "train reg_fs: 0.0018937737913802266\n",
      "Epoch: 9500 train loss=0.002550019 valid loss= 0.005542155\n",
      "train reg_fs: 0.001882110140286386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:47:37,160]\u001b[0m Trial 70 finished with value: 0.0034525650685377916 and parameters: {'lam': 0.002771220649899937, 'learning_rate': 0.15964156302333463, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002850960 valid loss= 0.005330740\n",
      "train reg_fs: 0.0018728958675637841\n",
      "Optimization Finished!\n",
      "test loss: 0.005707886535674334, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0034525650685377916\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007596122 valid loss= 0.010423449\n",
      "train reg_fs: 0.0026931550819426775\n",
      "Epoch: 1000 train loss=0.014225637 valid loss= 0.010029424\n",
      "train reg_fs: 0.0027456386014819145\n",
      "Epoch: 1500 train loss=0.017912228 valid loss= 0.010537044\n",
      "train reg_fs: 0.002770043443888426\n",
      "Epoch: 2000 train loss=0.010973943 valid loss= 0.010628764\n",
      "train reg_fs: 0.0027793538756668568\n",
      "Epoch: 2500 train loss=0.010121502 valid loss= 0.010907568\n",
      "train reg_fs: 0.0027674147859215736\n",
      "Epoch: 3000 train loss=0.013836003 valid loss= 0.009438812\n",
      "train reg_fs: 0.0027474137023091316\n",
      "Epoch: 3500 train loss=0.008411731 valid loss= 0.009406590\n",
      "train reg_fs: 0.0027126146014779806\n",
      "Epoch: 4000 train loss=0.006616578 valid loss= 0.010329195\n",
      "train reg_fs: 0.0026775423903018236\n",
      "Epoch: 4500 train loss=0.007156850 valid loss= 0.010153421\n",
      "train reg_fs: 0.002648990834131837\n",
      "Epoch: 5000 train loss=0.008728344 valid loss= 0.009009436\n",
      "train reg_fs: 0.0026231661904603243\n",
      "Epoch: 5500 train loss=0.003575265 valid loss= 0.010659926\n",
      "train reg_fs: 0.0025997452903538942\n",
      "Epoch: 6000 train loss=0.016450059 valid loss= 0.008834673\n",
      "train reg_fs: 0.002582215704023838\n",
      "Epoch: 6500 train loss=0.008011797 valid loss= 0.009650693\n",
      "train reg_fs: 0.002564558293670416\n",
      "Epoch: 7000 train loss=0.006516472 valid loss= 0.009740297\n",
      "train reg_fs: 0.002549121854826808\n",
      "Epoch: 7500 train loss=0.004630040 valid loss= 0.008940129\n",
      "train reg_fs: 0.0025312909856438637\n",
      "Epoch: 8000 train loss=0.005740557 valid loss= 0.009323439\n",
      "train reg_fs: 0.0025177530478686094\n",
      "Epoch: 8500 train loss=0.009084659 valid loss= 0.009093734\n",
      "train reg_fs: 0.002503530588001013\n",
      "Epoch: 9000 train loss=0.005648893 valid loss= 0.009173328\n",
      "train reg_fs: 0.0024926066398620605\n",
      "Epoch: 9500 train loss=0.004887712 valid loss= 0.008530487\n",
      "train reg_fs: 0.002483466174453497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:48:40,097]\u001b[0m Trial 71 finished with value: 0.006821056711585651 and parameters: {'lam': 0.0031016161811269582, 'learning_rate': 0.042563768968897894, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004839578 valid loss= 0.009340602\n",
      "train reg_fs: 0.0024755317717790604\n",
      "Optimization Finished!\n",
      "test loss: 0.008677003905177116, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.006821056711585651\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014178307 valid loss= 0.010922857\n",
      "train reg_fs: 0.003028241917490959\n",
      "Epoch: 1000 train loss=0.014492960 valid loss= 0.010268490\n",
      "train reg_fs: 0.0030625471845269203\n",
      "Epoch: 1500 train loss=0.020165624 valid loss= 0.010111094\n",
      "train reg_fs: 0.003059359034523368\n",
      "Epoch: 2000 train loss=0.007674293 valid loss= 0.010294916\n",
      "train reg_fs: 0.00303078256547451\n",
      "Epoch: 2500 train loss=0.012242517 valid loss= 0.008531852\n",
      "train reg_fs: 0.0029857729095965624\n",
      "Epoch: 3000 train loss=0.008848761 valid loss= 0.010193750\n",
      "train reg_fs: 0.002935778582468629\n",
      "Epoch: 3500 train loss=0.006554667 valid loss= 0.008487660\n",
      "train reg_fs: 0.002896326594054699\n",
      "Epoch: 4000 train loss=0.008587146 valid loss= 0.008290136\n",
      "train reg_fs: 0.002862120745703578\n",
      "Epoch: 4500 train loss=0.011790812 valid loss= 0.007895478\n",
      "train reg_fs: 0.002828134223818779\n",
      "Epoch: 5000 train loss=0.003827247 valid loss= 0.008372150\n",
      "train reg_fs: 0.002786594908684492\n",
      "Epoch: 5500 train loss=0.005231248 valid loss= 0.006648771\n",
      "train reg_fs: 0.002745293779298663\n",
      "Epoch: 6000 train loss=0.007861869 valid loss= 0.006878784\n",
      "train reg_fs: 0.0027037516701966524\n",
      "Epoch: 6500 train loss=0.003725696 valid loss= 0.006118929\n",
      "train reg_fs: 0.0026572567876428366\n",
      "Epoch: 7000 train loss=0.010705856 valid loss= 0.005625625\n",
      "train reg_fs: 0.0026184695307165384\n",
      "Epoch: 7500 train loss=0.004548317 valid loss= 0.006298683\n",
      "train reg_fs: 0.0025923894718289375\n",
      "Epoch: 8000 train loss=0.013117533 valid loss= 0.007182265\n",
      "train reg_fs: 0.0025675820652395487\n",
      "Epoch: 8500 train loss=0.004560371 valid loss= 0.006960134\n",
      "train reg_fs: 0.0025492783170193434\n",
      "Epoch: 9000 train loss=0.003379972 valid loss= 0.006641088\n",
      "train reg_fs: 0.002531120553612709\n",
      "Epoch: 9500 train loss=0.004979955 valid loss= 0.006292049\n",
      "train reg_fs: 0.00251653790473938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:49:42,780]\u001b[0m Trial 72 finished with value: 0.003665907758874083 and parameters: {'lam': 0.00351283062403678, 'learning_rate': 0.04500198608451809, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004352398 valid loss= 0.006191090\n",
      "train reg_fs: 0.002494777785614133\n",
      "Optimization Finished!\n",
      "test loss: 0.005852149333804846, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.003665907758874083\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016223835 valid loss= 0.009403441\n",
      "train reg_fs: 0.0028504712972790003\n",
      "Epoch: 1000 train loss=0.011160448 valid loss= 0.009391786\n",
      "train reg_fs: 0.00283583952113986\n",
      "Epoch: 1500 train loss=0.012616269 valid loss= 0.008594226\n",
      "train reg_fs: 0.002748365281149745\n",
      "Epoch: 2000 train loss=0.008251254 valid loss= 0.007746443\n",
      "train reg_fs: 0.002628759015351534\n",
      "Epoch: 2500 train loss=0.007715593 valid loss= 0.006362410\n",
      "train reg_fs: 0.002510904334485531\n",
      "Epoch: 3000 train loss=0.013083648 valid loss= 0.005251169\n",
      "train reg_fs: 0.0024162661284208298\n",
      "Epoch: 3500 train loss=0.005437846 valid loss= 0.005254372\n",
      "train reg_fs: 0.00234473985619843\n",
      "Epoch: 4000 train loss=0.012441769 valid loss= 0.005439830\n",
      "train reg_fs: 0.0022932987194508314\n",
      "Epoch: 4500 train loss=0.007091699 valid loss= 0.004925436\n",
      "train reg_fs: 0.0022560004144906998\n",
      "Epoch: 5000 train loss=0.004634724 valid loss= 0.004872572\n",
      "train reg_fs: 0.002229792531579733\n",
      "Epoch: 5500 train loss=0.002710462 valid loss= 0.004930425\n",
      "train reg_fs: 0.0022083783987909555\n",
      "Epoch: 6000 train loss=0.006233315 valid loss= 0.005278907\n",
      "train reg_fs: 0.0021900953724980354\n",
      "Epoch: 6500 train loss=0.003385218 valid loss= 0.004985055\n",
      "train reg_fs: 0.0021755604539066553\n",
      "Epoch: 7000 train loss=0.004055989 valid loss= 0.004115884\n",
      "train reg_fs: 0.002163646975532174\n",
      "Epoch: 7500 train loss=0.003227792 valid loss= 0.004337275\n",
      "train reg_fs: 0.0021523847244679928\n",
      "Epoch: 8000 train loss=0.003403089 valid loss= 0.004439332\n",
      "train reg_fs: 0.0021422598510980606\n",
      "Epoch: 8500 train loss=0.003503126 valid loss= 0.004526883\n",
      "train reg_fs: 0.002133069559931755\n",
      "Epoch: 9000 train loss=0.005547488 valid loss= 0.004468048\n",
      "train reg_fs: 0.002124291844666004\n",
      "Epoch: 9500 train loss=0.004868344 valid loss= 0.004287578\n",
      "train reg_fs: 0.0021164456848055124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:50:46,232]\u001b[0m Trial 73 finished with value: 0.0022767865988735816 and parameters: {'lam': 0.0033042346483640153, 'learning_rate': 0.054237185867367976, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004560230 valid loss= 0.004379696\n",
      "train reg_fs: 0.002108895918354392\n",
      "Optimization Finished!\n",
      "test loss: 0.004214203450828791, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022767865988735816\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011338488 valid loss= 0.007848551\n",
      "train reg_fs: 0.0033837060909718275\n",
      "Epoch: 1000 train loss=0.015487824 valid loss= 0.008550875\n",
      "train reg_fs: 0.0033539996948093176\n",
      "Epoch: 1500 train loss=0.008568363 valid loss= 0.006668541\n",
      "train reg_fs: 0.003244469640776515\n",
      "Epoch: 2000 train loss=0.009748392 valid loss= 0.005555734\n",
      "train reg_fs: 0.0031373435631394386\n",
      "Epoch: 2500 train loss=0.007203327 valid loss= 0.005213119\n",
      "train reg_fs: 0.0030666599050164223\n",
      "Epoch: 3000 train loss=0.004005675 valid loss= 0.005924395\n",
      "train reg_fs: 0.003018910763785243\n",
      "Epoch: 3500 train loss=0.005406442 valid loss= 0.006102017\n",
      "train reg_fs: 0.0029812140855938196\n",
      "Epoch: 4000 train loss=0.003683988 valid loss= 0.006119783\n",
      "train reg_fs: 0.0029465723782777786\n",
      "Epoch: 4500 train loss=0.003689154 valid loss= 0.005453744\n",
      "train reg_fs: 0.0029210252687335014\n",
      "Epoch: 5000 train loss=0.003354078 valid loss= 0.006019771\n",
      "train reg_fs: 0.002902186708524823\n",
      "Epoch: 5500 train loss=0.006381573 valid loss= 0.005692878\n",
      "train reg_fs: 0.00288519449532032\n",
      "Epoch: 6000 train loss=0.004893764 valid loss= 0.004951387\n",
      "train reg_fs: 0.0028723154682666063\n",
      "Epoch: 6500 train loss=0.011065741 valid loss= 0.004616406\n",
      "train reg_fs: 0.002859932603314519\n",
      "Epoch: 7000 train loss=0.004222156 valid loss= 0.005174431\n",
      "train reg_fs: 0.0028478882741183043\n",
      "Epoch: 7500 train loss=0.003378968 valid loss= 0.005338285\n",
      "train reg_fs: 0.002838526386767626\n",
      "Epoch: 8000 train loss=0.004343010 valid loss= 0.004925423\n",
      "train reg_fs: 0.0028301707934588194\n",
      "Epoch: 8500 train loss=0.005322671 valid loss= 0.005217518\n",
      "train reg_fs: 0.0028225136920809746\n",
      "Epoch: 9000 train loss=0.003358406 valid loss= 0.005210786\n",
      "train reg_fs: 0.0028144861571490765\n",
      "Epoch: 9500 train loss=0.003623898 valid loss= 0.004935053\n",
      "train reg_fs: 0.002807545242831111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:51:48,903]\u001b[0m Trial 74 finished with value: 0.0022611454083262287 and parameters: {'lam': 0.003910684154762945, 'learning_rate': 0.06571513761713318, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.004055592 valid loss= 0.004971071\n",
      "train reg_fs: 0.0028015763964504004\n",
      "Optimization Finished!\n",
      "test loss: 0.004791518207639456, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022611454083262287\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008303454 valid loss= 0.007735777\n",
      "train reg_fs: 0.0019406168721616268\n",
      "Epoch: 1000 train loss=0.008588573 valid loss= 0.007174065\n",
      "train reg_fs: 0.0019411331741139293\n",
      "Epoch: 1500 train loss=0.009341775 valid loss= 0.005847881\n",
      "train reg_fs: 0.0019235600484535098\n",
      "Epoch: 2000 train loss=0.007685547 valid loss= 0.004992545\n",
      "train reg_fs: 0.0018898257985711098\n",
      "Epoch: 2500 train loss=0.011408899 valid loss= 0.004946184\n",
      "train reg_fs: 0.001850169152021408\n",
      "Epoch: 3000 train loss=0.009313828 valid loss= 0.004399871\n",
      "train reg_fs: 0.0018185906810685992\n",
      "Epoch: 3500 train loss=0.005459948 valid loss= 0.004248985\n",
      "train reg_fs: 0.001794286072254181\n",
      "Epoch: 4000 train loss=0.006993588 valid loss= 0.004099042\n",
      "train reg_fs: 0.0017787505639716983\n",
      "Epoch: 4500 train loss=0.009419700 valid loss= 0.004262159\n",
      "train reg_fs: 0.0017688007792457938\n",
      "Epoch: 5000 train loss=0.003108429 valid loss= 0.004493119\n",
      "train reg_fs: 0.0017620691796764731\n",
      "Epoch: 5500 train loss=0.005812182 valid loss= 0.003975988\n",
      "train reg_fs: 0.0017577609978616238\n",
      "Epoch: 6000 train loss=0.003698726 valid loss= 0.004029259\n",
      "train reg_fs: 0.0017561506247147918\n",
      "Epoch: 6500 train loss=0.009029453 valid loss= 0.004182480\n",
      "train reg_fs: 0.0017557814717292786\n",
      "Epoch: 7000 train loss=0.005106604 valid loss= 0.004079824\n",
      "train reg_fs: 0.0017559396801516414\n",
      "Epoch: 7500 train loss=0.007933866 valid loss= 0.003984131\n",
      "train reg_fs: 0.0017565037123858929\n",
      "Epoch: 8000 train loss=0.010058336 valid loss= 0.003722607\n",
      "train reg_fs: 0.0017577458638697863\n",
      "Epoch: 8500 train loss=0.004661058 valid loss= 0.004194268\n",
      "train reg_fs: 0.0017591575160622597\n",
      "Epoch: 9000 train loss=0.003492767 valid loss= 0.003938347\n",
      "train reg_fs: 0.0017616674304008484\n",
      "Epoch: 9500 train loss=0.003758116 valid loss= 0.003716301\n",
      "train reg_fs: 0.001764063024893403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:52:51,840]\u001b[0m Trial 75 finished with value: 0.002041416291975112 and parameters: {'lam': 0.00229396472780502, 'learning_rate': 0.02630360668576471, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003302322 valid loss= 0.003816646\n",
      "train reg_fs: 0.0017669457010924816\n",
      "Optimization Finished!\n",
      "test loss: 0.004099213518202305, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002041416291975112\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007200090 valid loss= 0.004396028\n",
      "train reg_fs: 0.0016991890734061599\n",
      "Epoch: 1000 train loss=0.003501750 valid loss= 0.004642097\n",
      "train reg_fs: 0.0016165381530299783\n",
      "Epoch: 1500 train loss=0.002803048 valid loss= 0.003292460\n",
      "train reg_fs: 0.0015776143409311771\n",
      "Epoch: 2000 train loss=0.002183007 valid loss= 0.003602308\n",
      "train reg_fs: 0.001554589020088315\n",
      "Epoch: 2500 train loss=0.003029045 valid loss= 0.003928111\n",
      "train reg_fs: 0.0015398948453366756\n",
      "Epoch: 3000 train loss=0.003708537 valid loss= 0.003183733\n",
      "train reg_fs: 0.0015263003297150135\n",
      "Epoch: 3500 train loss=0.002838710 valid loss= 0.003860756\n",
      "train reg_fs: 0.0015129171079024673\n",
      "Epoch: 4000 train loss=0.002325587 valid loss= 0.003438513\n",
      "train reg_fs: 0.001495914882980287\n",
      "Epoch: 4500 train loss=0.002405419 valid loss= 0.004184200\n",
      "train reg_fs: 0.001471189083531499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:53:23,717]\u001b[0m Trial 76 finished with value: 0.002512352617570592 and parameters: {'lam': 0.0021130897855120025, 'learning_rate': 0.1896041045095112, 'num_epoch': 5000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.005831484 valid loss= 0.003932748\n",
      "train reg_fs: 0.0014451703755185008\n",
      "Optimization Finished!\n",
      "test loss: 0.0036006688605993986, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002512352617570592\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011087188 valid loss= 0.010053718\n",
      "train reg_fs: 0.0026888526044785976\n",
      "Epoch: 1000 train loss=0.010634288 valid loss= 0.009560818\n",
      "train reg_fs: 0.0027149308007210493\n",
      "Epoch: 1500 train loss=0.010710381 valid loss= 0.012208344\n",
      "train reg_fs: 0.0027246277313679457\n",
      "Epoch: 2000 train loss=0.009470096 valid loss= 0.008604978\n",
      "train reg_fs: 0.0027118665166199207\n",
      "Epoch: 2500 train loss=0.005836372 valid loss= 0.008927044\n",
      "train reg_fs: 0.0026813268195837736\n",
      "Epoch: 3000 train loss=0.010747247 valid loss= 0.008679259\n",
      "train reg_fs: 0.002635675249621272\n",
      "Epoch: 3500 train loss=0.010272837 valid loss= 0.008073970\n",
      "train reg_fs: 0.002581243170425296\n",
      "Epoch: 4000 train loss=0.012904275 valid loss= 0.007011943\n",
      "train reg_fs: 0.0025275149382650852\n",
      "Epoch: 4500 train loss=0.007996138 valid loss= 0.005821846\n",
      "train reg_fs: 0.0024707966949790716\n",
      "Epoch: 5000 train loss=0.006904379 valid loss= 0.005310333\n",
      "train reg_fs: 0.0024186866357922554\n",
      "Epoch: 5500 train loss=0.005461195 valid loss= 0.005566901\n",
      "train reg_fs: 0.0023722569458186626\n",
      "Epoch: 6000 train loss=0.006274029 valid loss= 0.005323797\n",
      "train reg_fs: 0.0023354871664196253\n",
      "Epoch: 6500 train loss=0.003854211 valid loss= 0.005263430\n",
      "train reg_fs: 0.002302717650309205\n",
      "Epoch: 7000 train loss=0.003014421 valid loss= 0.005284449\n",
      "train reg_fs: 0.0022728312760591507\n",
      "Epoch: 7500 train loss=0.003303125 valid loss= 0.005094976\n",
      "train reg_fs: 0.002242704853415489\n",
      "Epoch: 8000 train loss=0.005609741 valid loss= 0.005013052\n",
      "train reg_fs: 0.002218464855104685\n",
      "Epoch: 8500 train loss=0.003936242 valid loss= 0.004992588\n",
      "train reg_fs: 0.0021943773608654737\n",
      "Epoch: 9000 train loss=0.002577262 valid loss= 0.005070804\n",
      "train reg_fs: 0.0021737522911280394\n",
      "Epoch: 9500 train loss=0.004831708 valid loss= 0.004984295\n",
      "train reg_fs: 0.002153809415176511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:54:26,993]\u001b[0m Trial 77 finished with value: 0.0025751002709097446 and parameters: {'lam': 0.0031335575879042985, 'learning_rate': 0.038108289815129925, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003966719 valid loss= 0.004729373\n",
      "train reg_fs: 0.002135010901838541\n",
      "Optimization Finished!\n",
      "test loss: 0.004453602246940136, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025751002709097446\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008793375 valid loss= 0.007950571\n",
      "train reg_fs: 0.0024263537488877773\n",
      "Epoch: 1000 train loss=0.010502858 valid loss= 0.007209177\n",
      "train reg_fs: 0.002384115708991885\n",
      "Epoch: 1500 train loss=0.004739083 valid loss= 0.005231277\n",
      "train reg_fs: 0.002287595998495817\n",
      "Epoch: 2000 train loss=0.003172125 valid loss= 0.004959106\n",
      "train reg_fs: 0.002214489970356226\n",
      "Epoch: 2500 train loss=0.004620621 valid loss= 0.005138990\n",
      "train reg_fs: 0.0021735201589763165\n",
      "Epoch: 3000 train loss=0.003860328 valid loss= 0.005421375\n",
      "train reg_fs: 0.002152798930183053\n",
      "Epoch: 3500 train loss=0.003276712 valid loss= 0.004884018\n",
      "train reg_fs: 0.0021312690805643797\n",
      "Epoch: 4000 train loss=0.004883114 valid loss= 0.005506725\n",
      "train reg_fs: 0.002114352537319064\n",
      "Epoch: 4500 train loss=0.004070411 valid loss= 0.005343629\n",
      "train reg_fs: 0.002093404531478882\n",
      "Epoch: 5000 train loss=0.004974374 valid loss= 0.005158425\n",
      "train reg_fs: 0.002067648572847247\n",
      "Epoch: 5500 train loss=0.010491042 valid loss= 0.005029155\n",
      "train reg_fs: 0.002039160579442978\n",
      "Epoch: 6000 train loss=0.003304699 valid loss= 0.005305314\n",
      "train reg_fs: 0.002008379204198718\n",
      "Epoch: 6500 train loss=0.003543001 valid loss= 0.005429615\n",
      "train reg_fs: 0.0019782986491918564\n",
      "Epoch: 7000 train loss=0.007156480 valid loss= 0.005278070\n",
      "train reg_fs: 0.0019514115992933512\n",
      "Epoch: 7500 train loss=0.003395173 valid loss= 0.004506002\n",
      "train reg_fs: 0.0019289908232167363\n",
      "Epoch: 8000 train loss=0.005426822 valid loss= 0.004638342\n",
      "train reg_fs: 0.001909418380819261\n",
      "Epoch: 8500 train loss=0.003468859 valid loss= 0.004370549\n",
      "train reg_fs: 0.0018911794759333134\n",
      "Epoch: 9000 train loss=0.002759527 valid loss= 0.004650136\n",
      "train reg_fs: 0.0018752638716250658\n",
      "Epoch: 9500 train loss=0.004148455 valid loss= 0.004296239\n",
      "train reg_fs: 0.001861524535343051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:55:30,677]\u001b[0m Trial 78 finished with value: 0.002701987830388983 and parameters: {'lam': 0.002837269749399081, 'learning_rate': 0.051745170950853035, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002727906 valid loss= 0.004543536\n",
      "train reg_fs: 0.0018491155933588743\n",
      "Optimization Finished!\n",
      "test loss: 0.004249639809131622, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002701987830388983\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013526351 valid loss= 0.010458855\n",
      "train reg_fs: 0.0037846947088837624\n",
      "Epoch: 1000 train loss=0.010887987 valid loss= 0.009727878\n",
      "train reg_fs: 0.0038176067173480988\n",
      "Epoch: 1500 train loss=0.011602828 valid loss= 0.009709027\n",
      "train reg_fs: 0.003785564796999097\n",
      "Epoch: 2000 train loss=0.010876097 valid loss= 0.010967702\n",
      "train reg_fs: 0.0037206998094916344\n",
      "Epoch: 2500 train loss=0.014713952 valid loss= 0.008727115\n",
      "train reg_fs: 0.0036401248071342707\n",
      "Epoch: 3000 train loss=0.011174385 valid loss= 0.007967675\n",
      "train reg_fs: 0.0035652085207402706\n",
      "Epoch: 3500 train loss=0.009840754 valid loss= 0.007293176\n",
      "train reg_fs: 0.00348504981957376\n",
      "Epoch: 4000 train loss=0.009128693 valid loss= 0.006847698\n",
      "train reg_fs: 0.003400754649192095\n",
      "Epoch: 4500 train loss=0.006538149 valid loss= 0.006594764\n",
      "train reg_fs: 0.0033295205794274807\n",
      "Epoch: 5000 train loss=0.008479501 valid loss= 0.007241756\n",
      "train reg_fs: 0.003262048354372382\n",
      "Epoch: 5500 train loss=0.004699889 valid loss= 0.006123853\n",
      "train reg_fs: 0.0031949093099683523\n",
      "Epoch: 6000 train loss=0.004901506 valid loss= 0.006951609\n",
      "train reg_fs: 0.003130920697003603\n",
      "Epoch: 6500 train loss=0.006341994 valid loss= 0.006708674\n",
      "train reg_fs: 0.0030761335510760546\n",
      "Epoch: 7000 train loss=0.004308672 valid loss= 0.006503250\n",
      "train reg_fs: 0.0030242204666137695\n",
      "Epoch: 7500 train loss=0.004412246 valid loss= 0.006088206\n",
      "train reg_fs: 0.002975364914163947\n",
      "Epoch: 8000 train loss=0.005095437 valid loss= 0.005822630\n",
      "train reg_fs: 0.0029363478533923626\n",
      "Epoch: 8500 train loss=0.003668469 valid loss= 0.005803531\n",
      "train reg_fs: 0.002903439337387681\n",
      "Epoch: 9000 train loss=0.004953708 valid loss= 0.005720313\n",
      "train reg_fs: 0.0028762000147253275\n",
      "Epoch: 9500 train loss=0.003140328 valid loss= 0.005744316\n",
      "train reg_fs: 0.002852317877113819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:56:33,613]\u001b[0m Trial 79 finished with value: 0.002552598857612378 and parameters: {'lam': 0.004411415933342075, 'learning_rate': 0.04619480283033924, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.006090881 valid loss= 0.005374566\n",
      "train reg_fs: 0.0028327920008450747\n",
      "Optimization Finished!\n",
      "test loss: 0.005148976109921932, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002552598857612378\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.015120811 valid loss= 0.009832120\n",
      "train reg_fs: 0.0032703846227377653\n",
      "Epoch: 1000 train loss=0.008205923 valid loss= 0.011738926\n",
      "train reg_fs: 0.003314537461847067\n",
      "Epoch: 1500 train loss=0.012612293 valid loss= 0.010617026\n",
      "train reg_fs: 0.0033107150811702013\n",
      "Epoch: 2000 train loss=0.014326262 valid loss= 0.008733000\n",
      "train reg_fs: 0.003259469987824559\n",
      "Epoch: 2500 train loss=0.008095680 valid loss= 0.009251740\n",
      "train reg_fs: 0.0031901139300316572\n",
      "Epoch: 3000 train loss=0.009508552 valid loss= 0.007329827\n",
      "train reg_fs: 0.0031068078242242336\n",
      "Epoch: 3500 train loss=0.006398366 valid loss= 0.006443507\n",
      "train reg_fs: 0.0030283883679658175\n",
      "Epoch: 4000 train loss=0.005124738 valid loss= 0.005876947\n",
      "train reg_fs: 0.002940618898719549\n",
      "Epoch: 4500 train loss=0.004784253 valid loss= 0.005284854\n",
      "train reg_fs: 0.002872399054467678\n",
      "Epoch: 5000 train loss=0.007324444 valid loss= 0.004910246\n",
      "train reg_fs: 0.0028255253564566374\n",
      "Epoch: 5500 train loss=0.007208527 valid loss= 0.004971616\n",
      "train reg_fs: 0.0027910922653973103\n",
      "Epoch: 6000 train loss=0.007564060 valid loss= 0.004832215\n",
      "train reg_fs: 0.0027638731990009546\n",
      "Epoch: 6500 train loss=0.003769776 valid loss= 0.004969459\n",
      "train reg_fs: 0.002737391507253051\n",
      "Epoch: 7000 train loss=0.005196630 valid loss= 0.004940290\n",
      "train reg_fs: 0.002717786468565464\n",
      "Epoch: 7500 train loss=0.004320484 valid loss= 0.004766674\n",
      "train reg_fs: 0.002692575566470623\n",
      "Epoch: 8000 train loss=0.006527278 valid loss= 0.004701815\n",
      "train reg_fs: 0.0026697199791669846\n",
      "Epoch: 8500 train loss=0.005838249 valid loss= 0.005196852\n",
      "train reg_fs: 0.002649057889357209\n",
      "Epoch: 9000 train loss=0.004257557 valid loss= 0.005041072\n",
      "train reg_fs: 0.0026248693466186523\n",
      "Epoch: 9500 train loss=0.004373991 valid loss= 0.004906653\n",
      "train reg_fs: 0.002597007667645812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:57:36,115]\u001b[0m Trial 80 finished with value: 0.0024372136865027775 and parameters: {'lam': 0.003763882869249169, 'learning_rate': 0.06130075843413277, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.003645481 valid loss= 0.004970714\n",
      "train reg_fs: 0.002570719923824072\n",
      "Optimization Finished!\n",
      "test loss: 0.004785086028277874, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0024372136865027775\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020828992 valid loss= 0.013978221\n",
      "train reg_fs: 0.008028137497603893\n",
      "Epoch: 1000 train loss=0.016966719 valid loss= 0.012077294\n",
      "train reg_fs: 0.0077596670016646385\n",
      "Epoch: 1500 train loss=0.009404130 valid loss= 0.010513175\n",
      "train reg_fs: 0.0073375278152525425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:57:50,168]\u001b[0m Trial 81 finished with value: 0.0021569612526641775 and parameters: {'lam': 0.009471170893233821, 'learning_rate': 0.07022214294380301, 'num_epoch': 2000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.008325269 valid loss= 0.009405823\n",
      "train reg_fs: 0.006871690507978201\n",
      "Optimization Finished!\n",
      "test loss: 0.01065442617982626, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021569612526641775\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.013592704 valid loss= 0.006732538\n",
      "train reg_fs: 0.002121314173564315\n",
      "Epoch: 1000 train loss=0.008069805 valid loss= 0.006714297\n",
      "train reg_fs: 0.002032905351370573\n",
      "Epoch: 1500 train loss=0.011599787 valid loss= 0.005186669\n",
      "train reg_fs: 0.0019386466592550278\n",
      "Epoch: 2000 train loss=0.005244624 valid loss= 0.004706669\n",
      "train reg_fs: 0.001899512019008398\n",
      "Epoch: 2500 train loss=0.003052969 valid loss= 0.005322441\n",
      "train reg_fs: 0.001871271408163011\n",
      "Epoch: 3000 train loss=0.006720659 valid loss= 0.004035188\n",
      "train reg_fs: 0.0018372269114479423\n",
      "Epoch: 3500 train loss=0.007882020 valid loss= 0.005573079\n",
      "train reg_fs: 0.001798457931727171\n",
      "Epoch: 4000 train loss=0.006338286 valid loss= 0.004260658\n",
      "train reg_fs: 0.001759805134497583\n",
      "Epoch: 4500 train loss=0.005311992 valid loss= 0.004612266\n",
      "train reg_fs: 0.0017271674005314708\n",
      "Epoch: 5000 train loss=0.002421196 valid loss= 0.004508685\n",
      "train reg_fs: 0.0016967060510069132\n",
      "Epoch: 5500 train loss=0.005215266 valid loss= 0.004254078\n",
      "train reg_fs: 0.0016711511416360736\n",
      "Epoch: 6000 train loss=0.003647287 valid loss= 0.003753471\n",
      "train reg_fs: 0.0016520816134288907\n",
      "Epoch: 6500 train loss=0.002606749 valid loss= 0.004157615\n",
      "train reg_fs: 0.001637758919969201\n",
      "Epoch: 7000 train loss=0.003687777 valid loss= 0.003752211\n",
      "train reg_fs: 0.0016243703430518508\n",
      "Epoch: 7500 train loss=0.005359703 valid loss= 0.004240523\n",
      "train reg_fs: 0.0016135082114487886\n",
      "Epoch: 8000 train loss=0.004176878 valid loss= 0.003993813\n",
      "train reg_fs: 0.0016036891611292958\n",
      "Epoch: 8500 train loss=0.004447096 valid loss= 0.003655447\n",
      "train reg_fs: 0.0015949485823512077\n",
      "Epoch: 9000 train loss=0.004084556 valid loss= 0.003879023\n",
      "train reg_fs: 0.0015861173160374165\n",
      "Epoch: 9500 train loss=0.003010318 valid loss= 0.003985105\n",
      "train reg_fs: 0.0015773895429447293\n",
      "Epoch: 10000 train loss=0.004291696 valid loss= 0.003897228\n",
      "train reg_fs: 0.0015698355855420232\n",
      "Epoch: 10500 train loss=0.002390977 valid loss= 0.004095840\n",
      "train reg_fs: 0.001562642864882946\n",
      "Epoch: 11000 train loss=0.003124814 valid loss= 0.004450812\n",
      "train reg_fs: 0.0015560212777927518\n",
      "Epoch: 11500 train loss=0.001974080 valid loss= 0.004043275\n",
      "train reg_fs: 0.0015496694250032306\n",
      "Epoch: 12000 train loss=0.003131112 valid loss= 0.003747980\n",
      "train reg_fs: 0.0015432722866535187\n",
      "Epoch: 12500 train loss=0.002375604 valid loss= 0.004156074\n",
      "train reg_fs: 0.0015379824908450246\n",
      "Epoch: 13000 train loss=0.002953449 valid loss= 0.003738123\n",
      "train reg_fs: 0.0015330694150179625\n",
      "Epoch: 13500 train loss=0.003170287 valid loss= 0.004617825\n",
      "train reg_fs: 0.0015289551811292768\n",
      "Epoch: 14000 train loss=0.002154384 valid loss= 0.003903492\n",
      "train reg_fs: 0.0015248332638293505\n",
      "Epoch: 14500 train loss=0.003182295 valid loss= 0.003838541\n",
      "train reg_fs: 0.0015207433607429266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 22:59:24,024]\u001b[0m Trial 82 finished with value: 0.0028022370672165877 and parameters: {'lam': 0.0024664180444120523, 'learning_rate': 0.09500932999563713, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002819706 valid loss= 0.004294406\n",
      "train reg_fs: 0.0015173550928011537\n",
      "Optimization Finished!\n",
      "test loss: 0.003930678591132164, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0028022370672165877\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016142193 valid loss= 0.010065675\n",
      "train reg_fs: 0.0035219418350607157\n",
      "Epoch: 1000 train loss=0.014969431 valid loss= 0.009850155\n",
      "train reg_fs: 0.0035576282534748316\n",
      "Epoch: 1500 train loss=0.011432751 valid loss= 0.009695456\n",
      "train reg_fs: 0.003543686354532838\n",
      "Epoch: 2000 train loss=0.007501005 valid loss= 0.009096354\n",
      "train reg_fs: 0.0034671849571168423\n",
      "Epoch: 2500 train loss=0.005425060 valid loss= 0.007087695\n",
      "train reg_fs: 0.0033524511381983757\n",
      "Epoch: 3000 train loss=0.004390042 valid loss= 0.005949177\n",
      "train reg_fs: 0.003263903548941016\n",
      "Epoch: 3500 train loss=0.006429289 valid loss= 0.006099374\n",
      "train reg_fs: 0.003209610003978014\n",
      "Epoch: 4000 train loss=0.005521028 valid loss= 0.006053677\n",
      "train reg_fs: 0.0031805732287466526\n",
      "Epoch: 4500 train loss=0.008722330 valid loss= 0.005983131\n",
      "train reg_fs: 0.0031665849965065718\n",
      "Epoch: 5000 train loss=0.005027884 valid loss= 0.006973161\n",
      "train reg_fs: 0.0031592221930623055\n",
      "Epoch: 5500 train loss=0.011344456 valid loss= 0.005764925\n",
      "train reg_fs: 0.003155006328597665\n",
      "Epoch: 6000 train loss=0.005052268 valid loss= 0.006460994\n",
      "train reg_fs: 0.003149875905364752\n",
      "Epoch: 6500 train loss=0.005772790 valid loss= 0.005907056\n",
      "train reg_fs: 0.0031432334799319506\n",
      "Epoch: 7000 train loss=0.011693793 valid loss= 0.005690972\n",
      "train reg_fs: 0.0031283495482057333\n",
      "Epoch: 7500 train loss=0.005954149 valid loss= 0.005466500\n",
      "train reg_fs: 0.0031101456843316555\n",
      "Epoch: 8000 train loss=0.005511853 valid loss= 0.005528452\n",
      "train reg_fs: 0.0030883057042956352\n",
      "Epoch: 8500 train loss=0.005663689 valid loss= 0.005876187\n",
      "train reg_fs: 0.0030669074039906263\n",
      "Epoch: 9000 train loss=0.008670622 valid loss= 0.005343529\n",
      "train reg_fs: 0.003047286532819271\n",
      "Epoch: 9500 train loss=0.005943422 valid loss= 0.005268269\n",
      "train reg_fs: 0.0030311550945043564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:00:27,221]\u001b[0m Trial 83 finished with value: 0.0025917830751351085 and parameters: {'lam': 0.00407732094007567, 'learning_rate': 0.055850009185004226, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005080821 valid loss= 0.005557203\n",
      "train reg_fs: 0.003015801776200533\n",
      "Optimization Finished!\n",
      "test loss: 0.005360289942473173, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025917830751351085\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.020296570 valid loss= 0.005981427\n",
      "train reg_fs: 0.0017025769921019673\n",
      "Epoch: 1000 train loss=0.012972599 valid loss= 0.005203429\n",
      "train reg_fs: 0.0016306021716445684\n",
      "Epoch: 1500 train loss=0.008137573 valid loss= 0.006471876\n",
      "train reg_fs: 0.0015735285123810172\n",
      "Epoch: 2000 train loss=0.005497846 valid loss= 0.003160379\n",
      "train reg_fs: 0.001554502989165485\n",
      "Epoch: 2500 train loss=0.010196843 valid loss= 0.004786651\n",
      "train reg_fs: 0.0015466969925910234\n",
      "Epoch: 3000 train loss=0.004169807 valid loss= 0.003492499\n",
      "train reg_fs: 0.0015382786514237523\n",
      "Epoch: 3500 train loss=0.003312367 valid loss= 0.003308660\n",
      "train reg_fs: 0.0015269402647390962\n",
      "Epoch: 4000 train loss=0.004796102 valid loss= 0.003759496\n",
      "train reg_fs: 0.0015129195526242256\n",
      "Epoch: 4500 train loss=0.003905224 valid loss= 0.003212759\n",
      "train reg_fs: 0.001500056474469602\n",
      "Epoch: 5000 train loss=0.003825091 valid loss= 0.004008245\n",
      "train reg_fs: 0.0014896097127348185\n",
      "Epoch: 5500 train loss=0.003489500 valid loss= 0.004358782\n",
      "train reg_fs: 0.0014805527171120048\n",
      "Epoch: 6000 train loss=0.003185865 valid loss= 0.004164556\n",
      "train reg_fs: 0.0014719220343977213\n",
      "Epoch: 6500 train loss=0.002024786 valid loss= 0.003752789\n",
      "train reg_fs: 0.0014652415411546826\n",
      "Epoch: 7000 train loss=0.011287609 valid loss= 0.003858539\n",
      "train reg_fs: 0.0014578865375369787\n",
      "Epoch: 7500 train loss=0.006981663 valid loss= 0.002897600\n",
      "train reg_fs: 0.0014508746098726988\n",
      "Epoch: 8000 train loss=0.003264216 valid loss= 0.002628363\n",
      "train reg_fs: 0.0014430629089474678\n",
      "Epoch: 8500 train loss=0.005056477 valid loss= 0.002755853\n",
      "train reg_fs: 0.001434344332665205\n",
      "Epoch: 9000 train loss=0.001927506 valid loss= 0.002734714\n",
      "train reg_fs: 0.0014273443957790732\n",
      "Epoch: 9500 train loss=0.001956325 valid loss= 0.002133138\n",
      "train reg_fs: 0.0014187546912580729\n",
      "Epoch: 10000 train loss=0.002225009 valid loss= 0.002531316\n",
      "train reg_fs: 0.0014118108665570617\n",
      "Epoch: 10500 train loss=0.002321293 valid loss= 0.002983256\n",
      "train reg_fs: 0.0014033488696441054\n",
      "Epoch: 11000 train loss=0.004069838 valid loss= 0.002366991\n",
      "train reg_fs: 0.001395987463183701\n",
      "Epoch: 11500 train loss=0.003591466 valid loss= 0.001824038\n",
      "train reg_fs: 0.0013882122002542019\n",
      "Epoch: 12000 train loss=0.002109819 valid loss= 0.002554948\n",
      "train reg_fs: 0.0013820651220157743\n",
      "Epoch: 12500 train loss=0.002696494 valid loss= 0.001986298\n",
      "train reg_fs: 0.0013762658927589655\n",
      "Epoch: 13000 train loss=0.003690586 valid loss= 0.002037844\n",
      "train reg_fs: 0.0013710856437683105\n",
      "Epoch: 13500 train loss=0.003830350 valid loss= 0.001651483\n",
      "train reg_fs: 0.0013659774558618665\n",
      "Epoch: 14000 train loss=0.003432118 valid loss= 0.002483854\n",
      "train reg_fs: 0.001362288137897849\n",
      "Epoch: 14500 train loss=0.003911304 valid loss= 0.002545981\n",
      "train reg_fs: 0.0013583949767053127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:02:01,812]\u001b[0m Trial 84 finished with value: 0.001330104471561185 and parameters: {'lam': 0.001981769447557526, 'learning_rate': 0.07622709862959465, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002493540 valid loss= 0.002688167\n",
      "train reg_fs: 0.0013549987925216556\n",
      "Optimization Finished!\n",
      "test loss: 0.0024794188793748617, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001330104471561185\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010638623 valid loss= 0.008246979\n",
      "train reg_fs: 0.0017951119225472212\n",
      "Epoch: 1000 train loss=0.005720947 valid loss= 0.006394733\n",
      "train reg_fs: 0.001681059249676764\n",
      "Epoch: 1500 train loss=0.005215012 valid loss= 0.003659661\n",
      "train reg_fs: 0.001567282248288393\n",
      "Epoch: 2000 train loss=0.007965079 valid loss= 0.003684825\n",
      "train reg_fs: 0.0015192306600511074\n",
      "Epoch: 2500 train loss=0.003638463 valid loss= 0.002862522\n",
      "train reg_fs: 0.0014984464505687356\n",
      "Epoch: 3000 train loss=0.002882644 valid loss= 0.004449869\n",
      "train reg_fs: 0.0014824004611000419\n",
      "Epoch: 3500 train loss=0.004496315 valid loss= 0.003437762\n",
      "train reg_fs: 0.0014680130407214165\n",
      "Epoch: 4000 train loss=0.002733369 valid loss= 0.004287151\n",
      "train reg_fs: 0.0014595838729292154\n",
      "Epoch: 4500 train loss=0.004760237 valid loss= 0.002964229\n",
      "train reg_fs: 0.0014494037022814155\n",
      "Epoch: 5000 train loss=0.003446140 valid loss= 0.003189274\n",
      "train reg_fs: 0.0014373717131093144\n",
      "Epoch: 5500 train loss=0.003003543 valid loss= 0.004279911\n",
      "train reg_fs: 0.0014292364940047264\n",
      "Epoch: 6000 train loss=0.003631067 valid loss= 0.003180437\n",
      "train reg_fs: 0.0014171457150951028\n",
      "Epoch: 6500 train loss=0.005879407 valid loss= 0.003970416\n",
      "train reg_fs: 0.0014086465816944838\n",
      "Epoch: 7000 train loss=0.002299214 valid loss= 0.002549769\n",
      "train reg_fs: 0.0013943203957751393\n",
      "Epoch: 7500 train loss=0.001810877 valid loss= 0.002828173\n",
      "train reg_fs: 0.0013810558011755347\n",
      "Epoch: 8000 train loss=0.003017658 valid loss= 0.002630208\n",
      "train reg_fs: 0.0013684527948498726\n",
      "Epoch: 8500 train loss=0.002198233 valid loss= 0.003631233\n",
      "train reg_fs: 0.0013607251457870007\n",
      "Epoch: 9000 train loss=0.003559445 valid loss= 0.003181512\n",
      "train reg_fs: 0.001347295823507011\n",
      "Epoch: 9500 train loss=0.002501980 valid loss= 0.003565235\n",
      "train reg_fs: 0.0013383887708187103\n",
      "Epoch: 10000 train loss=0.003456558 valid loss= 0.002749453\n",
      "train reg_fs: 0.0013280825223773718\n",
      "Epoch: 10500 train loss=0.001745813 valid loss= 0.003602045\n",
      "train reg_fs: 0.0013235518708825111\n",
      "Epoch: 11000 train loss=0.001989048 valid loss= 0.003070971\n",
      "train reg_fs: 0.0013163978001102805\n",
      "Epoch: 11500 train loss=0.003715678 valid loss= 0.003427794\n",
      "train reg_fs: 0.0013159249210730195\n",
      "Epoch: 12000 train loss=0.007240745 valid loss= 0.002553675\n",
      "train reg_fs: 0.0013136988272890449\n",
      "Epoch: 12500 train loss=0.002415145 valid loss= 0.002363871\n",
      "train reg_fs: 0.0013033513678237796\n",
      "Epoch: 13000 train loss=0.006172506 valid loss= 0.003633432\n",
      "train reg_fs: 0.0013001873157918453\n",
      "Epoch: 13500 train loss=0.002075026 valid loss= 0.003134666\n",
      "train reg_fs: 0.0012909922515973449\n",
      "Epoch: 14000 train loss=0.001959175 valid loss= 0.003018754\n",
      "train reg_fs: 0.0012841330608353019\n",
      "Epoch: 14500 train loss=0.001867678 valid loss= 0.002659169\n",
      "train reg_fs: 0.0012821652926504612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:03:35,484]\u001b[0m Trial 85 finished with value: 0.001388060806335942 and parameters: {'lam': 0.0020215341533321714, 'learning_rate': 0.1810556163411079, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002541994 valid loss= 0.002689783\n",
      "train reg_fs: 0.0012809537583962083\n",
      "Optimization Finished!\n",
      "test loss: 0.0028365126345306635, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.001388060806335942\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.005383609 valid loss= 0.007659080\n",
      "train reg_fs: 0.0017337776953354478\n",
      "Epoch: 1000 train loss=0.004122109 valid loss= 0.009337391\n",
      "train reg_fs: 0.0016540295910090208\n",
      "Epoch: 1500 train loss=0.006162916 valid loss= 0.005375972\n",
      "train reg_fs: 0.00155261077452451\n",
      "Epoch: 2000 train loss=0.003408381 valid loss= 0.005565168\n",
      "train reg_fs: 0.0014406213304027915\n",
      "Epoch: 2500 train loss=0.004349696 valid loss= 0.004911309\n",
      "train reg_fs: 0.0013797130668535829\n",
      "Epoch: 3000 train loss=0.010821431 valid loss= 0.003878738\n",
      "train reg_fs: 0.0013350144727155566\n",
      "Epoch: 3500 train loss=0.002763304 valid loss= 0.004734762\n",
      "train reg_fs: 0.0013039439218118787\n",
      "Epoch: 4000 train loss=0.005600684 valid loss= 0.003963247\n",
      "train reg_fs: 0.0012814449146389961\n",
      "Epoch: 4500 train loss=0.006119811 valid loss= 0.003702884\n",
      "train reg_fs: 0.001263118232600391\n",
      "Epoch: 5000 train loss=0.011952567 valid loss= 0.003726076\n",
      "train reg_fs: 0.0012504650512710214\n",
      "Epoch: 5500 train loss=0.001922409 valid loss= 0.003618792\n",
      "train reg_fs: 0.0012405012967064977\n",
      "Epoch: 6000 train loss=0.002760728 valid loss= 0.004029836\n",
      "train reg_fs: 0.0012324737617745996\n",
      "Epoch: 6500 train loss=0.006004726 valid loss= 0.003389040\n",
      "train reg_fs: 0.001225951942615211\n",
      "Epoch: 7000 train loss=0.002887074 valid loss= 0.003908356\n",
      "train reg_fs: 0.0012209926499053836\n",
      "Epoch: 7500 train loss=0.001759623 valid loss= 0.003482498\n",
      "train reg_fs: 0.0012165046064183116\n",
      "Epoch: 8000 train loss=0.004854345 valid loss= 0.003132487\n",
      "train reg_fs: 0.0012126584770157933\n",
      "Epoch: 8500 train loss=0.001595234 valid loss= 0.003882146\n",
      "train reg_fs: 0.0012095639249309897\n",
      "Epoch: 9000 train loss=0.001654110 valid loss= 0.003381521\n",
      "train reg_fs: 0.0012068096548318863\n",
      "Epoch: 9500 train loss=0.001892376 valid loss= 0.004032043\n",
      "train reg_fs: 0.0012043167371302843\n",
      "Epoch: 10000 train loss=0.003464247 valid loss= 0.003713875\n",
      "train reg_fs: 0.0012023847084492445\n",
      "Epoch: 10500 train loss=0.001849832 valid loss= 0.003317269\n",
      "train reg_fs: 0.001200597151182592\n",
      "Epoch: 11000 train loss=0.002002306 valid loss= 0.003437955\n",
      "train reg_fs: 0.0011989378836005926\n",
      "Epoch: 11500 train loss=0.001874426 valid loss= 0.003621653\n",
      "train reg_fs: 0.0011973545188084245\n",
      "Epoch: 12000 train loss=0.004707946 valid loss= 0.003293210\n",
      "train reg_fs: 0.0011960586998611689\n",
      "Epoch: 12500 train loss=0.007843878 valid loss= 0.003256554\n",
      "train reg_fs: 0.0011949161998927593\n",
      "Epoch: 13000 train loss=0.003552033 valid loss= 0.004016756\n",
      "train reg_fs: 0.0011938692769035697\n",
      "Epoch: 13500 train loss=0.003193947 valid loss= 0.003489559\n",
      "train reg_fs: 0.0011929054744541645\n",
      "Epoch: 14000 train loss=0.002839424 valid loss= 0.004119497\n",
      "train reg_fs: 0.0011919880053028464\n",
      "Epoch: 14500 train loss=0.001924547 valid loss= 0.003559849\n",
      "train reg_fs: 0.001191180432215333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:05:10,953]\u001b[0m Trial 86 finished with value: 0.002844705700462814 and parameters: {'lam': 0.0019719592047000053, 'learning_rate': 0.1473590202569726, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001489663 valid loss= 0.004004923\n",
      "train reg_fs: 0.0011904092971235514\n",
      "Optimization Finished!\n",
      "test loss: 0.0036060730926692486, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002844705700462814\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010667948 valid loss= 0.008646694\n",
      "train reg_fs: 0.0017922742990776896\n",
      "Epoch: 1000 train loss=0.004616036 valid loss= 0.007883112\n",
      "train reg_fs: 0.001752366777509451\n",
      "Epoch: 1500 train loss=0.002946546 valid loss= 0.003394848\n",
      "train reg_fs: 0.0016192550538107753\n",
      "Epoch: 2000 train loss=0.006706554 valid loss= 0.003514458\n",
      "train reg_fs: 0.0015523071633651853\n",
      "Epoch: 2500 train loss=0.003002161 valid loss= 0.003528049\n",
      "train reg_fs: 0.0015219873748719692\n",
      "Epoch: 3000 train loss=0.005244330 valid loss= 0.003834198\n",
      "train reg_fs: 0.0015065736370161176\n",
      "Epoch: 3500 train loss=0.002321269 valid loss= 0.003469472\n",
      "train reg_fs: 0.0014953638892620802\n",
      "Epoch: 4000 train loss=0.003414852 valid loss= 0.003325138\n",
      "train reg_fs: 0.0014868512516841292\n",
      "Epoch: 4500 train loss=0.002408258 valid loss= 0.004363236\n",
      "train reg_fs: 0.0014788623666390777\n",
      "Epoch: 5000 train loss=0.004173863 valid loss= 0.003589996\n",
      "train reg_fs: 0.0014724768698215485\n",
      "Epoch: 5500 train loss=0.003167651 valid loss= 0.003147036\n",
      "train reg_fs: 0.0014657354913651943\n",
      "Epoch: 6000 train loss=0.003397281 valid loss= 0.004049845\n",
      "train reg_fs: 0.0014589112251996994\n",
      "Epoch: 6500 train loss=0.003665854 valid loss= 0.003029562\n",
      "train reg_fs: 0.001452552154660225\n",
      "Epoch: 7000 train loss=0.004645910 valid loss= 0.004658501\n",
      "train reg_fs: 0.0014446255518123507\n",
      "Epoch: 7500 train loss=0.005055188 valid loss= 0.003241480\n",
      "train reg_fs: 0.001435384969227016\n",
      "Epoch: 8000 train loss=0.003800842 valid loss= 0.003384527\n",
      "train reg_fs: 0.0014257575385272503\n",
      "Epoch: 8500 train loss=0.005209134 valid loss= 0.003682243\n",
      "train reg_fs: 0.0014160651480779052\n",
      "Epoch: 9000 train loss=0.002009004 valid loss= 0.002932165\n",
      "train reg_fs: 0.0014073644997552037\n",
      "Epoch: 9500 train loss=0.005003639 valid loss= 0.003229789\n",
      "train reg_fs: 0.0014003433752804995\n",
      "Epoch: 10000 train loss=0.001789305 valid loss= 0.003349447\n",
      "train reg_fs: 0.0013934132875874639\n",
      "Epoch: 10500 train loss=0.002467541 valid loss= 0.003644759\n",
      "train reg_fs: 0.0013881061458960176\n",
      "Epoch: 11000 train loss=0.002145419 valid loss= 0.003415150\n",
      "train reg_fs: 0.001380722038447857\n",
      "Epoch: 11500 train loss=0.001891826 valid loss= 0.003315802\n",
      "train reg_fs: 0.001373632694594562\n",
      "Epoch: 12000 train loss=0.001598817 valid loss= 0.003508177\n",
      "train reg_fs: 0.0013693030923604965\n",
      "Epoch: 12500 train loss=0.002044637 valid loss= 0.003118271\n",
      "train reg_fs: 0.0013647762825712562\n",
      "Epoch: 13000 train loss=0.006255085 valid loss= 0.003144574\n",
      "train reg_fs: 0.001359610934741795\n",
      "Epoch: 13500 train loss=0.001479460 valid loss= 0.003046420\n",
      "train reg_fs: 0.0013542633969336748\n",
      "Epoch: 14000 train loss=0.002055085 valid loss= 0.003189444\n",
      "train reg_fs: 0.0013508902629837394\n",
      "Epoch: 14500 train loss=0.002492716 valid loss= 0.002937189\n",
      "train reg_fs: 0.001349211554042995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:06:49,242]\u001b[0m Trial 87 finished with value: 0.0018235573523838783 and parameters: {'lam': 0.002004898372981465, 'learning_rate': 0.16671218853215442, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002082265 valid loss= 0.003102162\n",
      "train reg_fs: 0.0013448485406115651\n",
      "Optimization Finished!\n",
      "test loss: 0.0029443386010825634, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0018235573523838783\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014713963 valid loss= 0.007451165\n",
      "train reg_fs: 0.0016019184840843081\n",
      "Epoch: 1000 train loss=0.006640989 valid loss= 0.007505485\n",
      "train reg_fs: 0.001531529240310192\n",
      "Epoch: 1500 train loss=0.005345261 valid loss= 0.004436340\n",
      "train reg_fs: 0.0014499258249998093\n",
      "Epoch: 2000 train loss=0.002601562 valid loss= 0.003579739\n",
      "train reg_fs: 0.0014157549012452364\n",
      "Epoch: 2500 train loss=0.003242519 valid loss= 0.005383048\n",
      "train reg_fs: 0.0013846938963979483\n",
      "Epoch: 3000 train loss=0.003926409 valid loss= 0.003720894\n",
      "train reg_fs: 0.0013604724081233144\n",
      "Epoch: 3500 train loss=0.013603989 valid loss= 0.003744096\n",
      "train reg_fs: 0.0013419821625575423\n",
      "Epoch: 4000 train loss=0.005153583 valid loss= 0.005802914\n",
      "train reg_fs: 0.0013290797360241413\n",
      "Epoch: 4500 train loss=0.002163841 valid loss= 0.003971925\n",
      "train reg_fs: 0.0013187261065468192\n",
      "Epoch: 5000 train loss=0.003605419 valid loss= 0.002878654\n",
      "train reg_fs: 0.0013119159266352654\n",
      "Epoch: 5500 train loss=0.002683225 valid loss= 0.003824671\n",
      "train reg_fs: 0.0013068282278254628\n",
      "Epoch: 6000 train loss=0.002089560 valid loss= 0.003262952\n",
      "train reg_fs: 0.001301865908317268\n",
      "Epoch: 6500 train loss=0.005511024 valid loss= 0.004373377\n",
      "train reg_fs: 0.0012982066255062819\n",
      "Epoch: 7000 train loss=0.003127064 valid loss= 0.003620893\n",
      "train reg_fs: 0.0012929721269756556\n",
      "Epoch: 7500 train loss=0.001997717 valid loss= 0.003567747\n",
      "train reg_fs: 0.0012904595350846648\n",
      "Epoch: 8000 train loss=0.001901437 valid loss= 0.002917958\n",
      "train reg_fs: 0.0012881337897852063\n",
      "Epoch: 8500 train loss=0.001482556 valid loss= 0.003689115\n",
      "train reg_fs: 0.0012858874397352338\n",
      "Epoch: 9000 train loss=0.011372259 valid loss= 0.003649641\n",
      "train reg_fs: 0.0012839882401749492\n",
      "Epoch: 9500 train loss=0.002028934 valid loss= 0.002947443\n",
      "train reg_fs: 0.0012823721626773477\n",
      "Epoch: 10000 train loss=0.002033091 valid loss= 0.003304701\n",
      "train reg_fs: 0.0012804556172341108\n",
      "Epoch: 10500 train loss=0.002284122 valid loss= 0.003040243\n",
      "train reg_fs: 0.0012785581639036536\n",
      "Epoch: 11000 train loss=0.002686430 valid loss= 0.003306123\n",
      "train reg_fs: 0.0012767253210768104\n",
      "Epoch: 11500 train loss=0.001896704 valid loss= 0.003470592\n",
      "train reg_fs: 0.0012746048159897327\n",
      "Epoch: 12000 train loss=0.003610803 valid loss= 0.003728154\n",
      "train reg_fs: 0.001271380577236414\n",
      "Epoch: 12500 train loss=0.002247693 valid loss= 0.003940286\n",
      "train reg_fs: 0.0012676200130954385\n",
      "Epoch: 13000 train loss=0.011057672 valid loss= 0.003408660\n",
      "train reg_fs: 0.0012645086972042918\n",
      "Epoch: 13500 train loss=0.004040398 valid loss= 0.003132538\n",
      "train reg_fs: 0.0012629051925614476\n",
      "Epoch: 14000 train loss=0.003205673 valid loss= 0.003402092\n",
      "train reg_fs: 0.0012610184494405985\n",
      "Epoch: 14500 train loss=0.003998072 valid loss= 0.003524037\n",
      "train reg_fs: 0.0012584595242515206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:08:23,327]\u001b[0m Trial 88 finished with value: 0.0021917179499300705 and parameters: {'lam': 0.0018153640166374085, 'learning_rate': 0.1794690870338991, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002357918 valid loss= 0.003395597\n",
      "train reg_fs: 0.001257452298887074\n",
      "Optimization Finished!\n",
      "test loss: 0.0032253030221909285, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0021917179499300705\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.010889378 valid loss= 0.008262127\n",
      "train reg_fs: 0.0013796400744467974\n",
      "Epoch: 1000 train loss=0.011098183 valid loss= 0.007177549\n",
      "train reg_fs: 0.0013526242692023516\n",
      "Epoch: 1500 train loss=0.007919559 valid loss= 0.005348955\n",
      "train reg_fs: 0.0013243420980870724\n",
      "Epoch: 2000 train loss=0.005196430 valid loss= 0.004159081\n",
      "train reg_fs: 0.0012938856380060315\n",
      "Epoch: 2500 train loss=0.002102385 valid loss= 0.003620755\n",
      "train reg_fs: 0.0012634589802473783\n",
      "Epoch: 3000 train loss=0.010127565 valid loss= 0.004283512\n",
      "train reg_fs: 0.001243874430656433\n",
      "Epoch: 3500 train loss=0.003016142 valid loss= 0.004008097\n",
      "train reg_fs: 0.0012269202852621675\n",
      "Epoch: 4000 train loss=0.009336506 valid loss= 0.004130897\n",
      "train reg_fs: 0.0012079880107194185\n",
      "Epoch: 4500 train loss=0.002006676 valid loss= 0.003863022\n",
      "train reg_fs: 0.0011911753099411726\n",
      "Epoch: 5000 train loss=0.003626811 valid loss= 0.003758747\n",
      "train reg_fs: 0.0011744103394448757\n",
      "Epoch: 5500 train loss=0.002969330 valid loss= 0.003575579\n",
      "train reg_fs: 0.0011584130115807056\n",
      "Epoch: 6000 train loss=0.002919773 valid loss= 0.003318956\n",
      "train reg_fs: 0.0011411710875108838\n",
      "Epoch: 6500 train loss=0.004699843 valid loss= 0.003881530\n",
      "train reg_fs: 0.0011261451290920377\n",
      "Epoch: 7000 train loss=0.005152037 valid loss= 0.003458404\n",
      "train reg_fs: 0.0011116203386336565\n",
      "Epoch: 7500 train loss=0.002286494 valid loss= 0.003549015\n",
      "train reg_fs: 0.0010967510752379894\n",
      "Epoch: 8000 train loss=0.004236779 valid loss= 0.003595368\n",
      "train reg_fs: 0.001084418036043644\n",
      "Epoch: 8500 train loss=0.004447671 valid loss= 0.003400791\n",
      "train reg_fs: 0.00107226159889251\n",
      "Epoch: 9000 train loss=0.017752463 valid loss= 0.003689573\n",
      "train reg_fs: 0.0010623871348798275\n",
      "Epoch: 9500 train loss=0.002301583 valid loss= 0.003906089\n",
      "train reg_fs: 0.0010534494649618864\n",
      "Epoch: 10000 train loss=0.001914829 valid loss= 0.003091281\n",
      "train reg_fs: 0.0010459166951477528\n",
      "Epoch: 10500 train loss=0.004057624 valid loss= 0.004832995\n",
      "train reg_fs: 0.00103953352663666\n",
      "Epoch: 11000 train loss=0.004284880 valid loss= 0.003174325\n",
      "train reg_fs: 0.0010335856350138783\n",
      "Epoch: 11500 train loss=0.002447785 valid loss= 0.003418006\n",
      "train reg_fs: 0.0010280889691784978\n",
      "Epoch: 12000 train loss=0.001538572 valid loss= 0.003337746\n",
      "train reg_fs: 0.0010230710031464696\n",
      "Epoch: 12500 train loss=0.001812556 valid loss= 0.003400715\n",
      "train reg_fs: 0.0010185444261878729\n",
      "Epoch: 13000 train loss=0.005311328 valid loss= 0.003221339\n",
      "train reg_fs: 0.0010147583670914173\n",
      "Epoch: 13500 train loss=0.003432204 valid loss= 0.003492209\n",
      "train reg_fs: 0.0010115288896486163\n",
      "Epoch: 14000 train loss=0.001550945 valid loss= 0.003645066\n",
      "train reg_fs: 0.0010079945204779506\n",
      "Epoch: 14500 train loss=0.002164446 valid loss= 0.003670529\n",
      "train reg_fs: 0.0010052172001451254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:09:56,761]\u001b[0m Trial 89 finished with value: 0.002361716243406185 and parameters: {'lam': 0.0016088283668165006, 'learning_rate': 0.07805128260521309, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002403411 valid loss= 0.003350617\n",
      "train reg_fs: 0.0010025696828961372\n",
      "Optimization Finished!\n",
      "test loss: 0.003119805594906211, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002361716243406185\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014702179 valid loss= 0.007864516\n",
      "train reg_fs: 0.001591921434737742\n",
      "Epoch: 1000 train loss=0.007892973 valid loss= 0.005173285\n",
      "train reg_fs: 0.0015328861773014069\n",
      "Epoch: 1500 train loss=0.002524422 valid loss= 0.004769213\n",
      "train reg_fs: 0.0014800335047766566\n",
      "Epoch: 2000 train loss=0.002814697 valid loss= 0.004536582\n",
      "train reg_fs: 0.0014352175639942288\n",
      "Epoch: 2500 train loss=0.003568549 valid loss= 0.004984946\n",
      "train reg_fs: 0.0014064082643017173\n",
      "Epoch: 3000 train loss=0.003808723 valid loss= 0.004132499\n",
      "train reg_fs: 0.0013756067492067814\n",
      "Epoch: 3500 train loss=0.002444487 valid loss= 0.004149307\n",
      "train reg_fs: 0.0013454864965751767\n",
      "Epoch: 4000 train loss=0.005992167 valid loss= 0.003677241\n",
      "train reg_fs: 0.0013171511236578226\n",
      "Epoch: 4500 train loss=0.005783645 valid loss= 0.004187403\n",
      "train reg_fs: 0.001289509586058557\n",
      "Epoch: 5000 train loss=0.002598223 valid loss= 0.003955189\n",
      "train reg_fs: 0.0012622365029528737\n",
      "Epoch: 5500 train loss=0.002517752 valid loss= 0.003473166\n",
      "train reg_fs: 0.001234099268913269\n",
      "Epoch: 6000 train loss=0.002961962 valid loss= 0.003584897\n",
      "train reg_fs: 0.0012120801256969571\n",
      "Epoch: 6500 train loss=0.002099636 valid loss= 0.003760498\n",
      "train reg_fs: 0.0011972992215305567\n",
      "Epoch: 7000 train loss=0.008527120 valid loss= 0.003844806\n",
      "train reg_fs: 0.0011858615325763822\n",
      "Epoch: 7500 train loss=0.003068010 valid loss= 0.003569694\n",
      "train reg_fs: 0.0011757981264963746\n",
      "Epoch: 8000 train loss=0.004442058 valid loss= 0.003242840\n",
      "train reg_fs: 0.0011676246067509055\n",
      "Epoch: 8500 train loss=0.001461220 valid loss= 0.003676286\n",
      "train reg_fs: 0.001160929910838604\n",
      "Epoch: 9000 train loss=0.003480035 valid loss= 0.002954016\n",
      "train reg_fs: 0.0011554560624063015\n",
      "Epoch: 9500 train loss=0.002550971 valid loss= 0.003301854\n",
      "train reg_fs: 0.001150917960330844\n",
      "Epoch: 10000 train loss=0.003367904 valid loss= 0.003744510\n",
      "train reg_fs: 0.0011470156023278832\n",
      "Epoch: 10500 train loss=0.003075040 valid loss= 0.003339888\n",
      "train reg_fs: 0.0011437333887442946\n",
      "Epoch: 11000 train loss=0.002722400 valid loss= 0.003388083\n",
      "train reg_fs: 0.0011409305734559894\n",
      "Epoch: 11500 train loss=0.002764578 valid loss= 0.004276868\n",
      "train reg_fs: 0.0011384682729840279\n",
      "Epoch: 12000 train loss=0.012157059 valid loss= 0.003182615\n",
      "train reg_fs: 0.0011361408978700638\n",
      "Epoch: 12500 train loss=0.001408002 valid loss= 0.003915225\n",
      "train reg_fs: 0.0011340894270688295\n",
      "Epoch: 13000 train loss=0.003250580 valid loss= 0.003207343\n",
      "train reg_fs: 0.0011323649669066072\n",
      "Epoch: 13500 train loss=0.003909293 valid loss= 0.003615135\n",
      "train reg_fs: 0.0011307194363325834\n",
      "Epoch: 14000 train loss=0.002395824 valid loss= 0.003642708\n",
      "train reg_fs: 0.0011293644784018397\n",
      "Epoch: 14500 train loss=0.002209456 valid loss= 0.003534882\n",
      "train reg_fs: 0.0011280952021479607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:11:30,624]\u001b[0m Trial 90 finished with value: 0.002567932523190953 and parameters: {'lam': 0.0018546404333791866, 'learning_rate': 0.1278668487304108, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.001378099 valid loss= 0.003669623\n",
      "train reg_fs: 0.0011269208043813705\n",
      "Optimization Finished!\n",
      "test loss: 0.003400615882128477, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002567932523190953\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.016918646 valid loss= 0.008120442\n",
      "train reg_fs: 0.0014351399149745703\n",
      "Epoch: 1000 train loss=0.006222978 valid loss= 0.006433621\n",
      "train reg_fs: 0.0013521852670237422\n",
      "Epoch: 1500 train loss=0.005958803 valid loss= 0.006257329\n",
      "train reg_fs: 0.0012994164135307074\n",
      "Epoch: 2000 train loss=0.004006357 valid loss= 0.003798666\n",
      "train reg_fs: 0.0012272435706108809\n",
      "Epoch: 2500 train loss=0.004111351 valid loss= 0.005483063\n",
      "train reg_fs: 0.0011866316199302673\n",
      "Epoch: 3000 train loss=0.004010825 valid loss= 0.005608739\n",
      "train reg_fs: 0.0011614836985245347\n",
      "Epoch: 3500 train loss=0.003077547 valid loss= 0.006479582\n",
      "train reg_fs: 0.0011444102274253964\n",
      "Epoch: 4000 train loss=0.001809612 valid loss= 0.003968563\n",
      "train reg_fs: 0.0011380036594346166\n",
      "Epoch: 4500 train loss=0.004081113 valid loss= 0.003924621\n",
      "train reg_fs: 0.0011343531077727675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:12:03,348]\u001b[0m Trial 91 finished with value: 0.002880830539854397 and parameters: {'lam': 0.0016388286441939618, 'learning_rate': 0.1853898883843987, 'num_epoch': 5000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 train loss=0.001530567 valid loss= 0.003990906\n",
      "train reg_fs: 0.001122371875680983\n",
      "Optimization Finished!\n",
      "test loss: 0.0034761144779622555, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002880830539854397\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008506778 valid loss= 0.008873461\n",
      "train reg_fs: 0.001899849739857018\n",
      "Epoch: 1000 train loss=0.005579614 valid loss= 0.006084732\n",
      "train reg_fs: 0.0016341285081580281\n",
      "Epoch: 1500 train loss=0.006288896 valid loss= 0.004739100\n",
      "train reg_fs: 0.0014965215232223272\n",
      "Epoch: 2000 train loss=0.004380761 valid loss= 0.004103956\n",
      "train reg_fs: 0.0014452014584094286\n",
      "Epoch: 2500 train loss=0.003339712 valid loss= 0.004052003\n",
      "train reg_fs: 0.0014155603712424636\n",
      "Epoch: 3000 train loss=0.003226181 valid loss= 0.003646937\n",
      "train reg_fs: 0.0013966714031994343\n",
      "Epoch: 3500 train loss=0.002230205 valid loss= 0.004094234\n",
      "train reg_fs: 0.0013835623394697905\n",
      "Epoch: 4000 train loss=0.003957944 valid loss= 0.003926939\n",
      "train reg_fs: 0.001374050392769277\n",
      "Epoch: 4500 train loss=0.006852879 valid loss= 0.003520346\n",
      "train reg_fs: 0.0013669683830812573\n",
      "Epoch: 5000 train loss=0.003541574 valid loss= 0.003394394\n",
      "train reg_fs: 0.0013615005882456899\n",
      "Epoch: 5500 train loss=0.003155984 valid loss= 0.003955835\n",
      "train reg_fs: 0.0013571063755080104\n",
      "Epoch: 6000 train loss=0.001590515 valid loss= 0.004218206\n",
      "train reg_fs: 0.001353702275082469\n",
      "Epoch: 6500 train loss=0.003651153 valid loss= 0.003225229\n",
      "train reg_fs: 0.001350764068774879\n",
      "Epoch: 7000 train loss=0.001912244 valid loss= 0.003934192\n",
      "train reg_fs: 0.0013483586953952909\n",
      "Epoch: 7500 train loss=0.001920735 valid loss= 0.004014740\n",
      "train reg_fs: 0.0013463938375934958\n",
      "Epoch: 8000 train loss=0.001712451 valid loss= 0.003661518\n",
      "train reg_fs: 0.0013448058161884546\n",
      "Epoch: 8500 train loss=0.005234069 valid loss= 0.003179742\n",
      "train reg_fs: 0.001343335839919746\n",
      "Epoch: 9000 train loss=0.001659426 valid loss= 0.003418864\n",
      "train reg_fs: 0.0013419530587270856\n",
      "Epoch: 9500 train loss=0.001760138 valid loss= 0.003640174\n",
      "train reg_fs: 0.0013408244121819735\n",
      "Epoch: 10000 train loss=0.004759239 valid loss= 0.003656554\n",
      "train reg_fs: 0.0013398678274825215\n",
      "Epoch: 10500 train loss=0.003678537 valid loss= 0.003167171\n",
      "train reg_fs: 0.001339023932814598\n",
      "Epoch: 11000 train loss=0.002448729 valid loss= 0.003577798\n",
      "train reg_fs: 0.0013382142642512918\n",
      "Epoch: 11500 train loss=0.001834904 valid loss= 0.003595747\n",
      "train reg_fs: 0.0013374924892559648\n",
      "Epoch: 12000 train loss=0.002283176 valid loss= 0.003600623\n",
      "train reg_fs: 0.0013368369545787573\n",
      "Epoch: 12500 train loss=0.004046776 valid loss= 0.003648378\n",
      "train reg_fs: 0.0013362307799980044\n",
      "Epoch: 13000 train loss=0.002199332 valid loss= 0.003589195\n",
      "train reg_fs: 0.0013356984127312899\n",
      "Epoch: 13500 train loss=0.004279009 valid loss= 0.003323526\n",
      "train reg_fs: 0.0013351908419281244\n",
      "Epoch: 14000 train loss=0.002411664 valid loss= 0.003370028\n",
      "train reg_fs: 0.0013347618514671922\n",
      "Epoch: 14500 train loss=0.002121799 valid loss= 0.003550963\n",
      "train reg_fs: 0.0013343244791030884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:13:37,396]\u001b[0m Trial 92 finished with value: 0.0023173451736468995 and parameters: {'lam': 0.002224365359393, 'learning_rate': 0.19986835017924043, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002459998 valid loss= 0.003613923\n",
      "train reg_fs: 0.0013339341385290027\n",
      "Optimization Finished!\n",
      "test loss: 0.003450653050094843, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0023173451736468995\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.007797904 valid loss= 0.011436593\n",
      "train reg_fs: 0.0012319617671892047\n",
      "Epoch: 1000 train loss=0.007730673 valid loss= 0.004439230\n",
      "train reg_fs: 0.0011635447153821588\n",
      "Epoch: 1500 train loss=0.006770708 valid loss= 0.003499368\n",
      "train reg_fs: 0.0011365690734237432\n",
      "Epoch: 2000 train loss=0.004897113 valid loss= 0.004260184\n",
      "train reg_fs: 0.0011176042025908828\n",
      "Epoch: 2500 train loss=0.004103892 valid loss= 0.005246269\n",
      "train reg_fs: 0.0010986579582095146\n",
      "Epoch: 3000 train loss=0.002123578 valid loss= 0.003705469\n",
      "train reg_fs: 0.001083791139535606\n",
      "Epoch: 3500 train loss=0.009025719 valid loss= 0.003625178\n",
      "train reg_fs: 0.0010731617221608758\n",
      "Epoch: 4000 train loss=0.003914983 valid loss= 0.003045426\n",
      "train reg_fs: 0.0010642001871019602\n",
      "Epoch: 4500 train loss=0.001872268 valid loss= 0.002878196\n",
      "train reg_fs: 0.0010574494954198599\n",
      "Epoch: 5000 train loss=0.001260135 valid loss= 0.003773238\n",
      "train reg_fs: 0.0010525189572945237\n",
      "Epoch: 5500 train loss=0.001405658 valid loss= 0.003074019\n",
      "train reg_fs: 0.0010485113598406315\n",
      "Epoch: 6000 train loss=0.001283704 valid loss= 0.003010413\n",
      "train reg_fs: 0.0010448184330016375\n",
      "Epoch: 6500 train loss=0.003488481 valid loss= 0.003802602\n",
      "train reg_fs: 0.0010417647426947951\n",
      "Epoch: 7000 train loss=0.002096210 valid loss= 0.003448322\n",
      "train reg_fs: 0.0010394473792985082\n",
      "Epoch: 7500 train loss=0.001775339 valid loss= 0.003209713\n",
      "train reg_fs: 0.0010367038194090128\n",
      "Epoch: 8000 train loss=0.003916226 valid loss= 0.002892916\n",
      "train reg_fs: 0.001034243032336235\n",
      "Epoch: 8500 train loss=0.006463643 valid loss= 0.003688369\n",
      "train reg_fs: 0.001031419145874679\n",
      "Epoch: 9000 train loss=0.001287552 valid loss= 0.002781174\n",
      "train reg_fs: 0.0010293195955455303\n",
      "Epoch: 9500 train loss=0.003930878 valid loss= 0.003196282\n",
      "train reg_fs: 0.0010275206295773387\n",
      "Epoch: 10000 train loss=0.002038830 valid loss= 0.003013969\n",
      "train reg_fs: 0.0010252477368339896\n",
      "Epoch: 10500 train loss=0.005857408 valid loss= 0.002708284\n",
      "train reg_fs: 0.0010237430687993765\n",
      "Epoch: 11000 train loss=0.001691999 valid loss= 0.002701726\n",
      "train reg_fs: 0.001022943644784391\n",
      "Epoch: 11500 train loss=0.003951163 valid loss= 0.003260359\n",
      "train reg_fs: 0.0010211403714492917\n",
      "Epoch: 12000 train loss=0.002202993 valid loss= 0.003286749\n",
      "train reg_fs: 0.0010201933328062296\n",
      "Epoch: 12500 train loss=0.002726196 valid loss= 0.004568991\n",
      "train reg_fs: 0.001019130228087306\n",
      "Epoch: 13000 train loss=0.001447807 valid loss= 0.003369777\n",
      "train reg_fs: 0.0010183308040723205\n",
      "Epoch: 13500 train loss=0.001918490 valid loss= 0.003468266\n",
      "train reg_fs: 0.0010176952928304672\n",
      "Epoch: 14000 train loss=0.001665873 valid loss= 0.003849538\n",
      "train reg_fs: 0.0010162943508476019\n",
      "Epoch: 14500 train loss=0.001266106 valid loss= 0.003077716\n",
      "train reg_fs: 0.0010151395108550787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:15:10,818]\u001b[0m Trial 93 finished with value: 0.0027209901789833095 and parameters: {'lam': 0.0014459194486549848, 'learning_rate': 0.15746628340953922, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002602377 valid loss= 0.003689552\n",
      "train reg_fs: 0.0010131907183676958\n",
      "Optimization Finished!\n",
      "test loss: 0.003583081066608429, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0027209901789833095\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.011255580 valid loss= 0.007978393\n",
      "train reg_fs: 0.0015215434832498431\n",
      "Epoch: 1000 train loss=0.012169044 valid loss= 0.009169942\n",
      "train reg_fs: 0.0015518910950049758\n",
      "Epoch: 1500 train loss=0.007609625 valid loss= 0.008072651\n",
      "train reg_fs: 0.0015671480214223266\n",
      "Epoch: 2000 train loss=0.007728071 valid loss= 0.008047239\n",
      "train reg_fs: 0.0015707759885117412\n",
      "Epoch: 2500 train loss=0.005724469 valid loss= 0.007843569\n",
      "train reg_fs: 0.0015631435671821237\n",
      "Epoch: 3000 train loss=0.008411277 valid loss= 0.006981863\n",
      "train reg_fs: 0.0015459726564586163\n",
      "Epoch: 3500 train loss=0.012878777 valid loss= 0.006448791\n",
      "train reg_fs: 0.0015255786711350083\n",
      "Epoch: 4000 train loss=0.004019546 valid loss= 0.005464343\n",
      "train reg_fs: 0.0015012500807642937\n",
      "Epoch: 4500 train loss=0.005938690 valid loss= 0.004405907\n",
      "train reg_fs: 0.001476921490393579\n",
      "Epoch: 5000 train loss=0.007141229 valid loss= 0.004116094\n",
      "train reg_fs: 0.0014546802267432213\n",
      "Epoch: 5500 train loss=0.007939986 valid loss= 0.003468416\n",
      "train reg_fs: 0.0014361543580889702\n",
      "Epoch: 6000 train loss=0.003132496 valid loss= 0.004104117\n",
      "train reg_fs: 0.001421511871740222\n",
      "Epoch: 6500 train loss=0.004210918 valid loss= 0.004124040\n",
      "train reg_fs: 0.0014097550883889198\n",
      "Epoch: 7000 train loss=0.002600249 valid loss= 0.004498811\n",
      "train reg_fs: 0.0014001386007294059\n",
      "Epoch: 7500 train loss=0.005204358 valid loss= 0.003993117\n",
      "train reg_fs: 0.0013912369031459093\n",
      "Epoch: 8000 train loss=0.004063704 valid loss= 0.004385479\n",
      "train reg_fs: 0.0013825056375935674\n",
      "Epoch: 8500 train loss=0.001887347 valid loss= 0.004027959\n",
      "train reg_fs: 0.0013738768175244331\n",
      "Epoch: 9000 train loss=0.002716302 valid loss= 0.004150877\n",
      "train reg_fs: 0.0013655893271788955\n",
      "Epoch: 9500 train loss=0.004666314 valid loss= 0.004072421\n",
      "train reg_fs: 0.0013568588765338063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:16:14,197]\u001b[0m Trial 94 finished with value: 0.002911288072720518 and parameters: {'lam': 0.0017597055470728446, 'learning_rate': 0.04957200552531153, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005597705 valid loss= 0.004241979\n",
      "train reg_fs: 0.0013488553231582046\n",
      "Optimization Finished!\n",
      "test loss: 0.004157211631536484, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002911288072720518\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.014059922 valid loss= 0.008200386\n",
      "train reg_fs: 0.0022417749278247356\n",
      "Epoch: 1000 train loss=0.015080958 valid loss= 0.008502058\n",
      "train reg_fs: 0.0022687811870127916\n",
      "Epoch: 1500 train loss=0.020130476 valid loss= 0.006843813\n",
      "train reg_fs: 0.0022710401099175215\n",
      "Epoch: 2000 train loss=0.016407372 valid loss= 0.006132333\n",
      "train reg_fs: 0.0022510907147079706\n",
      "Epoch: 2500 train loss=0.007063795 valid loss= 0.005687532\n",
      "train reg_fs: 0.002213421044871211\n",
      "Epoch: 3000 train loss=0.006683642 valid loss= 0.004585717\n",
      "train reg_fs: 0.0021713089663535357\n",
      "Epoch: 3500 train loss=0.007803741 valid loss= 0.004518498\n",
      "train reg_fs: 0.0021323850378394127\n",
      "Epoch: 4000 train loss=0.007918828 valid loss= 0.004186030\n",
      "train reg_fs: 0.0021005296148359776\n",
      "Epoch: 4500 train loss=0.009259945 valid loss= 0.004449546\n",
      "train reg_fs: 0.002077746205031872\n",
      "Epoch: 5000 train loss=0.006705497 valid loss= 0.003987527\n",
      "train reg_fs: 0.002059555146843195\n",
      "Epoch: 5500 train loss=0.004221354 valid loss= 0.003907865\n",
      "train reg_fs: 0.002044780645519495\n",
      "Epoch: 6000 train loss=0.006196338 valid loss= 0.003806673\n",
      "train reg_fs: 0.00203094445168972\n",
      "Epoch: 6500 train loss=0.016309489 valid loss= 0.004054296\n",
      "train reg_fs: 0.0020173927769064903\n",
      "Epoch: 7000 train loss=0.003250757 valid loss= 0.004375802\n",
      "train reg_fs: 0.0020058294758200645\n",
      "Epoch: 7500 train loss=0.007224062 valid loss= 0.004157536\n",
      "train reg_fs: 0.001996669452637434\n",
      "Epoch: 8000 train loss=0.005836253 valid loss= 0.004628811\n",
      "train reg_fs: 0.001987190917134285\n",
      "Epoch: 8500 train loss=0.006526358 valid loss= 0.004005202\n",
      "train reg_fs: 0.00197877106256783\n",
      "Epoch: 9000 train loss=0.003204005 valid loss= 0.004092972\n",
      "train reg_fs: 0.001970863901078701\n",
      "Epoch: 9500 train loss=0.003479437 valid loss= 0.004517863\n",
      "train reg_fs: 0.0019640009850263596\n",
      "Epoch: 10000 train loss=0.011127563 valid loss= 0.004331922\n",
      "train reg_fs: 0.001958136912435293\n",
      "Epoch: 10500 train loss=0.002877920 valid loss= 0.003994044\n",
      "train reg_fs: 0.0019530850695446134\n",
      "Epoch: 11000 train loss=0.006117836 valid loss= 0.004618979\n",
      "train reg_fs: 0.0019483271753415465\n",
      "Epoch: 11500 train loss=0.009677213 valid loss= 0.004046475\n",
      "train reg_fs: 0.0019440334290266037\n",
      "Epoch: 12000 train loss=0.002671800 valid loss= 0.003715977\n",
      "train reg_fs: 0.00193988683167845\n",
      "Epoch: 12500 train loss=0.005930697 valid loss= 0.004157645\n",
      "train reg_fs: 0.0019358160207048059\n",
      "Epoch: 13000 train loss=0.002124423 valid loss= 0.004421018\n",
      "train reg_fs: 0.0019317778060212731\n",
      "Epoch: 13500 train loss=0.003676299 valid loss= 0.004308598\n",
      "train reg_fs: 0.0019277374958619475\n",
      "Epoch: 14000 train loss=0.003942178 valid loss= 0.004345578\n",
      "train reg_fs: 0.0019237496890127659\n",
      "Epoch: 14500 train loss=0.003393919 valid loss= 0.003704802\n",
      "train reg_fs: 0.0019202729454264045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:17:47,897]\u001b[0m Trial 95 finished with value: 0.0022612345421931025 and parameters: {'lam': 0.002608649997457742, 'learning_rate': 0.04078809199552035, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002370385 valid loss= 0.004128395\n",
      "train reg_fs: 0.0019167648861184716\n",
      "Optimization Finished!\n",
      "test loss: 0.004084211308509111, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0022612345421931025\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.021276999 valid loss= 0.008440186\n",
      "train reg_fs: 0.002823822433128953\n",
      "Epoch: 1000 train loss=0.009637309 valid loss= 0.006960043\n",
      "train reg_fs: 0.0026055702473968267\n",
      "Epoch: 1500 train loss=0.010021872 valid loss= 0.005990455\n",
      "train reg_fs: 0.0023729519452899694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:18:01,746]\u001b[0m Trial 96 finished with value: 0.0025641926322165125 and parameters: {'lam': 0.003223151680851331, 'learning_rate': 0.14200288363949057, 'num_epoch': 2000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 train loss=0.005308143 valid loss= 0.004837760\n",
      "train reg_fs: 0.002248982433229685\n",
      "Optimization Finished!\n",
      "test loss: 0.004567737691104412, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0025641926322165125\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009488992 valid loss= 0.008415399\n",
      "train reg_fs: 0.0017420474905520678\n",
      "Epoch: 1000 train loss=0.011070977 valid loss= 0.007890284\n",
      "train reg_fs: 0.0017525410512462258\n",
      "Epoch: 1500 train loss=0.008799305 valid loss= 0.007575824\n",
      "train reg_fs: 0.001744312234222889\n",
      "Epoch: 2000 train loss=0.005441072 valid loss= 0.006498886\n",
      "train reg_fs: 0.0017263960326090455\n",
      "Epoch: 2500 train loss=0.005417495 valid loss= 0.005997949\n",
      "train reg_fs: 0.0017066937871277332\n",
      "Epoch: 3000 train loss=0.012768278 valid loss= 0.005167870\n",
      "train reg_fs: 0.001685958239249885\n",
      "Epoch: 3500 train loss=0.003769410 valid loss= 0.004622933\n",
      "train reg_fs: 0.0016630681930109859\n",
      "Epoch: 4000 train loss=0.004968820 valid loss= 0.004967361\n",
      "train reg_fs: 0.001640591653995216\n",
      "Epoch: 4500 train loss=0.006596399 valid loss= 0.004089247\n",
      "train reg_fs: 0.0016148335998877883\n",
      "Epoch: 5000 train loss=0.004679109 valid loss= 0.004097240\n",
      "train reg_fs: 0.0015938919968903065\n",
      "Epoch: 5500 train loss=0.005221135 valid loss= 0.004363503\n",
      "train reg_fs: 0.0015757540240883827\n",
      "Epoch: 6000 train loss=0.003070349 valid loss= 0.004689127\n",
      "train reg_fs: 0.0015591031406074762\n",
      "Epoch: 6500 train loss=0.003281699 valid loss= 0.004498420\n",
      "train reg_fs: 0.0015453137457370758\n",
      "Epoch: 7000 train loss=0.003361243 valid loss= 0.004423335\n",
      "train reg_fs: 0.001531435875222087\n",
      "Epoch: 7500 train loss=0.004935384 valid loss= 0.004081607\n",
      "train reg_fs: 0.001517094555310905\n",
      "Epoch: 8000 train loss=0.003770950 valid loss= 0.004561985\n",
      "train reg_fs: 0.0015045662876218557\n",
      "Epoch: 8500 train loss=0.002003682 valid loss= 0.004814512\n",
      "train reg_fs: 0.0014924636343494058\n",
      "Epoch: 9000 train loss=0.005500548 valid loss= 0.004016261\n",
      "train reg_fs: 0.0014815405011177063\n",
      "Epoch: 9500 train loss=0.004475964 valid loss= 0.003969911\n",
      "train reg_fs: 0.001469906186684966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:19:05,063]\u001b[0m Trial 97 finished with value: 0.0030851982298768965 and parameters: {'lam': 0.0020439583784631096, 'learning_rate': 0.03356859117768529, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.002980193 valid loss= 0.004532730\n",
      "train reg_fs: 0.0014589244965463877\n",
      "Optimization Finished!\n",
      "test loss: 0.004157662857323885, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.0030851982298768965\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.009234101 valid loss= 0.012973038\n",
      "train reg_fs: 0.002984433202072978\n",
      "Epoch: 1000 train loss=0.007428818 valid loss= 0.005672896\n",
      "train reg_fs: 0.002713469322770834\n",
      "Epoch: 1500 train loss=0.011041992 valid loss= 0.008292492\n",
      "train reg_fs: 0.0026062752585858107\n",
      "Epoch: 2000 train loss=0.008502425 valid loss= 0.006587085\n",
      "train reg_fs: 0.0024807879235595465\n",
      "Epoch: 2500 train loss=0.006087477 valid loss= 0.008360018\n",
      "train reg_fs: 0.002343744970858097\n",
      "Epoch: 3000 train loss=0.004330563 valid loss= 0.004745309\n",
      "train reg_fs: 0.0022572758607566357\n",
      "Epoch: 3500 train loss=0.002880387 valid loss= 0.004669245\n",
      "train reg_fs: 0.002206194680184126\n",
      "Epoch: 4000 train loss=0.016631937 valid loss= 0.004648977\n",
      "train reg_fs: 0.002175426809117198\n",
      "Epoch: 4500 train loss=0.008881714 valid loss= 0.004840710\n",
      "train reg_fs: 0.0021523605100810528\n",
      "Epoch: 5000 train loss=0.003069190 valid loss= 0.004560494\n",
      "train reg_fs: 0.0021371603943407536\n",
      "Epoch: 5500 train loss=0.004456155 valid loss= 0.004991072\n",
      "train reg_fs: 0.002125395927578211\n",
      "Epoch: 6000 train loss=0.003065068 valid loss= 0.003943597\n",
      "train reg_fs: 0.002116554416716099\n",
      "Epoch: 6500 train loss=0.004065124 valid loss= 0.006759317\n",
      "train reg_fs: 0.0021094486583024263\n",
      "Epoch: 7000 train loss=0.006926588 valid loss= 0.004347517\n",
      "train reg_fs: 0.002103896578773856\n",
      "Epoch: 7500 train loss=0.003786209 valid loss= 0.004251200\n",
      "train reg_fs: 0.002099077682942152\n",
      "Epoch: 8000 train loss=0.004068501 valid loss= 0.003778312\n",
      "train reg_fs: 0.0020952392369508743\n",
      "Epoch: 8500 train loss=0.003819145 valid loss= 0.004057986\n",
      "train reg_fs: 0.002092152601107955\n",
      "Epoch: 9000 train loss=0.003081309 valid loss= 0.004035130\n",
      "train reg_fs: 0.002089336747303605\n",
      "Epoch: 9500 train loss=0.004000005 valid loss= 0.004481461\n",
      "train reg_fs: 0.0020869330037385225\n",
      "Epoch: 10000 train loss=0.002337931 valid loss= 0.003845664\n",
      "train reg_fs: 0.0020849276334047318\n",
      "Epoch: 10500 train loss=0.005959206 valid loss= 0.004728719\n",
      "train reg_fs: 0.002083118073642254\n",
      "Epoch: 11000 train loss=0.004232329 valid loss= 0.004431828\n",
      "train reg_fs: 0.0020814675372093916\n",
      "Epoch: 11500 train loss=0.003455762 valid loss= 0.004334220\n",
      "train reg_fs: 0.0020801450591534376\n",
      "Epoch: 12000 train loss=0.006895200 valid loss= 0.004153983\n",
      "train reg_fs: 0.002078807447105646\n",
      "Epoch: 12500 train loss=0.004274845 valid loss= 0.004314066\n",
      "train reg_fs: 0.002077625133097172\n",
      "Epoch: 13000 train loss=0.003677705 valid loss= 0.004178880\n",
      "train reg_fs: 0.0020766009110957384\n",
      "Epoch: 13500 train loss=0.004998727 valid loss= 0.003886137\n",
      "train reg_fs: 0.002075622556731105\n",
      "Epoch: 14000 train loss=0.010647297 valid loss= 0.004309230\n",
      "train reg_fs: 0.002074731979519129\n",
      "Epoch: 14500 train loss=0.005310199 valid loss= 0.004608958\n",
      "train reg_fs: 0.0020739317405968904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:20:40,731]\u001b[0m Trial 98 finished with value: 0.002130529359348813 and parameters: {'lam': 0.003453798975458993, 'learning_rate': 0.17690255206703084, 'num_epoch': 15000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 train loss=0.002900390 valid loss= 0.004145938\n",
      "train reg_fs: 0.002073173876851797\n",
      "Optimization Finished!\n",
      "test loss: 0.004032257944345474, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.002130529359348813\n",
      "num_samples : 10\n",
      "Epoch: 500 train loss=0.008871822 valid loss= 0.008747883\n",
      "train reg_fs: 0.0026135423686355352\n",
      "Epoch: 1000 train loss=0.010953718 valid loss= 0.007898545\n",
      "train reg_fs: 0.00263993046246469\n",
      "Epoch: 1500 train loss=0.022759663 valid loss= 0.005893365\n",
      "train reg_fs: 0.0026474210899323225\n",
      "Epoch: 2000 train loss=0.007236104 valid loss= 0.006171024\n",
      "train reg_fs: 0.0026458476204425097\n",
      "Epoch: 2500 train loss=0.006261945 valid loss= 0.006517915\n",
      "train reg_fs: 0.0026341290213167667\n",
      "Epoch: 3000 train loss=0.011132867 valid loss= 0.005942019\n",
      "train reg_fs: 0.002620021579787135\n",
      "Epoch: 3500 train loss=0.008858128 valid loss= 0.005629649\n",
      "train reg_fs: 0.002604320179671049\n",
      "Epoch: 4000 train loss=0.011011438 valid loss= 0.005034741\n",
      "train reg_fs: 0.002575451973825693\n",
      "Epoch: 4500 train loss=0.005852136 valid loss= 0.005637916\n",
      "train reg_fs: 0.002549197990447283\n",
      "Epoch: 5000 train loss=0.004397992 valid loss= 0.005667805\n",
      "train reg_fs: 0.0025237516965717077\n",
      "Epoch: 5500 train loss=0.007760826 valid loss= 0.005630513\n",
      "train reg_fs: 0.002497961511835456\n",
      "Epoch: 6000 train loss=0.006604603 valid loss= 0.005848260\n",
      "train reg_fs: 0.002474581589922309\n",
      "Epoch: 6500 train loss=0.004611870 valid loss= 0.006169559\n",
      "train reg_fs: 0.0024517702404409647\n",
      "Epoch: 7000 train loss=0.006721441 valid loss= 0.005826935\n",
      "train reg_fs: 0.0024318366777151823\n",
      "Epoch: 7500 train loss=0.007377175 valid loss= 0.005908006\n",
      "train reg_fs: 0.0024104539770632982\n",
      "Epoch: 8000 train loss=0.005667841 valid loss= 0.006227829\n",
      "train reg_fs: 0.0023888610303401947\n",
      "Epoch: 8500 train loss=0.004539500 valid loss= 0.006307486\n",
      "train reg_fs: 0.002369471127167344\n",
      "Epoch: 9000 train loss=0.004965080 valid loss= 0.006591493\n",
      "train reg_fs: 0.0023500854149460793\n",
      "Epoch: 9500 train loss=0.004300100 valid loss= 0.006951821\n",
      "train reg_fs: 0.0023327628150582314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 23:21:43,701]\u001b[0m Trial 99 finished with value: 0.004502912776663161 and parameters: {'lam': 0.0029781479803679175, 'learning_rate': 0.06834172421687182, 'num_epoch': 10000}. Best is trial 40 with value: 0.0002758848348645575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 train loss=0.005784603 valid loss= 0.006862444\n",
      "train reg_fs: 0.0023113726638257504\n",
      "Optimization Finished!\n",
      "test loss: 0.007284075021743774, test acc: 1.0\n",
      "In trial:---------------------\n",
      "validation mse: 0.004502912776663161\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "model = None\n",
    "study = optuna.create_study(pruner=None)\n",
    "study.optimize(llspin_objective, n_trials=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_mat_train = best_model.get_prob_alpha(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = study.best_params['learning_rate']\n",
    "best_epoch = study.best_params['num_epoch']\n",
    "best_lam = study.best_params['lam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Finished*************\n",
      "Best model's lambda: 0.0040673743054347265\n",
      "Best model's learning rate: 0.1681500997512317\n",
      "Best model's num of epochs: 15000\n",
      "Test mse : 0.00030549069087572415\n",
      "Test r2 : 0.9926284198170583\n"
     ]
    }
   ],
   "source": [
    "y_pred_llspin = best_model.test(X_test)[0]\n",
    "            \n",
    "print(\"Trial Finished*************\")\n",
    "print(\"Best model's lambda: {}\".format(best_lam))\n",
    "print(\"Best model's learning rate: {}\".format(best_lr))\n",
    "print(\"Best model's num of epochs: {}\".format(best_epoch))\n",
    "print(\"Test mse : {}\".format(mean_squared_error(y_test.reshape(-1),y_pred_llspin.reshape(-1))))\n",
    "print(\"Test r2 : {}\".format(r2_score(y_test.reshape(-1),y_pred_llspin.reshape(-1),multioutput='raw_values')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the training gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm,colors\n",
    "\n",
    "cmap = cm.Blues\n",
    "bounds=[0,0.5,1]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "title_size = 30\n",
    "xtick_size = 20\n",
    "ytick_size = 20\n",
    "xlabel_size = 35\n",
    "ylabel_size = 35\n",
    "colorbar_tick_size = 20\n",
    "title_pad = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "sorted_order = np.concatenate((np.where(train_label == 1)[0],np.where(train_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_train[sorted_order,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([1,3,5,7,9])\n",
    "axes[0].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "im2 = axes[1].imshow(gate_mat_train[sorted_order,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([1,3,5,7,9])\n",
    "axes[1].set_yticklabels([2,4,6,8,10],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "\n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the test gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_mat_test = best_model.get_prob_alpha(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2,sharex=False, sharey=True,figsize=(8, 6))\n",
    "\n",
    "fig.subplots_adjust(bottom=0.01)\n",
    "\n",
    "sorted_order_test = np.concatenate((np.where(test_label == 1)[0],np.where(test_label == 2)[0]))\n",
    "\n",
    "im1 = axes[0].imshow(ref_feat_mat_test[sorted_order_test,:].astype(int),aspect='auto',cmap=cmap, norm=norm)\n",
    "axes[0].set_title(\"Ground Truth\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[0].set_ylabel(\"Sample Index\",fontsize=ylabel_size)\n",
    "axes[0].set_yticks([0,9,19,29,39,49])\n",
    "axes[0].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[0].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "cbar = fig.colorbar(im1,ax=axes[0], cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "    \n",
    "im2 = axes[1].imshow(gate_mat_test[sorted_order_test,:],aspect='auto',cmap=cmap)\n",
    "axes[1].set_title(\"LLSPIN Gates\",fontsize=title_size,fontweight=\"bold\",pad=title_pad)\n",
    "axes[1].set_yticks([0,9,19,29,39,49])\n",
    "axes[1].set_yticklabels([1,10,20,30,40,50],fontsize=ytick_size)\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].set_xticklabels(list(range(1,6)),fontsize=xtick_size)\n",
    "axes[1].set_xlabel(\"Feature Index\",fontsize=xlabel_size,labelpad=-5)\n",
    "    \n",
    "cbar = fig.colorbar(im2,ax=axes[1])\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_size)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
